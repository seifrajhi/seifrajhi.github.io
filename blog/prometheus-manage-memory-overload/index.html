<!DOCTYPE html><html lang="en" class="blogpost-view-page"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, shrink-to-fit=no"/><meta data-react-helmet="true" name="description" property="og:description" content="Explore strategies to manage memory overload in Prometheus, ensuring stability and performance even when dealing with large Write-Ahead Logs (WAL)."/><meta data-react-helmet="true" name="keywords" content="Prometheus,memory overload,WAL,monitoring,kubernetes"/><meta data-react-helmet="true" name="author" content="@RajhiSaifeddine"/><meta data-react-helmet="true" property="og:title" content="Prometheus Restart Troubles: Managing Memory Overload üß† - Blog"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:creator" content="@RajhiSaifeddine"/><meta data-react-helmet="true" name="twitter:title" content="Prometheus Restart Troubles: Managing Memory Overload üß† - Blog"/><meta data-react-helmet="true" name="twitter:description" content="Explore strategies to manage memory overload in Prometheus, ensuring stability and performance even when dealing with large Write-Ahead Logs (WAL)."/><meta data-react-helmet="true" name="image" property="og:image" content="https://seifrajhi.github.io/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png"/><meta data-react-helmet="true" name="twitter:image" content="https://seifrajhi.github.io/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png"/><meta data-react-helmet="true" property="og:url" content="https://seifrajhi.github.io/blog/prometheus-manage-memory-overload/"/><meta name="theme-color" content="#ffffff"/><link rel="stylesheet" href="/styles.19780313cdbeec1e4ef5.css"/><link rel="stylesheet"/><link rel="alternate" type="application/rss+xml" title="Saifeddine Rajhi&#x27;s Blog RSS Feed" href="/rss.xml"/><title data-react-helmet="true">Prometheus Restart Troubles: Managing Memory Overload üß† - Blog by Saifeddine Rajhi</title><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","image":"/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png","headline":"Prometheus Restart Troubles: Managing Memory Overload üß†","dateCreated":"2024-10-29","datePublished":"2024-10-29","dateModified":"2024-10-29","inLanguage":"en-US","isFamilyFriendly":true,"isAccessibleForFree":true,"author":{"@type":"Person","name":"Saifeddine Rajhi","url":"https://seifrajhi.github.io"},"publisher":{"@type":"Organization","name":"Saifeddine Rajhi's Website"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://seifrajhi.github.io/blog/prometheus-manage-memory-overload/"},"keywords":["Prometheus","memory overload","WAL","monitoring","kubernetes"],"genre":["Platform engineer","software engineering","science","deep learning","statistics"],"articleSection":"Technical Blog","articleBody":"\n> **When Prometheus Can't Keep Up with the WAL üìà**\n\n## üìó Introduction\n\nHave you ever had Prometheus crash due to an out-of-memory error while trying to catch up by reading the Write-Ahead Log (WAL)? It's a frustrating problem, but let's check it out.\n\nPrometheus is great for monitoring, but when it restarts, it needs to process data from the Write-Ahead Log (WAL), which can be memory-intensive. This often leads to OOMKilled crashes, especially if Prometheus is already running close to its memory limits.\n\nThe issue usually stems from either collecting too much data or running too close to memory limits. This has been a long-standing concern, with [reports dating back to an open issue since 2020 on GitHub](https://github.com/prometheus/prometheus/issues/6934), highlighting the significant challenges faced by users in managing Prometheus' memory during WAL replay.\n\n### ‚ÅâÔ∏è The Problem\n\n<br>\n\nhttps://giphy.com/gifs/strangerthings-netflix-stranger-things-ka55CqnDNjQ7iIKtRa\n\nWhile upgrading [the Helm chart of kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack), we noticed several pods were not ready, including `prometheus-prometheus-operator-prometheus-0`, which showed a status of `3/4 Running` with a recent termination due to being OOMKilled.\n\nThe logs revealed the root cause:\n\n```shell\nts=2024‚Äì06‚Äì14T09:49:10.383Z caller=head.go:840 level=info component=tsdb msg=\"Deletion of corrupted mmap chunk files failed, discarding chunk files completely\" err=\"cannot handle error: iterate on on-disk chunks: out of sequence m-mapped chunk for series ref 946594555, last chunk: [1718071739971, 1718075459971], new: [1718049629971, 1718053199971]\"\n```\n\nIt seems like it's stuck in the running state, where the pod is not yet ready. Let's describe the pod to see what is wrong:\n\n```shell\nState:       Running\n    Started:   Tue, 14 Jun 2024 10:04:03 +0200\nLast State:  Terminated\n    Reason:    OOMKilled\n```\n\nAh, there it is. Prometheus is indeed running, but it got terminated due to an OOMKill‚Ää‚Äî‚Äärunning out of memory. It seems Prometheus is in the midst of recovering from the Write Ahead Log (WAL), which might be causing the memory spike. This could stem from an error during recovery or a restart, where Prometheus doesn't have enough memory to write everything into the WAL.\n\n![cardinality](./cardinality.png)\n\nOne potential solution could be allocating more memory to Prometheus and analyzing why the WAL is getting clogged up. Essentially, we need to investigate what changed to suddenly cause this spike in memory usage in our once serene environment.\n\nThe issue persisted due to the WAL replay process requiring 2‚Äì3 times more memory than the running Prometheus instance. Despite running smoothly with around 30Gi of memory usage, the WAL replay process demanded over 50+Gi, ultimately leading to OOMKilled crashes during startup. Simply increasing the RAM limit wasn't a viable solution, as the excessive memory usage occurred specifically during the replay phase.\n\nThis problem aligns with a longstanding issue on GitHub since 2020, where users have consistently reported challenges managing Prometheus' memory during WAL replay. We encountered similar difficulties during our upgrade process, highlighting the critical need for resolution.\n\n### üí° Understanding Memory Overheads in WAL Replay\n\nIn the past, WAL replay often caused significant overhead, leading to unexpected out-of-memory (OOM) situations. For instance, if your Prometheus was already running at 70% of its memory limit and the overhead during replay surged by 300%, it could easily lead to crashes. Additionally, increased CPU usage during replay, especially in low CPU environments like Kubernetes, could slow down processes like garbage collection, resulting in slower memory release.\n\nHowever, recent benchmarks of Prometheus versions at Google show a different picture. While there's been a noticeable 2x increase in CPU usage during replay, the memory overhead, including heap and working sets, is only around 1‚Äì5%. This raises the question: are the reported OOM issues symptoms of a larger problem, with the replay OOM merely surfacing it?\n\nCurrently, two prevalent scenarios appear:\n1. **Excessive Data Collection**: If your Prometheus setup scrapes too many series or samples, it's prone to OOM crashes during replay, regardless of the memory overhead.\n2. **Running Close to Memory Limits**: Even a slight overhead during replay can trigger OOM crashes if Prometheus is already running near its memory limit, such as at 95%.\n\nThese issues often revolve around cardinality‚Ää‚Äî‚Ääthe combination of all label values per metric. High cardinality metrics, like those tracking multiple URLs or response codes, can quickly escalate memory usage. In short, much of Prometheus' memory woes can be attributed to cardinality.\n\n### üîÑ How Does Remote Write Work?\n\nThe remote write reads data from Prometheus' [write ahead log](https://en.wikipedia.org/wiki/Write-ahead_logging).\n\n![wal](./wal.png)\n\nData generated by scrape is written to the WAL, so this essentially gives us a 2- to 3-hour buffer on disk of data for remote write. The RW system now has a subroutine that reads the WAL and passes the data back to remote write.\n\nRemote write still has a small in-memory buffer, and the routine reading the WAL pauses where it is if it's not able to append new data to the buffer. This means we no longer drop data if the buffer is full, and the buffer doesn't need to be large enough to handle a longer outage.\n\nAs long as the remote endpoint isn't down for hours, remote write no longer loses data (with some caveats, like Prometheus restarts), since the WAL is truncated every two hours or so.\n\n### üõ†Ô∏è Issue Resolutions\n\nIf you've never experienced this issue before (lucky you!), here's a handy solution I found effective. Since Prometheus may not be up and running to utilize PromQL for detecting potential issues, we need an alternative method to identify high cardinality. One approach is to get hands-on with some kubectl exec magic:\n\n```sh\nkubectl exec -it -n monitoring pods/prometheus-prometheus-kube-prometheus-prometheus-0 -- sh\n```\n\nThen, run the Prometheus TSDB analysis:\n\n```sh\n/prometheus $ promtool tsdb analyze .\n```\n\nThis analysis will provide insights into metrics with high cardinality, like `haproxy_server_http_responses_total`, which might be causing memory issues. In such cases, updating or optimizing the problematic metric, such as haproxy, can alleviate memory strain.\n\nAlternatively, consider increasing Prometheus' memory allocation or deploying it to a specific node group with ample memory resources.\n\nHere are some additional strategies to mitigate memory overhead and OOM crashes:\n\n- **Verify Memory Overhead**: Ensure that the memory overhead during replay is within acceptable limits (e.g., 10‚Äì15%). Running Prometheus close to its memory limit is risky due to dynamic garbage collection and limited room for unexpected cardinality spikes or queries.\n- **Optimize Storage and Scraping**: Regularly optimize Prometheus' storage, scraping, and remote write configurations to reduce memory usage. Upgrading to newer releases can often provide optimizations in this regard.\n- **Automate Recovery from OOM**: Implement auto-recovery mechanisms to handle OOM crash loops, such as automatically deleting the Write-Ahead Log (WAL) on OOM events. This ensures smoother recovery from memory-related issues.\n- **Implement Scraping Limits**: Consider introducing forceful scrape limits to prevent Prometheus from scraping targets when memory usage exceeds a certain threshold. This proactive approach can help avoid memory-intensive situations and potential OOM crashes.\n\nBy implementing these strategies, you can effectively manage Prometheus' memory challenges and ensure smooth operation in your monitoring environment.\n\n### üîö Conclusion\n\nDealing with Prometheus OOM errors during WAL replay can be challenging. By understanding the root causes, such as excessive data collection and high cardinality metrics, and implementing solutions like optimizing storage and scraping configurations, increasing memory allocations, and setting up auto-recovery mechanisms, you can mitigate these issues.\n\n**Thank You üñ§**\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordcount":1173}</script><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://seifrajhi.github.io/"},{"@type":"ListItem","position":2,"name":"Blog","item":"https://seifrajhi.github.io/blog/"},{"@type":"ListItem","position":3,"name":"Prometheus Restart Troubles: Managing Memory Overload üß†","item":"https://seifrajhi.github.io/blog/prometheus-manage-memory-overload/"}]}</script><link crossorigin="" href="https://utteranc.es" rel="preconnect"/><link crossorigin="" href="https://www.google-analytics.com" rel="preconnect"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="icon" href="/favicon-32x32.png?v=47ae28bb567c9025f1fee24afb2d20c9" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=47ae28bb567c9025f1fee24afb2d20c9"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v25/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/dancingscript/v25/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup8.woff2"/><link rel="preload" as="font" type="font/woff2" crossorigin="anonymous" href="/static/webfonts/s/ledger/v16/j8_q6-HK1L3if_sBnMrx.woff2"/><style>@font-face{font-display:swap;font-family:Dancing Script;font-style:normal;font-weight:400;src:url(/static/webfonts/s/dancingscript/v25/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup8.woff2) format("woff2")}@font-face{font-display:swap;font-family:Dancing Script;font-style:normal;font-weight:700;src:url(/static/webfonts/s/dancingscript/v25/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup8.woff2) format("woff2")}@font-face{font-display:swap;font-family:Dancing Script;font-style:normal;font-weight:400;src:url(/static/webfonts/s/dancingscript/v25/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7BMSo3Sup6.woff) format("woff")}@font-face{font-display:swap;font-family:Dancing Script;font-style:normal;font-weight:700;src:url(/static/webfonts/s/dancingscript/v25/If2cXTr6YS-zF4S-kcSWSVi_sxjsohD9F50Ruu7B1i03Sup6.woff) format("woff")}@font-face{font-display:swap;font-family:Ledger;font-style:normal;font-weight:400;src:url(/static/webfonts/s/ledger/v16/j8_q6-HK1L3if_sBnMrx.woff2) format("woff2")}@font-face{font-display:swap;font-family:Ledger;font-style:normal;font-weight:400;src:url(/static/webfonts/s/ledger/v16/j8_q6-HK1L3if_sBnMr3.woff) format("woff")}</style><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><script>
  
  function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='G-LLPCCGNLH7',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'G-LLPCCGNLH7', 'auto', {"alwaysSendReferrer":true});
      ga('set', 'anonymizeIp', true);
      
      
      
      
      }</script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LLPCCGNLH7"></script><script>
      
      function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='G-LLPCCGNLH7',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-LLPCCGNLH7', {"anonymize_ip":true,"send_page_view":false});gtag('config', 'GTM-5V895PDS', {"anonymize_ip":true,"send_page_view":false});
      }
      </script><link rel="stylesheet"/><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="canonical" href="https://seifrajhi.github.io/blog/prometheus-manage-memory-overload/" data-baseprotocol="https:" data-basehost="seifrajhi.github.io"/><link rel="sitemap" type="application/xml" href="/sitemap-index.xml"/></head><body><script>
void function() {
  window.__onThemeChange = function() {}

  var preferredTheme
  try {
    preferredTheme = localStorage.getItem('theme')
  } catch (err) { }

  function setTheme(newTheme) {
    if (preferredTheme && document.body.classList.contains(preferredTheme)) {
      document.body.classList.replace(preferredTheme, newTheme)
    } else {
      document.body.classList.add(newTheme)
    }

    window.__theme = newTheme
    preferredTheme = newTheme
    window.__onThemeChange(newTheme)
  }

  window.__setPreferredTheme = function(newTheme) {
    setTheme(newTheme)
    try {
      localStorage.setItem('theme', newTheme)
    } catch (err) {}
  }

  var darkQuery = window.matchMedia('(prefers-color-scheme: dark)')
  darkQuery.addListener(function(e) {
    window.__setPreferredTheme(e.matches ? 'dark' : 'light')
  })

  setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'))
}()
    </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><div class="blogpost-header"><div class="view-page-header"><div class="view-page-header-wrapper"><div class="logo-wrapper"><div class="logo"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained logo-img"><div style="max-width:150px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg%20height=&#x27;174&#x27;%20width=&#x27;150&#x27;%20xmlns=&#x27;http://www.w3.org/2000/svg&#x27;%20version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#080808;position:absolute;top:0;left:0;bottom:0;right:0"></div><picture><source type="image/avif" data-srcset="/static/a1a51351bdf7de55eaaa515eb15ce2da/2e0ee/saifeddine-rajhi.avif 38w,/static/a1a51351bdf7de55eaaa515eb15ce2da/81dba/saifeddine-rajhi.avif 75w,/static/a1a51351bdf7de55eaaa515eb15ce2da/20c67/saifeddine-rajhi.avif 150w,/static/a1a51351bdf7de55eaaa515eb15ce2da/94b9f/saifeddine-rajhi.avif 300w" sizes="(min-width: 150px) 150px, 100vw"/><source type="image/webp" data-srcset="/static/a1a51351bdf7de55eaaa515eb15ce2da/92aab/saifeddine-rajhi.webp 38w,/static/a1a51351bdf7de55eaaa515eb15ce2da/359cc/saifeddine-rajhi.webp 75w,/static/a1a51351bdf7de55eaaa515eb15ce2da/aac41/saifeddine-rajhi.webp 150w,/static/a1a51351bdf7de55eaaa515eb15ce2da/a15c6/saifeddine-rajhi.webp 300w" sizes="(min-width: 150px) 150px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 150px) 150px, 100vw" decoding="async" loading="lazy" data-src="/static/a1a51351bdf7de55eaaa515eb15ce2da/885b3/saifeddine-rajhi.png" data-srcset="/static/a1a51351bdf7de55eaaa515eb15ce2da/9c61d/saifeddine-rajhi.png 38w,/static/a1a51351bdf7de55eaaa515eb15ce2da/d405f/saifeddine-rajhi.png 75w,/static/a1a51351bdf7de55eaaa515eb15ce2da/885b3/saifeddine-rajhi.png 150w,/static/a1a51351bdf7de55eaaa515eb15ce2da/4aeea/saifeddine-rajhi.png 300w" alt="Saifeddine Rajhi"/></picture><noscript><picture><source type="image/avif" srcSet="/static/a1a51351bdf7de55eaaa515eb15ce2da/2e0ee/saifeddine-rajhi.avif 38w,/static/a1a51351bdf7de55eaaa515eb15ce2da/81dba/saifeddine-rajhi.avif 75w,/static/a1a51351bdf7de55eaaa515eb15ce2da/20c67/saifeddine-rajhi.avif 150w,/static/a1a51351bdf7de55eaaa515eb15ce2da/94b9f/saifeddine-rajhi.avif 300w" sizes="(min-width: 150px) 150px, 100vw"/><source type="image/webp" srcSet="/static/a1a51351bdf7de55eaaa515eb15ce2da/92aab/saifeddine-rajhi.webp 38w,/static/a1a51351bdf7de55eaaa515eb15ce2da/359cc/saifeddine-rajhi.webp 75w,/static/a1a51351bdf7de55eaaa515eb15ce2da/aac41/saifeddine-rajhi.webp 150w,/static/a1a51351bdf7de55eaaa515eb15ce2da/a15c6/saifeddine-rajhi.webp 300w" sizes="(min-width: 150px) 150px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 150px) 150px, 100vw" decoding="async" loading="lazy" src="/static/a1a51351bdf7de55eaaa515eb15ce2da/885b3/saifeddine-rajhi.png" srcSet="/static/a1a51351bdf7de55eaaa515eb15ce2da/9c61d/saifeddine-rajhi.png 38w,/static/a1a51351bdf7de55eaaa515eb15ce2da/d405f/saifeddine-rajhi.png 75w,/static/a1a51351bdf7de55eaaa515eb15ce2da/885b3/saifeddine-rajhi.png 150w,/static/a1a51351bdf7de55eaaa515eb15ce2da/4aeea/saifeddine-rajhi.png 300w" alt="Saifeddine Rajhi"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1,e.parentNode.parentNode.querySelector("[data-placeholder-image]").style.opacity=0)}}</script></div></div><div class="name"><a href="/blog/" title="back to blog">Saifeddine <br/> Rajhi</a></div></div><h2 class="blog-title"><a href="/blog/" title="back to the homepage">Blog</a></h2></div></div><nav class="main-navigation"><ul><li><a rel="home" title="Go Home" href="/">Home</a></li><li><a title="Go to my Technical Blog" href="/blog/">Blog</a></li><li><a title="Go to my Thoughts" href="/thoughts/">Thoughts</a></li><li><a title="My public talks" href="/talks/">talks</a></li><li><a title="Review My Resume" href="/cv/platform-engineer/">cv</a></li></ul></nav></div><main><article class="blog-wrapper"><header><figure class="cover"><div class="cover-filter"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper cover cover-image"><div aria-hidden="true" style="padding-top:55.625%"></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;object-fit:fill;object-position:center" decoding="async" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACtklEQVR42j2SS29SURSF718zJh04dugPMDoyPhMHmmjUJupEEx+Jg0Ztq619FyiXZy99UCgVblsoBS6vUqA8boFCsS2fG2oc7Oydc/ZZe+21jrKe3CGRSxCIBAnHwmzt/kaPb0sdIRLX0fe3iexJvafzOxoe5NDOFvu5JEYhTerAIClhFAw2krsoiUODbq2Ic26KoEdlzWHFsziDc3YS98I0q+oimnUO9/wU4bVlQpqLZcssZ80qzXKeuoCetWrQbZKWWokKu65Zpt2ocCK5Hy554BJQzW7BOvWDdRm0ta7R7t/XS7SEQEtySVjmElEK6TiN8gGJg5QAZvfZlKkrLtvgoXdpAU214HPY2FzxoDks6ME1fE4rqrDs39mmfxIStqfCsnN8NBhyXMyKDAmUvXwS2sf8aVS5ODHp1stEVrysCbtV2wIBtx2/U8Bl2Fmzxvm/6Pf25F1X6o5s12ubpERHZTsTx61vMB3w/o+JVQejy3a+eW2M++z81JYYW7Yy6Xczv6kxIz39bNn0UjnKcNGqcN6qDsxRdrJxVqMhnLofe3gdl4D7YkGCySC+6AaqnGnGLlo6hms7gDPiH5y5pX88uMWOUeXwqMFJoz5w+nJlceiifbkCp8ccletMeaqk0nXEQjqeWTpzI/REq95pEzom7ZaJanzFufuWxxvv0YsRDop5lJg41dem725f4LbE89ECw2M5Ho6aGHOT1N49pDLyhsrnZ3TOu3TqRRpmlYmJJ3z8dIMXX54R2wuQE6eVuFgtSEKyKjrUBiK/Gi/xerzAo+8N8qqN1pfnmD8+0Bh7x3mvK6aIu0Lg9s07DA1d5+qVa6w4HZTNEopffndeLM8eZsgUMhyWMwRiaYZ/pVBDBqVanqRmJalOks3tky3myElvWgx4OvySW/fucvvBfVyaGz2f4C/kAfbrUk1tkwAAAABJRU5ErkJggg==" alt=""/><picture><source type="image/webp" data-srcset="/static/dee8a66c7ee1ff012bb686e835e8e69c/fdac4/prometheus-cover.webp 750w,/static/dee8a66c7ee1ff012bb686e835e8e69c/0f929/prometheus-cover.webp 1080w,/static/dee8a66c7ee1ff012bb686e835e8e69c/fc20e/prometheus-cover.webp 1366w,/static/dee8a66c7ee1ff012bb686e835e8e69c/24ca0/prometheus-cover.webp 1600w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="object-fit:fill;object-position:center;opacity:0" sizes="100vw" decoding="async" loading="lazy" data-src="/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png" data-srcset="/static/dee8a66c7ee1ff012bb686e835e8e69c/6f128/prometheus-cover.png 750w,/static/dee8a66c7ee1ff012bb686e835e8e69c/dc9a9/prometheus-cover.png 1080w,/static/dee8a66c7ee1ff012bb686e835e8e69c/cb4db/prometheus-cover.png 1366w,/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png 1600w" alt="Prometheus Restart Troubles: Managing Memory Overload üß†"/></picture><noscript><picture><source type="image/webp" srcSet="/static/dee8a66c7ee1ff012bb686e835e8e69c/fdac4/prometheus-cover.webp 750w,/static/dee8a66c7ee1ff012bb686e835e8e69c/0f929/prometheus-cover.webp 1080w,/static/dee8a66c7ee1ff012bb686e835e8e69c/fc20e/prometheus-cover.webp 1366w,/static/dee8a66c7ee1ff012bb686e835e8e69c/24ca0/prometheus-cover.webp 1600w" sizes="100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="object-fit:fill;object-position:center;opacity:0" sizes="100vw" decoding="async" loading="lazy" src="/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png" srcSet="/static/dee8a66c7ee1ff012bb686e835e8e69c/6f128/prometheus-cover.png 750w,/static/dee8a66c7ee1ff012bb686e835e8e69c/dc9a9/prometheus-cover.png 1080w,/static/dee8a66c7ee1ff012bb686e835e8e69c/cb4db/prometheus-cover.png 1366w,/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png 1600w" alt="Prometheus Restart Troubles: Managing Memory Overload üß†"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1,e.parentNode.parentNode.querySelector("[data-placeholder-image]").style.opacity=0)}}</script></div></div><figcaption data-nosnippet="" class="image-title">Photo by Saifeddine Rajhi</figcaption></figure><h1>Prometheus Restart Troubles: Managing Memory Overload üß†</h1><div data-nosnippet="" class="blog-details"><time class="blog-createdat" dateTime="2024-10-29">Oct 29, 2024</time><span> ‚Ä¢ </span><span class="blog-time2read">5<!-- -->mins<!-- --> read</span><div class="theme-switcher"><div class="theme-switcher-toggler"><div class="theme-switcher-track"></div><div class="theme-switcher-thumb"></div><input class="theme-switcher-input" type="checkbox" readonly="" aria-label="Switch between Dark and Light modes"/></div></div></div><ul data-nosnippet="" class="blog-tags"><li>Prometheus</li><li>memory overload</li><li>WAL</li><li>monitoring</li><li>kubernetes</li></ul></header><div class="blog-divider"></div><div id="intro"></div><div class="content-wrapper"><div data-nosnippet="" class="blog-content-nav-wrapper"><ul class="blog-content-nav"><h2>Content</h2><ul class="toc-list"></ul></ul></div><div class="content blog-content"><blockquote>
<p><strong>When Prometheus Can't Keep Up with the WAL üìà</strong></p>
</blockquote>
<h2 id="-introduction" style="position:relative;"><a href="#-introduction" aria-label=" introduction permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>üìó Introduction</h2>
<p>Have you ever had Prometheus crash due to an out-of-memory error while trying to catch up by reading the Write-Ahead Log (WAL)? It's a frustrating problem, but let's check it out.</p>
<p>Prometheus is great for monitoring, but when it restarts, it needs to process data from the Write-Ahead Log (WAL), which can be memory-intensive. This often leads to OOMKilled crashes, especially if Prometheus is already running close to its memory limits.</p>
<p>The issue usually stems from either collecting too much data or running too close to memory limits. This has been a long-standing concern, with <a href="https://github.com/prometheus/prometheus/issues/6934" target="_blank" rel="noopener noreferrer">reports dating back to an open issue since 2020 on GitHub</a>, highlighting the significant challenges faced by users in managing Prometheus' memory during WAL replay.</p>
<h3 id="Ô∏è-the-problem" style="position:relative;"><a href="#%EF%B8%8F-the-problem" aria-label="Ô∏è the problem permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>‚ÅâÔ∏è The Problem</h3>
<br>
<div style="width:100%;height:0;padding-bottom:100%;position:relative;"><iframe src="https://giphy.com/embed/ka55CqnDNjQ7iIKtRa" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen></iframe></div>
<p>While upgrading <a href="https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack" target="_blank" rel="noopener noreferrer">the Helm chart of kube-prometheus-stack</a>, we noticed several pods were not ready, including <code class="language-text">prometheus-prometheus-operator-prometheus-0</code>, which showed a status of <code class="language-text">3/4 Running</code> with a recent termination due to being OOMKilled.</p>
<p>The logs revealed the root cause:</p>
<div class="gatsby-highlight" data-language="shell"><pre class="language-shell"><code class="language-shell"><span class="token assign-left variable">ts</span><span class="token operator">=</span><span class="token number">2024</span>‚Äì06‚Äì14T09:49:10.383Z <span class="token assign-left variable">caller</span><span class="token operator">=</span>head.go:840 <span class="token assign-left variable">level</span><span class="token operator">=</span>info <span class="token assign-left variable">component</span><span class="token operator">=</span>tsdb <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"Deletion of corrupted mmap chunk files failed, discarding chunk files completely"</span> <span class="token assign-left variable">err</span><span class="token operator">=</span><span class="token string">"cannot handle error: iterate on on-disk chunks: out of sequence m-mapped chunk for series ref 946594555, last chunk: [1718071739971, 1718075459971], new: [1718049629971, 1718053199971]"</span></code></pre></div>
<p>It seems like it's stuck in the running state, where the pod is not yet ready. Let's describe the pod to see what is wrong:</p>
<div class="gatsby-highlight" data-language="shell"><pre class="language-shell"><code class="language-shell">State:       Running
    Started:   Tue, <span class="token number">14</span> Jun <span class="token number">2024</span> <span class="token number">10</span>:04:03 +0200
Last State:  Terminated
    Reason:    OOMKilled</code></pre></div>
<p>Ah, there it is. Prometheus is indeed running, but it got terminated due to an OOMKill‚Ää‚Äî‚Äärunning out of memory. It seems Prometheus is in the midst of recovering from the Write Ahead Log (WAL), which might be causing the memory spike. This could stem from an error during recovery or a restart, where Prometheus doesn't have enough memory to write everything into the WAL.</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 403px; ">
      <span class="gatsby-resp-image-background-image" style="padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAETUlEQVR42lVTWW8aVxid31apUp+aVKrUxk0fWqlK0lRVWvUhSZc0adLadb3U2Klt8LAMBowNwQYBJoAxywwwMCtzh2UAD8NObIMhTmwH04sfKlW6m66+c893vns+xL+zwEaXM4QaJFGQ1P5vkGj26iCSOpGEq1aIr2WiqICjEoP5HNMIG9VJNFritbWcuSqaq9n/hukAmIvAUs8aK8AgC+sSbfDvPnLHvrI5brcKW3TkOZIOa5moCn85SYXnyzyMM8uCqSIYOdrqTcf96VhecNVKESZhY0IrVu+tsHJPbZuogU1ybxFJ76PxwFzY+0cyNFdkdZAB4pWMIciTLl52ChUyR9fy20XhBeHTW713QXsRtX5dF62p0BJChjTEyymn6X7Q+ThPaSqiWR6D9QEGt+R7dqAAztGRo61aCsQN645nWGh1zfigU7CSEJzc0+TSmnm9ymRfbuUtMGdIroibnVc1tnZMF6TGQazAb6fCagZXU+E1PLCSCK6ClCERUCEcYUgldfdMrgWvp1nYgDmXeX2nSo1Gozf9djW3XQFYKqLJ8JTbZcP0i3tBr8ezHfTvBJzTiFf/NIA9fjI/Oz37O74zPS6yYD17078cjaqSv8yh1ayFwbVbG+qd7a3nS/Mej1On1Ths60HXX8jPE9d/+ezaTzc//O76+8aZHxoFU1PGIe3rflsGJuXq84Skwe/REft29w5KJd1+N5aIbMZ8fyPffPrBszsTz+7c+PXLT14s/wgFdxq5i3fDdj1bYrAyi5U5Y5nDJFqdJZdLrDaXWilQGgVgYfcs4rXP0KElLrrKRlYFYi2X1ucoY5bayKUNILGSTVvEFCaSRinjLYFAZuw2vZDQllhs1z6J8HFjiUNlYKjnLTBDRTTJHHqoxA/rVLuCvz3tvBm0z89OoJDhu7Oz087ZaXvQq799raQjqwgT1af352L+P+noYhVgLG0LUni1WRtHX8KqjeA8P393tY/qjVa704GHi7MuEViEYB0RmAl5pqiwKkdju1R6l0jhjHA5HELAxfk5EAGO48ViMRKJuJxOnucg+LBBJ/zzSGofjfmmHMb7UfeTOGEM0lyOjWeAMByOqQaDgc1mU6lUdrsNPnF0dAwvj9pSBayToedjb4ukelIzZ3f90yz7WTpFhpwNpQyDqlUlmUz6fD7I2e/3xxKGF92jAymz1ShskHtLiJAwRKLot2bvosvRaeYIUZAKAoyjGQbCeJ4/OeldKb8c9FrHbakkbMECN6XNMThonvQbnz6cnsE21497h7Gi1DvpHh225YNit9u9HMJSjd6edg/y3gKjL3D2smCFXmjAxoAt+ejzj3774uPvr73nt5ub/RNZkbvHR/VatdlQBqevAZdu1cu10l6RXauKJmh7aBjYPBCcgpof3r65cP/u01s3WJIINVvFfLjAWmsVut9t9Lqv5DzOESslzqAAS0UYu7UCTAeZdZh2dHf+X8slnBOXkWHmAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="cardinality" title="" src="/static/4457980b0539bcef67ad94fef9940f92/045fd/cardinality.png" srcset="/static/4457980b0539bcef67ad94fef9940f92/04472/cardinality.png 170w,
/static/4457980b0539bcef67ad94fef9940f92/9f933/cardinality.png 340w,
/static/4457980b0539bcef67ad94fef9940f92/045fd/cardinality.png 403w" sizes="(max-width: 403px) 100vw, 403px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
    </span>
          </p>
<p>One potential solution could be allocating more memory to Prometheus and analyzing why the WAL is getting clogged up. Essentially, we need to investigate what changed to suddenly cause this spike in memory usage in our once serene environment.</p>
<p>The issue persisted due to the WAL replay process requiring 2‚Äì3 times more memory than the running Prometheus instance. Despite running smoothly with around 30Gi of memory usage, the WAL replay process demanded over 50+Gi, ultimately leading to OOMKilled crashes during startup. Simply increasing the RAM limit wasn't a viable solution, as the excessive memory usage occurred specifically during the replay phase.</p>
<p>This problem aligns with a longstanding issue on GitHub since 2020, where users have consistently reported challenges managing Prometheus' memory during WAL replay. We encountered similar difficulties during our upgrade process, highlighting the critical need for resolution.</p>
<h3 id="-understanding-memory-overheads-in-wal-replay" style="position:relative;"><a href="#-understanding-memory-overheads-in-wal-replay" aria-label=" understanding memory overheads in wal replay permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>üí° Understanding Memory Overheads in WAL Replay</h3>
<p>In the past, WAL replay often caused significant overhead, leading to unexpected out-of-memory (OOM) situations. For instance, if your Prometheus was already running at 70% of its memory limit and the overhead during replay surged by 300%, it could easily lead to crashes. Additionally, increased CPU usage during replay, especially in low CPU environments like Kubernetes, could slow down processes like garbage collection, resulting in slower memory release.</p>
<p>However, recent benchmarks of Prometheus versions at Google show a different picture. While there's been a noticeable 2x increase in CPU usage during replay, the memory overhead, including heap and working sets, is only around 1‚Äì5%. This raises the question: are the reported OOM issues symptoms of a larger problem, with the replay OOM merely surfacing it?</p>
<p>Currently, two prevalent scenarios appear:</p>
<ol>
<li><strong>Excessive Data Collection</strong>: If your Prometheus setup scrapes too many series or samples, it's prone to OOM crashes during replay, regardless of the memory overhead.</li>
<li><strong>Running Close to Memory Limits</strong>: Even a slight overhead during replay can trigger OOM crashes if Prometheus is already running near its memory limit, such as at 95%.</li>
</ol>
<p>These issues often revolve around cardinality‚Ää‚Äî‚Ääthe combination of all label values per metric. High cardinality metrics, like those tracking multiple URLs or response codes, can quickly escalate memory usage. In short, much of Prometheus' memory woes can be attributed to cardinality.</p>
<h3 id="-how-does-remote-write-work" style="position:relative;"><a href="#-how-does-remote-write-work" aria-label=" how does remote write work permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>üîÑ How Does Remote Write Work?</h3>
<p>The remote write reads data from Prometheus' <a href="https://en.wikipedia.org/wiki/Write-ahead_logging" target="_blank" rel="noopener noreferrer">write ahead log</a>.</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <span class="gatsby-resp-image-background-image" style="padding-bottom: 66.47058823529413%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB9ElEQVR42o1T7XLTMBD0Q+ZdYKZ9nfKfJ+B38g+GklJIGju2ZTfEH7Ily7Kk5STXAYYwxTM3kke6vb3dU4QrnzEOVavQtD2OaY40Y4iPGXJWousHcDHiX190FdBapM8SScqQpgnatoVSA4qCoa4r9FK9DuicCxEA9USJHE3D0XKBXqgQQo7oOglBLJ2ZKMm+ztAZAys6sCxFkzxBJd8xHL5B5QmG4x6m47B6hB0krBR/Ay6smqYhrbJQWcseGSvw43SCnXQoEsKaSxe0IdAZ0L3EhaG/xDkHK4oAoKnyicDquoYlPX0YAlzuWtqbaZoB6QzEmHSCo9zIC34+nwOg9dWJoR2HUHEB8+DhnPYTARVUuK6q0IkiCZ7zDKws0Sc7RJ6FT/Ch6TK8huToROuk9UWOvqdkRcYIMf/zFkZJGAKtH+9R7b5CPn5C5A+32y3iOH5haMJFX6jvOnK1Q0UdeCBflDEW9HOLhn4VxL7nMGRm5FtIknnWZpcnGHJQEptxHEOLilZNbJ2dx0SfS+jdl+D2f42NrzRR214fvwYQApTE1psjHz5CfHgfDMQfPrtfLl/GwScTSLzf4VQWeLj/jJu3b/Du7i6MUZbEKFke7uC3nKsMF9BhGLDebHA4xFivN1itVri5vaVnmGK/f6LYB4OuPb2ffzTryGFZsqsAAAAASUVORK5CYII='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="wal" title="" src="/static/ae8f0b6c864a690e0f78a8be41523357/c5bb3/wal.png" srcset="/static/ae8f0b6c864a690e0f78a8be41523357/04472/wal.png 170w,
/static/ae8f0b6c864a690e0f78a8be41523357/9f933/wal.png 340w,
/static/ae8f0b6c864a690e0f78a8be41523357/c5bb3/wal.png 680w,
/static/ae8f0b6c864a690e0f78a8be41523357/b12f7/wal.png 1020w,
/static/ae8f0b6c864a690e0f78a8be41523357/d9b5d/wal.png 1224w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
    </span>
          </p>
<p>Data generated by scrape is written to the WAL, so this essentially gives us a 2- to 3-hour buffer on disk of data for remote write. The RW system now has a subroutine that reads the WAL and passes the data back to remote write.</p>
<p>Remote write still has a small in-memory buffer, and the routine reading the WAL pauses where it is if it's not able to append new data to the buffer. This means we no longer drop data if the buffer is full, and the buffer doesn't need to be large enough to handle a longer outage.</p>
<p>As long as the remote endpoint isn't down for hours, remote write no longer loses data (with some caveats, like Prometheus restarts), since the WAL is truncated every two hours or so.</p>
<h3 id="Ô∏è-issue-resolutions" style="position:relative;"><a href="#%EF%B8%8F-issue-resolutions" aria-label="Ô∏è issue resolutions permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>üõ†Ô∏è Issue Resolutions</h3>
<p>If you've never experienced this issue before (lucky you!), here's a handy solution I found effective. Since Prometheus may not be up and running to utilize PromQL for detecting potential issues, we need an alternative method to identify high cardinality. One approach is to get hands-on with some kubectl exec magic:</p>
<div class="gatsby-highlight" data-language="sh"><pre class="language-sh"><code class="language-sh">kubectl <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> <span class="token parameter variable">-n</span> monitoring pods/prometheus-prometheus-kube-prometheus-prometheus-0 -- <span class="token function">sh</span></code></pre></div>
<p>Then, run the Prometheus TSDB analysis:</p>
<div class="gatsby-highlight" data-language="sh"><pre class="language-sh"><code class="language-sh">/prometheus $ promtool tsdb analyze <span class="token builtin class-name">.</span></code></pre></div>
<p>This analysis will provide insights into metrics with high cardinality, like <code class="language-text">haproxy_server_http_responses_total</code>, which might be causing memory issues. In such cases, updating or optimizing the problematic metric, such as haproxy, can alleviate memory strain.</p>
<p>Alternatively, consider increasing Prometheus' memory allocation or deploying it to a specific node group with ample memory resources.</p>
<p>Here are some additional strategies to mitigate memory overhead and OOM crashes:</p>
<ul>
<li><strong>Verify Memory Overhead</strong>: Ensure that the memory overhead during replay is within acceptable limits (e.g., 10‚Äì15%). Running Prometheus close to its memory limit is risky due to dynamic garbage collection and limited room for unexpected cardinality spikes or queries.</li>
<li><strong>Optimize Storage and Scraping</strong>: Regularly optimize Prometheus' storage, scraping, and remote write configurations to reduce memory usage. Upgrading to newer releases can often provide optimizations in this regard.</li>
<li><strong>Automate Recovery from OOM</strong>: Implement auto-recovery mechanisms to handle OOM crash loops, such as automatically deleting the Write-Ahead Log (WAL) on OOM events. This ensures smoother recovery from memory-related issues.</li>
<li><strong>Implement Scraping Limits</strong>: Consider introducing forceful scrape limits to prevent Prometheus from scraping targets when memory usage exceeds a certain threshold. This proactive approach can help avoid memory-intensive situations and potential OOM crashes.</li>
</ul>
<p>By implementing these strategies, you can effectively manage Prometheus' memory challenges and ensure smooth operation in your monitoring environment.</p>
<h3 id="-conclusion" style="position:relative;"><a href="#-conclusion" aria-label=" conclusion permalink" class="anchor before"><svg class="anchor-icon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>üîö Conclusion</h3>
<p>Dealing with Prometheus OOM errors during WAL replay can be challenging. By understanding the root causes, such as excessive data collection and high cardinality metrics, and implementing solutions like optimizing storage and scraping configurations, increasing memory allocations, and setting up auto-recovery mechanisms, you can mitigate these issues.</p>
<p><strong>Thank You üñ§</strong></p>
<br>
<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>
<blockquote>
<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>
</blockquote>
<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>
<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href="https://www.linkedin.com/in/rajhi-saif/" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/in/rajhi-saif/</a></p>
<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href="https://x.com/rajhisaifeddine" target="_blank" rel="noopener noreferrer">https://x.com/rajhisaifeddine</a></p>
<p><strong>The end ‚úåüèª</strong></p>
<h1 align="center">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>
<p><strong>üìÖ Stay updated</strong></p>
<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p></div></div><div id="content-end"></div></article><div data-nosnippet="" class="social-share-wrapper"><h3>Share Your Love</h3><button keywords="" aria-label="Share Via Facebook" class="react-share__ShareButton social-share-item facebook" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="facebook" class="svg-inline--fa fa-facebook " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5V334.2H141.4V256h52.8V222.3c0-87.1 39.4-127.5 125-127.5c16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1c-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287V510.1C413.8 494.8 512 386.9 512 256h0z"></path></svg></button><button keywords="" aria-label="Share Via Twitter" class="react-share__ShareButton social-share-item twitter" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="x-twitter" class="svg-inline--fa fa-x-twitter " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></button><button aria-label="Share Via LinkedIn" keywords="" class="react-share__ShareButton social-share-item linkedin" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin" class="svg-inline--fa fa-linkedin " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></button><button keywords="" aria-label="Share Via Reddit" class="react-share__ShareButton social-share-item reddit" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="reddit" class="svg-inline--fa fa-reddit " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M0 256C0 114.6 114.6 0 256 0S512 114.6 512 256s-114.6 256-256 256L37.1 512c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256zM349.6 153.6c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34c-34.5 3.7-61.4 33-61.4 68.4l0 .2c-37.5 1.6-71.8 12.3-99 29.1c-10.1-7.8-22.8-12.5-36.5-12.5c-33 0-59.8 26.8-59.8 59.8c0 24 14.1 44.6 34.4 54.1c2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54c0-33-26.8-59.8-59.8-59.8c-13.7 0-26.3 4.6-36.4 12.4c-27.4-17-62.1-27.7-100-29.1l0-.2c0-25.4 18.9-46.5 43.4-49.9l0 0c4.4 18.8 21.3 32.8 41.5 32.8zM177.1 246.9c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6s-31.4-8.8-30.4-30.5s15.4-38.3 32.1-38.3zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6c-1-21.7 11.8-39.3 28.5-39.3s31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9 .8-6.2 3.9-6.5c18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1 .3 5.1 3.6 3.9 6.5z"></path></svg></button><button keywords="" aria-label="Add to Pocket" class="react-share__ShareButton social-share-item pocket" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="get-pocket" class="svg-inline--fa fa-get-pocket " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M407.6 64h-367C18.5 64 0 82.5 0 104.6v135.2C0 364.5 99.7 464 224.2 464c124 0 223.8-99.5 223.8-224.2V104.6c0-22.4-17.7-40.6-40.4-40.6zm-162 268.5c-12.4 11.8-31.4 11.1-42.4 0C89.5 223.6 88.3 227.4 88.3 209.3c0-16.9 13.8-30.7 30.7-30.7 17 0 16.1 3.8 105.2 89.3 90.6-86.9 88.6-89.3 105.5-89.3 16.9 0 30.7 13.8 30.7 30.7 0 17.8-2.9 15.7-114.8 123.2z"></path></svg></button></div><br/><br/><br/></main><aside class="blogpost-sidebar"><div data-nosnippet="" class="blog-navigation-wrapper"><h3>Read Other Posts</h3><nav class="blog-navigation"><div class="nav-links"><a rel="next" class="next-post" href="/blog/docker-image-optimization/">Docker Image Optimization: A Toolbox of efficient Tricks<!-- --> ‚Üí</a><a rel="prev" class="prev-post" href="/blog/container-runtimes-cri-overview/">‚Üê <!-- -->Container Runtimes and CRI: A Technical Overview üõ†Ô∏è</a><a class="all-posts" href="/blog/">All Posts</a></div></nav></div></aside><footer data-nosnippet=""><div class="footer-wrapper"><div data-nosnippet="" class="social"><ul class="social-list"><li class="social-item social-linkedin"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="linkedin" href="https://www.linkedin.com/in/rajhi-saif/" title="Saifeddine Rajhi on LinkedIn" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg><span>LinkedIn</span></a></li><li class="social-item social-github"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="github" href="https://github.com/seifrajhi" title="Saifeddine Rajhi on Github" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><span>GitHub</span></a></li><li class="social-item social-email"><a itemProp="email" eventCategory="social" eventAction="click" eventLabel="email" href="mailto:rajhiseif@gmail.com" title="Saifeddine Rajhi&#x27;s Email"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4 0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4c0-26.5-21.5-48-48-48L48 64zM0 176L0 384c0 35.3 28.7 64 64 64l384 0c35.3 0 64-28.7 64-64l0-208L294.4 339.2c-22.8 17.1-54 17.1-76.8 0L0 176z"></path></svg><span>Email</span></a></li><li class="social-item social-bluesky"><a rel="me" itemProp="url" eventCategory="bluesky" eventAction="click" eventLabel="social" href="https://bsky.app/profile/saifrajhi.bsky.social" title="Saifeddine Rajhi on Bluesky Social" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="bluesky" class="svg-inline--fa fa-bluesky fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M111.8 62.2C170.2 105.9 233 194.7 256 242.4c23-47.6 85.8-136.4 144.2-180.2c42.1-31.6 110.3-56 110.3 21.8c0 15.5-8.9 130.5-14.1 149.2C478.2 298 412 314.6 353.1 304.5c102.9 17.5 129.1 75.5 72.5 133.5c-107.4 110.2-154.3-27.6-166.3-62.9l0 0c-1.7-4.9-2.6-7.8-3.3-7.8s-1.6 3-3.3 7.8l0 0c-12 35.3-59 173.1-166.3 62.9c-56.5-58-30.4-116 72.5-133.5C100 314.6 33.8 298 15.7 233.1C10.4 214.4 1.5 99.4 1.5 83.9c0-77.8 68.2-53.4 110.3-21.8z"></path></svg><span>Bluesky Social</span></a></li><li class="social-item social-X/Twitter"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="X/Twitter" href="https://x.com/RajhiSaifeddine" title="Saifeddine Rajhi on X/Twitter" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="x-twitter" class="svg-inline--fa fa-x-twitter fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg><span>X/Twitter</span></a></li><li class="social-item social-reddit"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="reddit" href="https://www.reddit.com/user/ScoreApprehensive992/" title="Saifeddine Rajhi on Reddit" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="reddit-alien" class="svg-inline--fa fa-reddit-alien fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M373 138.6c-25.2 0-46.3-17.5-51.9-41l0 0c-30.6 4.3-54.2 30.7-54.2 62.4l0 .2c47.4 1.8 90.6 15.1 124.9 36.3c12.6-9.7 28.4-15.5 45.5-15.5c41.3 0 74.7 33.4 74.7 74.7c0 29.8-17.4 55.5-42.7 67.5c-2.4 86.8-97 156.6-213.2 156.6S45.5 410.1 43 323.4C17.6 311.5 0 285.7 0 255.7c0-41.3 33.4-74.7 74.7-74.7c17.2 0 33 5.8 45.7 15.6c34-21.1 76.8-34.4 123.7-36.4l0-.3c0-44.3 33.7-80.9 76.8-85.5C325.8 50.2 347.2 32 373 32c29.4 0 53.3 23.9 53.3 53.3s-23.9 53.3-53.3 53.3zM157.5 255.3c-20.9 0-38.9 20.8-40.2 47.9s17.1 38.1 38 38.1s36.6-9.8 37.8-36.9s-14.7-49.1-35.7-49.1zM395 303.1c-1.2-27.1-19.2-47.9-40.2-47.9s-36.9 22-35.7 49.1c1.2 27.1 16.9 36.9 37.8 36.9s39.3-11 38-38.1zm-60.1 70.8c1.5-3.6-1-7.7-4.9-8.1c-23-2.3-47.9-3.6-73.8-3.6s-50.8 1.3-73.8 3.6c-3.9 .4-6.4 4.5-4.9 8.1c12.9 30.8 43.3 52.4 78.7 52.4s65.8-21.6 78.7-52.4z"></path></svg><span>Reddit</span></a></li><li class="social-item social-stackoverflow"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="StackOverflow" href="https://stackoverflow.com/users/21897244/saifeddine-rajhi" title="Saifeddine Rajhi on StackOverflow" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="stack-overflow" class="svg-inline--fa fa-stack-overflow fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M290.7 311L95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"></path></svg><span>StackOverflow</span></a></li><li class="social-item social-Goodreads"><a rel="me" eventLabel="StackOverflow" href="https://www.goodreads.com/user/show/176103378-saifeddine" title="Saifeddine Rajhi on Goodreads" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="goodreads" class="svg-inline--fa fa-goodreads fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M299.9 191.2c5.1 37.3-4.7 79-35.9 100.7-22.3 15.5-52.8 14.1-70.8 5.7-37.1-17.3-49.5-58.6-46.8-97.2 4.3-60.9 40.9-87.9 75.3-87.5 46.9-.2 71.8 31.8 78.2 78.3zM448 88v336c0 30.9-25.1 56-56 56H56c-30.9 0-56-25.1-56-56V88c0-30.9 25.1-56 56-56h336c30.9 0 56 25.1 56 56zM330 313.2s-.1-34-.1-217.3h-29v40.3c-.8.3-1.2-.5-1.6-1.2-9.6-20.7-35.9-46.3-76-46-51.9.4-87.2 31.2-100.6 77.8-4.3 14.9-5.8 30.1-5.5 45.6 1.7 77.9 45.1 117.8 112.4 115.2 28.9-1.1 54.5-17 69-45.2.5-1 1.1-1.9 1.7-2.9.2.1.4.1.6.2.3 3.8.2 30.7.1 34.5-.2 14.8-2 29.5-7.2 43.5-7.8 21-22.3 34.7-44.5 39.5-17.8 3.9-35.6 3.8-53.2-1.2-21.5-6.1-36.5-19-41.1-41.8-.3-1.6-1.3-1.3-2.3-1.3h-26.8c.8 10.6 3.2 20.3 8.5 29.2 24.2 40.5 82.7 48.5 128.2 37.4 49.9-12.3 67.3-54.9 67.4-106.3z"></path></svg><span>Goodreads</span></a></li><li class="social-item social-osi"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="StackOverflow" href="https://ossinsight.io/analyze/seifrajhi" title="Saifeddine Rajhi on OSSInsights" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="osi" class="svg-inline--fa fa-osi fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M8 266.44C10.3 130.64 105.4 34 221.8 18.34c138.8-18.6 255.6 75.8 278 201.1 21.3 118.8-44 230-151.6 274-9.3 3.8-14.4 1.7-18-7.7q-26.7-69.45-53.4-139c-3.1-8.1-1-13.2 7-16.8 24.2-11 39.3-29.4 43.3-55.8a71.47 71.47 0 0 0-64.5-82.2c-39-3.4-71.8 23.7-77.5 59.7-5.2 33 11.1 63.7 41.9 77.7 9.6 4.4 11.5 8.6 7.8 18.4q-26.85 69.9-53.7 139.9c-2.6 6.9-8.3 9.3-15.5 6.5-52.6-20.3-101.4-61-130.8-119-24.9-49.2-25.2-87.7-26.8-108.7zm20.9-1.9c.4 6.6.6 14.3 1.3 22.1 6.3 71.9 49.6 143.5 131 183.1 3.2 1.5 4.4.8 5.6-2.3q22.35-58.65 45-117.3c1.3-3.3.6-4.8-2.4-6.7-31.6-19.9-47.3-48.5-45.6-86 1-21.6 9.3-40.5 23.8-56.3 30-32.7 77-39.8 115.5-17.6a91.64 91.64 0 0 1 45.2 90.4c-3.6 30.6-19.3 53.9-45.7 69.8-2.7 1.6-3.5 2.9-2.3 6q22.8 58.8 45.2 117.7c1.2 3.1 2.4 3.8 5.6 2.3 35.5-16.6 65.2-40.3 88.1-72 34.8-48.2 49.1-101.9 42.3-161-13.7-117.5-119.4-214.8-255.5-198-106.1 13-195.3 102.5-197.1 225.8z"></path></svg><span>OSSInsights</span></a></li><li class="social-item social-devstats"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="StackOverflow" href="https://devstats.cluster.fun/?user=seifrajhi" title="Saifeddine Rajhi on DevStats" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="chart-line" class="svg-inline--fa fa-chart-line fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M64 64c0-17.7-14.3-32-32-32S0 46.3 0 64L0 400c0 44.2 35.8 80 80 80l400 0c17.7 0 32-14.3 32-32s-14.3-32-32-32L80 416c-8.8 0-16-7.2-16-16L64 64zm406.6 86.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L320 210.7l-57.4-57.4c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L240 221.3l57.4 57.4c12.5 12.5 32.8 12.5 45.3 0l128-128z"></path></svg><span>DevStats</span></a></li><li class="social-item social-RSS"><a rel="me" itemProp="url" eventCategory="social" eventAction="click" eventLabel="RSS" href="https://seifrajhi.github.io/rss.xml" title="Subscribe to my blog post" target="blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" class="svg-inline--fa fa-rss fa-beat fa-2x " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 64C0 46.3 14.3 32 32 32c229.8 0 416 186.2 416 416c0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96C14.3 96 0 81.7 0 64zM0 416a64 64 0 1 1 128 0A64 64 0 1 1 0 416zM32 160c159.1 0 288 128.9 288 288c0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224c-17.7 0-32-14.3-32-32s14.3-32 32-32z"></path></svg><span>RSS</span></a></li></ul></div><div class="copyright">Saifeddine Rajhi ¬© 1994 - <!-- -->2025<!-- --> <br/><a rel="license" href="https://creativecommons.org/licenses/by/4.0/" title="Content is published under CC BY 4.0 license">CC BY 4.0</a></div><div class="pgp"><a href="https://keybase.io/saifrajhi">0C3B BABB 8BC1 EA2B</a></div></div></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/prometheus-manage-memory-overload/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-2f4f174b7ccfc9183c7b.js\"],\"component---cache-caches-gatsby-plugin-offline-app-shell-js\":[\"/component---cache-caches-gatsby-plugin-offline-app-shell-js-88fb5c28d68e831e730a.js\"],\"component---src-pages-404-tsx\":[\"/component---src-pages-404-tsx-a0e3d27d11d1ae18e8f0.js\"],\"component---src-pages-blog-js\":[\"/component---src-pages-blog-js-ebba4d9aefd856068672.js\"],\"component---src-pages-cv-platform-engineer-js\":[\"/component---src-pages-cv-platform-engineer-js-6b113f68e4ef180c17b2.js\"],\"component---src-pages-index-tsx\":[\"/component---src-pages-index-tsx-cca2029691d058282d40.js\"],\"component---src-pages-talks-js\":[\"/component---src-pages-talks-js-d3fd645d0085de17a5e9.js\"],\"component---src-pages-thoughts-js\":[\"/component---src-pages-thoughts-js-0950be014b397a2b3d9c.js\"],\"component---src-templates-blog-template-js\":[\"/component---src-templates-blog-template-js-8b499d4855ef1cb13add.js\"],\"component---src-templates-talk-template-js\":[\"/component---src-templates-talk-template-js-7623845caf43043e0341.js\"],\"component---src-templates-thought-template-js\":[\"/component---src-templates-thought-template-js-b8bdd67706c6a1d2873c.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="eaddde9f0729f628bfa3";</script><script src="/webpack-runtime-7456f0bc58205084e1e1.js" async></script><script src="/framework-580c5b11fe009445c659.js" async></script><script src="/app-2f4f174b7ccfc9183c7b.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>