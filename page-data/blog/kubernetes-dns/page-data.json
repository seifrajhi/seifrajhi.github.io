{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/kubernetes-dns/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>Kubernetes DNS Expeditionüî•</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>Kubernetes is an orchestration system for managing containerized applications. One of its key features is DNS, which allows pods to communicate with each other using DNS names instead of IP addresses.</p>\n<p>In this blog post, we will walk through the life of a DNS query in Kubernetes, from when a pod performs a lookup to when it receives the IP address of the requested hostname. We will also discuss how DNS plays a role in service discovery, which is the process of routing incoming requests to the correct workloads running in the cluster.</p>\n<p>By understanding how DNS works in Kubernetes, you will be better equipped to debug issues and troubleshoot problems with your applications.</p>\n<h2 id=\"pods-communication-in-kubernetes\" style=\"position:relative;\"><a href=\"#pods-communication-in-kubernetes\" aria-label=\"pods communication in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Pods communication in Kubernetes</h2>\n<p>Using IP addresses to communicate between pods presents two key challenges:</p>\n<ul>\n<li><strong>Dynamic IP assignment:</strong> Pods can be assigned new IP addresses during creation, scaling, or restarts. Tracking these changing addresses and updating configurations becomes complex and error-prone.</li>\n<li><strong>External accessibility limitation:</strong> Pods' IP addresses are not reachable outside the Kubernetes cluster due to non-routability. To access pods externally, a service is required.</li>\n</ul>\n<p>Services address these issues by establishing a consistent name for a pod group:</p>\n<ul>\n<li><code class=\"language-text\">Stable Communication:</code> Pods can refer to the service name instead of dynamic IP addresses when connecting to other pods. The service efficiently routes traffic to the intended pod.</li>\n</ul>\n<p>Beyond IP-related challenges, services offer several advantages:</p>\n<ul>\n<li><strong>Load balancing:</strong> Traffic distribution across pods enhances application performance by maintaining balanced workloads.</li>\n<li><strong>High availability:</strong> Service configuration ensures traffic redirection to functioning pods if one fails, ensuring uninterrupted application availability.</li>\n<li><strong>DNS resolution:</strong> Services can be registered with Kubernetes DNS, enabling easy pod-to-pod connectivity without needing to know individual pod IP addresses.</li>\n</ul>\n<h2 id=\"-kubernetes-dns-and-service-discovery\" style=\"position:relative;\"><a href=\"#-kubernetes-dns-and-service-discovery\" aria-label=\" kubernetes dns and service discovery permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üóù Kubernetes DNS and Service discovery</h2>\n<p>In Kubernetes, service discovery relies on the essential component of DNS (Domain Name System). Service resources facilitate service discovery by associating an IP address with a healthy pod, enabling seamless connections.</p>\n<p>Upon creating a <code class=\"language-text\">service</code>, the Kubernetes cluster's <code class=\"language-text\">DNS server</code> generates an <code class=\"language-text\">A record</code>, mapping the <code class=\"language-text\">service's DNS name</code> to its <code class=\"language-text\">IP address</code>.</p>\n<p>Consequently, pods can conveniently access the service using its DNS name. The DNS server dynamically updates the A record to reflect changes in the service's IP address, ensuring accuracy.</p>\n<p>The <strong>Domain Name System (DNS)</strong> is a mechanism that connects user-friendly names, like domain names, to corresponding IP addresses. This translation simplifies end-users' access to target domains. Kubernetes clusters incorporate an internal DNS service by default, ensuring efficient service discovery even as pods and services are created, shifted, or removed across nodes.</p>\n<p>Recent Kubernetes versions transitioned from <code class=\"language-text\">kube-dns</code> to <code class=\"language-text\">CoreDNS</code> to address security and stability concerns, with CoreDNS introduced in version <code class=\"language-text\">1.11</code>.</p>\n<p>Both implementations function similarly:</p>\n<ul>\n<li>\n<p>A <code class=\"language-text\">kube-dns</code> service and one or more pods are created.</p>\n</li>\n<li>\n<p>The <code class=\"language-text\">kube-dns</code> service monitors the Kubernetes API for service and endpoint events and changes its DNS entries as appropriate. When you modify these Kubernetes services and their related pods with creating, editing, or deleting operations, these events are auto-triggered.</p>\n</li>\n<li>\n<p><code class=\"language-text\">Kubelet</code> assigns the <code class=\"language-text\">cluster IP</code> of the kube-dns service to every new pod <code class=\"language-text\">etc/resolv.conf</code> nameserver option, along with suitable search settings to allow for shorter hostnames:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">nameserver <span class=\"token number\">10.32</span>.0.10\nsearch namespace.svc.cluster.local svc.cluster.local cluster.local\noptions ndots:5</code></pre></div>\n</li>\n</ul>\n<p>Containerized applications may then resolve hostnames like <code class=\"language-text\">example-service.namespace</code> to the appropriate cluster IP address.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 64.11764705882354%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAADY0lEQVR42o2S+2/bVBTHU+g2NInf+AsYZdWQ+KWCTfxSftmQpm5CsEkDxrTxqBgVDKQKKVJHpkjTVk1CwDTQ0BiDUnVNm0eTOq8mbuukXhI7tmM7juO8H1voK20EYl1i53DdLRXiJ6700bn363u/vueeY+h5e+pg32nnTy+fchw0oHHypGm3yWTq7u/v70bLpxFdhv8/ugyvf+K3DV0JweHz2G+60jHq6+vbpccRs3m/3eX9wjrr+3Ji2nHBOuP+DAvgQ1MObMhic50ft9g/tWK+IYsd+2hwcPA5w6tnPO8cHrTmDr0//S4APN9stg+h+Eqj0XhR/0GIjP9QW/8LpGylJefvA0kl4PdJG9wZtwAv55FeBjFTaiulGty1uk4Z0GE9LcPq6uppBDAMo3EcB8vLK1vLpdK+QCjyvZSvAs3LW2wqp8aFtIpM1UWSVilOUuNiBqE0RaUIDsx/TjfUUzSsra1dQACO402CILTNRgPuT05+7Pjuxh2SuAfhUET1eQLgDxIQXKJgKS4Ci24oygoIsqIlM2WYmJ75cOeG9Xr9c1EUgaIolaZpKFcqsM7Rb+Ae/DpF0jBnc7UCM25YnPUBgfkhgmDn5mEM4+Guh9NS2RJY7LPbhttVrFaLrz14UCPKxXKoUqnEarWam3be3Isv0dez1RWgBKUVTcgQjrAwT0QhJUpwa2wBjn9dgWMXq5pzIQ3BoPuDTrn3/Lc9OjcPxdgfC9U1iAupFpOUICbwQDAkkHwIxv0kvHWpBCfMBQ2PZsDrf/yGT+kHWWXxPSXPWykufDtXVCbZ7Pw5JO/2hH2/JgsZIKhIy+HDwOZ2QpQTUJFSwEsKTDiCYHHiWipXAvus7+yO4UqjYNHgISRz9Nbfah2Kq6wXyc8SUernDGoJOiE3o4zUphPpdlxQtqH5dJviRKQlVSFdBJd37sxOasli5JfGoxoUlxNbK39mQa7Q47rOCOnb5T82ICHnW0K6sN17j3kyR0Zorul96Aksnu08WTcpel/IlNk3+UL4qIziEj/dq39YCFNfxVipjahHWHEzyiQ3Ioy4EWWTdV2juNS6ToyTNsembEc6hrue0PUv9PWegYGBvZevXTtw9eo3LxlNpgNG0+Veo9HYOzIyst9sHu3RGR39tmd4eHgf2v/MP1NJfOGqBqThAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/5cb974034ce91ea9033f87e172cf6a62/c5bb3/dns-server.png\" srcset=\"/static/5cb974034ce91ea9033f87e172cf6a62/04472/dns-server.png 170w,\n/static/5cb974034ce91ea9033f87e172cf6a62/9f933/dns-server.png 340w,\n/static/5cb974034ce91ea9033f87e172cf6a62/c5bb3/dns-server.png 680w,\n/static/5cb974034ce91ea9033f87e172cf6a62/b12f7/dns-server.png 1020w,\n/static/5cb974034ce91ea9033f87e172cf6a62/b5a09/dns-server.png 1360w,\n/static/5cb974034ce91ea9033f87e172cf6a62/29007/dns-server.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"overview-of-the-kubernetes-dnsrecords\" style=\"position:relative;\"><a href=\"#overview-of-the-kubernetes-dnsrecords\" aria-label=\"overview of the kubernetes dnsrecords permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Overview of the Kubernetes DNS¬†Records</h2>\n<p>Let's understand Kubernetes DNS records better with the help of an example.</p>\n<p>The entire DNS A record for a Kubernetes service will look like:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">service.namespace.svc.cluster.local</code></pre></div>\n<p>A pod would have a record in this format, which would represent the pod's real IP address:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token number\">10</span>-32-0-125.namespace.pod.cluster.local</code></pre></div>\n<p>Besides, <strong>SRV records</strong> are created for the specified <strong>ports</strong> of a Kubernetes service:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">_port-name._protocol.service.namespace.svc.cluster.local</code></pre></div>\n<p>As a result, your <code class=\"language-text\">application</code> or <code class=\"language-text\">microservice</code> may hit a simple and consistent hostname to reach other services or pods on the cluster, thanks to the built-in DNS-based service discovery mechanism.</p>\n<h3 id=\"resolving-shorter-hostnames-and-searching-domains\" style=\"position:relative;\"><a href=\"#resolving-shorter-hostnames-and-searching-domains\" aria-label=\"resolving shorter hostnames and searching domains permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Resolving shorter hostnames and searching domains</h3>\n<p>You won't always need to utiuselize the whole hostname to access another service because of the search domain suffixes set in the <code class=\"language-text\">resolv.conf</code> file.</p>\n<p>If you're contacting a service in the same namespace, you may just call it by its name:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">other-service</code></pre></div>\n<p>Add <code class=\"language-text\">other-namespace</code> to the query if the service is in a different namespace:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">other-service.other-namespace</code></pre></div>\n<p>You'll need to use at least the following if you're going after a pod:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">pod-ip.other-namespace.pod</code></pre></div>\n<p>Only the <code class=\"language-text\">.svc</code> suffixes are automatically completed in the default <code class=\"language-text\">resolv.conf</code> file.\nTherefore, it is essential to specify the settings up to¬†<code class=\"language-text\">.pod</code>.</p>\n<p>An example service definition looks like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Service\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> foo\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> bar\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token number\">80</span>\n      <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> http</code></pre></div>\n<p>The <code class=\"language-text\">A record</code> and <code class=\"language-text\">SRV record</code> (discussed later in the article) that are created in this instance look like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">foo.bar.svc.cluster.local                  <span class=\"token number\">30</span>   A   <span class=\"token number\">10.129</span>.1.26\n_http._tcp.nginx.default.svc.cluster.local <span class=\"token number\">3600</span> SRV <span class=\"token number\">0</span> <span class=\"token number\">100</span> <span class=\"token number\">80</span> <span class=\"token number\">10</span>-129-1-26.foo.bar.svc.cluster.local.</code></pre></div>\n<p>To create the fully qualified domain name FQDN for this service, we use the name of the <strong>service (foo)</strong>, the <strong>namespace (bar</strong>), and the cluster domain <strong>(cluster.local)</strong>.</p>\n<p>Any workload running in the cluster can now resolve the service's IP address using this DNS name.</p>\n<h3 id=\"dns-lookups-onservices\" style=\"position:relative;\"><a href=\"#dns-lookups-onservices\" aria-label=\"dns lookups onservices permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>DNS lookups on¬†services</h3>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 46.470588235294116%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAABf0lEQVR42h1Ry47cMAzL//9YC7S33dNuME08TmI7tuT3I04y1SzAAw2IpkgNEkBnt3kQAZkWXEqDPuZGSOXwsWhwROhJRGnYjY2p5nrQ1CC9CV7r5z9Y5xiMq/G8Xu04CUe/cm3WByKtX/1+9esm0s679oscSAxBCxy/3ePhdwHZt+Oqx0mguVSadeE4b7AeXIg+VgN2notSAXBQAVWFSXNmVpm1banVs7ajtk7mpXVHgtZJQr9Yg0VK9fEZ2Ry0eTsn2PH7i5wjKKyx+RinKTMWd70b3IQsQrhxbFLVUuvP/rQL1TEIZwAFisWpzRgBNdaQgS/mya021BCgK4BZmx4iiUtM0bpMCaiwDXem2LxMbJtnOVNmq3F6PMavUcs9/2Sm/MsmJ8bVJvTnB//9S/z9A3wdlMfmoXDeljU7I1D13WQ2p2m6EKkh6+N5v6gsIfcYU7auENB6dMNqlNSb3J5KcKFXgTpQN1KhkEScCwbpzu+bl3a+D14JPbUTffoPerr5vT6PgXwAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/a8e8d9ff6d0751a2a9c22ca192890248/c5bb3/dns-lookup.png\" srcset=\"/static/a8e8d9ff6d0751a2a9c22ca192890248/04472/dns-lookup.png 170w,\n/static/a8e8d9ff6d0751a2a9c22ca192890248/9f933/dns-lookup.png 340w,\n/static/a8e8d9ff6d0751a2a9c22ca192890248/c5bb3/dns-lookup.png 680w,\n/static/a8e8d9ff6d0751a2a9c22ca192890248/b12f7/dns-lookup.png 1020w,\n/static/a8e8d9ff6d0751a2a9c22ca192890248/b5a09/dns-lookup.png 1360w,\n/static/a8e8d9ff6d0751a2a9c22ca192890248/29007/dns-lookup.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>When a pod performs a DNS lookup, the query is first sent to the local DNS resolver in the pod. This resolver uses the <code class=\"language-text\">resolv.conf</code> configuration file. In this file, the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/\" target=\"_blank\" rel=\"noopener noreferrer\">nodelocaldns</a> server is set up as the default recursive DNS resolver, which acts as a cache.</p>\n<p>If this cache does not contain the IP address for the requested hostname, the query is forwarded to the cluster DNS server (<a href=\"https://coredns.io/\" target=\"_blank\" rel=\"noopener noreferrer\">CoreDNS</a>).</p>\n<p>This DNS server determines the IP address by consulting the Kubernetes service registry. This registry contains a mapping of service names to their corresponding IP addresses. This allows the cluster DNS server to return the correct IP address to the requesting pod.</p>\n<p>Any domains that are queried but are not in the Kubernetes service registry are forwarded to an upstream DNS server.</p>\n<p>We will go through each of these components in more detail step by step.</p>\n<h2 id=\"pod-foo\" style=\"position:relative;\"><a href=\"#pod-foo\" aria-label=\"pod foo permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Pod foo</h2>\n<p>When a pod sends an API request to a service within the same Kubernetes cluster, it must first resolve the IP address of the service. To do this, the pod performs a DNS lookup using the DNS server specified in its <a href=\"https://en.wikipedia.org/wiki/Resolv.conf\" target=\"_blank\" rel=\"noopener noreferrer\">/etc/resolv.conf</a> configuration file.</p>\n<p>This file, which is provisioned by the <code class=\"language-text\">Kubelet</code>, defines the settings for DNS lookups in the pod. It contains a reference to the cluster DNS server.</p>\n<p>By default, this configuration file looks something like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">search namespace.svc.cluster.local svc.cluster.local cluster.local\nnameserver <span class=\"token number\">10.123</span>.0.10\noptions ndots:5</code></pre></div>\n<h3 id=\"pod-config\" style=\"position:relative;\"><a href=\"#pod-config\" aria-label=\"pod config permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Pod config</h3>\n<p>By default, the <code class=\"language-text\">/etc/resolv.conf</code> file provided by the Kubelet will forward all DNS queries to the cluster's DNS server (10.123.0.10 in the example above). The Kubelet also defines search domains and the <code class=\"language-text\">ndots</code> option for DNS queries.</p>\n<p>The search domains specify which domain suffixes should be searched when incomplete domains (non-FQDNs) are given. The ndots option determines when a query for the absolute domain is made directly instead of first appending the search domains.</p>\n<p>To better understand how this works, let's look at an example. Suppose a pod named <code class=\"language-text\">foo</code> performs a DNS lookup for <code class=\"language-text\">bar.other-ns</code>. If the ndots option is set to 5 (the default value), the resolver will count the number of dots in the domain.</p>\n<p>If there are fewer than <strong>5 dots</strong>, the search domains will be appended before the DNS lookup is performed on the DNS server. If there are 5 or more dots, the domain will be queried as-is without appending the search domains.</p>\n<p>In this example, <code class=\"language-text\">bar.other-ns</code> has less than 5 dots, so the search domains will be appended before the DNS lookup is performed.</p>\n<p>By default, the search domains are:</p>\n<ul>\n<li>&#x3C;requester_namespace>.svc.cluster.local</li>\n<li>svc.cluster.local</li>\n<li>cluster.local</li>\n</ul>\n<p>Until a valid response is found, these search domains are appended to the domain and queried.</p>\n<p>The resolver will try the following queries one by one:</p>\n<ul>\n<li>bar.other-ns.&#x3C;requester_namespace>.svc.cluster.local</li>\n<li>bar.other-ns.svc.cluster.local (<em>‚áê match found!</em>)</li>\n</ul>\n<p>The bar service will be listening on <code class=\"language-text\">bar.other-ns.svc.cluster.local</code>, so a match is found and the proper <code class=\"language-text\">A-record</code> is returned.</p>\n<p>To change the behavior of a pod's DNS resolver, you can change the DNS config of a pod:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> default\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dns<span class=\"token punctuation\">-</span>example\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> test\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> nginx\n  <span class=\"token key atrule\">dnsPolicy</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"None\"</span>\n  <span class=\"token key atrule\">dnsConfig</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">nameservers</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> 1.2.3.4\n    <span class=\"token key atrule\">searches</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> ns1.svc.cluster<span class=\"token punctuation\">-</span>domain.example\n      <span class=\"token punctuation\">-</span> my.dns.search.suffix\n    <span class=\"token key atrule\">options</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> ndots\n        <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2\"</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> edns0</code></pre></div>\n<p>In the example above, the <code class=\"language-text\">dnsPolicy</code> is set to <strong>\"None\"</strong>, which means that the pod will not use the default DNS settings provided by the cluster.</p>\n<p>‚Üí Instead, the <code class=\"language-text\">dnsConfig</code> field is used to specify custom DNS settings for the pod.</p>\n<p>The <code class=\"language-text\">nameservers</code> field is used to specify the DNS servers that the pod should use for DNS lookups.</p>\n<p>The <code class=\"language-text\">searches</code> field is used to specify the search domains that should be used for incomplete domains.</p>\n<p>The <code class=\"language-text\">options</code> field is used to specify custom options for the DNS resolver, such as the <code class=\"language-text\">ndots</code> and <code class=\"language-text\">edns0</code> options in the example above.</p>\n<p>These settings will be used by the pod's DNS resolver instead of the default settings provided by the cluster. For more information on pod DNS configuration, <a href=\"https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config\" target=\"_blank\" rel=\"noopener noreferrer\">see the official docs</a>.</p>\n<h2 id=\"Ô∏è-authoritative-dnsserver\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-authoritative-dnsserver\" aria-label=\"Ô∏è authoritative dnsserver permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Authoritative DNS¬†server</h2>\n<p>In Kubernetes clusters up to version 1.13, <code class=\"language-text\">kube-dns</code> acted as the <strong>authoritative DNS server for Kubernetes</strong>. In Kubernetes version <code class=\"language-text\">1.13</code>, <a href=\"https://kubernetes.io/blog/2018/12/03/kubernetes-1-13-release-announcement/#coredns-is-now-the-default-dns-server-for-kubernetes\" target=\"_blank\" rel=\"noopener noreferrer\">CoreDNS replaced kube-dns</a> as the default component for authoritative DNS queries.</p>\n<p>The DNS server adds all services to its authoritative DNS zone, so that it can resolve domain names to IP addresses for Kubernetes services. Various software implementations exist for the authoritative DNS server in Kubernetes.</p>\n<p>CoreDNS is a popular choice, as it supports building a DNS zone from the Kubernetes service registry.</p>\n<p>It also offers extra features such as <code class=\"language-text\">caching</code>, <code class=\"language-text\">forwarding</code>, and <code class=\"language-text\">logging</code>.</p>\n<p>An example of a configuration file of CoreDNS:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\">.<span class=\"token punctuation\">:</span>53 <span class=\"token punctuation\">{</span>\n    errors\n    health <span class=\"token punctuation\">{</span>\n        lameduck 5s\n    <span class=\"token punctuation\">}</span>\n    ready\n    kubernetes cluster.local in<span class=\"token punctuation\">-</span>addr.arpa ip6.arpa <span class=\"token punctuation\">{</span>\n        fallthrough in<span class=\"token punctuation\">-</span>addr.arpa ip6.arpa\n        ttl 30\n    <span class=\"token punctuation\">}</span>\n    forward . /etc/resolv.conf\n    cache 30\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>Important to note are the kubernetes zone and the forward statement.</p>\n<h2 id=\"nodelocaldns\" style=\"position:relative;\"><a href=\"#nodelocaldns\" aria-label=\"nodelocaldns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Nodelocaldns</h2>\n<p>DNS queries are a common and essential part of network communication. They need to be processed quickly to avoid performance issues. Slow DNS queries can cause problems that are difficult to diagnose and troubleshoot.</p>\n<p>To improve the performance of DNS queries in a Kubernetes cluster, a cache layer can be added on each node using the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/\" target=\"_blank\" rel=\"noopener noreferrer\">nodelocaldns</a> component. This component caches the responses to DNS queries.</p>\n<p>If no response is found in the cache, it forwards the query to the authoritative nameserver (CoreDNS). The response is stored in the local cache so that it can be used to serve future queries from the same or other pods on the same node.</p>\n<p>This reduces the amount of network traffic between pods and the DNS server. This means lower latencies and faster DNS query performance. The function of <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/\" target=\"_blank\" rel=\"noopener noreferrer\">nodelocaldns</a> is often fulfilled by CoreDNS as well.</p>\n<h2 id=\"a-note-on-the-ttl-time-to-live-of-records-in-kubernetes\" style=\"position:relative;\"><a href=\"#a-note-on-the-ttl-time-to-live-of-records-in-kubernetes\" aria-label=\"a note on the ttl time to live of records in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>A note on the TTL (time-to-live) of records in Kubernetes</h2>\n<p>In Kubernetes, the <code class=\"language-text\">time-to-live (TTL)</code> of DNS records is determined by the <code class=\"language-text\">DNS server</code> implementation that is being used.</p>\n<p>By default, CoreDNS sets the TTL of DNS records to <code class=\"language-text\">30 seconds</code>. This means that when a DNS query is resolved, the response will be cached for up to 30 seconds before it is considered stale. The TTL of DNS records can be modified using the <code class=\"language-text\">ttl</code> option in the <code class=\"language-text\">CoreDNS configuration file</code>.</p>\n<p>The TTL of DNS records is an important parameter because it determines how long a DNS response will be considered valid before a new query must be made.</p>\n<p>A shorter TTL can improve the accuracy of DNS responses, but it can also increase the load on the DNS server. A longer TTL can reduce the load on the DNS server. However, it can also cause DNS responses to be outdated or inaccurate if the underlying DNS records are updated.</p>\n<p>Therefore, the appropriate TTL should be chosen based on the specific requirements of the cluster.</p>\n<h2 id=\"bonus-srvrecords\" style=\"position:relative;\"><a href=\"#bonus-srvrecords\" aria-label=\"bonus srvrecords permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Bonus: SRV¬†records</h2>\n<p>So far we've only talked about resolving IP addresses using A-records. Kubernetes also uses SRV (service) records to resolve the port numbers of named services. This allows clients to discover the port numbers of services by querying the DNS server for the appropriate SRV record.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  ports:\n    - port: <span class=\"token number\">80</span>\n      name: http</code></pre></div>\n<p>In this service, the container port 80 is exposed and is given the name <strong>\"http\"</strong>. Because the port is named, Kubernetes will <em>generate</em> an SRV record with the following name: <code class=\"language-text\">_&lt;port>._&lt;proto>.&lt;service>.&lt;ns>.svc.&lt;zone></code>.</p>\n<p>In this case, the SRV record will be named <code class=\"language-text\">_http._tcp.nginx.default.svc.cluster.local</code>. A DNS query for this record would return the port number and IP address of the named service:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">dig</span> +short SRV _http._tcp.nginx.default.svc.cluster.local\n<span class=\"token number\">0</span> <span class=\"token number\">100</span> <span class=\"token number\">80</span> <span class=\"token number\">10</span>-129-1-26.nginx.default.svc.cluster.local.</code></pre></div>\n<p>Some services, such as Kerberos, use SRV records for the discovery of the KDC (Key Distribution Center) servers.</p>\n<h2 id=\"putting-it-all-together\" style=\"position:relative;\"><a href=\"#putting-it-all-together\" aria-label=\"putting it all together permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Putting it all together</h2>\n<p>Whenever you create a pod, it gets assigned an IP.\nAny two pods in your cluster can talk to each other using their IP addresses.\nThe problem with using IP addresses for pods to talk to each other is that these IPs may change as pods get deleted and recreated.\nFor pods to consistently address each other correctly, you can use a Service.\nWhen you create a service using kubectl, the Kubernetes apiserver will save its data, and another pod called kubernetes-controller-manager will wake up and break that service down into two resources: Endpoints and EndpointSlices.\nCoreDNS will use those resources to know how to turn a service name into a service IP. Additionally, each node's kube-proxy pods will update the node's iptables rules. Those iptables rules cause requests to the service's IP to get addressed to the service's pods.\nFinally, when a pod makes a request, it will do a DNS query to CoreDNS to get the service's IP. Then, when sending packets to that IP, the iptables rules created by kube-proxy will cause the packets to get addressed to an actual pod's IP.</p>\n<h2 id=\"-a-few-morenotes\" style=\"position:relative;\"><a href=\"#-a-few-morenotes\" aria-label=\" a few morenotes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üí° A few more¬†notes</h2>\n<p>There are some missing more points, that I did not cover.</p>\n<p>Among those details is <a href=\"https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/\" target=\"_blank\" rel=\"noopener noreferrer\">how a pod gets assigned an IP</a> and <a href=\"https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/\" target=\"_blank\" rel=\"noopener noreferrer\">how iptables rules work</a>.\nI also haven't touched on <a href=\"https://github.com/containernetworking/cni\" target=\"_blank\" rel=\"noopener noreferrer\">CNI plugin implementations</a>, like <a href=\"https://www.tkng.io/cni/kindnet/\" target=\"_blank\" rel=\"noopener noreferrer\">Kindnet</a>.</p>\n<p>A tour through <a href=\"https://medium.com/techlog/diving-into-linux-networking-and-docker-bridge-veth-and-iptables-a05eb27b1e72\" target=\"_blank\" rel=\"noopener noreferrer\">container networking</a> itself would also be helpful for most readers.</p>\n<p>Finally, if you want to learn more about CoreDNS itself, <a href=\"https://www.youtube.com/watch?v=qRiLmLACYSY\" target=\"_blank\" rel=\"noopener noreferrer\">this talk is a great start</a>.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h2>\n<p>In this blog post, we explored how pods in Kubernetes networks talk to each other. We learned about the different components involved in Kubernetes DNS, and how they work together to resolve DNS queries. We also explored some of the challenges of Kubernetes DNS, and how to overcome them.</p>\n<p><em>We hope that you have found this blog post helpful. If you have any other tips or tricks that you would like to share, please leave a comment below.</em>\n<br><br></p>\n<div style=\"width:100%;height:0;padding-bottom:83%;position:relative;\"><iframe src=\"https://giphy.com/embed/TNnyxINX87VAKbNYmZ\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe></div>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <em><strong>Until next time üéâ</strong></em></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":10,"rawMarkdownBody":"\n> **Kubernetes DNS Expeditionüî•**\n\n## üìö Introduction\n\nKubernetes is an orchestration system for managing containerized applications. One of its key features is DNS, which allows pods to communicate with each other using DNS names instead of IP addresses.\n\nIn this blog post, we will walk through the life of a DNS query in Kubernetes, from when a pod performs a lookup to when it receives the IP address of the requested hostname. We will also discuss how DNS plays a role in service discovery, which is the process of routing incoming requests to the correct workloads running in the cluster.\n\nBy understanding how DNS works in Kubernetes, you will be better equipped to debug issues and troubleshoot problems with your applications.\n\n## Pods communication in Kubernetes\n\nUsing IP addresses to communicate between pods presents two key challenges:\n\n* **Dynamic IP assignment:** Pods can be assigned new IP addresses during creation, scaling, or restarts. Tracking these changing addresses and updating configurations becomes complex and error-prone.\n* **External accessibility limitation:** Pods' IP addresses are not reachable outside the Kubernetes cluster due to non-routability. To access pods externally, a service is required.\n\nServices address these issues by establishing a consistent name for a pod group:\n\n* `Stable Communication:` Pods can refer to the service name instead of dynamic IP addresses when connecting to other pods. The service efficiently routes traffic to the intended pod.\n\n\nBeyond IP-related challenges, services offer several advantages:\n\n* **Load balancing:** Traffic distribution across pods enhances application performance by maintaining balanced workloads.\n* **High availability:** Service configuration ensures traffic redirection to functioning pods if one fails, ensuring uninterrupted application availability.\n* **DNS resolution:** Services can be registered with Kubernetes DNS, enabling easy pod-to-pod connectivity without needing to know individual pod IP addresses.\n\n## üóù Kubernetes DNS and Service discovery\n\nIn Kubernetes, service discovery relies on the essential component of DNS (Domain Name System). Service resources facilitate service discovery by associating an IP address with a healthy pod, enabling seamless connections.\n\nUpon creating a `service`, the Kubernetes cluster's `DNS server` generates an `A record`, mapping the `service's DNS name` to its `IP address`.\n\nConsequently, pods can conveniently access the service using its DNS name. The DNS server dynamically updates the A record to reflect changes in the service's IP address, ensuring accuracy.\n\nThe **Domain Name System (DNS)** is a mechanism that connects user-friendly names, like domain names, to corresponding IP addresses. This translation simplifies end-users' access to target domains. Kubernetes clusters incorporate an internal DNS service by default, ensuring efficient service discovery even as pods and services are created, shifted, or removed across nodes.\n\nRecent Kubernetes versions transitioned from `kube-dns` to `CoreDNS` to address security and stability concerns, with CoreDNS introduced in version `1.11`.\n\nBoth implementations function similarly:\n\n* A `kube-dns` service and one or more pods are created.\n* The `kube-dns` service monitors the Kubernetes API for service and endpoint events and changes its DNS entries as appropriate. When you modify these Kubernetes services and their related pods with creating, editing, or deleting operations, these events are auto-triggered.\n* `Kubelet` assigns the `cluster IP` of the kube-dns service to every new pod `etc/resolv.conf` nameserver option, along with suitable search settings to allow for shorter hostnames:\n\n    ```shell\n    nameserver 10.32.0.10\n    search namespace.svc.cluster.local svc.cluster.local cluster.local\n    options ndots:5\n    ```\n\nContainerized applications may then resolve hostnames like `example-service.namespace` to the appropriate cluster IP address.\n\n![alt text](./dns-server.png)\n\n## Overview of the Kubernetes DNS¬†Records\n\nLet's understand Kubernetes DNS records better with the help of an example. \n\nThe entire DNS A record for a Kubernetes service will look like:\n\n```shell\nservice.namespace.svc.cluster.local\n```\n\nA pod would have a record in this format, which would represent the pod's real IP address:\n\n```shell\n10-32-0-125.namespace.pod.cluster.local\n```\n\nBesides, **SRV records** are created for the specified **ports** of a Kubernetes service:\n\n```shell\n_port-name._protocol.service.namespace.svc.cluster.local\n```\n\nAs a result, your `application` or `microservice` may hit a simple and consistent hostname to reach other services or pods on the cluster, thanks to the built-in DNS-based service discovery mechanism.\n\n### Resolving shorter hostnames and searching domains\n\nYou won't always need to utiuselize the whole hostname to access another service because of the search domain suffixes set in the `resolv.conf` file. \n\nIf you're contacting a service in the same namespace, you may just call it by its name:\n\n```shell\nother-service\n```\n\nAdd `other-namespace` to the query if the service is in a different namespace:\n\n```shell\nother-service.other-namespace\n```\n\nYou'll need to use at least the following if you're going after a pod:\n\n```shell\npod-ip.other-namespace.pod\n```\n\nOnly the `.svc` suffixes are automatically completed in the default `resolv.conf` file.\nTherefore, it is essential to specify the settings up to¬†`.pod`.\n\nAn example service definition looks like this:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: foo\n  namespace: bar\nspec:\n  ports:\n    - port: 80\n      name: http\n```\n\nThe `A record` and `SRV record` (discussed later in the article) that are created in this instance look like this:\n\n```shell\nfoo.bar.svc.cluster.local                  30   A   10.129.1.26\n_http._tcp.nginx.default.svc.cluster.local 3600 SRV 0 100 80 10-129-1-26.foo.bar.svc.cluster.local.\n```\n\nTo create the fully qualified domain name FQDN for this service, we use the name of the **service (foo)**, the **namespace (bar**), and the cluster domain **(cluster.local)**.\n\nAny workload running in the cluster can now resolve the service's IP address using this DNS name.\n\n### DNS lookups on¬†services\n\n![alt text](./dns-lookup.png)\n\nWhen a pod performs a DNS lookup, the query is first sent to the local DNS resolver in the pod. This resolver uses the `resolv.conf` configuration file. In this file, the [nodelocaldns](https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/) server is set up as the default recursive DNS resolver, which acts as a cache.\n\nIf this cache does not contain the IP address for the requested hostname, the query is forwarded to the cluster DNS server ([CoreDNS](https://coredns.io/)).\n\nThis DNS server determines the IP address by consulting the Kubernetes service registry. This registry contains a mapping of service names to their corresponding IP addresses. This allows the cluster DNS server to return the correct IP address to the requesting pod.\n\nAny domains that are queried but are not in the Kubernetes service registry are forwarded to an upstream DNS server.\n\nWe will go through each of these components in more detail step by step.\n\n## Pod foo\n\nWhen a pod sends an API request to a service within the same Kubernetes cluster, it must first resolve the IP address of the service. To do this, the pod performs a DNS lookup using the DNS server specified in its [/etc/resolv.conf](https://en.wikipedia.org/wiki/Resolv.conf) configuration file.\n\nThis file, which is provisioned by the `Kubelet`, defines the settings for DNS lookups in the pod. It contains a reference to the cluster DNS server.\n\nBy default, this configuration file looks something like this:\n\n```shell\nsearch namespace.svc.cluster.local svc.cluster.local cluster.local\nnameserver 10.123.0.10\noptions ndots:5\n```\n\n### Pod config\n\nBy default, the `/etc/resolv.conf` file provided by the Kubelet will forward all DNS queries to the cluster's DNS server (10.123.0.10 in the example above). The Kubelet also defines search domains and the `ndots` option for DNS queries.\n\nThe search domains specify which domain suffixes should be searched when incomplete domains (non-FQDNs) are given. The ndots option determines when a query for the absolute domain is made directly instead of first appending the search domains.\n\nTo better understand how this works, let's look at an example. Suppose a pod named `foo` performs a DNS lookup for `bar.other-ns`. If the ndots option is set to 5 (the default value), the resolver will count the number of dots in the domain.\n\nIf there are fewer than **5 dots**, the search domains will be appended before the DNS lookup is performed on the DNS server. If there are 5 or more dots, the domain will be queried as-is without appending the search domains. \n\nIn this example, `bar.other-ns` has less than 5 dots, so the search domains will be appended before the DNS lookup is performed.\n\nBy default, the search domains are:\n\n* <requester_namespace>.svc.cluster.local\n* svc.cluster.local\n* cluster.local\n\nUntil a valid response is found, these search domains are appended to the domain and queried.\n\nThe resolver will try the following queries one by one:\n\n* bar.other-ns.<requester_namespace>.svc.cluster.local\n* bar.other-ns.svc.cluster.local (_‚áê match found!_)\n\nThe bar service will be listening on `bar.other-ns.svc.cluster.local`, so a match is found and the proper `A-record` is returned.\n\nTo change the behavior of a pod's DNS resolver, you can change the DNS config of a pod:\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  namespace: default\n  name: dns-example\nspec:\n  containers:\n    - name: test\n      image: nginx\n  dnsPolicy: \"None\"\n  dnsConfig:\n    nameservers:\n      - 1.2.3.4\n    searches:\n      - ns1.svc.cluster-domain.example\n      - my.dns.search.suffix\n    options:\n      - name: ndots\n        value: \"2\"\n      - name: edns0\n```\n\nIn the example above, the `dnsPolicy` is set to **\"None\"**, which means that the pod will not use the default DNS settings provided by the cluster.\n\n‚Üí Instead, the `dnsConfig` field is used to specify custom DNS settings for the pod.\n\nThe `nameservers` field is used to specify the DNS servers that the pod should use for DNS lookups.\n\nThe `searches` field is used to specify the search domains that should be used for incomplete domains.\n\nThe `options` field is used to specify custom options for the DNS resolver, such as the `ndots` and `edns0` options in the example above.\n\nThese settings will be used by the pod's DNS resolver instead of the default settings provided by the cluster. For more information on pod DNS configuration, [see the official docs](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config).\n\n\n## üõ†Ô∏è Authoritative DNS¬†server\n\nIn Kubernetes clusters up to version 1.13, `kube-dns` acted as the **authoritative DNS server for Kubernetes**. In Kubernetes version `1.13`, [CoreDNS replaced kube-dns](https://kubernetes.io/blog/2018/12/03/kubernetes-1-13-release-announcement/#coredns-is-now-the-default-dns-server-for-kubernetes) as the default component for authoritative DNS queries.\n\nThe DNS server adds all services to its authoritative DNS zone, so that it can resolve domain names to IP addresses for Kubernetes services. Various software implementations exist for the authoritative DNS server in Kubernetes.\n\nCoreDNS is a popular choice, as it supports building a DNS zone from the Kubernetes service registry.\n\nIt also offers extra features such as `caching`, `forwarding`, and `logging`.\n\nAn example of a configuration file of CoreDNS:\n\n```yaml\n.:53 {\n    errors\n    health {\n        lameduck 5s\n    }\n    ready\n    kubernetes cluster.local in-addr.arpa ip6.arpa {\n        fallthrough in-addr.arpa ip6.arpa\n        ttl 30\n    }\n    forward . /etc/resolv.conf\n    cache 30\n}\n```\n\nImportant to note are the kubernetes zone and the forward statement.\n\n## Nodelocaldns\n\nDNS queries are a common and essential part of network communication. They need to be processed quickly to avoid performance issues. Slow DNS queries can cause problems that are difficult to diagnose and troubleshoot.\n\nTo improve the performance of DNS queries in a Kubernetes cluster, a cache layer can be added on each node using the [nodelocaldns](https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/) component. This component caches the responses to DNS queries.\n\nIf no response is found in the cache, it forwards the query to the authoritative nameserver (CoreDNS). The response is stored in the local cache so that it can be used to serve future queries from the same or other pods on the same node.\n\nThis reduces the amount of network traffic between pods and the DNS server. This means lower latencies and faster DNS query performance. The function of [nodelocaldns](https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/) is often fulfilled by CoreDNS as well.\n\n## A note on the TTL (time-to-live) of records in Kubernetes\n\nIn Kubernetes, the `time-to-live (TTL)` of DNS records is determined by the `DNS server` implementation that is being used.\n\nBy default, CoreDNS sets the TTL of DNS records to `30 seconds`. This means that when a DNS query is resolved, the response will be cached for up to 30 seconds before it is considered stale. The TTL of DNS records can be modified using the `ttl` option in the `CoreDNS configuration file`.\n\nThe TTL of DNS records is an important parameter because it determines how long a DNS response will be considered valid before a new query must be made.\n\nA shorter TTL can improve the accuracy of DNS responses, but it can also increase the load on the DNS server. A longer TTL can reduce the load on the DNS server. However, it can also cause DNS responses to be outdated or inaccurate if the underlying DNS records are updated.\n\nTherefore, the appropriate TTL should be chosen based on the specific requirements of the cluster.\n\n## Bonus: SRV¬†records\n\nSo far we've only talked about resolving IP addresses using A-records. Kubernetes also uses SRV (service) records to resolve the port numbers of named services. This allows clients to discover the port numbers of services by querying the DNS server for the appropriate SRV record.\n\n```shell\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  ports:\n    - port: 80\n      name: http\n```\n\nIn this service, the container port 80 is exposed and is given the name **\"http\"**. Because the port is named, Kubernetes will _generate_ an SRV record with the following name: `_<port>._<proto>.<service>.<ns>.svc.<zone>`.\n\nIn this case, the SRV record will be named `_http._tcp.nginx.default.svc.cluster.local`. A DNS query for this record would return the port number and IP address of the named service:\n\n```shell\ndig +short SRV _http._tcp.nginx.default.svc.cluster.local\n0 100 80 10-129-1-26.nginx.default.svc.cluster.local.\n```\n\nSome services, such as Kerberos, use SRV records for the discovery of the KDC (Key Distribution Center) servers.\n\n## Putting it all together\n\nWhenever you create a pod, it gets assigned an IP.\nAny two pods in your cluster can talk to each other using their IP addresses.\nThe problem with using IP addresses for pods to talk to each other is that these IPs may change as pods get deleted and recreated.\nFor pods to consistently address each other correctly, you can use a Service.\nWhen you create a service using kubectl, the Kubernetes apiserver will save its data, and another pod called kubernetes-controller-manager will wake up and break that service down into two resources: Endpoints and EndpointSlices.\nCoreDNS will use those resources to know how to turn a service name into a service IP. Additionally, each node's kube-proxy pods will update the node's iptables rules. Those iptables rules cause requests to the service's IP to get addressed to the service's pods.\nFinally, when a pod makes a request, it will do a DNS query to CoreDNS to get the service's IP. Then, when sending packets to that IP, the iptables rules created by kube-proxy will cause the packets to get addressed to an actual pod's IP.\n\n\n## üí° A few more¬†notes\n\nThere are some missing more points, that I did not cover.\n\nAmong those details is [how a pod gets assigned an IP](https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/) and [how iptables rules work](https://ronaknathani.com/blog/2020/07/kubernetes-nodeport-and-iptables-rules/).\nI also haven't touched on [CNI plugin implementations](https://github.com/containernetworking/cni), like [Kindnet](https://www.tkng.io/cni/kindnet/).\n\nA tour through [container networking](https://medium.com/techlog/diving-into-linux-networking-and-docker-bridge-veth-and-iptables-a05eb27b1e72) itself would also be helpful for most readers.\n\nFinally, if you want to learn more about CoreDNS itself, [this talk is a great start](https://www.youtube.com/watch?v=qRiLmLACYSY).\n\n## Conclusion\n\nIn this blog post, we explored how pods in Kubernetes networks talk to each other. We learned about the different components involved in Kubernetes DNS, and how they work together to resolve DNS queries. We also explored some of the challenges of Kubernetes DNS, and how to overcome them.\n\n_We hope that you have found this blog post helpful. If you have any other tips or tricks that you would like to share, please leave a comment below._\n<br><br>\n\n\nhttps://giphy.com/gifs/theoffice-TNnyxINX87VAKbNYmZ\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  _**Until next time üéâ**_\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":2328},"frontmatter":{"id":"4532d72916bcebb84b4fc1ad","path":"/blog/kubernetes-dns/","humanDate":"Oct 15, 2024","fullDate":"2024-10-15","title":"Connecting the Dots: Understanding How Pods Talk in Kubernetes Networks","keywords":["Kubernetes","DNS","Pods communication","Kubernetes networking","Service discovery","Cluster DNS","Kubernetes architecture"],"excerpt":"Discover Kubernetes networking and how DNS plays a major role in enabling  communication between pods, mechanisms behind service discovery and the architecture that supports pod interactions within a Kubernetes cluster.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABAAF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgAB/9oADAMBAAIQAxAAAAHUOw6K6rf/xAAZEAEAAwEBAAAAAAAAAAAAAAACAAEDEhH/2gAIAQEAAQUC1XJOr6iNKs8x7P/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABwQAAEDBQAAAAAAAAAAAAAAAAABEBECITFBUf/aAAgBAQAGPwK3RJ20VIYb/8QAGRABAAMBAQAAAAAAAAAAAAAAAREhMQAQ/9oACAEBAAE/IWJ0w3oDlRT4/kHWuyy/P//aAAwDAQACAAMAAAAQp8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEAAgIDAQAAAAAAAAAAAAABESEAEEFRkXH/2gAIAQEAAT8QGVSCIcLfmQAEtGpfmgYHcPeCrIyKYfdf/9k="},"images":{"fallback":{"src":"/static/b495943511b81e43c53fccee051c3f76/4d9e1/k8s-dns-cover.jpg","srcSet":"/static/b495943511b81e43c53fccee051c3f76/e76e5/k8s-dns-cover.jpg 750w,\n/static/b495943511b81e43c53fccee051c3f76/5c98f/k8s-dns-cover.jpg 1080w,\n/static/b495943511b81e43c53fccee051c3f76/4d9e1/k8s-dns-cover.jpg 1163w","sizes":"100vw"},"sources":[{"srcSet":"/static/b495943511b81e43c53fccee051c3f76/47593/k8s-dns-cover.webp 750w,\n/static/b495943511b81e43c53fccee051c3f76/705ed/k8s-dns-cover.webp 1080w,\n/static/b495943511b81e43c53fccee051c3f76/d3913/k8s-dns-cover.webp 1163w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5382631126397248}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/kubernetes-networking/","title":"Kube-Proxy and CNI: The Hidden Components of Kubernetes Networking","date":"2024-10-15 20:06:00"},"excerpt":"A Guide to Network Management in Kubernetes üï∏ üìå Overview Kubernetes networking is a complex and fascinating topic, with many moving parts‚Ä¶","html":"<blockquote>\n<p><strong>A Guide to Network Management in Kubernetes üï∏</strong></p>\n</blockquote>\n<h2 id=\"-overview\" style=\"position:relative;\"><a href=\"#-overview\" aria-label=\" overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Overview</h2>\n<p>Kubernetes networking is a complex and fascinating topic, with many moving parts. <code class=\"language-text\">Kube-Proxy</code> and <code class=\"language-text\">CNI</code> are two essential components of Kubernetes networking, working together to enable excellent communication between various components.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/components/#kube-proxy\" target=\"_blank\" rel=\"noopener noreferrer\">Kube-Proxy</a> is a network proxy that runs on each node in a Kubernetes cluster. It is responsible for maintaining network connectivity between services and pods. Kube-Proxy does this by translating service definitions into actionable networking rules.</p>\n<p><a href=\"https://www.cni.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">CNI</a>, The Container Network Interface (CNI) is a specification for configuring networking resources in Kubernetes. CNI provides a dynamic framework for provisioning IP addresses, establishing cross-host connectivity, and configuring overlay or underlay networks.</p>\n<p>This blog post will explore the inner workings of <strong>Kube-Proxy</strong> and <strong>CNI</strong>, and dive into how they integrate with Kubernetes. We will also discuss different Kubernetes network plugins.</p>\n<h2 id=\"-kube-proxy-kubernetes-networkproxy\" style=\"position:relative;\"><a href=\"#-kube-proxy-kubernetes-networkproxy\" aria-label=\" kube proxy kubernetes networkproxy permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚Ü≥ Kube-Proxy: Kubernetes network¬†proxy</h2>\n<p>In Kubernetes, the ephemeral nature of Pods means their IP addresses can change, making it challenging to establish stable connections ü§î. This is where the Service object comes into play. Services provide a consistent IP address to access Pods and are linked to a group of Pods. When traffic arrives at a Service, it is intelligently directed to the relevant backend Pods.</p>\n<p>But how does this mapping of <em><code class=\"language-text\">Service to Pod</code></em> actually function at the networking level? This is where Kube-Proxy excel.</p>\n<p>Kube-Proxy serves as a vital Kubernetes agent that resides on each node within the cluster. Its primary role involves monitoring changes to Service objects and their corresponding endpoints. It then translates these changes into tangible network rules within the node.</p>\n<p>Typically, Kube-Proxy operates within your cluster as a DaemonSet. However, depending on your cluster's installation type, it can also be directly installed as a Linux process on the node. Regardless of the setup, Kube-Proxy is the unsung hero ensuring that your network traffic efficiently reaches the right destinations in your Kubernetes cluster.</p>\n<h3 id=\"-how-kube-proxy-works\" style=\"position:relative;\"><a href=\"#-how-kube-proxy-works\" aria-label=\" how kube proxy works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üí≠ How Kube-proxy works</h3>\n<p>Once <code class=\"language-text\">kube-proxy</code> is installed, it establishes authentication with the <code class=\"language-text\">API server</code>. As new <strong>Services</strong> or <strong>endpoints</strong> are introduced or removed, the API server promptly communicates these changes to Kube-Proxy.</p>\n<p>Kube-Proxy takes these updates and translates them into <code class=\"language-text\">Network Address Translation (NAT)</code> rules within the node.</p>\n<blockquote>\n<p>These NAT rules are essentially mappings, linking Service IP addresses to Pod IP addresses.</p>\n</blockquote>\n<p>When traffic is directed towards a Service, it adheres to these rules, leading it to the appropriate backend Pod.</p>\n<p>To illustrate this process further, let's consider an example:</p>\n<p>Imagine we have a Service named <code class=\"language-text\">SVC01</code> with a <code class=\"language-text\">ClusterIP</code> type. When <code class=\"language-text\">SVC01</code> is created, the API server examines which Pods should be associated with this Service by matching labels to the Service's label selector. In our case, let's call these Pods <code class=\"language-text\">Pod01</code> and <code class=\"language-text\">Pod02</code>. Subsequently, the API server creates an abstraction known as an <code class=\"language-text\">endpoint</code>, representing the IP address of each of these Pods. So, <code class=\"language-text\">SVC01</code> becomes linked to <code class=\"language-text\">2 endpoints</code>, denoted as <code class=\"language-text\">EP01</code> and <code class=\"language-text\">EP02</code>.</p>\n<p>In the final step, the API server maps the IP address of <code class=\"language-text\">SVC01</code> to the IP addresses of <code class=\"language-text\">EP01</code> and <code class=\"language-text\">EP02</code>, solidifying the connection between the Service and its associated endpoints.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 33.529411764705884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABBUlEQVR42qWRbUvDMBSF9///hh98GTg7REGHOm1FBWEyNhlzXWre2s7aOgZit+SYJtYXFD/ohYdz7yUcTpIGPpVSyvKfakRRBEopCCHgnENKiTRNUJalPTBfPGNEZgjZIybUcUczSz2PowxZvnCGlDIIITEYDFEUT1gpjZdyieVb0inPsd4J4QUcrTOG7VNq1fOF1R2fYeuYoj9OnKHW5qoGq6pCW62Mq33IcrS699i/TCzNwxHWdnvYPLjF3kVsdjHagcRwMnOGX19Af3Ta9UQU2OgQtM+lSSMMdVJmZy8QaHa5SZj+ZIhvhvHDHEdXBMGNgN/j79RzYDi5ppiy7HfDv/7yK3B6Dj0s9oEpAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/5da025a9baa720d754be3a179a090889/c5bb3/step1.png\" srcset=\"/static/5da025a9baa720d754be3a179a090889/04472/step1.png 170w,\n/static/5da025a9baa720d754be3a179a090889/9f933/step1.png 340w,\n/static/5da025a9baa720d754be3a179a090889/c5bb3/step1.png 680w,\n/static/5da025a9baa720d754be3a179a090889/b12f7/step1.png 1020w,\n/static/5da025a9baa720d754be3a179a090889/00172/step1.png 1044w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 101.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAACxUlEQVR42o2S+U8TURDH+/caE7wCxgT0ByP+YAyJJkYhxgBBQaStlDaiorT0oByViOFI7727u23pvVe/vvegpSiFvmQys3N83sy8dWHA4zgOms0myuUyCoUCVFVFsVhEvV6Hbdssp91uwzUIrNVqdSGNRoMVUgi1OxdUq1WWey3QsiyIosg6pEXpdBr5fJ75qBYEgeVRKO22L5B2QQ8di3ZCj6IoSCaTDEp1NptlPnroOmjutcBSqYRarcZsjuO6IArNZDLM1wHqun79yHRXkiTBNE1m53I5BqM6lUp1dyrLMrNdnW76CokbhkkKFDYS9dGO6T6ppo/SgQ30KBf2qWtEVFQrJ6hUKgxGoZ04A1qWjY3dDNZ3OAR3eyXfIxxCCQ5r8TRWo0ls/+HpLZde6jJMC+6fSXwKClgK8mciwL0hwkOE6o7fs0FyQiICkQz5jezuWnqPyyRAfzgDX0zGSkyEf1OGN5TH26U4ppcTmPb9wnKEJzGJyXJEwvetHAE5l67nH+BpkS8iMKg7mIMnlGMXdYHRAYDe9RTcZBRPSDgXMqo3LDHd66fr+BLN9gfSf2v3SMbWkYrtXjlUEN8XiC5c8McPVfxOKv89ShdIl9rSRRhaHmaRI8LDUHMwTjRW0ypK5JvEdB6WzjPbKBf6/mIu02iBX3wCcWYEmxM3sPdqCOrsPUhrM2iaDgTvc6hzI4iR2NaLm8QeBh94Dacf0DYNyN5nkN8/gDw/hhPPYzTdYyiGF9CyHKiBl1BITOrEPI+g/XjXH+hYJrKL4ziYvMOKmivjqC2NQg/Pw7Ad8J8ncDR1G/yHUTR846i7H0JduwJIR9a8T6GQMZNTt6DM3Ud9YRja+iwbWfdPQJu9i+PJodPYxxEUvr65YmTyytp+CFzMj0x0BUriG/TEKkrpPdhOG/pBFMJmgMT8KJzF9OMdtPsA/wJD+sc6L4oSlgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/4b8d8cbb049ae99e91ee2d8690609698/c5bb3/step2.png\" srcset=\"/static/4b8d8cbb049ae99e91ee2d8690609698/04472/step2.png 170w,\n/static/4b8d8cbb049ae99e91ee2d8690609698/9f933/step2.png 340w,\n/static/4b8d8cbb049ae99e91ee2d8690609698/c5bb3/step2.png 680w,\n/static/4b8d8cbb049ae99e91ee2d8690609698/f3c12/step2.png 764w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 77.05882352941177%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB8UlEQVR42pWSbVPaQBSF+f+/oOMX25m2M1qomlHrOC2CVLQgYxWh1IQEGkISQkJeCPCB5Lh3IamMtk135mQ3d3efPffu5pCxxXGM6XQK13UxmUw2RPEoivi6XBYYLR6Px7BtG5ZlwfM8DvZ9fyO+XC6zAR3HwXw+RxAE6Ha7kCQJoiii3++j0+lwh4vFgoMzAU3T5CmTI0VRUqCqqvwAcpysywSk9MgduSBQu93m7mRZRrPZxGw2QxiGPJPc76L/WRH72LaDEatTAidXJIIkdaRa5/AfLZz6cCc2ZmHAbtfhMDqAHFJJSLnkSciqhaZooCWZL+qezXWUMaqNB9RuZQTTeZrZ07YCRkuUGioK50McfB1if629ipYq+T+8NLFT7EEbeen7jJ9QU2DlZgDhUsfxlY4jpuNvBpOJk7qFT7URjyXxQqkH3fJT4DOHEQOeM+DBhc4cDNlGA3vlHt4IN3h7dIed0w6L61w0lz8joJcFaKSbhAuNOVGQL0oonMk8RnPkOs8cDv8FrHzXIFQN7JcVfPj8gPwXkblMgN1VjI0Pqxo+lvt/T5lqWLz+hd2SincnP7BVqGErX8Nr4Q6vdq/YuM61Ldwyd328P5U2LuU5MI7wUxmh0dZx3VJZP2DS0Git+7VWcxrq9wO4fvjis3kEEgNgZwmQNEgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/fdf3dd3d45f21eaafabdd5e911f94490/c5bb3/step3.png\" srcset=\"/static/fdf3dd3d45f21eaafabdd5e911f94490/04472/step3.png 170w,\n/static/fdf3dd3d45f21eaafabdd5e911f94490/9f933/step3.png 340w,\n/static/fdf3dd3d45f21eaafabdd5e911f94490/c5bb3/step3.png 680w,\n/static/fdf3dd3d45f21eaafabdd5e911f94490/63ec5/step3.png 812w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>All of this configuration is currently only part of the control plane. We want this mapping to be actually implemented on the network. Once it is applied, traffic coming to the IP of <code class=\"language-text\">SVC01</code> will be forwarded to <code class=\"language-text\">EP01</code> or <code class=\"language-text\">EP02</code>.</p>\n<p>So here comes the <code class=\"language-text\">Kube-Proxy</code>. The API server will advertise these updates to the Kube-proxy on each node. Which will apply it as internal rules to the node.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 107.05882352941177%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsTAAALEwEAmpwYAAACAklEQVR42u2U246bMBCG9/0fpDfVtk2aVL2peshp8wCVsupmSTiDAuYQIEDg3xknbEFhs937Iv0aezz+PNge36Dnyw4FVEt0Zfpk/ZbPR54XF3Nv2p26rqV1dhE+/NLxaWpKDWY2BnPSzDr7yE40eGLfmdcDPFnXi/B5bmB8Z2G8tPHxp4LbH48YTLWT787GeKHDD/4R6BBwODMwWpwmv//2B+++/sbt97Xss380fytwbmLEk0lflq7UeOmcfWQXBgGTzrwrexhiMNlgOFXJbmm/ttKeRD7yDycKvNcybL6yPMIPU4goQ5wWiJICcZLLdhBnciyMUxyPx+un3MmWlGYZwkAgjiPEUQQhfCRJgqrGi18vkH+hIiuEwOr+HoqiYLVaQdN1FEWBIxGrur4OTNMUQRAgDEP4IiDYqc3wRnmeIyJfQGOeJ6TlRXmRC6DvedA1TerhUYVO2XC7veH7/V76LNOAstWgaobsp0ny/Gd/gb4PgyDr9RqbzQaGYcAkVVXVAVqmKccfKE5VVdnvB1KGDHAdB45ty0BeoJ1hQkCOsS1LxrCVGdJ29WZonrNiXQPyWKNXge3g/8C3AT06ZQZwUHMwffewiWmk0dXpvTb54YB9HFPtBrIaOBtW+23ix4BrmcefY6jffiQ6tcyX2KL7tdvtXix+zsJ1XamyLC9q+QlhAkBvqNvlwQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/7ae096e07f595ac802b4837c7ec36a3b/c5bb3/step4.png\" srcset=\"/static/7ae096e07f595ac802b4837c7ec36a3b/04472/step4.png 170w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/9f933/step4.png 340w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/c5bb3/step4.png 680w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/b12f7/step4.png 1020w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/e996b/step4.png 1050w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 118.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAYAAAD6S912AAAACXBIWXMAAAsTAAALEwEAmpwYAAACyklEQVR42p1UaU/bQBDl//+MfmypWq70UwVtgQISFVSClMRxfB+5SJo4sXNN35s0hyEWtJaednd25828nfHuyJZvPJlIs/P7RcStrgxHWc53Z3Mxn891jFs92Tt15eDcX+PMWwPro4tA3h7Xpeq01Wf217eQcP8skMPv0QIXsZSumvLpqgGiWG2ly1h2TxwQdl5L6MMxBEEkH7/a8ubgRvH+2FRbCdg9sf8lwwUhQYkfvliKfUimrXT5z4QbkgFKPYLMw4vofyR3Ze+bhQKgMKeOYn8FW8ejc0/efTakareKCZffdDaTJBlJfzBCW6QySjMdiTQby2CY6l4yHMoELVbYNvlsRbJsIiM4DYHRaKTj4+MjiBJktN2vkHA6ExkkiZTLZeCXVCpVubu7E9d1JQU592dbWFeE0+lUMYPcyWSKv2WqchKQpmmqGXKeZZnaU1xDAuljrGkbj8drQh5wbFs8RPdcT0zT0bnrOEqyWTBK5l7g+2LbrliA77kShaGeWRHyUAhj4Adiu4E0Gg21bSNkoEYciYezjhvqPAyCPKHveZqlYVTFrBniI4MiQs0eqNfrCp59liGj0hiFiAZw7iFIESEz8pFhFC2yC3OEuFDeSRMygyBEdESkQwEh7QzIcxYyJOi/KgorW76/lx/X12iPyiLyKwgdx5Oft7dye3OjCnNVZpS6aeIeUWHPhwz/BUIGDCSG5EYc5++QPRQgo1azgexCtEMgTVSOF58MBs8IKY9ENctD4FDXxIqQDc1qmbWaWJaFSi/GXrcrgy2EJpVAogU1BnxYkF6vlydstVp6mBscCWb+VDL3O+227vf7fWljzqA8uybEHVZRjMrDg9QQkYXhmvfyNMNOp6P/t2EYqopzjrSvCDlhYRiFL0qGf5dB+I8uiZYfO4KKeI7B6Mf18hnLvTaUx7uhfDoWP21zbWg2Ph+NzdfmD0dlGDKUOQMRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/21a523135ce7fd8705e614f56cb2fb8e/c5bb3/step5.png\" srcset=\"/static/21a523135ce7fd8705e614f56cb2fb8e/04472/step5.png 170w,\n/static/21a523135ce7fd8705e614f56cb2fb8e/9f933/step5.png 340w,\n/static/21a523135ce7fd8705e614f56cb2fb8e/c5bb3/step5.png 680w,\n/static/21a523135ce7fd8705e614f56cb2fb8e/cc488/step5.png 928w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Now traffic destined for the <code class=\"language-text\">SVC01</code> IP will follow this <a href=\"https://en.wikipedia.org/wiki/Network_address_translation#DNAT\" target=\"_blank\" rel=\"noopener noreferrer\">DNAT</a> rule and get forwarded to the Pods.</p>\n<blockquote>\n<p>Remember that <code class=\"language-text\">EP01</code> and <code class=\"language-text\">EP02</code> are basically the IPs of the Pods.</p>\n</blockquote>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 81.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACiUlEQVR42oWU208TQRTG+acVHogaY4xGE+OLz0qCiRJQU57gzdBoCApewGK3271fu+1utxbpbvt5vim7UgxxkpOZ3fnmd86cMzNLkFYUxbU2nU5RtbIsMeF/6YuinPdqXKg5tiUucF0XtmXBti0ZO3AcG5Z809I0rYG9Xg9GtwvH6MA1u2I67G4HltFFEIaYzWYCLAv4YQzvYBfB9lN8f/0YP7eeoL/zDNa3faTDUQ1MBhnMrx8RNx7hZP0uWi/voffuIdwPDUTJALNpOQd6UYKwuYX81TLMFzfgr6/g99Yq7MP3SPNfC0D7aA+jzVW4ojHXlpHJmnBvA2GSLgLd5ltkm7cw2n6AvHEf2Zs7sGTxVaD1pYnexm2Y66s4fb4Ca+0mAgmmBjKZvh/A67bhtQ5hnXyCeXwA98chbF1DmmV/gUkCS/65oqPWOz0S3WfYWgtRFKsCqqI4tg1N68AwbeiGCcfzEYiAxbpclESK4jiOFCCWvEfwgmje+z4iKcqURWFlLNPE7s4ODvb3YbKKUt3A8+DK4n+A4pxzvjirzBOrgerYyMKT42N0NE0toINAvF4LlDmf0AtbAJYC9BlyECCOIgWlUcDFC0DJ4f+BUhRGMj/Y8+hMw1C5onAwGNTAOI7VPOfcC6MD9mF1sHltKGQBVKQSpSdeA4mYc3me18B+vw9LAKY4p46adruNs7MzTCYTdf0UsCdAeqCIcIL5TdFlIKPl9aMmk+PEdNA5ddV9VkUhQO901HY45tZ5Z5nTfDhcAGqSX13X1Y5411utlgqEjtU5pLB6Uc7Pz9XEeDxW/2jMS9Wq8VCcED4ajeoXqWIsXRYyR4YUhNug8GqrdIRxF9x+9WxV7Q+i2qjAY9te2QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/9446bade439e11c0df96a1816c63a91e/c5bb3/step6.png\" srcset=\"/static/9446bade439e11c0df96a1816c63a91e/04472/step6.png 170w,\n/static/9446bade439e11c0df96a1816c63a91e/9f933/step6.png 340w,\n/static/9446bade439e11c0df96a1816c63a91e/c5bb3/step6.png 680w,\n/static/9446bade439e11c0df96a1816c63a91e/d48f1/step6.png 796w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 91.1764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACr0lEQVR42o2U22sTURDG+0fXWlAR8c0nRX1QsCI+KFarUFBBbVVQCr1AkCS72Uuyl2w2t73v5p7PmdNs0jVVPDCZ3XNmfvnOnLOzARqT8RhJkiDNBkgWJp7TFMPBAPkYjUbncYMhxQyFF89JKtZ4bPBPFEWwTRNNXUGrocA1VDh6DaauotvtLoG+78PQFFiVM2Em+/IpTJrzaG0JjOMEliajv38H1Z0tnD3aRPfVdTS/76LrhStglMAs/US4dwvykytQn20je3sT1ulXeGFyAUiSLVVC+O42ot1r8F/fQLa7DffbizWgVfqBgGLs51ehPd1E8HILztlhERiRQqehofNlB97nx+h9Ivv4ANbRewIGK2AYwyyfwP3wEMb+fchv7qK5fw/2ryMCxitgEseQqhLK5QokWYZpWWi1WrBte62G9mKNre26wjcpzve8FTCj0zw5PsbhwQFURRFJ7iLwMiCvtRwHDhn7NWBMp2waBoxGAxafNgX8D7D1NyBfG57stNtoEFSqVkUSJ/8J5D/MQU6zKWwdGIYioNvpCM+gHoHYd2huCaQkTubauYsasnGc1+8XFbIyVVVh8NbJqqSSFQVBUFCo6zrq9ToptaBpGnQyjknpHArAkFTyQkwnzs+81TF9kvw+n89FMK/3ej1hPM/vfVI2mUzWP71arYZKpQKFfK2moFQqwaXthBcUerRlSZKEelXTIcuSyOE/LyiczWaYTqfCs/lhSuqmFJSIGrJivpN8X4E5Oh43iDEp57yZUMh5S2BxzEWQF2bIqNP4voeUOozn9akDZQjiAbLhWMTlpbg4LgGej8mElEYDjMlz4mjxPiLl/xoFINfBoivQpvvIJWBQlAwRRBk1kKFQnncnvgn8peSHcSmQa8H1iuNIANeKMV/FcaPNqAR57XLgbxEiS20x1RDVAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/95b897d26d864ac2a8a437b40acd8fd4/c5bb3/step7.png\" srcset=\"/static/95b897d26d864ac2a8a437b40acd8fd4/04472/step7.png 170w,\n/static/95b897d26d864ac2a8a437b40acd8fd4/9f933/step7.png 340w,\n/static/95b897d26d864ac2a8a437b40acd8fd4/c5bb3/step7.png 680w,\n/static/95b897d26d864ac2a8a437b40acd8fd4/5d72a/step7.png 834w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Now of course I tried to keep the scenario as simple as possible. This is just to focus on the important part of the Kube-Proxy.</p>\n<p>There are a couple of points that are worth mentioning:</p>\n<ul>\n<li><strong>IP and port mappings:</strong> Services and endpoints in Kubernetes represent IP and port mappings, ensuring proper routing of traffic to specific combinations of IP addresses and ports within the cluster.</li>\n<li><strong>ClusterIP and DNAT translation:</strong> ClusterIP services use DNAT (Destination Network Address Translation) on the source node, keeping their IPs hidden from external access. They function as internal NAT rules, exclusively accessible within the cluster.</li>\n<li><strong>Service types and rode rules</strong>: Different service types can lead to the installation of distinct rules within nodes. These rules may be organized into chains, specific sets of rules with defined order in the traffic path.</li>\n<li><strong>Random pod selection:</strong> By default, NAT rules select a random Pod to handle incoming traffic. However, this behavior can vary depending on the chosen Kube-Proxy mode, which determines the load balancing strategy for routing traffic to Pods.</li>\n</ul>\n<h2 id=\"-understanding-kube-proxy-modes\" style=\"position:relative;\"><a href=\"#-understanding-kube-proxy-modes\" aria-label=\" understanding kube proxy modes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üí≠ Understanding Kube-Proxy modes</h2>\n<p>Kube-Proxy operates in various modes, each with its approach to implementing NAT rules. To grasp their workings and nuances, let's explore these modes:</p>\n<h3 id=\"-iptables-mode\" style=\"position:relative;\"><a href=\"#-iptables-mode\" aria-label=\" iptables mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úÖ IPtables mode</h3>\n<p>This is the default and widely used mode. Kube-Proxy relies on <code class=\"language-text\">IPtables</code>, a Linux feature for packet processing and filtering. In this mode, Kube-Proxy inserts <code class=\"language-text\">Service-to-Pod NAT</code> rules into IPtables, redirecting traffic from Service IP to Pod IP.</p>\n<p>However, IPtables can become less efficient with a large number of rules, as its sequential algorithm results in O(n) performance. It also lacks specific load balancing algorithms, using a random equal-cost distribution.</p>\n<p>Now the Kube-Proxy role can be described more as the \"installer\" of the rules.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 608px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 112.3529411764706%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC/0lEQVR42pVUaXPaUAzM//9H6XRC2qQJCSQkYGNsfN8HNjZQSL9kKwnMmQ8tM4veIXZX0huuQJ9F0yBLEhR5foKyLDGfz1FRbOpa4nkOI88yLJdLpsIVfxVFAd/zkMQx4igSRGGIl34f3cdHPD894bbTgaooSEm4zdnnBoGI7QlnsxkC35dkJm3hOg7M6RSWacLQddm3d0x0vK6q6oiQHDLhMRkjS1Mph4V4zXm8l3Mq9djlBSGXyJGTmaAlYmK+y2g/JbcmuXXIqUcGSiLhuwvCkkrWJxOMhkMp0bYsTA0DnuvuS2IBx7al7HjXDj770uGcNjyAb9fX6Pd66Ha76Nzc4G0wkOmzCx4aR+7lRNMkcm9FkM4vSg5pUqzYPgOOXH4SJ+TMoftQcnjqPRLlyY9VVXKic8JSpuzBpZKSONojSxN5Eh6Vx+s0iUk830KEUznj3BPCLC9gOx5My4Flu/CDiJoewvMC6PoULkXZE3jdwvO2Z47r09M7eodhOse7kUOxZnjTM4ydCprLZxntU6h2RXclxQM4p81TrAppUR8Ik2JBlzXMeI27voGhOROB264GK/nANFzBCJbQ/YVg4jVQSYBjX/HxMHBQ1usDYUyEKrlLKWqGA9tP4RD8KIcb1+KQXWluTcJzAQvwfmQWeJ8WKMrVgTDKSdUp8fGxgTZWoYyG9C41SchKEnEb9EY+fj5PcE8VPA5s3PV0ITWj39CDFfLZ4tQh98gKa9hRI5FhBhV0r8KUfvQ2SYXk4dVETwmElMsXp94CeXn0bxOTQ5VcGNSric+92oGSjR3YiU39tOKN9NpKNvu7CRPOzglpKG3zW2yH0JwMo1237v6DcEFu1nDSD3K2EWdu9oecrk9E/4mQ1Znsvmfg5tcInQcF3++HuP7xihc1lJ5eEJ73ULFrulzt+8frd6NAX43wqiV4GUd4Gvr0TGYneQzNXSA7dlhUS1g0US+p5d218NMFgmxJcYmAka0opznJYdjRHPPm6B0Cn1/jc4fz9ZfYfv4Cfz5dyO3RfMgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/3b7002549d26704094bc19d0b4628f5b/18872/iptables-modes.png\" srcset=\"/static/3b7002549d26704094bc19d0b4628f5b/04472/iptables-modes.png 170w,\n/static/3b7002549d26704094bc19d0b4628f5b/9f933/iptables-modes.png 340w,\n/static/3b7002549d26704094bc19d0b4628f5b/18872/iptables-modes.png 608w\" sizes=\"(max-width: 608px) 100vw, 608px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"-ipvs-mode\" style=\"position:relative;\"><a href=\"#-ipvs-mode\" aria-label=\" ipvs mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úÖ IPVS mode</h3>\n<p>IPVS (IP Virtual Server) is designed for load balancing and offers efficient lookup with O(1) complexity, ensuring consistent performance regardless of rule count. Kube-Proxy in this mode inserts rules into IPVS instead of IPtables.</p>\n<p>IPVS supports various load balancing algorithms like round robin and least connections. Note that IPVS may not be available on all Linux systems, unlike IPtables.</p>\n<h3 id=\"-kernelspace-mode\" style=\"position:relative;\"><a href=\"#-kernelspace-mode\" aria-label=\" kernelspace mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úÖ KernelSpace mode</h3>\n<p>This mode is exclusive to Windows nodes. Kube-Proxy utilizes Windows Virtual Filtering Platform (VFP) to insert packet filtering rules. VFP works similarly to IPtables on Linux, responsible for packet encapsulation and destination IP address replacement. If you're familiar with virtual machines on the Windows platform, think of VFP as an extension of the Hyper-V switch.</p>\n<h3 id=\"-userspace-mode\" style=\"position:relative;\"><a href=\"#-userspace-mode\" aria-label=\" userspace mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úÖ Userspace mode</h3>\n<p>In the early days, Kube-Proxy used the Userspace mode, where it managed connections by proxying them through a user-level process. While charming and simple, this mode is less efficient than others and is akin to riding a bike with training wheels.</p>\n<p>Each Kube-Proxy mode has its advantages and limitations, making the choice of mode an essential consideration based on your specific cluster's needs and infrastructure.</p>\n<p><strong>‚õì Checking Kube-Proxy mode</strong></p>\n<p>To determine the mode in which Kube-Proxy is running, you can use the <code class=\"language-text\">/proxyMode</code> endpoint, which Kube-Proxy exposes for querying information.</p>\n<p>Here's how you can do it:</p>\n<ul>\n<li><strong>SSH into a cluster node:</strong> Connect to one of the nodes within your Kubernetes cluster using SSH.</li>\n</ul>\n<p>*** Use curl to query Kube-Proxy:** Once connected, execute the following command using curl to query the Kube-Proxy mode:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">curl</span> <span class=\"token parameter variable\">-v</span> localhost:10249/proxyMode</code></pre></div>\n<p>This command will retrieve information about the Kube-Proxy mode, helping you verify which mode it is currently operating in.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.294117647058826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABCUlEQVR42o2SRwrDMBREfRrj3ntbuOOCscH3P8oP80EhgRQthmgRPU2xsu87VVVFXddRFEXk+z4lScLnOI5Z4hwEATmOQ5qmka7rH6UAeBwHnedJ0zRR0zTU9z0VRcFgKMsyFqAAmqb5VYoAbdtGy7IQHijL8uksDEOGpmnKDuHiJ/C6LhqGgeZ5prZtGQ6gqqoc7TWeYRg/YQxc15XyPOdIiAPBCbr0PI9c1+U/Wpb1F/bmEM7gEt1hJPzWdc1nPCLj7tkhXEJiIDyAPsdx5C5l3TEQECyL/rAu+sMYqABjILZt2/KR7/vmqCImYBBWxcICLg1ENPHNfbqI7mT7Y6D4RMRl2YvfgA9AtV56tDoHdAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/fcb95fb20e18694c52ba207069d16f80/c5bb3/kp-mode.png\" srcset=\"/static/fcb95fb20e18694c52ba207069d16f80/04472/kp-mode.png 170w,\n/static/fcb95fb20e18694c52ba207069d16f80/9f933/kp-mode.png 340w,\n/static/fcb95fb20e18694c52ba207069d16f80/c5bb3/kp-mode.png 680w,\n/static/fcb95fb20e18694c52ba207069d16f80/b12f7/kp-mode.png 1020w,\n/static/fcb95fb20e18694c52ba207069d16f80/b5a09/kp-mode.png 1360w,\n/static/fcb95fb20e18694c52ba207069d16f80/1134b/kp-mode.png 1470w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Here you can see the last line that Kube-Proxy is using <code class=\"language-text\">iptables</code> mode.</p>\n<p><strong>Recap: Kubernetes Service and Kube-Proxy:</strong></p>\n<ul>\n<li>A Kubernetes Service operates akin to a proxy by providing a stable IP address for client connections. It directs traffic received at this IP to the corresponding backend Pod IP, effectively solving the issue of Pods' dynamic IP changes.</li>\n<li>In terms of load balancing, it depends on which aspect of Kube-Proxy is under consideration. The Kube-Proxy agent itself does not handle traffic or perform load balancing; it's solely part of the control plane responsible for creating Service rules. However, Kube-Proxy, through the rules it generates, facilitates load balancing by distributing traffic across multiple identical Pods associated with a specific Service. These Pods serve as replicas and collectively handle incoming requests.</li>\n</ul>\n<h2 id=\"-container-network-interface-cni\" style=\"position:relative;\"><a href=\"#-container-network-interface-cni\" aria-label=\" container network interface cni permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚Ü≥ Container Network Interface CNI</h2>\n<p>Container Network Interface (CNI) is a framework that allows you to dynamically configure networking resources for your Kubernetes clusters. It uses a plugin architecture, so you can use the CNI plugins that best meet your needs.</p>\n<p>CNI can be used to configure both <code class=\"language-text\">overlay</code> and <code class=\"language-text\">underlay</code> networks:</p>\n<ul>\n<li><strong>Overlay networks</strong> encapsulate network traffic using a virtual interface such as <a href=\"https://datatracker.ietf.org/doc/html/rfc7348\" target=\"_blank\" rel=\"noopener noreferrer\">Virtual Extensible LAN (VXLAN)</a>.</li>\n<li><strong>Underlay networks</strong> work at the physical level and comprise switches and routers.</li>\n</ul>\n<p>Once you've chosen a network configuration type, the container runtime defines the network that containers will join. The runtime adds the interface to the container namespace via a call to the CNI plugin and allocates the connected subnetwork routes via calls to the I<code class=\"language-text\">P Address Management (IPAM)</code> plugin.</p>\n<p>CNI can be used with Kubernetes and other Kubernetes-based container orchestration platforms such as OpenShift. It uses a software-defined networking (SDN) approach to unify container communication throughout clusters.</p>\n<h2 id=\"-kubernetes-networking\" style=\"position:relative;\"><a href=\"#-kubernetes-networking\" aria-label=\" kubernetes networking permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìç Kubernetes networking</h2>\n<p>Kubernetes provides networking for containerized applications with a flat network structure. This eliminates the need to map host ports to container ports, enabling the operation of a distributed system without dynamic port allocation.</p>\n<p>The networking architecture in Kubernetes is based on the Container Network Interface (CNI) plugin specification. This plugin acts as a common interface between the Kubernetes runtime and the underlying network, supporting various networking solutions like Flannel, Calico, Weave Net, and Cilium.</p>\n<h3 id=\"how-kubernetes-networking-works\" style=\"position:relative;\"><a href=\"#how-kubernetes-networking-works\" aria-label=\"how kubernetes networking works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>How Kubernetes networking works?</h3>\n<p>When a Kubernetes Pod is created, the CNI plugin configures the network interface, assigning an IP address to the Pod. This facilitates communication within the Kubernetes Pod network, which is a flat network accessible to all Pods in the cluster.</p>\n<p>Additionally, Pods can interact with external applications through the Kubernetes Service network, a virtual network that exposes Pods to external entities.</p>\n<p>Kubernetes networking offers several benefits:</p>\n<ul>\n<li><code class=\"language-text\">Portability</code>: Kubernetes clusters can be deployed across different cloud providers and on-premises environments.</li>\n<li><code class=\"language-text\">Scalability</code>: It supports a large number of Pods within a Kubernetes cluster.</li>\n<li><code class=\"language-text\">Reliability</code>: Ensures consistent connectivity for Pods in a Kubernetes cluster.</li>\n</ul>\n<p>Both Linux container and container networking technology are continuing to evolve to meet the needs of applications running in various environments. CNI is an initiative of the Cloud-Native Computing Foundation (CNCF), which specifies the configuration of Linux container network interfaces.</p>\n<p>CNI was created to make networking solutions integratable with a range of container orchestration systems and runtimes. Instead of making the networking solutions pluggable, it defines a common interface standard for both the networking and container execution layers.</p>\n<div class=\"note\">\n    <p><strong>üîµ Note:</strong></p>\n    <p>CNI is not native to Kubernetes. Developers using the CNI standard can create network plugins to interoperate with a variety of container runtimes. CNI networks can use an encapsulated network model,\n    such as <a href=\"https://www.techtarget.com/whatis/definition/VXLAN\">Virtual Extensible LAN (VXLAN)</a>, or an unencapsulated‚Ää-‚Ääalso known as decapsulated‚Ää-‚Äänetwork model, such as <a href=\"https://www.techtarget.com/searchnetworking/definition/BGP-Border-Gateway-Protocol\">Border Gateway Protocol (BGP).</a></p>\n</div>\n<p><strong>How CNI works?</strong></p>\n<p>CNI uses a plugin architecture to configure the Kubernetes cluster's networking. The CNI plugin is responsible for creating and configuring the network interface for each container. When a container is created,\nthe Kubernetes kubelet calls the CNI plugin to set up the network interface, assign an IP address, and add it to the Kubernetes network.</p>\n<p>The CNI plugin also interacts with the <code class=\"language-text\">IP Address Management (IPAM) plugin</code> to allocate IP addresses to containers. This involves managing the pool of available IP addresses and assigning them as needed. Once the network interface is established, the kubelet starts the container,\nenabling it to communicate with other containers on the Kubernetes network.</p>\n<p>CNI focuses on the connectivity of container networks and the removal of allocated resources upon the termination of containers. This focus makes CNI specifications simple and allows them to be widely adopted.\nFor additional information on CNI specifications, including third-party plugins and runtimes, refer to the <a href=\"https://github.com/containernetworking/cni\" target=\"_blank\" rel=\"noopener noreferrer\">CNI GitHub project</a>.</p>\n<h2 id=\"diverse-kubernetes-network-plugins-necessity\" style=\"position:relative;\"><a href=\"#diverse-kubernetes-network-plugins-necessity\" aria-label=\"diverse kubernetes network plugins necessity permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üßµDiverse Kubernetes network plugins necessity</h2>\n<p>Kubernetes relies on a rich ecosystem of network plugins, many of which are endorsed and widely adopted by major container orchestration platforms, with Kubernetes at the forefront.</p>\n<p>These plugins play a crucial role in enabling various container networking functions, all while adhering to the rigorous standards set forth in the Container Network Interface (CNI) specification. Given the inherent complexity of networking, CNI thoughtfully delineates specifications for multiple plugins, recognizing that user requirements can greatly vary.</p>\n<p>Within the realm of CNI, networks can be instantiated using two primary models: <code class=\"language-text\">encapsulated</code> and <code class=\"language-text\">unencapsulated</code>.</p>\n<p><strong>The encapsulated(Overlay) network model:</strong></p>\n<p>This model is represented by technologies like <code class=\"language-text\">VXLAN</code> and <code class=\"language-text\">IPsec</code>, overlays a logical Layer 2 network over an existing Layer 3 network topology. This approach simplifies routing complexity and minimizes overhead.</p>\n<p>It relies on UDP ports to disseminate encapsulation data among Kubernetes workers, creating a bridge connecting these workers and pods. Communication management within pods is then expertly handled by Docker or alternative container engines.</p>\n<p>This encapsulated network model proves particularly advantageous for scenarios that favor a Layer 2 bridge, especially those sensitive to Kubernetes worker latencies in a Layer 3 environment.</p>\n<p>For distributed data centers spanning distinct geographic locales, minimizing latency is pivotal in preventing network segmentation.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBElEQVR42jXO2VfaQBQHYP93+1DPqYdz2oc+tVbKVgVDtYhsAbKyBUIxELZQaRAkrGFmEkKWJlTvuTMP85vv3HviOE777zL1u3RfJ3Hh8Vd5lawuYvQ63QCOY6+BkeeXOL/M8tsMD6muXOgMqO5wA5ALT9DeiTJShf/Ild/l+Pj7UO883PTF5+e3O4AMbgBP/cKHcMsXV84wmOXjBH2aKfuqQ/k/tq+ZVYIZ4GwXYyZBCoUpFGFQkASrnVGXtMsiitAoTKPvJExWOqUymWZKtLg6Yt26KQGsolyR4581ECBgkPTaXwBrFw+1r/guRLkvXoSVIcbMovS81n9d24oy6i2j3LOzG3YdIIH7z53vJzQPS/pFQXvD4IpVrxklSCxKPehhuLdi9IZJ12oPVAqXA5QdIvVQcePPztbA5AbgIjWNUDBEaG6Uyj/X0iz9UOXax7WNgxVj1W85NZCfXOYqFzgXpJXPd0+fAqxuOvXe4uxL0V/QA+QfN4rgZSwnRdLPjf7Ow+5Rtsbj2Bi8qCOlJcpVUZYbQyhNd7ZtArRvjdSmhMSJJDyxw3lbmCBBNrW99YrdMk1ju1ktlNVmoxrG/mBohq5D6N7IPrgNzb1umZZpOrZlOW/lYdu2HdtpDjiMCGW4uxyfIBoFMitS2c5LPzntxpajxEz8IYjNaGFc76+PxMP/AEh1+jWVe4GGAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/fe31a7b21e4d40d9442e70ac58134af8/c5bb3/overlay.png\" srcset=\"/static/fe31a7b21e4d40d9442e70ac58134af8/04472/overlay.png 170w,\n/static/fe31a7b21e4d40d9442e70ac58134af8/9f933/overlay.png 340w,\n/static/fe31a7b21e4d40d9442e70ac58134af8/c5bb3/overlay.png 680w,\n/static/fe31a7b21e4d40d9442e70ac58134af8/442cb/overlay.png 752w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><strong>üß© The unencapsulated(Underlay) network model:</strong></p>\n<p>This model extends a Layer 3 network to facilitate the routing of packets among containers. Unlike the encapsulated counterpart, this model does not introduce an isolated Layer 2 network or any associated overhead. However, it places the onus of managing necessary route distribution squarely on the shoulders of Kubernetes workers.</p>\n<p>To make this work, a network protocol is put into action, connecting Kubernetes workers and utilizing the Border Gateway Protocol (BGP) to efficiently propagate routing information to pods. Within these pods, the role of overseeing communication with workloads is assumed by Docker or a comparable container engine. The unencapsulated network model is ideally suited for scenarios favoring a routed Layer 3 network.</p>\n<p>Here, routes for Kubernetes workers undergo dynamic updates at the operating system level, effectively mitigating latency concerns. In essence, Kubernetes networking unfolds as a multifaceted landscape, offering a plethora of plugin choices while accommodating diverse network models tailored to the distinct needs of your containerized workloads.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 62.35294117647059%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACMElEQVR42rWRy44SURCGe8aZuBvnbYwrFz6BUde+gnE1sOEJdDITdxqN0bhgw0o2xGDUKDGsgOF+a+jmkqaBgaGhOacp/78zjKOuPUlxiqqv/qpTbZjdUeR7eSPFUkUV8nnJX5rjODKZTFQQbGTiOqdnDff4Z02kWCyqfC4nORh8MjIej/VqtZLRaBQ1bLt/tFhpqVSqvmm2AyQDJIJmsxnUajVfay29Xu8E3DMPXLlc9m3bDlzXDa1er5Nb+74viEcM/ohspFQqKSQFEDsJBMOY4FhW77RnWcf0C4WCMk0zfAHZarWKYSpaKSXdbjcaCs5mM06hBoOBEO50OtLv9xHrq6W3kEHPOh06znPP8xhXYK841kBDT6fT34IE8UexI6FWq8W9iG119fhiKZ+zhVefUqmXDiaHmCbHF5Alh1vP5/MrwSNOiHuFbhvcLJLhcLjp25bfGc3kzcevH96/ff3OsixO6CO/IcNXsAZxnxOGO0SHCHeDWwHgkjUWrznJyHXDHV6cT1543vKEPvarIKDJcXfg+CE1Px5EowaSj2EFjPttsVjM+RwufImDjj+QK+KjPEX+CfwzCGSwojV3x6ngn+PJX5DLU8u4dnbW6/Wddrv9sNFoPAB4FwPtGX8dxPbR6x4mvA+BR6i5fRnfCYFkMnkznU4fplKpW7FYbBf+Xjab3SeQyWQOGAdzQNv6rLvG7SYSiUNqUOuP7vF4/AZBGsT/mW57tgyNNcb/PL8AAgKbi/2oqAgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/27ed908cc7970fd2efa2a90f6893ba20/c5bb3/underlay.png\" srcset=\"/static/27ed908cc7970fd2efa2a90f6893ba20/04472/underlay.png 170w,\n/static/27ed908cc7970fd2efa2a90f6893ba20/9f933/underlay.png 340w,\n/static/27ed908cc7970fd2efa2a90f6893ba20/c5bb3/underlay.png 680w,\n/static/27ed908cc7970fd2efa2a90f6893ba20/17a7a/underlay.png 753w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-cni-withcilium\" style=\"position:relative;\"><a href=\"#-cni-withcilium\" aria-label=\" cni withcilium permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üêù CNI with¬†Cilium</h2>\n<p><a href=\"./cilium.png\">alt text</a></p>\n<p><a href=\"https://www.solo.io/topics/cilium/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium</a> is an open-source project that enables networking, security, and observability for Kubernetes clusters and other containerized environments.</p>\n<p>It is based on a technology called <a href=\"https://ebpf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">eBPF</a>, which can inject network control logic, security controls, and observability features directly into the Linux kernel.</p>\n<p><a href=\"https://docs.cilium.io/en/stable/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium CNI</a> is a powerful networking plugin for Kubernetes which provides enhanced security and networking capabilities for containerised applications. It leverages the power of eBPF (extended Berkeley Packet Filter), a highly efficient and programmable kernel-level technology, to deliver transparent network security and traffic monitoring features.</p>\n<p>Cilium uses VXLAN to form an overlay network and extended Berkeley Packet Filter to manage network connectivity and application rules. It supports both IPv4 and IPv6 addressing and uses BGP for unencapsulated routing. Cilium can support multiple Kubernetes clusters and, like Multus, provides multi-CNI capabilities.</p>\n<p>Cilium handles aspects of network management, such as network policies, through HTTP request filters. Policies can be written to YAML or JSON files, both of which provide network traffic enforcement for incoming and outgoing traffic.</p>\n<blockquote>\n<p>Cilium can run using VXLAN as an overlay network for encapsulation and routingor BGP routing as an underlay network. Cilium used to rely on metallb to power it's BGP features, but since Cilium 1.3 it is possible to use their own implementation built on GoBGP.</p>\n</blockquote>\n<p>Cilium Is the only CNI with L7 aware policies. This means you can write Kubernetes networking policies that understand DNS, HTTP, and even Kafka.</p>\n<p>For example, you can write a DNS L7 networking policy to:</p>\n<p><strong>üß© Restrict DNS Resolution to¬†Subset:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> cilium.io/v2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CiliumClusterwideNetworkPolicy\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dns<span class=\"token punctuation\">-</span>allow<span class=\"token punctuation\">-</span>list\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">endpointSelector</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token key atrule\">egress</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">toEndpoints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchLabels</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">io.kubernetes.pod.namespace</span><span class=\"token punctuation\">:</span> kube<span class=\"token punctuation\">-</span>system\n        <span class=\"token key atrule\">k8s-app</span><span class=\"token punctuation\">:</span> kube<span class=\"token punctuation\">-</span>dns\n      <span class=\"token key atrule\">toPorts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n          <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"53\"</span>\n            <span class=\"token key atrule\">protocol</span><span class=\"token punctuation\">:</span> UDP\n          <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">dns</span><span class=\"token punctuation\">:</span>\n              <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchPattern</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"*.abc.xyz\"</span>\n              <span class=\"token punctuation\">-</span> </code></pre></div>\n<p><strong>üß© Allow POST HTTP requests to abc.xyz:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> cilium.io/v2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CiliumNetworkPolicy\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> http<span class=\"token punctuation\">-</span>post<span class=\"token punctuation\">-</span>abc<span class=\"token punctuation\">-</span>xyz\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">endpointSelector</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token key atrule\">egress</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">toPorts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"443\"</span>\n              <span class=\"token key atrule\">protocol</span><span class=\"token punctuation\">:</span> TCP\n      <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">http</span><span class=\"token punctuation\">:</span>\n          <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">method</span><span class=\"token punctuation\">:</span> POST\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">toFQDNs</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchPattern</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"*.abc.xyz\"</span></code></pre></div>\n<p><strong>üß© Restrict Kafka Topic Access to the Following Pods:</strong></p>\n<p>Typically, we're forced to write networking policies like: \"Allow any application with the label kafka-consumer\" to speak to Kafka. This casts a rather wide net, when with L7 policies we can limit the access to individual topics depending on the labels. As such, we can say that only the \"beer-brewer\" can publish to the hops topic. Amazing, right?</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> cilium.io/v2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CiliumNetworkPolicy\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> beer<span class=\"token punctuation\">-</span>brewers\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">ingress</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">fromEndpoints</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchLabels</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">role</span><span class=\"token punctuation\">:</span> beer<span class=\"token punctuation\">-</span>brewer\n      <span class=\"token key atrule\">toPorts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token number\">9092</span>\n              <span class=\"token key atrule\">protocol</span><span class=\"token punctuation\">:</span> TCP\n          <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">kafka</span><span class=\"token punctuation\">:</span>\n              <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">role</span><span class=\"token punctuation\">:</span> produce\n                <span class=\"token key atrule\">topic</span><span class=\"token punctuation\">:</span> hops</code></pre></div>\n<h3 id=\"-developer-experience\" style=\"position:relative;\"><a href=\"#-developer-experience\" aria-label=\" developer experience permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üé© Developer experience</h3>\n<p>Now don't worry if these resources look difficult, because Cilium has that covered too. All of these network policies can be visualised, modified, and event constructed through an entirely point and click visual builder.</p>\n<p>Check out the <a href=\"https://editor.networkpolicy.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium Editor</a> to see for yourself.</p>\n<h3 id=\"-installing-cilium\" style=\"position:relative;\"><a href=\"#-installing-cilium\" aria-label=\" installing cilium permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üêß Installing Cilium</h3>\n<p>Cilium is installable as a Helm chart. So you'll first need to make the repository available:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm repo <span class=\"token function\">add</span> cilium https://helm.cilium.io/</code></pre></div>\n<p>Next, we can begin to understand and tweak the default values for the installation we require.</p>\n<p>The highlights are:</p>\n<p><strong>IPAM mode:</strong></p>\n<p>Cilium has a few different modes to manage IPAM.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.mode</span><span class=\"token operator\">=</span>cluster-pool\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4PodCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4MaskSize</span><span class=\"token operator\">=</span><span class=\"token number\">23</span></code></pre></div>\n<p>Cilium also has a preview feature where the IPAM mode can be set to <code class=\"language-text\">cluster-pool-v2beta</code>,\nwhich allows for dynamic, resource usage-based, allocation of node CIDRs.</p>\n<p><strong>eBPF and XDP:</strong></p>\n<p>eBPF is a relatively new technology that runs within the Linux kernel and enables the execution of eBPF programs, which run in a sandbox environment.</p>\n<p>These programs allow for user-land code to run within the kernel with unprecedented performance; extending the capabilities of the kernel.</p>\n<p>XDP leverages eBPF to provide a highly performant packet processing pipeline that runs as soon as the networking driver receives the packet. What does this actually mean? Well, with XDP‚Ää-‚ÄäCilium can help mitigate DDOS attacks by dropping packets before they even hit the traditional networking stack.</p>\n<p>Cilium's use of eBPF and XDP means we're not reliant on iptables, so we can actually disable the kube-proxy altogether. You'll need to do this with kubeadm and through Cilium's deploy.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">kubeProxyReplacement</span><span class=\"token operator\">=</span>probe</code></pre></div>\n<p><strong>Native routing:</strong></p>\n<p>As discussed above, Cilium doesn't need encapsulation to handle the routing of packets within our cluster; so let's ensure we enable it.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--nativeRoutingCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16</code></pre></div>\n<p><strong>Hubble:</strong></p>\n<p>As Hubble and Cilium observability is a big part of the appeal, let's not forget to enable it.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.relay.enabled</span><span class=\"token operator\">=</span>true\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.enabled</span><span class=\"token operator\">=</span>true\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.listenAddress</span><span class=\"token operator\">=</span><span class=\"token string\">\":4244\"</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.ui.enabled</span><span class=\"token operator\">=</span>true</code></pre></div>\n<p><strong>Complete install:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm repo <span class=\"token function\">add</span> cilium https://helm.cilium.io/\nhelm upgrade <span class=\"token parameter variable\">--install</span> cilium/cilium cilium <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--version</span> <span class=\"token number\">1.13</span>.4 <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--namespace</span> kube-system <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">image.repository</span><span class=\"token operator\">=</span>quay.io/cilium/cilium <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.mode</span><span class=\"token operator\">=</span>cluster-pool <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4PodCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16 <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4MaskSize</span><span class=\"token operator\">=</span><span class=\"token number\">23</span> <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.nativeRoutingCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16 <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.endpointRoutes.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.relay.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.listenAddress</span><span class=\"token operator\">=</span><span class=\"token string\">\":4244\"</span> <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.ui.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">kubeProxyReplacement</span><span class=\"token operator\">=</span>probe <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">k8sServiceHost</span><span class=\"token operator\">=</span><span class=\"token variable\">${PUBLIC_IPv4}</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">k8sServicePort</span><span class=\"token operator\">=</span><span class=\"token number\">6443</span></code></pre></div>\n<p>Cilium might be much newer to the Kubernetes CNI landscape, but in its short time,\nit has become the gold standard for Kubernetes networking.</p>\n<p>While Calico is also a great option, Cilium's adoption of eBPF and XDP provides a future-facing solution,\nenriched with the best debugging tool available (Hubble) and the best developer experience with the assistance of the Cilium Editor.</p>\n<h2 id=\"closing-thoughts\" style=\"position:relative;\"><a href=\"#closing-thoughts\" aria-label=\"closing thoughts permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Closing thoughts</h2>\n<p>Kubernetes networking is powered by two vital components: Kube-Proxy and CNI.</p>\n<p>Kube-Proxy maintains network rules and forwards traffic to Pods, while CNI provides a common interface to the underlying network. These components are essential for running containerized applications on Kubernetes.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <em><strong>Until next time üéâ</strong></em></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/replicable-local-development-environments/","title":"Minimizing local machine dependencies with replicable development environments üìà","date":"2024-10-15 18:06:00"},"excerpt":"Isolated, shareable, and secure local setup strategies üî• üìö Introduction The modern software development relies heavily upon external‚Ä¶","html":"<blockquote>\n<p><strong>Isolated, shareable, and secure local setup strategies üî•</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>The modern software development relies heavily upon external libraries, frameworks, and packages to expedite project delivery.</p>\n<p>While these dependencies offer many benefits, they also introduce potential risks, such as <a href=\"https://www.cloudflare.com/en-gb/learning/security/what-is-remote-code-execution/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>remote code execution (RCE)</strong></a> vulnerabilities.</p>\n<p>To address these concerns, we will explore various strategies and tools designed to minimize local machine dependencies and establish replicable development environments.</p>\n<p>We will explore the specifics of <a href=\"https://earthly.dev/blog/repeatable-builds-every-time/\" target=\"_blank\" rel=\"noopener noreferrer\">modular Dockerfile builds</a>, <a href=\"https://containers.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">Dev Containers</a>, <a href=\"https://nixos.wiki/wiki/Configuration_Collection\" target=\"_blank\" rel=\"noopener noreferrer\">Nix configurations</a>, and customization techniques!</p>\n<div class=\"important\">\n    <p><strong>‚ùó Important:</strong></p>\n    <p>This article serves as a follow-up to <a href=\"https://seifrajhi.github.io/blog/devcontainers-replicable-local-setup/\">my previous blog on DevContainers</a>, continuing the exploration of effective methods to mitigate dependency management challenges.</p>\n</div>\n<p>Let‚Äôs get started :)</p>\n<h2 id=\"optimize-developer-workflows-with-modular-docker-builds-and-devcontainer-integration\" style=\"position:relative;\"><a href=\"#optimize-developer-workflows-with-modular-docker-builds-and-devcontainer-integration\" aria-label=\"optimize developer workflows with modular docker builds and devcontainer integration permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Optimize Developer workflows with Modular Docker builds and Devcontainer integration</h2>\n<p>To maximize the effectiveness of containerized development environments, it is imperative to use <strong>modular Dockerfile structures</strong> and integrate <strong>dev container solutions</strong>.</p>\n<p>The provided <code class=\"language-text\">Dockerfile</code> snippet highlights a modular approach using a configurable base image, tailored specifically for <code class=\"language-text\">CUDA profiling</code> with <code class=\"language-text\">TensorFlow</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token comment\"># Make this Dockerfile modular by using a configurable base image</span>\nARG BASE_IMAGE\nFROM <span class=\"token variable\">${BASE_IMAGE}</span>\n<span class=\"token comment\"># For CUDA profiling, TensorFlow requires CUPTI.</span>\nENV LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:<span class=\"token variable\">$LD_LIBRARY_PATH</span>\n<span class=\"token comment\"># Link the libcuda stub to the location where Tensorflow is searching for it and reconfigure</span>\n<span class=\"token comment\"># dynamic linker run-time bindings</span>\nRUN <span class=\"token function\">ln</span> <span class=\"token parameter variable\">-s</span> /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 <span class=\"token punctuation\">\\</span>\n  <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"/usr/local/cuda/lib64/stubs\"</span> <span class=\"token operator\">></span> /etc/ld.so.conf.d/z-cuda-stubs.conf <span class=\"token punctuation\">\\</span>\n  <span class=\"token operator\">&amp;&amp;</span> ldconfig</code></pre></div>\n<p>While containerization brings many advantages, it does not inherently solve the issue of managing developer experience.</p>\n<p>Then check out DevContainer, a great tool that simplifies tasks like cache ordering and configuration management.</p>\n<p>Below is an example of a <code class=\"language-text\">DevContainer JSON configuration snippet</code> that illustrates its capabilities:</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n<span class=\"token property\">\"image\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"mcr.microsoft.com/vscode/devcontainers/base:jammy\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"features\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"ghcr.io/devcontainers/features/node:1\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"ghcr.io/devcontainers/features/python:1\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>With DevContainer integrated into containerized environments, developers can enhance their workflow efficiency, reduce cognitive load, and focus on coding tasks without being hindered by setup complexities.</p>\n<p>This combination of containerization with tools like Docker and DevContainer not only boosts security and reproducibility but also elevates the overall developer experience, fostering a more productive and collaborative development environment across projects.</p>\n<p>Because we want to encourage cross-team collaboration, we want to standardize the tooling across teams as much as possible.</p>\n<p>Different language ecosystems will have different tools and we want to keep using those. You can't tell the frontend team not to use <code class=\"language-text\">package.json</code> / <code class=\"language-text\">npm</code> / <code class=\"language-text\">Yarn</code> etc‚Ää-‚Ääthat would be cumbersome for them. <em>So we're not touching the language-specific build layer.</em></p>\n<p>In addition, because we want to be able to iterate quickly when there are CI failures, we will containerize the build as much as possible. If the failure is part of a containerized script, then it will be easier to reproduce it locally.</p>\n<p>Three prominent approaches for achieving this include:</p>\n<ul>\n<li><strong>Makefile + Dockerfile:</strong> Using Makefiles as a collection of daily commands (e.g., <code class=\"language-text\">make build</code>, <code class=\"language-text\">make start</code>, <code class=\"language-text\">make package</code>, <code class=\"language-text\">make test</code>) complements Dockerfiles, keeping most of the build contained within containers.</li>\n<li><strong>bash + Dockerfile:</strong> Another alternative involves collecting scripts for everyday tasks within a dedicated directory (e.g.,¬†<code class=\"language-text\">./build</code>,¬†<code class=\"language-text\">./test</code>,¬†<code class=\"language-text\">./release</code>).</li>\n<li><strong>Bake + Dockerfile:</strong> Using <a href=\"https://github.com/SanderMertens/bake\" target=\"_blank\" rel=\"noopener noreferrer\">bake</a> as a collection of daily commands (e.g., <code class=\"language-text\">bake build</code>, <code class=\"language-text\">bake start</code>¬†, etc)¬†.</li>\n</ul>\n<p>All these approaches enable the quick reproduction of issues during Continuous Integration (CI) failures since the failing actions occur within containerized scripts.</p>\n<div class=\"note\">\n    <p><strong>üîµ Note:</strong></p>\n    <p><a href=\"https://github.com/tsuru/docker-nginx-with-modules\">Here</a>\n, you can find a project that contains a Dockerfile that allows you to create a custom Docker image with any number of additional dynamic modules, using makefile.\n</p>\n</div>\n<h2 id=\"simplifying-system-sependencies-with-nix-packagemanager\" style=\"position:relative;\"><a href=\"#simplifying-system-sependencies-with-nix-packagemanager\" aria-label=\"simplifying system sependencies with nix packagemanager permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Simplifying system sependencies with Nix Package¬†manager</h2>\n<p>While containerization and modular builds offer significant benefits, heavy system dependencies like OpenSSL, QEMU, and CUDA can still pose challenges.</p>\n<p>To address this issue, Nix‚Ää-‚Ääa Unix-like package manager‚Ää-‚Ääprovides a solution that is operating system-neutral, versioned, and reproducible.</p>\n<p>Nix can install virtually anything in a truly reproducible way, similar to <code class=\"language-text\">package-lock.json</code>, making it an ideal choice for managing system dependencies.</p>\n<p>The following example demonstrates how Nix can be used to simplify system dependencies:</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  inputs = <span class=\"token punctuation\">{</span>\n    nixpkgs.url = <span class=\"token string\">\"github:nixos/nixpkgs\"</span>;\n    devenv.url = <span class=\"token string\">\"github:cachix/devenv\"</span>;\n  <span class=\"token punctuation\">}</span>;\n\n  outputs = <span class=\"token punctuation\">{</span> nixpkgs<span class=\"token punctuation\">,</span> devenv<span class=\"token punctuation\">,</span> ... <span class=\"token punctuation\">}</span>@inputs<span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    devShells = nixpkgs.lib.genAttrs nixpkgs.lib.platforms.unix (system<span class=\"token operator\">:</span>\n      let pkgs = import nixpkgs <span class=\"token punctuation\">{</span> inherit system; <span class=\"token punctuation\">}</span>; in <span class=\"token punctuation\">{</span>\n        default = devenv.lib.mkShell <span class=\"token punctuation\">{</span>\n          inherit inputs pkgs;\n          modules = <span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">{</span>\n              pre-commit.hooks = <span class=\"token punctuation\">{</span>\n                eslint.enable = <span class=\"token boolean\">true</span>;\n                prettier.enable = <span class=\"token boolean\">true</span>;\n                black.enable = <span class=\"token boolean\">true</span>;\n                isort.enable = <span class=\"token boolean\">true</span>;\n              <span class=\"token punctuation\">}</span>;\n              packages = <span class=\"token punctuation\">[</span>\n                pkgs.python\n                pkgs.nodejs\n              <span class=\"token punctuation\">]</span>;\n            <span class=\"token punctuation\">}</span>\n          <span class=\"token punctuation\">]</span>;\n        <span class=\"token punctuation\">}</span>;\n      <span class=\"token punctuation\">}</span>\n    );\n  <span class=\"token punctuation\">}</span>;\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>By combining <code class=\"language-text\">Nix</code> with <code class=\"language-text\">[direnv](https://direnv.net/)</code> and the associated VSCode extension, changes made in the repository can be instantly reflected without rebuilding the entire container.</p>\n<p>To automatically switch nix shells when switching projects, you can do this by using <a href=\"https://github.com/nix-community/nix-direnv\" target=\"_blank\" rel=\"noopener noreferrer\">nix-direnv</a> and the <a href=\"https://marketplace.visualstudio.com/items?itemName=mkhl.direnv\" target=\"_blank\" rel=\"noopener noreferrer\">VSCode extension</a> direnv for integration. View the nix-direnv github page linked for a guide on setting it up.</p>\n<p>The¬†<code class=\"language-text\">.envrc</code> file below demonstrates how to create a development environment and predefine a Google Cloud project for convenience</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token comment\"># .envrc</span>\n<span class=\"token comment\"># Create the development environment</span>\nuse flake\n<span class=\"token comment\"># Predefine a Google Cloud project if not provided for convenience</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">GOOGLE_PROJECT_ID</span><span class=\"token operator\">=</span><span class=\"token variable\">${GOOGLE_PROJECT_ID<span class=\"token operator\">:-</span>foobar}</span>\n<span class=\"token comment\"># Fetch Google Application Credential from Vault</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">[</span> <span class=\"token operator\">!</span> <span class=\"token parameter variable\">-f</span> key.json <span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token keyword\">then</span>\n  vault kv get <span class=\"token parameter variable\">-field</span><span class=\"token operator\">=</span>keyfile <span class=\"token variable\">$GOOGLE_PROJECT_ID</span> <span class=\"token operator\">></span> key.json\n<span class=\"token keyword\">fi</span></code></pre></div>\n<h2 id=\"more-customization-with-home-manager-and-dotfiles\" style=\"position:relative;\"><a href=\"#more-customization-with-home-manager-and-dotfiles\" aria-label=\"more customization with home manager and dotfiles permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>More customization with Home-Manager and Dotfiles</h2>\n<p><a href=\"https://nix-community.github.io/home-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">Home-Manager</a> and <a href=\"https://www.webpro.nl/articles/getting-started-with-dotfiles\" target=\"_blank\" rel=\"noopener noreferrer\">Dotfiles</a> offer a wealth of possibilities for customizing and optimizing your development environment.</p>\n<p>Here are two lightweight examples to demonstrate the usage of these tools:</p>\n<h3 id=\"home-manager-example\" style=\"position:relative;\"><a href=\"#home-manager-example\" aria-label=\"home manager example permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Home-Manager example</h3>\n<p>Create a basic Home-Manager configuration file named <code class=\"language-text\">~/.config/homebrew/home.nix</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token punctuation\">{</span>\n  imports <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"./overrides.nix\"</span>\n  <span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\n  env.extraPackages <span class=\"token operator\">=</span> with pkgs<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token function\">vim</span>\n    nodejs\n    <span class=\"token function\">yarn</span>\n  <span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n\n  services.vscode <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token builtin class-name\">enable</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n    extraArgs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"--user-data-dir=<span class=\"token environment constant\">$HOME</span>/.cache/code\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>Then, define overrides in <code class=\"language-text\">~/.config/homebrew/overrides.nix</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token punctuation\">{</span>\n  vim.packages <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    pkgs.vimPlug // Install Vim Plugins\n  <span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>This example sets up a basic development environment with <code class=\"language-text\">Vim</code>, <code class=\"language-text\">NodeJS</code>, <code class=\"language-text\">Yarn</code>, and <code class=\"language-text\">VSCode</code> configured to store user data in <code class=\"language-text\">$HOME/.cache/code</code>.</p>\n<h3 id=\"dotfiles-example\" style=\"position:relative;\"><a href=\"#dotfiles-example\" aria-label=\"dotfiles example permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Dotfiles example</h3>\n<p>Create a <a href=\"https://github.com/ohmyzsh/ohmyzsh\" target=\"_blank\" rel=\"noopener noreferrer\">ZSH</a> configuration file named <code class=\"language-text\">~/.zshrc</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token comment\"># Enable plugins</span>\n<span class=\"token assign-left variable\">plugins</span><span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>git z shocks<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Configure plugins</span>\n<span class=\"token builtin class-name\">source</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>brew <span class=\"token parameter variable\">--prefix</span> zsh-syntax-highlighting<span class=\"token variable\">)</span></span>/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\nautoload <span class=\"token parameter variable\">-U</span> compinit <span class=\"token operator\">&amp;&amp;</span> compinit\n\n<span class=\"token comment\"># Alias</span>\n<span class=\"token builtin class-name\">alias</span> <span class=\"token assign-left variable\">ll</span><span class=\"token operator\">=</span><span class=\"token string\">'ls -lahG'</span>\n<span class=\"token builtin class-name\">alias</span> <span class=\"token assign-left variable\">grep</span><span class=\"token operator\">=</span><span class=\"token string\">'grep --color=auto'</span>\n<span class=\"token builtin class-name\">alias</span> <span class=\"token assign-left variable\">diff</span><span class=\"token operator\">=</span><span class=\"token string\">'diff --color'</span>\n<span class=\"token builtin class-name\">alias</span> <span class=\"token assign-left variable\">history</span><span class=\"token operator\">=</span><span class=\"token string\">\"fc -lr\"</span>\n\n<span class=\"token comment\"># Prompt</span>\n<span class=\"token assign-left variable\">ZSH_THEME</span><span class=\"token operator\">=</span><span class=\"token string\">\"robbyrussell\"</span>\n\n<span class=\"token comment\"># Color scheme</span>\n<span class=\"token assign-left variable\"><span class=\"token environment constant\">LS_COLORS</span></span><span class=\"token operator\">=</span><span class=\"token string\">\"di=34;46:ln=35;43:so=35;43:pi=35;43:ex=35;41:bd=43;34:cd=36;43:su=35;40:sg=36;40:tw=32;41:ow=33;42:st=37;44:\"</span></code></pre></div>\n<p>This example sets up a basic <code class=\"language-text\">ZSH configuration</code> with <strong>syntax highlighting</strong>, <strong>colorful output</strong>, <strong>useful aliases</strong>, and a <strong>custom prompt theme</strong>.</p>\n<h2 id=\"-final-thoughts\" style=\"position:relative;\"><a href=\"#-final-thoughts\" aria-label=\" final thoughts permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Final thoughts</h2>\n<p>Using tools like Docker, Makefile, Nix, Direnv, Home-Manager, and <a href=\"https://www.webpro.nl/articles/getting-started-with-dotfiles\" target=\"_blank\" rel=\"noopener noreferrer\">Dotfiles</a> to create secure, reliable, and efficient development environments.</p>\n<p>Prioritize security measures and adapt to new developments to safeguard your digital assets and propel the software industry forward.</p>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ üáµüá∏</em></strong></p>\n<p><br><br></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò</p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>References:</strong></p>\n<ul>\n<li><a href=\"https://nixos.wiki/wiki/Visual_Studio_Code\" target=\"_blank\" rel=\"noopener noreferrer\">Visual Studio Code and NixOS</a></li>\n<li><a href=\"https://nixos.wiki/wiki/Nix_Ecosystem\" target=\"_blank\" rel=\"noopener noreferrer\">Nix Ecosystem</a></li>\n<li><a href=\"https://code.visualstudio.com/docs/devcontainers/containers\" target=\"_blank\" rel=\"noopener noreferrer\">Dev Containers</a></li>\n<li><a href=\"https://containers.dev/overview\" target=\"_blank\" rel=\"noopener noreferrer\">DevContainers Overview</a></li>\n<li><a href=\"https://nix-community.github.io/home-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">Nix Home Manager</a></li>\n</ul>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}