{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/monitoring-coredns-dns-performance/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>Running DNS-intensive workloads can sometimes lead to intermittent <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#coredns\" target=\"_blank\" rel=\"noopener noreferrer\">CoreDNS</a> failures caused by DNS throttling. These issues can have a significant impact on your applications.</p>\n<p>Such disruptions can hinder the reliability and performance of your services, making it mandatory to have a monitoring solution in place. AWS offers a suite of open-source tools‚Ää‚Äî‚Ää<a href=\"https://aws.amazon.com/cloudwatch/\" target=\"_blank\" rel=\"noopener noreferrer\">CloudWatch</a>, <a href=\"https://www.fluentd.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Fluentd</a>, and <a href=\"https://grafana.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Grafana</a>‚Ää‚Äî‚Ääthat can be integrated to monitor CoreDNS.</p>\n<h2 id=\"-introduction-to-kubernetes-dns\" style=\"position:relative;\"><a href=\"#-introduction-to-kubernetes-dns\" aria-label=\" introduction to kubernetes dns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üß© Introduction to Kubernetes DNS</h2>\n<p>Kubernetes relies on <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#introduction\" target=\"_blank\" rel=\"noopener noreferrer\">DNS</a> for service discovery within clusters. When applications running in pods need to communicate with each other, they often refer to services by their domain names rather than IP addresses.</p>\n<p>This is where Kubernetes DNS comes into play. It ensures that these domain names are resolved to the correct IP addresses, allowing pods and services to communicate.</p>\n<p>In Kubernetes, each pod is assigned a temporary IP address. However, these IP addresses are dynamic and can change over time, making it challenging for applications to keep track of them. Kubernetes addresses this challenge by assigning fully qualified domain names (<a href=\"https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#dns-records\" target=\"_blank\" rel=\"noopener noreferrer\">FQDNs</a>) to pods and services.</p>\n<p>CoreDNS, the default DNS provider in Kubernetes, is responsible for handling DNS queries within the cluster. It maps these FQDNs to the corresponding IP addresses, enabling communication between pods and services.</p>\n<h2 id=\"Ô∏è-coredns-in-kubernetes\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-coredns-in-kubernetes\" aria-label=\"Ô∏è coredns in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è CoreDNS in Kubernetes</h2>\n<p>CoreDNS plays an important role in providing DNS services within Kubernetes clusters. As the default DNS provider since Kubernetes v1.13, CoreDNS simplifies cluster networking by enabling clients to access services using DNS names rather than IP addresses. It resolves domain name requests and facilitates service discovery within the cluster.</p>\n<h3 id=\"Ô∏è-how-coredns-operates\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-how-coredns-operates\" aria-label=\"Ô∏è how coredns operates permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚öôÔ∏è How CoreDNS Operates</h3>\n<p>CoreDNS operates as a resolver and forwarder for DNS requests within Kubernetes clusters. When a pod needs to communicate with another service, it sends a DNS query to CoreDNS, specifying the domain name of the target service. CoreDNS then resolves this query by mapping the domain name to the corresponding IP address using its internal records.</p>\n<p>For external domain names that CoreDNS is not authoritative for, it forwards the DNS query to public resolvers or upstream DNS servers for resolution.</p>\n<p>To enhance performance and reduce latency, CoreDNS can cache DNS responses for frequently accessed domain names. This caching mechanism improves the responsiveness of DNS queries and reduces the load on upstream DNS servers.</p>\n<p>CoreDNS achieves this functionality through its modular architecture and extensible plugin system, allowing operators to customize and optimize DNS resolution according to their specific requirements.</p>\n<h2 id=\"-mitigating-coredns-throttling-in-amazon-eks\" style=\"position:relative;\"><a href=\"#-mitigating-coredns-throttling-in-amazon-eks\" aria-label=\" mitigating coredns throttling in amazon eks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Mitigating CoreDNS Throttling in Amazon EKS</h2>\n<p>In Amazon EKS clusters, CoreDNS and DNS throttling issues can be challenging to identify and troubleshoot. While many users focus on monitoring CoreDNS logs and metrics, they often overlook the hard limit of 1024 <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#vpc-dns-limits\" target=\"_blank\" rel=\"noopener noreferrer\">packets per second (PPS)</a> enforced at the Elastic Network Interface (ENI) level. Understanding how this limit can lead to throttling issues requires insight into the typical DNS resolution flow of a Kubernetes pod.</p>\n<p>In a Kubernetes environment, pods must resolve domain names for both internal and external services to enable communication. This resolution process involves routing DNS queries through the worker node's ENI, particularly when resolving external endpoints. Even for internal endpoints, if the CoreDNS pod is not co-located with the querying pod, DNS packets still traverse the worker node's ENI.</p>\n<p>Consider a scenario where there is a sudden surge in DNS queries, causing the PPS to approach the hard limit of 1024. This situation can result in DNS throttling, impacting all microservices running on the affected worker node. Unfortunately, troubleshooting such issues can be hard because the focus tends to be on CoreDNS pods rather than ENI metrics.</p>\n<p>To mitigate DNS throttling issues in EKS clusters, it is important to monitor packet drops occurring at the ENI level continuously. This monitoring allows for early detection and prevention of potential outages. In this blog post, we introduce a solution that leverages network performance metrics to identify DNS throttling issues effectively.</p>\n<h3 id=\"Ô∏è-solution\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-solution\" aria-label=\"Ô∏è solution permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ°Ô∏è Solution</h3>\n<p>An easy way to identify the DNS throttling issues in worker nodes is by capturing the <code class=\"language-text\">linklocal_allowance_exceeded</code> metric provided by the Elastic Network Adapter (ENA) driver and other metrics as well.</p>\n<p>The <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent\" target=\"_blank\" rel=\"noopener noreferrer\"><code class=\"language-text\">linklocal_allowance_exceeded</code></a> metric indicates the number of packets dropped because the PPS of the traffic to local proxy services exceeded the maximum for the network interface. This impacts traffic to the DNS service, the Instance Metadata Service, and the Amazon Time Sync Service.</p>\n<p>Instead of tracking this event in real-time, we can stream this metric to <a href=\"https://aws.amazon.com/prometheus/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Managed Service for Prometheus</a> and visualize it in <a href=\"https://aws.amazon.com/grafana/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Managed Grafana</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 581px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 77.64705882352942%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAB7k1C6hn/xAAaEAACAgMAAAAAAAAAAAAAAAAAAQISESEx/9oACAEBAAEFAuF1YztpOR//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAcEAABAwUAAAAAAAAAAAAAAAARABBBAQISIVH/2gAIAQEABj8CCxlhtCtscb//xAAbEAEAAgIDAAAAAAAAAAAAAAABESEAEDFBcf/aAAgBAQABPyEQGB7+E6aYeorG0ibPbX//2gAMAwEAAgADAAAAENPf/8QAFhEBAQEAAAAAAAAAAAAAAAAAARBB/9oACAEDAQE/EANn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxAAAwEAAwEAAAAAAAAAAAAAAREhABAxUXH/2gAIAQEAAT8QAgtIU3EoRYEUuLazKQXp3xkBA0nupv/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"adot\" title=\"\" src=\"/static/9c0e9af412476642f6bdb554799934fd/f0d01/adot.jpg\" srcset=\"/static/9c0e9af412476642f6bdb554799934fd/651be/adot.jpg 170w,\n/static/9c0e9af412476642f6bdb554799934fd/d30a3/adot.jpg 340w,\n/static/9c0e9af412476642f6bdb554799934fd/f0d01/adot.jpg 581w\" sizes=\"(max-width: 581px) 100vw, 581px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"Ô∏è-hands-on-collect-and-visualize-coredns-metrics-in-aws-eks\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-hands-on-collect-and-visualize-coredns-metrics-in-aws-eks\" aria-label=\"Ô∏è hands on collect and visualize coredns metrics in aws eks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Hands-on: Collect and Visualize CoreDNS Metrics in AWS EKS</h2>\n<h3 id=\"-coredns-prometheus-plugin\" style=\"position:relative;\"><a href=\"#-coredns-prometheus-plugin\" aria-label=\" coredns prometheus plugin permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìä CoreDNS Prometheus Plugin</h3>\n<p>The <a href=\"https://coredns.io/plugins/metrics/\" target=\"_blank\" rel=\"noopener noreferrer\">CoreDNS Prometheus plugin</a> exposes metrics in the <a href=\"https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md\" target=\"_blank\" rel=\"noopener noreferrer\">OpenMetrics</a> format, a text-based standard that evolved from the <a href=\"https://prometheus.io/docs/instrumenting/exposition_formats/#text-based-format\" target=\"_blank\" rel=\"noopener noreferrer\">Prometheus format</a>. In a Kubernetes cluster, the plugin is enabled by default, so you can begin monitoring <a href=\"https://www.datadoghq.com/blog/coredns-metrics\" target=\"_blank\" rel=\"noopener noreferrer\">many key metrics</a> as soon as you launch your cluster.</p>\n<p>By default, the Prometheus plugin writes metrics to a <code class=\"language-text\">/metrics</code> endpoint on port <code class=\"language-text\">9153</code> on each CoreDNS pod.</p>\n<h3 id=\"Ô∏è-create-an-amazon-managed-service-for-prometheus-workspace-and-managed-service-for-grafana\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-create-an-amazon-managed-service-for-prometheus-workspace-and-managed-service-for-grafana\" aria-label=\"Ô∏è create an amazon managed service for prometheus workspace and managed service for grafana permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèóÔ∏è Create an Amazon Managed Service for Prometheus Workspace and Managed Service for Grafana</h3>\n<p>In this step, we will create a workspace for Amazon Managed Service for Prometheus and Managed Service for Grafana. The configuration in these files creates:</p>\n<ul>\n<li>AMP workspace</li>\n<li>AMP alert manager definition</li>\n</ul>\n<h4 id=\"code-classlanguage-textmaintfcode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textmaintfcode\" aria-label=\"code classlanguage textmaintfcode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">main.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">module<span class=\"token type variable\"> \"prometheus\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-prometheus/aws\"</span>\n\n    <span class=\"token property\">workspace_alias</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"demo-coredns\"</span>\n\n    <span class=\"token property\">alert_manager_definition</span> <span class=\"token punctuation\">=</span> <span class=\"token heredoc string\">&lt;&lt;-EOT\n    alertmanager_config: |\n        route:\n            receiver: 'default'\n        receivers:\n            - name: 'default'\n    EOT</span>\n\n    <span class=\"token property\">rule_group_namespaces</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h4 id=\"code-classlanguage-textversionstfcode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textversionstfcode\" aria-label=\"code classlanguage textversionstfcode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">versions.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">terraform</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">required_version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 1.3\"</span>\n\n    <span class=\"token keyword\">required_providers</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">aws</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">source</span>  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"hashicorp/aws\"</span>\n            <span class=\"token property\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 5.32\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>To run the Terraform code, execute:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">$ terraform init\n$ terraform plan\n$ terraform apply</code></pre></div>\n<h3 id=\"Ô∏è-create-a-default-grafana-workspace\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-create-a-default-grafana-workspace\" aria-label=\"Ô∏è create a default grafana workspace permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üñ•Ô∏è Create a Default Grafana Workspace</h3>\n<p>The below configuration files will create a default Grafana workspace using defaults provided by the module.</p>\n<h4 id=\"code-classlanguage-textmaintfcode-1\" style=\"position:relative;\"><a href=\"#code-classlanguage-textmaintfcode-1\" aria-label=\"code classlanguage textmaintfcode 1 permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">main.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">provider<span class=\"token type variable\"> \"aws\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">region</span> <span class=\"token punctuation\">=</span> local.region\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">data <span class=\"token type variable\">\"aws_availability_zones\"</span></span> <span class=\"token string\">\"available\"</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">locals</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">region</span>      <span class=\"token punctuation\">=</span> <span class=\"token string\">\"eu-west-1\"</span>\n    <span class=\"token property\">name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"amg-ex-<span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token punctuation\">{</span><span class=\"token function\">replace</span><span class=\"token punctuation\">(</span><span class=\"token function\">basename</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">path</span><span class=\"token punctuation\">.</span><span class=\"token type variable\">cwd</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"_\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"-\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span>\"</span>\n    <span class=\"token property\">description</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"AWS Managed Grafana service for <span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token punctuation\">{</span><span class=\"token keyword\">local</span><span class=\"token punctuation\">.</span><span class=\"token type variable\">name</span><span class=\"token punctuation\">}</span></span>\"</span>\n\n    <span class=\"token property\">vpc_cidr</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"10.0.0.0/16\"</span>\n    <span class=\"token property\">azs</span>      <span class=\"token punctuation\">=</span> slice(data.aws_availability_zones.available.names, <span class=\"token number\">0</span>, <span class=\"token number\">3</span>)\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"managed_grafana\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n    <span class=\"token property\">name</span>                      <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">associate_license</span>         <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n    <span class=\"token property\">description</span>               <span class=\"token punctuation\">=</span> local.description\n    <span class=\"token property\">account_access_type</span>       <span class=\"token punctuation\">=</span> <span class=\"token string\">\"CURRENT_ACCOUNT\"</span>\n    <span class=\"token property\">authentication_providers</span>  <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"AWS_SSO\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token property\">permission_type</span>           <span class=\"token punctuation\">=</span> <span class=\"token string\">\"SERVICE_MANAGED\"</span>\n    <span class=\"token property\">data_sources</span>              <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"CLOUDWATCH\"</span>, <span class=\"token string\">\"PROMETHEUS\"</span>, <span class=\"token string\">\"XRAY\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token property\">notification_destinations</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"SNS\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token property\">stack_set_name</span>            <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">grafana_version</span>           <span class=\"token punctuation\">=</span> <span class=\"token string\">\"9.4\"</span>\n\n    <span class=\"token property\">configuration</span> <span class=\"token punctuation\">=</span> jsonencode(<span class=\"token punctuation\">{</span>\n        <span class=\"token property\">unifiedAlerting</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">enabled</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n        <span class=\"token punctuation\">}</span>,\n        <span class=\"token property\">plugins</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">pluginAdminEnabled</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>)\n\n    <span class=\"token property\">vpc_configuration</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">subnet_ids</span> <span class=\"token punctuation\">=</span> module.vpc.private_subnets\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token property\">security_group_rules</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">egress_postgresql</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">description</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"Allow egress to PostgreSQL\"</span>\n            <span class=\"token property\">from_port</span>   <span class=\"token punctuation\">=</span> <span class=\"token number\">5432</span>\n            <span class=\"token property\">to_port</span>     <span class=\"token punctuation\">=</span> <span class=\"token number\">5432</span>\n            <span class=\"token property\">protocol</span>    <span class=\"token punctuation\">=</span> <span class=\"token string\">\"tcp\"</span>\n            <span class=\"token property\">cidr_blocks</span> <span class=\"token punctuation\">=</span> module.vpc.private_subnets_cidr_blocks\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token property\">workspace_api_keys</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">viewer</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">key_name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"viewer\"</span>\n            <span class=\"token property\">key_role</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"VIEWER\"</span>\n            <span class=\"token property\">seconds_to_live</span> <span class=\"token punctuation\">=</span> <span class=\"token number\">3600</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token property\">editor</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">key_name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"editor\"</span>\n            <span class=\"token property\">key_role</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"EDITOR\"</span>\n            <span class=\"token property\">seconds_to_live</span> <span class=\"token punctuation\">=</span> <span class=\"token number\">3600</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token property\">admin</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">key_name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"admin\"</span>\n            <span class=\"token property\">key_role</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"ADMIN\"</span>\n            <span class=\"token property\">seconds_to_live</span> <span class=\"token punctuation\">=</span> <span class=\"token number\">3600</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token property\">create_iam_role</span>                <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n    <span class=\"token property\">iam_role_name</span>                  <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">use_iam_role_name_prefix</span>       <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n    <span class=\"token property\">iam_role_description</span>           <span class=\"token punctuation\">=</span> local.description\n    <span class=\"token property\">iam_role_path</span>                  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"/grafana/\"</span>\n    <span class=\"token property\">iam_role_force_detach_policies</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n    <span class=\"token property\">iam_role_max_session_duration</span>  <span class=\"token punctuation\">=</span> <span class=\"token number\">7200</span>\n    <span class=\"token property\">iam_role_tags</span>                  <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">role</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span> <span class=\"token punctuation\">}</span>\n\n    <span class=\"token property\">tags</span> <span class=\"token punctuation\">=</span> local.tags\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"managed_grafana_default\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n    <span class=\"token property\">name</span>              <span class=\"token punctuation\">=</span> <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token punctuation\">{</span><span class=\"token keyword\">local</span><span class=\"token punctuation\">.</span><span class=\"token type variable\">name</span><span class=\"token punctuation\">}</span></span>-default\"</span>\n    <span class=\"token property\">associate_license</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n\n    <span class=\"token property\">tags</span> <span class=\"token punctuation\">=</span> local.tags\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"managed_grafana_disabled\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n    <span class=\"token property\">name</span>   <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">create</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"vpc\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span>  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/vpc/aws\"</span>\n    <span class=\"token property\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"~> 5.0\"</span>\n\n    <span class=\"token property\">name</span> <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">cidr</span> <span class=\"token punctuation\">=</span> local.vpc_cidr\n\n    <span class=\"token property\">azs</span>             <span class=\"token punctuation\">=</span> local.azs\n    <span class=\"token property\">private_subnets</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span>for k, v in local.azs : cidrsubnet(local.vpc_cidr, <span class=\"token number\">4</span>, k)<span class=\"token punctuation\">]</span>\n    <span class=\"token property\">public_subnets</span>  <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span>for k, v in local.azs : cidrsubnet(local.vpc_cidr, <span class=\"token number\">8</span>, k + <span class=\"token number\">48</span>)<span class=\"token punctuation\">]</span>\n\n    <span class=\"token property\">enable_nat_gateway</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span> \n    <span class=\"token property\">single_nat_gateway</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n\n    <span class=\"token property\">tags</span> <span class=\"token punctuation\">=</span> local.tags\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h4 id=\"code-classlanguage-textversionstfcode-1\" style=\"position:relative;\"><a href=\"#code-classlanguage-textversionstfcode-1\" aria-label=\"code classlanguage textversionstfcode 1 permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">versions.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">terraform</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">required_version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 1.0\"</span>\n\n    <span class=\"token keyword\">required_providers</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">aws</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">source</span>  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"hashicorp/aws\"</span>\n            <span class=\"token property\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 5.0\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>To run this code, execute:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">$ terraform init\n$ terraform plan\n$ terraform apply</code></pre></div>\n<h3 id=\"-deploying-prometheus-ethtool-exporter\" style=\"position:relative;\"><a href=\"#-deploying-prometheus-ethtool-exporter\" aria-label=\" deploying prometheus ethtool exporter permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Deploying Prometheus Ethtool Exporter</h3>\n<p><a href=\"https://linux.die.net/man/8/ethtool\" target=\"_blank\" rel=\"noopener noreferrer\">Ethtool</a> is a Linux tool for configuring and gathering information about Ethernet devices on worker nodes. We will use ethtool's output to detect packet loss and convert it to Prometheus format with a Prometheus ethtool exporter utility.</p>\n<p>Deploy the exporter using:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">-f</span> https://raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml</code></pre></div>\n<h3 id=\"-deploy-adot-collector-to-scrape-ethtool-metrics\" style=\"position:relative;\"><a href=\"#-deploy-adot-collector-to-scrape-ethtool-metrics\" aria-label=\" deploy adot collector to scrape ethtool metrics permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üì¶ Deploy ADOT Collector to Scrape Ethtool Metrics</h3>\n<p>In this step, we will deploy the ADOT collector and configure it to ingest metrics to Amazon Managed Service for Prometheus. We will use the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/opentelemetry.html\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon EKS add-on for ADOT operator</a> to send the metrics <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent\" target=\"_blank\" rel=\"noopener noreferrer\">linklocal_allowance_exceeded</a> to Amazon Managed Service for Prometheus for monitoring CoreDNS.</p>\n<h4 id=\"create-an-iam-role-and-amazon-eks-service-account\" style=\"position:relative;\"><a href=\"#create-an-iam-role-and-amazon-eks-service-account\" aria-label=\"create an iam role and amazon eks service account permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Create an IAM Role and Amazon EKS Service Account</h4>\n<p>We will deploy the ADOT collector to run under the identity of a Kubernetes <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\" target=\"_blank\" rel=\"noopener noreferrer\">service account</a> <code class=\"language-text\">adot-collector</code>. <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\" target=\"_blank\" rel=\"noopener noreferrer\">IAM roles for service accounts (IRSA)</a> let you associate the <code class=\"language-text\">AmazonPrometheusRemoteWriteAccess</code> role with a Kubernetes service account, thereby providing IAM permissions to any pod utilizing the service account to ingest the metrics to Amazon Managed Service for Prometheus.</p>\n<p>You need <code class=\"language-text\">kubectl</code> and <code class=\"language-text\">eksctl</code> CLI tools to run the script. They must be configured to access your Amazon EKS cluster.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">eksctl create iamserviceaccount <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--name</span> adot-collector <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--namespace</span> default <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--region</span> eu-west-1 <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--cluster</span> coredns-monitoring-demo <span class=\"token punctuation\">\\</span>\n--attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--approve</span> <span class=\"token punctuation\">\\</span>\n--override-existing-serviceaccounts</code></pre></div>\n<h4 id=\"install-adot-add-on\" style=\"position:relative;\"><a href=\"#install-adot-add-on\" aria-label=\"install adot add on permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install ADOT Add-on</h4>\n<p>You can check the list of add-ons enabled for different versions of Amazon EKS using the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">aws eks describe-addon-versions --addon-name adot --kubernetes-version <span class=\"token number\">1.28</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--query</span> <span class=\"token string\">\"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\"</span> <span class=\"token parameter variable\">--output</span> text</code></pre></div>\n<p>Run the following command to install the ADOT add-on, replacing the <code class=\"language-text\">--addon-version</code> flag based on your Amazon EKS cluster version as shown in the step above.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">aws eks create-addon --addon-name adot --addon-version v0.66.0-eksbuild.1 --cluster-name coredns-monitoring-demo</code></pre></div>\n<p>Verify that the ADOT add-on is ready using the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl get po <span class=\"token parameter variable\">-n</span> opentelemetry-operator-system</code></pre></div>\n<p>The following procedure uses an example YAML file with <code class=\"language-text\">deployment</code> as the mode value. This is the default mode and deploys the ADOT Collector similarly to a standalone application. This configuration receives OTLP metrics from the sample application and Amazon Managed Service for Prometheus metrics scraped from pods on the cluster.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">curl</span> <span class=\"token parameter variable\">-o</span> collector-config-amp.yaml https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml</code></pre></div>\n<p>In <code class=\"language-text\">collector-config-amp.yaml</code>, replace the following with your own values:</p>\n<ul>\n<li><code class=\"language-text\">mode: deployment</code></li>\n<li><code class=\"language-text\">serviceAccount: adot-collector</code></li>\n<li><code class=\"language-text\">endpoint: \"\"</code></li>\n<li><code class=\"language-text\">region: \"\"</code></li>\n<li><code class=\"language-text\">name: adot-collector</code></li>\n</ul>\n<p>Apply the configuration:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">-f</span> collector-config-amp.yaml</code></pre></div>\n<p>Once the ADOT collector is deployed, the metrics will be stored successfully in Amazon Prometheus.</p>\n<h3 id=\"-visualize-ethtool-metrics-in-amazon-managed-grafana\" style=\"position:relative;\"><a href=\"#-visualize-ethtool-metrics-in-amazon-managed-grafana\" aria-label=\" visualize ethtool metrics in amazon managed grafana permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìà Visualize Ethtool Metrics in Amazon Managed Grafana</h3>\n<p>Configure the Amazon Managed Service for Prometheus workspace as a datasource inside the Amazon Managed Grafana console.</p>\n<p>Let's explore the metrics in Amazon Managed Grafana now: Click the explore button, and search for <code class=\"language-text\">ethtool</code>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 45.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAABLklEQVR42m2QW2rDMBREvY3Yji3JkiNZsiLJbyctIdCSr0CX0d/u/6MTm5S2GA6X4UpzX1GwVlZOSaO146Ki7EBZSWi5iD9IVavKKkTdXe5f0/tnlKQ547oybZrSXZwBiH1WxAnZxfkmeNpnPElJhN+lPKIY5TVbkMqqyolSs0IWXCFmOf8NSicpBRFlgjAldVMIs2LqxtTBHjvnh2dsne8BhA+jNh4NsEgkmMgILw8GCy8oH4amnZtmgoDTL6zCuR7mEEZUf5jzvMiJwJBPc4VCUtqDtFxoXA5DbpLuGQ5GcF4Y4F9KqDB/yHpirMTC684/gj2EXDOPzjDjelBoAnAPH+b5dO37sxAaQ635f+A/mkfT/Hp0XT+cu/4E2m6+XN5ut/v55Qq9JjcJzfgNOSlWDJU98DgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"apm\" title=\"\" src=\"/static/8073f7721006157bf3b6efc69fec4184/c5bb3/apm.png\" srcset=\"/static/8073f7721006157bf3b6efc69fec4184/04472/apm.png 170w,\n/static/8073f7721006157bf3b6efc69fec4184/9f933/apm.png 340w,\n/static/8073f7721006157bf3b6efc69fec4184/c5bb3/apm.png 680w,\n/static/8073f7721006157bf3b6efc69fec4184/b12f7/apm.png 1020w,\n/static/8073f7721006157bf3b6efc69fec4184/b5a09/apm.png 1360w,\n/static/8073f7721006157bf3b6efc69fec4184/07a9c/apm.png 1440w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Let's build a dashboard for the linklocal_allowance_exceeded metric by using the query</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">rate<span class=\"token punctuation\">(</span>node_net_ethtool<span class=\"token punctuation\">{</span>device<span class=\"token operator\">=</span><span class=\"token string\">\"eth0\"</span>,type<span class=\"token operator\">=</span><span class=\"token string\">\"linklocal_allo\nwance_exceeded\"</span><span class=\"token punctuation\">}</span> <span class=\"token punctuation\">[</span>30s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 53.529411764705884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA6ElEQVR42p2SaU7EMAyFcwVmaRpncewsRAX+cP/D4SadzqgDCCF9spyXPtuKq3xIBvB0nl9O+sD5Yg5HPfupo024XEFNJqwHwAOzjQ6zxEfFONoRoxqSxGeG4XtclJbqx+vfGeY+0n/N4NkGBk+SdOiW05NIj6KGoIhL5OLE79AIFmGLUTBdhD3a+wdr5xSz9eyxCi4kyc3tVUGi7fQcHA9EyfVddqHa2yel11yXlBtiKmXJpXFuAXOIRa4iVeI26u4gVbBRlfbBdemFSa8jjSbb8vYRDn/BBHiVsa2UDGm220p154+v/QUx8kjqifT8IgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"result\" title=\"\" src=\"/static/65e84ae8ccc9fd90579aa4af904c0687/c5bb3/result.png\" srcset=\"/static/65e84ae8ccc9fd90579aa4af904c0687/04472/result.png 170w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/9f933/result.png 340w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/c5bb3/result.png 680w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/b12f7/result.png 1020w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/b5a09/result.png 1360w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/07a9c/result.png 1440w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>We can see that there were no packets dropped as the value is zero. You can further extend this by configuring alerts in the alert manager in Amazon Managed Service for Prometheus to send notifications.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h2>\n<p>In this post, we showed how to monitor and create alerts for CoreDNS throttling issues using AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus, and Amazon Managed Grafana. By monitoring the coreDNS metrics, customers can proactively detect packet drops and take preventive actions.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":8,"rawMarkdownBody":"\n## üìö Introduction\n\nRunning DNS-intensive workloads can sometimes lead to intermittent [CoreDNS](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#coredns) failures caused by DNS throttling. These issues can have a significant impact on your applications.\n\nSuch disruptions can hinder the reliability and performance of your services, making it mandatory to have a monitoring solution in place. AWS offers a suite of open-source tools‚Ää‚Äî‚Ää[CloudWatch](https://aws.amazon.com/cloudwatch/), [Fluentd](https://www.fluentd.org/), and [Grafana](https://grafana.com/)‚Ää‚Äî‚Ääthat can be integrated to monitor CoreDNS.\n\n## üß© Introduction to Kubernetes DNS\n\nKubernetes relies on [DNS](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#introduction) for service discovery within clusters. When applications running in pods need to communicate with each other, they often refer to services by their domain names rather than IP addresses.\n\nThis is where Kubernetes DNS comes into play. It ensures that these domain names are resolved to the correct IP addresses, allowing pods and services to communicate.\n\nIn Kubernetes, each pod is assigned a temporary IP address. However, these IP addresses are dynamic and can change over time, making it challenging for applications to keep track of them. Kubernetes addresses this challenge by assigning fully qualified domain names ([FQDNs](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#dns-records)) to pods and services.\n\nCoreDNS, the default DNS provider in Kubernetes, is responsible for handling DNS queries within the cluster. It maps these FQDNs to the corresponding IP addresses, enabling communication between pods and services.\n\n## üõ†Ô∏è CoreDNS in Kubernetes\n\nCoreDNS plays an important role in providing DNS services within Kubernetes clusters. As the default DNS provider since Kubernetes v1.13, CoreDNS simplifies cluster networking by enabling clients to access services using DNS names rather than IP addresses. It resolves domain name requests and facilitates service discovery within the cluster.\n\n### ‚öôÔ∏è How CoreDNS Operates\n\nCoreDNS operates as a resolver and forwarder for DNS requests within Kubernetes clusters. When a pod needs to communicate with another service, it sends a DNS query to CoreDNS, specifying the domain name of the target service. CoreDNS then resolves this query by mapping the domain name to the corresponding IP address using its internal records.\n\nFor external domain names that CoreDNS is not authoritative for, it forwards the DNS query to public resolvers or upstream DNS servers for resolution.\n\nTo enhance performance and reduce latency, CoreDNS can cache DNS responses for frequently accessed domain names. This caching mechanism improves the responsiveness of DNS queries and reduces the load on upstream DNS servers.\n\nCoreDNS achieves this functionality through its modular architecture and extensible plugin system, allowing operators to customize and optimize DNS resolution according to their specific requirements.\n\n## üöÄ Mitigating CoreDNS Throttling in Amazon EKS\n\nIn Amazon EKS clusters, CoreDNS and DNS throttling issues can be challenging to identify and troubleshoot. While many users focus on monitoring CoreDNS logs and metrics, they often overlook the hard limit of 1024 [packets per second (PPS)](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#vpc-dns-limits) enforced at the Elastic Network Interface (ENI) level. Understanding how this limit can lead to throttling issues requires insight into the typical DNS resolution flow of a Kubernetes pod.\n\nIn a Kubernetes environment, pods must resolve domain names for both internal and external services to enable communication. This resolution process involves routing DNS queries through the worker node's ENI, particularly when resolving external endpoints. Even for internal endpoints, if the CoreDNS pod is not co-located with the querying pod, DNS packets still traverse the worker node's ENI.\n\nConsider a scenario where there is a sudden surge in DNS queries, causing the PPS to approach the hard limit of 1024. This situation can result in DNS throttling, impacting all microservices running on the affected worker node. Unfortunately, troubleshooting such issues can be hard because the focus tends to be on CoreDNS pods rather than ENI metrics.\n\nTo mitigate DNS throttling issues in EKS clusters, it is important to monitor packet drops occurring at the ENI level continuously. This monitoring allows for early detection and prevention of potential outages. In this blog post, we introduce a solution that leverages network performance metrics to identify DNS throttling issues effectively.\n\n### üõ°Ô∏è Solution\n\nAn easy way to identify the DNS throttling issues in worker nodes is by capturing the `linklocal_allowance_exceeded` metric provided by the Elastic Network Adapter (ENA) driver and other metrics as well.\n\nThe [`linklocal_allowance_exceeded`](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent) metric indicates the number of packets dropped because the PPS of the traffic to local proxy services exceeded the maximum for the network interface. This impacts traffic to the DNS service, the Instance Metadata Service, and the Amazon Time Sync Service.\n\nInstead of tracking this event in real-time, we can stream this metric to [Amazon Managed Service for Prometheus](https://aws.amazon.com/prometheus/) and visualize it in [Amazon Managed Grafana](https://aws.amazon.com/grafana/).\n\n\n![adot](adot.jpg)\n\n\n## üõ†Ô∏è Hands-on: Collect and Visualize CoreDNS Metrics in AWS EKS\n\n### üìä CoreDNS Prometheus Plugin\n\nThe [CoreDNS Prometheus plugin](https://coredns.io/plugins/metrics/) exposes metrics in the [OpenMetrics](https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md) format, a text-based standard that evolved from the [Prometheus format](https://prometheus.io/docs/instrumenting/exposition_formats/#text-based-format). In a Kubernetes cluster, the plugin is enabled by default, so you can begin monitoring [many key metrics](https://www.datadoghq.com/blog/coredns-metrics) as soon as you launch your cluster.\n\nBy default, the Prometheus plugin writes metrics to a `/metrics` endpoint on port `9153` on each CoreDNS pod.\n\n### üèóÔ∏è Create an Amazon Managed Service for Prometheus Workspace and Managed Service for Grafana\n\nIn this step, we will create a workspace for Amazon Managed Service for Prometheus and Managed Service for Grafana. The configuration in these files creates:\n\n- AMP workspace\n- AMP alert manager definition\n\n#### `main.tf`\n\n```hcl\nmodule \"prometheus\" {\n    source = \"terraform-aws-modules/managed-service-prometheus/aws\"\n\n    workspace_alias = \"demo-coredns\"\n\n    alert_manager_definition = <<-EOT\n    alertmanager_config: |\n        route:\n            receiver: 'default'\n        receivers:\n            - name: 'default'\n    EOT\n\n    rule_group_namespaces = {}\n}\n```\n\n#### `versions.tf`\n\n```hcl\nterraform {\n    required_version = \">= 1.3\"\n\n    required_providers {\n        aws = {\n            source  = \"hashicorp/aws\"\n            version = \">= 5.32\"\n        }\n    }\n}\n```\n\nTo run the Terraform code, execute:\n\n```sh\n$ terraform init\n$ terraform plan\n$ terraform apply\n```\n\n### üñ•Ô∏è Create a Default Grafana Workspace\n\nThe below configuration files will create a default Grafana workspace using defaults provided by the module.\n\n#### `main.tf`\n\n```hcl\nprovider \"aws\" {\n    region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n    region      = \"eu-west-1\"\n    name        = \"amg-ex-${replace(basename(path.cwd), \"_\", \"-\")}\"\n    description = \"AWS Managed Grafana service for ${local.name}\"\n\n    vpc_cidr = \"10.0.0.0/16\"\n    azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n}\n\nmodule \"managed_grafana\" {\n    source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n    name                      = local.name\n    associate_license         = false\n    description               = local.description\n    account_access_type       = \"CURRENT_ACCOUNT\"\n    authentication_providers  = [\"AWS_SSO\"]\n    permission_type           = \"SERVICE_MANAGED\"\n    data_sources              = [\"CLOUDWATCH\", \"PROMETHEUS\", \"XRAY\"]\n    notification_destinations = [\"SNS\"]\n    stack_set_name            = local.name\n    grafana_version           = \"9.4\"\n\n    configuration = jsonencode({\n        unifiedAlerting = {\n            enabled = true\n        },\n        plugins = {\n            pluginAdminEnabled = false\n        }\n    })\n\n    vpc_configuration = {\n        subnet_ids = module.vpc.private_subnets\n    }\n    security_group_rules = {\n        egress_postgresql = {\n            description = \"Allow egress to PostgreSQL\"\n            from_port   = 5432\n            to_port     = 5432\n            protocol    = \"tcp\"\n            cidr_blocks = module.vpc.private_subnets_cidr_blocks\n        }\n    }\n\n    workspace_api_keys = {\n        viewer = {\n            key_name        = \"viewer\"\n            key_role        = \"VIEWER\"\n            seconds_to_live = 3600\n        }\n        editor = {\n            key_name        = \"editor\"\n            key_role        = \"EDITOR\"\n            seconds_to_live = 3600\n        }\n        admin = {\n            key_name        = \"admin\"\n            key_role        = \"ADMIN\"\n            seconds_to_live = 3600\n        }\n    }\n\n    create_iam_role                = true\n    iam_role_name                  = local.name\n    use_iam_role_name_prefix       = true\n    iam_role_description           = local.description\n    iam_role_path                  = \"/grafana/\"\n    iam_role_force_detach_policies = true\n    iam_role_max_session_duration  = 7200\n    iam_role_tags                  = { role = true }\n\n    tags = local.tags\n}\n\nmodule \"managed_grafana_default\" {\n    source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n    name              = \"${local.name}-default\"\n    associate_license = false\n\n    tags = local.tags\n}\n\nmodule \"managed_grafana_disabled\" {\n    source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n    name   = local.name\n    create = false\n}\n\nmodule \"vpc\" {\n    source  = \"terraform-aws-modules/vpc/aws\"\n    version = \"~> 5.0\"\n\n    name = local.name\n    cidr = local.vpc_cidr\n\n    azs             = local.azs\n    private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n    public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n\n    enable_nat_gateway = false \n    single_nat_gateway = true\n\n    tags = local.tags\n}\n```\n\n#### `versions.tf`\n\n```hcl\nterraform {\n    required_version = \">= 1.0\"\n\n    required_providers {\n        aws = {\n            source  = \"hashicorp/aws\"\n            version = \">= 5.0\"\n        }\n    }\n}\n```\n\nTo run this code, execute:\n\n```sh\n$ terraform init\n$ terraform plan\n$ terraform apply\n```\n\n### üöÄ Deploying Prometheus Ethtool Exporter\n\n[Ethtool](https://linux.die.net/man/8/ethtool) is a Linux tool for configuring and gathering information about Ethernet devices on worker nodes. We will use ethtool's output to detect packet loss and convert it to Prometheus format with a Prometheus ethtool exporter utility.\n\nDeploy the exporter using:\n\n```sh\nkubectl apply -f https://raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml\n```\n\n### üì¶ Deploy ADOT Collector to Scrape Ethtool Metrics\n\nIn this step, we will deploy the ADOT collector and configure it to ingest metrics to Amazon Managed Service for Prometheus. We will use the [Amazon EKS add-on for ADOT operator](https://docs.aws.amazon.com/eks/latest/userguide/opentelemetry.html) to send the metrics [linklocal_allowance_exceeded](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent) to Amazon Managed Service for Prometheus for monitoring CoreDNS.\n\n#### Create an IAM Role and Amazon EKS Service Account\n\nWe will deploy the ADOT collector to run under the identity of a Kubernetes [service account](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) `adot-collector`. [IAM roles for service accounts (IRSA)](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html) let you associate the `AmazonPrometheusRemoteWriteAccess` role with a Kubernetes service account, thereby providing IAM permissions to any pod utilizing the service account to ingest the metrics to Amazon Managed Service for Prometheus.\n\nYou need `kubectl` and `eksctl` CLI tools to run the script. They must be configured to access your Amazon EKS cluster.\n\n```sh\neksctl create iamserviceaccount \\\n--name adot-collector \\\n--namespace default \\\n--region eu-west-1 \\\n--cluster coredns-monitoring-demo \\\n--attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \\\n--approve \\\n--override-existing-serviceaccounts\n```\n\n#### Install ADOT Add-on\n\nYou can check the list of add-ons enabled for different versions of Amazon EKS using the following command:\n\n```sh\naws eks describe-addon-versions --addon-name adot --kubernetes-version 1.28 \\\n    --query \"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\" --output text\n```\n\nRun the following command to install the ADOT add-on, replacing the `--addon-version` flag based on your Amazon EKS cluster version as shown in the step above.\n\n```sh\naws eks create-addon --addon-name adot --addon-version v0.66.0-eksbuild.1 --cluster-name coredns-monitoring-demo\n```\n\nVerify that the ADOT add-on is ready using the following command:\n\n```sh\nkubectl get po -n opentelemetry-operator-system\n```\n\nThe following procedure uses an example YAML file with `deployment` as the mode value. This is the default mode and deploys the ADOT Collector similarly to a standalone application. This configuration receives OTLP metrics from the sample application and Amazon Managed Service for Prometheus metrics scraped from pods on the cluster.\n\n```sh\ncurl -o collector-config-amp.yaml https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml\n```\n\nIn `collector-config-amp.yaml`, replace the following with your own values:\n\n- `mode: deployment`\n- `serviceAccount: adot-collector`\n- `endpoint: \"\"`\n- `region: \"\"`\n- `name: adot-collector`\n\nApply the configuration:\n\n```sh\nkubectl apply -f collector-config-amp.yaml\n```\n\nOnce the ADOT collector is deployed, the metrics will be stored successfully in Amazon Prometheus.\n\n### üìà Visualize Ethtool Metrics in Amazon Managed Grafana\n\nConfigure the Amazon Managed Service for Prometheus workspace as a datasource inside the Amazon Managed Grafana console.\n\nLet's explore the metrics in Amazon Managed Grafana now: Click the explore button, and search for `ethtool`.\n\n![apm](./apm.png)\n\nLet's build a dashboard for the linklocal_allowance_exceeded metric by using the query\n\n```shell\nrate(node_net_ethtool{device=\"eth0\",type=\"linklocal_allo\nwance_exceeded\"} [30s])\n```\n\n![result](./result.png)\n\nWe can see that there were no packets dropped as the value is zero. You can further extend this by configuring alerts in the alert manager in Amazon Managed Service for Prometheus to send notifications.\n\n## Conclusion\n\nIn this post, we showed how to monitor and create alerts for CoreDNS throttling issues using AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus, and Amazon Managed Grafana. By monitoring the coreDNS metrics, customers can proactively detect packet drops and take preventive actions.\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1406},"frontmatter":{"id":"8fb13d41ebd7961bec03c200","path":"/blog/monitoring-coredns-dns-performance/","humanDate":"Oct 21, 2024","fullDate":"2024-10-21","title":"Everything You Need to Know About Monitoring CoreDNS for DNS Performance","keywords":["CoreDNS","Amazon EKS","Kubernetes","Monitoring"],"excerpt":"Ensure reliable DNS resolution in Amazon Kubernetes clusters by monitoring CoreDNS performance. This guide covers essential metrics and best practices for effective DNS monitoring.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADDElEQVR42h2S60+aBxTG+cv2oTNbl7abXUzpXC3etS1e26ogioBQQC5KZfWGYJSh9VKlRlBkWulMF7fZqivN1mTZvPC+XBSsqY2b+e3tPjzJyfnwO8/z5Mj20+c8f3WA0TVJi3UGdVeIemOQarWHZvsqSn2ISu081R0hFPeGabRGqXkQpVofQV4f4KtqL+XmOLfcR5TYRGRv9s7xLfxFY2eABn2Ajt4YLbYwtaoeWh2L1JmilGnmUKjnuFzqolgTotH+QjqwRIHSy5WKfqq6fudO7xHFH4HTS3Hk5VqaDEMYesPUtfuoumtB7/SjNo9QpLRS2TbNrY5Z5DUeLt50kF/RTYlqhoI7Xq7fD/JpoY284iFKHWlkT9ZEnKObuMZ3iG4kCMfeouv/lcHZOM2OCPWmefq+j9H68EcUrSGKNFFq7Vs0u99Q63zNbVucks6X3DD8JkVOSQ6fnzCz/o+kM9Zff2B1+4zI9jmhjSwNbQ8prrVRpwtQpfbySb6Ka41P6Jz8F2Mgi24sS9PQEXWPclS5sty0JpGNrx7TM5lgYjnNytYpj+azxHZOefrzKVPRJP6VUyzTJ4yuvKPFk6GhL0WBXuCiKsHXehGlO81tV4oyR5Iii9Th/cG33HVto2x5xsRigtWtD6ztnOEe2OFqXhcVhcP4nopMxE4wPz7kijbBDUsCy4RIpVMgT7UvuUtTak/xrVkClplfMjAr0NT1CtfYH/iW3+NdPKS5fAzFhS4ufTlI30KO4XCONl+GS+0HjCwJRDczTD0T+KJ9l0LzR2CSb0wSsKFbKlO7Qan2FwbnkyxsvCe4fozJt4vJvsnoUoaR6DEaCVbZneJC8z6uOYGf4imGQwk+b91Dbkr+/zLyTgHZ47UTWgf+xOIXsE1lGY1kmVzeoz+4iyd8wPgPAlrP39R/J3JvIE2+QeQzCVLm3Ody2740i5Q7pbgPBAoMCWTBF+/wRU6wT+WkXg7xLOYw+kV0Iwk0HkHaZTD409S4k5IyqDyHEixJvk7kmlGC9SRRWEWuGwWu6hL8B/hEfHqMLUR0AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/bf9e127d7b6dc07f97525a890e662947/e7e88/coredns-cover.png","srcSet":"/static/bf9e127d7b6dc07f97525a890e662947/1d7e8/coredns-cover.png 750w,\n/static/bf9e127d7b6dc07f97525a890e662947/f874f/coredns-cover.png 1080w,\n/static/bf9e127d7b6dc07f97525a890e662947/365c0/coredns-cover.png 1366w,\n/static/bf9e127d7b6dc07f97525a890e662947/e7e88/coredns-cover.png 1440w","sizes":"100vw"},"sources":[{"srcSet":"/static/bf9e127d7b6dc07f97525a890e662947/ea0da/coredns-cover.webp 750w,\n/static/bf9e127d7b6dc07f97525a890e662947/d1e72/coredns-cover.webp 1080w,\n/static/bf9e127d7b6dc07f97525a890e662947/c101e/coredns-cover.webp 1366w,\n/static/bf9e127d7b6dc07f97525a890e662947/5eda1/coredns-cover.webp 1440w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.54375}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"nextThought":{"frontmatter":{"path":"/blog/daemonless-kaniko-container-images/","title":"Building Container Images in Kubernetes Cluster with Kaniko","date":"2024-10-21 22:22:00"},"excerpt":"Daemonless Docker Image Building in k8s¬†‚ò∏Ô∏è üìå Introduction Kaniko is an open-source tool developed by Google that enables building container‚Ä¶","html":"<blockquote>\n<p><strong>Daemonless Docker Image Building in k8s¬†‚ò∏Ô∏è</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Introduction</h2>\n<p><a href=\"https://github.com/GoogleContainerTools/kaniko\" target=\"_blank\" rel=\"noopener noreferrer\">Kaniko</a> is an open-source tool developed by Google that enables building container images from a Dockerfile inside a Kubernetes cluster without requiring a Docker daemon. Kaniko executes each command in the Dockerfile in the user space using an executor image, which runs inside a container, such as a Kubernetes pod. This allows building container images in environments where the user doesn't have root access, like a Kubernetes cluster. In this blog post, we will explore how to use Kaniko to build container images in a Kubernetes cluster without a Docker daemon.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 52.352941176470594%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjklEQVR42p2R70/TQBzG+5/72uA7JegLo28MIYBA0hBUlN8QQkAmmVkIs7CtY7TrunZbe13v+uFuG5IYXdRLnlxy1z73PJ+vxbRVKK2Cgr9f1hS332vyyL8bFhJ5tUxY3SPupyT9mG4YIAY9yNP/MFQ5w7Nn3JVWqLseNafKjeNw26hBNphiqNNn+sFBDGkfhmLSSGYg9EGmL0T0qKSrE4o/G0oJfnOsjgehX5Dnj4yURma+UVIPR02GZFBOOJpNSX6eWQ/D7AbjC6ORkd7b7R6BL0g1NiEK5C+zMCamWdIbtzRtLdNRCUFwW2jw0KhFXP8ISDSmLXuT8ukFYqh/9AJk9Zi8WSXqJgRBSJoOR2FGyAYZfjvE6n22ibY3uf6ec3OpeD37nqdPXlK58Gh9WaN1uEWsU8SVCrH9iuhom42VPd68eEulVB8xN8nOT77xfGYOq7k6z9WnMuvv4OuuwPm4w+XCErXdU9y1JZrrNq69irtzzJ0LrbrmvX9AZ2MBr9zAdRS+q4hLJ3Q+LHIPEuv7q0d8groAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"kaniko\" title=\"\" src=\"/static/7f674431801748e12a68c2b774ef9ff1/c5bb3/kaniko.png\" srcset=\"/static/7f674431801748e12a68c2b774ef9ff1/04472/kaniko.png 170w,\n/static/7f674431801748e12a68c2b774ef9ff1/9f933/kaniko.png 340w,\n/static/7f674431801748e12a68c2b774ef9ff1/c5bb3/kaniko.png 680w,\n/static/7f674431801748e12a68c2b774ef9ff1/b12f7/kaniko.png 1020w,\n/static/7f674431801748e12a68c2b774ef9ff1/c1b63/kaniko.png 1200w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-benefits-of-kaniko\" style=\"position:relative;\"><a href=\"#-benefits-of-kaniko\" aria-label=\" benefits of kaniko permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Benefits of Kaniko</h2>\n<p>Kaniko offers several benefits for building images in Kubernetes:</p>\n<ul>\n<li><strong>No Docker daemon required</strong>: Kaniko eliminates the need for a Docker daemon in a Kubernetes cluster, reducing security risks and overhead.</li>\n<li><strong>Improved security</strong>: By building images in userspace without privileges, Kaniko reduces the attack surface compared to using Docker.</li>\n<li><strong>Kubernetes integration</strong>: Kaniko is specifically designed to build images within a Kubernetes pod, seamlessly integrating into Kubernetes workflows.</li>\n<li><strong>Caching</strong>: During builds, Kaniko caches image layers, enabling faster image rebuilding.</li>\n<li><strong>Debugging</strong>: Kaniko provides robust debugging tools for troubleshooting builds, enhancing the development process.</li>\n</ul>\n<h2 id=\"Ô∏è-how-kaniko-works\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-how-kaniko-works\" aria-label=\"Ô∏è how kaniko works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚öôÔ∏è How Kaniko Works</h2>\n<p>Kaniko builds container images by parsing the Dockerfile and executing each command within a container isolated from the host environment. Instead of using a Docker daemon, Kaniko simulates the Docker builder by providing its own implementations of Docker commands like <code class=\"language-text\">ADD</code>, <code class=\"language-text\">COPY</code>, <code class=\"language-text\">RUN</code>, etc.</p>\n<p>Each command gets executed in its own scratch container based on the base image. This allows Kaniko to capture changes made by each command and construct the final image layer by layer. Kaniko also intelligently caches image layers to optimize rebuild time. The hashing of commands and layers allows for avoiding redundant build steps.</p>\n<p>For more detailed information, you can refer to the <a href=\"https://github.com/GoogleContainerTools/kaniko#readme\" target=\"_blank\" rel=\"noopener noreferrer\">Kaniko documentation</a>.</p>\n<h2 id=\"-kaniko-vs-dind\" style=\"position:relative;\"><a href=\"#-kaniko-vs-dind\" aria-label=\" kaniko vs dind permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üÜö Kaniko vs DinD</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABxElEQVR42nVTbU7CQBCt+osLeAePYIz34RYkXsR/fsZTEDSgqIQfJJTIR5BQCgXaQihud3yv7hJQnOR1tzNv387O7DoOrNFo5D3Pk263m7ZaLfF9X+I41svlUmazWVKv10+q1eoJYkm/3xeMejAYyGKxkCiKUq21wJ93rE0mkwuBff2YpGnKX21AgTPCcPR6vdaGk7n4ocZGMAiCggmusEBhgaIyFinu3m63TwnDUbAvywNnRed4PC78yZC7DYdDpi/z+VzbFDqdzhlh/6fTqe71esxqf4ao3Tlq9YC6XaF+NyDfhWF4BdzCf4njHhOc08cYOcjqhmu4lhpW78DA2hGQc3bt0GDbcoa7q4NdrtGtN+xURlcrOOozOv7COXyV+Gcs2zh9HMkh1/jK1KCWw6uRtVRrW3H57ds26yOH3N8+B8r0slvZyO6hRgpBFUehevr4VI2+p/yRr4LpbBPjSO72Wmo5SDe1mfFuEaskkSiOJQ7ncv/uyqPb5aWXwdBj93npJQHH8m2m1NoceZ/xKEuIBmNfRv5IFhD6rxSbI9dqtddSqSTFYlHjCfJViOu6GThvNl2gmcHF/3bcAjGNeyp4jq/fZ44LVaL5K5cAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"DinD\" title=\"\" src=\"/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/c5bb3/dind.png\" srcset=\"/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/04472/dind.png 170w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/9f933/dind.png 340w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/c5bb3/dind.png 680w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/b12f7/dind.png 1020w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/b5a09/dind.png 1360w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/2cefc/dind.png 1400w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>DinD (Docker in Docker) technology shares the host's Docker daemon with the container it's running in. This means that it has full access to Docker on the host, potentially impacting the host's Docker environment, which can be really dangerous. But Kaniko is more secure because it doesn't need access to the host's Docker daemon inside the container, reducing potential security risks.</p>\n<p>On the other hand, Kaniko is primarily useful for building a Docker image, while DinD has a broader range of uses, with building images being just one of them. You can perform various tasks with DinD, such as managing containers on the daemon host and monitoring their status.</p>\n<h2 id=\"-kaniko-vs-buildpacks\" style=\"position:relative;\"><a href=\"#-kaniko-vs-buildpacks\" aria-label=\" kaniko vs buildpacks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üÜö Kaniko vs Buildpacks</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABq0lEQVR42q1TbU7CQBCtHsI7cARjvI+3MOEi/IPwQw8hIRESECQRA1QKFCq0RaBQPna745t+CELkl5O8dHbn7duZnammwUzTvCOY67qBruvU6/Wo0+mo2WxGi8ViW6lUUo1GIzWfz7er1YrAUTGHLMsK+CxraIlBKE2RiSAIiCGlVFgz+OANI+YoxFXCA0ScTPpH0HGce95EBhv4EpnJ6XQqfN+XvN/tdq8Z7C+XSwmOYA5EpOd5G95njZMMJ5OJaLfb1O/3w7JwmI4zxKUETlgyLmGh0wyHw+EtbnywbTsLYg7r3GAwyIKcxxtmarXaFQOcDDLPcwxgTm48Hmf5LGskehcxztlljHMW6SCLHDr3gvJKQDkB3ibyfb8cx0p+5O9je5RYg7U0kOi/jLU0KHMnpVLqF4QQco3Y88dQvpmf3FnpuFPJXWY75rMGa2kghIN5MFchtrsdrVdLenzV6endIDSAzJFFnregHWLH/HikgrMlK4y1D4Evx+aRomSMlFJ/l1yv16vFYpEKhYJqNpvh78SzyGC/hW+r1QrRxvowngAxZRgGjUaj6jcocgiZIHL6CQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Buildpacks\" title=\"\" src=\"/static/073eca87c29c2dab8529e3190decedb2/c5bb3/buildpacks.png\" srcset=\"/static/073eca87c29c2dab8529e3190decedb2/04472/buildpacks.png 170w,\n/static/073eca87c29c2dab8529e3190decedb2/9f933/buildpacks.png 340w,\n/static/073eca87c29c2dab8529e3190decedb2/c5bb3/buildpacks.png 680w,\n/static/073eca87c29c2dab8529e3190decedb2/b12f7/buildpacks.png 1020w,\n/static/073eca87c29c2dab8529e3190decedb2/b5a09/buildpacks.png 1360w,\n/static/073eca87c29c2dab8529e3190decedb2/2cefc/buildpacks.png 1400w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Buildpacks are highly automated and aim to make image building easier, without requiring you to write a Dockerfile for your project. In contrast, Kaniko requires manual Dockerfile creation and configuration.</p>\n<p>On the other hand, Kaniko is a more low-level project that allows you to customize your project extensively, making your build process highly customizable. In comparison, the level of customization in Buildpacks can be somewhat challenging and occasionally impossible.</p>\n<h2 id=\"-using-kaniko-in-kubernetes\" style=\"position:relative;\"><a href=\"#-using-kaniko-in-kubernetes\" aria-label=\" using kaniko in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèó Using Kaniko In Kubernetes</h2>\n<p>To use Kaniko in Kubernetes, a pod specification is created with Kaniko as the container image, and the Dockerfile is mounted as a volume. Upon running the pod, Kaniko will proceed to build the image from the Dockerfile and push it to the designated registry.</p>\n<h3 id=\"example-pod-specification\" style=\"position:relative;\"><a href=\"#example-pod-specification\" aria-label=\"example pod specification permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Example Pod Specification</h3>\n<p>An example pod specification for running Kaniko is as follows:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> gcr.io/kaniko<span class=\"token punctuation\">-</span>project/executor<span class=\"token punctuation\">:</span>latest\n        <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"--dockerfile=/Dockerfile\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--destination=myregistry/myimage\"</span><span class=\"token punctuation\">]</span>\n        <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile\n                <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /Dockerfile\n    <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile\n            <span class=\"token key atrule\">configMap</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile<span class=\"token punctuation\">-</span>configmap\n    <span class=\"token key atrule\">restartPolicy</span><span class=\"token punctuation\">:</span> Never</code></pre></div>\n<p>The Dockerfile is stored in a ConfigMap which gets mounted by Kaniko to build the image.</p>\n<p>Kaniko provides a secure and efficient way to build container images within a Kubernetes cluster. By avoiding privileged Docker daemons, Kaniko simplifies image building while improving security. The caching and Kubernetes integration make Kaniko a natural fit for automating image creation as part of a CD pipeline.</p>\n<h2 id=\"-tutorial-build-container-images-with-kaniko-in-kubernetes\" style=\"position:relative;\"><a href=\"#-tutorial-build-container-images-with-kaniko-in-kubernetes\" aria-label=\" tutorial build container images with kaniko in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Tutorial: Build Container Images with Kaniko in Kubernetes</h2>\n<p>Kaniko is a tool that allows building container images from a Dockerfile inside a Kubernetes cluster without needing Docker. In this tutorial, we'll walk through an example of using Kaniko to build and push an image to a registry from a Kubernetes pod.</p>\n<h3 id=\"prerequisites\" style=\"position:relative;\"><a href=\"#prerequisites\" aria-label=\"prerequisites permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Prerequisites</h3>\n<ul>\n<li>Kubernetes cluster</li>\n<li>Docker Hub account for pushing the built image</li>\n</ul>\n<h3 id=\"1-write-a-dockerfile\" style=\"position:relative;\"><a href=\"#1-write-a-dockerfile\" aria-label=\"1 write a dockerfile permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>1. Write a Dockerfile</h3>\n<p>First, we'll write a simple Dockerfile that defines our example image:</p>\n<div class=\"gatsby-highlight\" data-language=\"dockerfile\"><pre class=\"language-dockerfile\"><code class=\"language-dockerfile\"><span class=\"token instruction\"><span class=\"token keyword\">FROM</span> alpine:3.12</span>\n<span class=\"token instruction\"><span class=\"token keyword\">RUN</span> apk add --update nginx <span class=\"token operator\">\\</span>\n &amp;&amp; rm -rf /var/cache/apk/*</span>\n<span class=\"token instruction\"><span class=\"token keyword\">RUN</span> echo <span class=\"token string\">'This image is created by kaniko'</span> > /usr/share/nginx/html/index.html</span>\n<span class=\"token instruction\"><span class=\"token keyword\">EXPOSE</span> 80</span>\n<span class=\"token instruction\"><span class=\"token keyword\">CMD</span> [<span class=\"token string\">\"nginx\"</span>, <span class=\"token string\">\"-g\"</span>, <span class=\"token string\">\"daemon off;\"</span>]</span></code></pre></div>\n<p>This Dockerfile starts from the alpine base image, installs nginx, copies over a custom <code class=\"language-text\">index.html</code>, exposes port 80, and sets the container command.</p>\n<h3 id=\"2-create-a-configmap-for-the-dockerfile\" style=\"position:relative;\"><a href=\"#2-create-a-configmap-for-the-dockerfile\" aria-label=\"2 create a configmap for the dockerfile permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>2. Create a ConfigMap for the Dockerfile</h3>\n<p>Next, we'll create a ConfigMap that contains this Dockerfile so that we can mount it into the Kaniko pod later:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl create configmap dockerfile-config --from-file<span class=\"token operator\">=</span>Dockerfile</code></pre></div>\n<h3 id=\"3-define-a-pod-spec-for-kaniko\" style=\"position:relative;\"><a href=\"#3-define-a-pod-spec-for-kaniko\" aria-label=\"3 define a pod spec for kaniko permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>3. Define a Pod Spec for Kaniko</h3>\n<p>Now we can define a pod spec in a YAML file with Kaniko as the container:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> gcr.io/kaniko<span class=\"token punctuation\">-</span>project/executor<span class=\"token punctuation\">:</span>latest\n        <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"--dockerfile=/Dockerfile\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--context=/workspace\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--destination=mydockerhubusername/nginx-image\"</span><span class=\"token punctuation\">]</span>\n        <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile \n                <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /Dockerfile\n    <span class=\"token key atrule\">restartPolicy</span><span class=\"token punctuation\">:</span> Never\n    <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile\n            <span class=\"token key atrule\">configMap</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile<span class=\"token punctuation\">-</span>config</code></pre></div>\n<p>The key parts are:</p>\n<ul>\n<li>Mounting our ConfigMap containing the Dockerfile to <code class=\"language-text\">/Dockerfile</code></li>\n<li>Setting the Dockerfile path in the <code class=\"language-text\">args</code></li>\n<li>Specifying the destination image repository and tag</li>\n</ul>\n<h3 id=\"4-run-the-kaniko-pod\" style=\"position:relative;\"><a href=\"#4-run-the-kaniko-pod\" aria-label=\"4 run the kaniko pod permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>4. Run the Kaniko Pod</h3>\n<p>We can now create the pod to trigger the Kaniko build:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl create <span class=\"token parameter variable\">-f</span> kaniko.yaml</code></pre></div>\n<p>Once launched, you can watch the pod's logs to see the build process:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl logs <span class=\"token parameter variable\">-f</span> kaniko</code></pre></div>\n<p>After the build completes, the image will be pushed to the destination registry specified.</p>\n<h3 id=\"5-verify-the-built-image\" style=\"position:relative;\"><a href=\"#5-verify-the-built-image\" aria-label=\"5 verify the built image permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>5. Verify the Built Image</h3>\n<p>Finally, we can pull and run a container from the image built by Kaniko to verify it works as expected:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> pull mydockerhubusername/nginx-image\n<span class=\"token function\">docker</span> run <span class=\"token parameter variable\">-p</span> <span class=\"token number\">80</span>:80 mydockerhubusername/nginx-image</code></pre></div>\n<p>When you visit <code class=\"language-text\">localhost</code>, you should see the custom <code class=\"language-text\">index.html</code> from the image served by nginx!</p>\n<p>And that's it! We used Kaniko to build and push a Docker image from a Kubernetes pod, without needing direct access to Docker. Kaniko is a handy tool to integrate image building into a Kubernetes-based CI/CD pipeline.</p>\n<h2 id=\"-common-use-cases-and-examples\" style=\"position:relative;\"><a href=\"#-common-use-cases-and-examples\" aria-label=\" common use cases and examples permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Common Use Cases and Examples</h2>\n<ul>\n<li>‚úÖ <strong>Kubernetes CI/CD pipelines</strong>: Kaniko can be used to build application container images as part of a continuous integration and deployment workflow in Kubernetes. For example, building images within a Kubernetes cluster after application code is pushed to a git repository.</li>\n<li>‚úÖ <strong>Building images in serverless architectures</strong>: When running containerized workloads on serverless platforms like AWS Fargate, Kaniko allows building images as part of the serverless workflow without needing a dedicated Docker environment.</li>\n<li>‚úÖ <strong>Building images in constrained environments</strong>: Kaniko can build images in environments that don't allow running privileged containers like a Docker daemon. For example on managed Kubernetes services that have security restrictions.</li>\n<li>‚úÖ <strong>Debugging Dockerfiles</strong>: Kaniko can be used to debug Dockerfile commands and scripts by building images step-by-step.</li>\n<li>‚úÖ <strong>Reproducing builds</strong>: The cache digest produced by Kaniko makes builds reproducible by allowing exactly the same image to be rebuilt multiple times.</li>\n<li>‚úÖ <strong>Self-hosted image registries</strong>: Kaniko can push images to private registries and doesn't depend on hub.docker.com for hosting images.</li>\n<li>‚úÖ <strong>Custom base images</strong>: Kaniko allows building custom base images efficiently from scratch before using them in application images.</li>\n<li>‚úÖ <strong>Multi-stage builds</strong>: Kaniko supports multi-stage Dockerfiles out of the box for creating final production images.</li>\n<li>‚úÖ <strong>Scratch image builds</strong>: Images can be built from scratch without needing a base image.</li>\n</ul>\n<p>Kaniko fits nicely into Kubernetes and CI/CD workflows, allows building images in restricted environments, and provides reproducibility and debugging for Dockerfile builds.</p>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèÅ Conclusion</h2>\n<p>Kaniko enables building container images within a Kubernetes cluster without privileged access or external Docker daemons. It offers improved security, simpler setup, and easier integration with existing Kubernetes workflows.</p>\n<p>By using Kaniko, the build and push process can be entirely self-contained within the cluster, eliminating the need for external dependencies and simplifying build orchestration. This approach paves the way for faster and more integrable builds in CI/CD pipelines with security as a guiding principle.</p>\n<p><strong>Thank You üñ§</strong></p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}