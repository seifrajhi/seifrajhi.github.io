{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/monitoring-coredns-dns-performance/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>Running DNS-intensive workloads can sometimes lead to intermittent <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#coredns\" target=\"_blank\" rel=\"noopener noreferrer\">CoreDNS</a> failures caused by DNS throttling. These issues can have a significant impact on your applications.</p>\n<p>Such disruptions can hinder the reliability and performance of your services, making it mandatory to have a monitoring solution in place. AWS offers a suite of open-source tools‚Ää‚Äî‚Ää<a href=\"https://aws.amazon.com/cloudwatch/\" target=\"_blank\" rel=\"noopener noreferrer\">CloudWatch</a>, <a href=\"https://www.fluentd.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Fluentd</a>, and <a href=\"https://grafana.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Grafana</a>‚Ää‚Äî‚Ääthat can be integrated to monitor CoreDNS.</p>\n<h2 id=\"-introduction-to-kubernetes-dns\" style=\"position:relative;\"><a href=\"#-introduction-to-kubernetes-dns\" aria-label=\" introduction to kubernetes dns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üß© Introduction to Kubernetes DNS</h2>\n<p>Kubernetes relies on <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#introduction\" target=\"_blank\" rel=\"noopener noreferrer\">DNS</a> for service discovery within clusters. When applications running in pods need to communicate with each other, they often refer to services by their domain names rather than IP addresses.</p>\n<p>This is where Kubernetes DNS comes into play. It ensures that these domain names are resolved to the correct IP addresses, allowing pods and services to communicate.</p>\n<p>In Kubernetes, each pod is assigned a temporary IP address. However, these IP addresses are dynamic and can change over time, making it challenging for applications to keep track of them. Kubernetes addresses this challenge by assigning fully qualified domain names (<a href=\"https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#dns-records\" target=\"_blank\" rel=\"noopener noreferrer\">FQDNs</a>) to pods and services.</p>\n<p>CoreDNS, the default DNS provider in Kubernetes, is responsible for handling DNS queries within the cluster. It maps these FQDNs to the corresponding IP addresses, enabling communication between pods and services.</p>\n<h2 id=\"Ô∏è-coredns-in-kubernetes\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-coredns-in-kubernetes\" aria-label=\"Ô∏è coredns in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è CoreDNS in Kubernetes</h2>\n<p>CoreDNS plays an important role in providing DNS services within Kubernetes clusters. As the default DNS provider since Kubernetes v1.13, CoreDNS simplifies cluster networking by enabling clients to access services using DNS names rather than IP addresses. It resolves domain name requests and facilitates service discovery within the cluster.</p>\n<h3 id=\"Ô∏è-how-coredns-operates\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-how-coredns-operates\" aria-label=\"Ô∏è how coredns operates permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚öôÔ∏è How CoreDNS Operates</h3>\n<p>CoreDNS operates as a resolver and forwarder for DNS requests within Kubernetes clusters. When a pod needs to communicate with another service, it sends a DNS query to CoreDNS, specifying the domain name of the target service. CoreDNS then resolves this query by mapping the domain name to the corresponding IP address using its internal records.</p>\n<p>For external domain names that CoreDNS is not authoritative for, it forwards the DNS query to public resolvers or upstream DNS servers for resolution.</p>\n<p>To enhance performance and reduce latency, CoreDNS can cache DNS responses for frequently accessed domain names. This caching mechanism improves the responsiveness of DNS queries and reduces the load on upstream DNS servers.</p>\n<p>CoreDNS achieves this functionality through its modular architecture and extensible plugin system, allowing operators to customize and optimize DNS resolution according to their specific requirements.</p>\n<h2 id=\"-mitigating-coredns-throttling-in-amazon-eks\" style=\"position:relative;\"><a href=\"#-mitigating-coredns-throttling-in-amazon-eks\" aria-label=\" mitigating coredns throttling in amazon eks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Mitigating CoreDNS Throttling in Amazon EKS</h2>\n<p>In Amazon EKS clusters, CoreDNS and DNS throttling issues can be challenging to identify and troubleshoot. While many users focus on monitoring CoreDNS logs and metrics, they often overlook the hard limit of 1024 <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#vpc-dns-limits\" target=\"_blank\" rel=\"noopener noreferrer\">packets per second (PPS)</a> enforced at the Elastic Network Interface (ENI) level. Understanding how this limit can lead to throttling issues requires insight into the typical DNS resolution flow of a Kubernetes pod.</p>\n<p>In a Kubernetes environment, pods must resolve domain names for both internal and external services to enable communication. This resolution process involves routing DNS queries through the worker node's ENI, particularly when resolving external endpoints. Even for internal endpoints, if the CoreDNS pod is not co-located with the querying pod, DNS packets still traverse the worker node's ENI.</p>\n<p>Consider a scenario where there is a sudden surge in DNS queries, causing the PPS to approach the hard limit of 1024. This situation can result in DNS throttling, impacting all microservices running on the affected worker node. Unfortunately, troubleshooting such issues can be hard because the focus tends to be on CoreDNS pods rather than ENI metrics.</p>\n<p>To mitigate DNS throttling issues in EKS clusters, it is important to monitor packet drops occurring at the ENI level continuously. This monitoring allows for early detection and prevention of potential outages. In this blog post, we introduce a solution that leverages network performance metrics to identify DNS throttling issues effectively.</p>\n<h3 id=\"Ô∏è-solution\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-solution\" aria-label=\"Ô∏è solution permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ°Ô∏è Solution</h3>\n<p>An easy way to identify the DNS throttling issues in worker nodes is by capturing the <code class=\"language-text\">linklocal_allowance_exceeded</code> metric provided by the Elastic Network Adapter (ENA) driver and other metrics as well.</p>\n<p>The <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent\" target=\"_blank\" rel=\"noopener noreferrer\"><code class=\"language-text\">linklocal_allowance_exceeded</code></a> metric indicates the number of packets dropped because the PPS of the traffic to local proxy services exceeded the maximum for the network interface. This impacts traffic to the DNS service, the Instance Metadata Service, and the Amazon Time Sync Service.</p>\n<p>Instead of tracking this event in real-time, we can stream this metric to <a href=\"https://aws.amazon.com/prometheus/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Managed Service for Prometheus</a> and visualize it in <a href=\"https://aws.amazon.com/grafana/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Managed Grafana</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 581px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 77.64705882352942%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAB7k1C6hn/xAAaEAACAgMAAAAAAAAAAAAAAAAAAQISESEx/9oACAEBAAEFAuF1YztpOR//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAcEAABAwUAAAAAAAAAAAAAAAARABBBAQISIVH/2gAIAQEABj8CCxlhtCtscb//xAAbEAEAAgIDAAAAAAAAAAAAAAABESEAEDFBcf/aAAgBAQABPyEQGB7+E6aYeorG0ibPbX//2gAMAwEAAgADAAAAENPf/8QAFhEBAQEAAAAAAAAAAAAAAAAAARBB/9oACAEDAQE/EANn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxAAAwEAAwEAAAAAAAAAAAAAAREhABAxUXH/2gAIAQEAAT8QAgtIU3EoRYEUuLazKQXp3xkBA0nupv/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"adot\" title=\"\" src=\"/static/9c0e9af412476642f6bdb554799934fd/f0d01/adot.jpg\" srcset=\"/static/9c0e9af412476642f6bdb554799934fd/651be/adot.jpg 170w,\n/static/9c0e9af412476642f6bdb554799934fd/d30a3/adot.jpg 340w,\n/static/9c0e9af412476642f6bdb554799934fd/f0d01/adot.jpg 581w\" sizes=\"(max-width: 581px) 100vw, 581px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"Ô∏è-hands-on-collect-and-visualize-coredns-metrics-in-aws-eks\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-hands-on-collect-and-visualize-coredns-metrics-in-aws-eks\" aria-label=\"Ô∏è hands on collect and visualize coredns metrics in aws eks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Hands-on: Collect and Visualize CoreDNS Metrics in AWS EKS</h2>\n<h3 id=\"-coredns-prometheus-plugin\" style=\"position:relative;\"><a href=\"#-coredns-prometheus-plugin\" aria-label=\" coredns prometheus plugin permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìä CoreDNS Prometheus Plugin</h3>\n<p>The <a href=\"https://coredns.io/plugins/metrics/\" target=\"_blank\" rel=\"noopener noreferrer\">CoreDNS Prometheus plugin</a> exposes metrics in the <a href=\"https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md\" target=\"_blank\" rel=\"noopener noreferrer\">OpenMetrics</a> format, a text-based standard that evolved from the <a href=\"https://prometheus.io/docs/instrumenting/exposition_formats/#text-based-format\" target=\"_blank\" rel=\"noopener noreferrer\">Prometheus format</a>. In a Kubernetes cluster, the plugin is enabled by default, so you can begin monitoring <a href=\"https://www.datadoghq.com/blog/coredns-metrics\" target=\"_blank\" rel=\"noopener noreferrer\">many key metrics</a> as soon as you launch your cluster.</p>\n<p>By default, the Prometheus plugin writes metrics to a <code class=\"language-text\">/metrics</code> endpoint on port <code class=\"language-text\">9153</code> on each CoreDNS pod.</p>\n<h3 id=\"Ô∏è-create-an-amazon-managed-service-for-prometheus-workspace-and-managed-service-for-grafana\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-create-an-amazon-managed-service-for-prometheus-workspace-and-managed-service-for-grafana\" aria-label=\"Ô∏è create an amazon managed service for prometheus workspace and managed service for grafana permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèóÔ∏è Create an Amazon Managed Service for Prometheus Workspace and Managed Service for Grafana</h3>\n<p>In this step, we will create a workspace for Amazon Managed Service for Prometheus and Managed Service for Grafana. The configuration in these files creates:</p>\n<ul>\n<li>AMP workspace</li>\n<li>AMP alert manager definition</li>\n</ul>\n<h4 id=\"code-classlanguage-textmaintfcode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textmaintfcode\" aria-label=\"code classlanguage textmaintfcode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">main.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">module<span class=\"token type variable\"> \"prometheus\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-prometheus/aws\"</span>\n\n    <span class=\"token property\">workspace_alias</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"demo-coredns\"</span>\n\n    <span class=\"token property\">alert_manager_definition</span> <span class=\"token punctuation\">=</span> <span class=\"token heredoc string\">&lt;&lt;-EOT\n    alertmanager_config: |\n        route:\n            receiver: 'default'\n        receivers:\n            - name: 'default'\n    EOT</span>\n\n    <span class=\"token property\">rule_group_namespaces</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h4 id=\"code-classlanguage-textversionstfcode\" style=\"position:relative;\"><a href=\"#code-classlanguage-textversionstfcode\" aria-label=\"code classlanguage textversionstfcode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">versions.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">terraform</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">required_version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 1.3\"</span>\n\n    <span class=\"token keyword\">required_providers</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">aws</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">source</span>  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"hashicorp/aws\"</span>\n            <span class=\"token property\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 5.32\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>To run the Terraform code, execute:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token comment\"># terraform init</span>\n<span class=\"token comment\"># terraform plan</span>\n<span class=\"token comment\"># terraform apply</span></code></pre></div>\n<h3 id=\"Ô∏è-create-a-default-grafana-workspace\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-create-a-default-grafana-workspace\" aria-label=\"Ô∏è create a default grafana workspace permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üñ•Ô∏è Create a Default Grafana Workspace</h3>\n<p>The below configuration files will create a default Grafana workspace using defaults provided by the module.</p>\n<h4 id=\"code-classlanguage-textmaintfcode-1\" style=\"position:relative;\"><a href=\"#code-classlanguage-textmaintfcode-1\" aria-label=\"code classlanguage textmaintfcode 1 permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a><code class=\"language-text\">main.tf</code></h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">provider<span class=\"token type variable\"> \"aws\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">region</span> <span class=\"token punctuation\">=</span> local.region\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">data <span class=\"token type variable\">\"aws_availability_zones\"</span></span> <span class=\"token string\">\"available\"</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">locals</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">region</span>      <span class=\"token punctuation\">=</span> <span class=\"token string\">\"eu-west-1\"</span>\n    <span class=\"token property\">name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"amg-ex-<span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token punctuation\">{</span><span class=\"token function\">replace</span><span class=\"token punctuation\">(</span><span class=\"token function\">basename</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">path</span><span class=\"token punctuation\">.</span><span class=\"token type variable\">cwd</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"_\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"-\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span>\"</span>\n    <span class=\"token property\">description</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"AWS Managed Grafana service for <span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token punctuation\">{</span><span class=\"token keyword\">local</span><span class=\"token punctuation\">.</span><span class=\"token type variable\">name</span><span class=\"token punctuation\">}</span></span>\"</span>\n\n    <span class=\"token property\">vpc_cidr</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"10.0.0.0/16\"</span>\n    <span class=\"token property\">azs</span>      <span class=\"token punctuation\">=</span> slice(data.aws_availability_zones.available.names, <span class=\"token number\">0</span>, <span class=\"token number\">3</span>)\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"managed_grafana\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n    <span class=\"token property\">name</span>                      <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">associate_license</span>         <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n    <span class=\"token property\">description</span>               <span class=\"token punctuation\">=</span> local.description\n    <span class=\"token property\">account_access_type</span>       <span class=\"token punctuation\">=</span> <span class=\"token string\">\"CURRENT_ACCOUNT\"</span>\n    <span class=\"token property\">authentication_providers</span>  <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"AWS_SSO\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token property\">permission_type</span>           <span class=\"token punctuation\">=</span> <span class=\"token string\">\"SERVICE_MANAGED\"</span>\n    <span class=\"token property\">data_sources</span>              <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"CLOUDWATCH\"</span>, <span class=\"token string\">\"PROMETHEUS\"</span>, <span class=\"token string\">\"XRAY\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token property\">notification_destinations</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"SNS\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token property\">stack_set_name</span>            <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">grafana_version</span>           <span class=\"token punctuation\">=</span> <span class=\"token string\">\"9.4\"</span>\n\n    <span class=\"token property\">configuration</span> <span class=\"token punctuation\">=</span> jsonencode(<span class=\"token punctuation\">{</span>\n        <span class=\"token property\">unifiedAlerting</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">enabled</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n        <span class=\"token punctuation\">}</span>,\n        <span class=\"token property\">plugins</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">pluginAdminEnabled</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>)\n\n    <span class=\"token property\">vpc_configuration</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">subnet_ids</span> <span class=\"token punctuation\">=</span> module.vpc.private_subnets\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token property\">security_group_rules</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">egress_postgresql</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">description</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"Allow egress to PostgreSQL\"</span>\n            <span class=\"token property\">from_port</span>   <span class=\"token punctuation\">=</span> <span class=\"token number\">5432</span>\n            <span class=\"token property\">to_port</span>     <span class=\"token punctuation\">=</span> <span class=\"token number\">5432</span>\n            <span class=\"token property\">protocol</span>    <span class=\"token punctuation\">=</span> <span class=\"token string\">\"tcp\"</span>\n            <span class=\"token property\">cidr_blocks</span> <span class=\"token punctuation\">=</span> module.vpc.private_subnets_cidr_blocks\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token property\">workspace_api_keys</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">viewer</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">key_name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"viewer\"</span>\n            <span class=\"token property\">key_role</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"VIEWER\"</span>\n            <span class=\"token property\">seconds_to_live</span> <span class=\"token punctuation\">=</span> <span class=\"token number\">3600</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token property\">editor</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">key_name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"editor\"</span>\n            <span class=\"token property\">key_role</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"EDITOR\"</span>\n            <span class=\"token property\">seconds_to_live</span> <span class=\"token punctuation\">=</span> <span class=\"token number\">3600</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token property\">admin</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">key_name</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"admin\"</span>\n            <span class=\"token property\">key_role</span>        <span class=\"token punctuation\">=</span> <span class=\"token string\">\"ADMIN\"</span>\n            <span class=\"token property\">seconds_to_live</span> <span class=\"token punctuation\">=</span> <span class=\"token number\">3600</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token property\">create_iam_role</span>                <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n    <span class=\"token property\">iam_role_name</span>                  <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">use_iam_role_name_prefix</span>       <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n    <span class=\"token property\">iam_role_description</span>           <span class=\"token punctuation\">=</span> local.description\n    <span class=\"token property\">iam_role_path</span>                  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"/grafana/\"</span>\n    <span class=\"token property\">iam_role_force_detach_policies</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n    <span class=\"token property\">iam_role_max_session_duration</span>  <span class=\"token punctuation\">=</span> <span class=\"token number\">7200</span>\n    <span class=\"token property\">iam_role_tags</span>                  <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">role</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span> <span class=\"token punctuation\">}</span>\n\n    <span class=\"token property\">tags</span> <span class=\"token punctuation\">=</span> local.tags\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"managed_grafana_default\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n    <span class=\"token property\">name</span>              <span class=\"token punctuation\">=</span> <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token punctuation\">{</span><span class=\"token keyword\">local</span><span class=\"token punctuation\">.</span><span class=\"token type variable\">name</span><span class=\"token punctuation\">}</span></span>-default\"</span>\n    <span class=\"token property\">associate_license</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n\n    <span class=\"token property\">tags</span> <span class=\"token punctuation\">=</span> local.tags\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"managed_grafana_disabled\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/managed-service-grafana/aws\"</span>\n\n    <span class=\"token property\">name</span>   <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">create</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">module<span class=\"token type variable\"> \"vpc\" </span></span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">source</span>  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"terraform-aws-modules/vpc/aws\"</span>\n    <span class=\"token property\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\"~> 5.0\"</span>\n\n    <span class=\"token property\">name</span> <span class=\"token punctuation\">=</span> local.name\n    <span class=\"token property\">cidr</span> <span class=\"token punctuation\">=</span> local.vpc_cidr\n\n    <span class=\"token property\">azs</span>             <span class=\"token punctuation\">=</span> local.azs\n    <span class=\"token property\">private_subnets</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span>for k, v in local.azs : cidrsubnet(local.vpc_cidr, <span class=\"token number\">4</span>, k)<span class=\"token punctuation\">]</span>\n    <span class=\"token property\">public_subnets</span>  <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">[</span>for k, v in local.azs : cidrsubnet(local.vpc_cidr, <span class=\"token number\">8</span>, k + <span class=\"token number\">48</span>)<span class=\"token punctuation\">]</span>\n\n    <span class=\"token property\">enable_nat_gateway</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">false</span> \n    <span class=\"token property\">single_nat_gateway</span> <span class=\"token punctuation\">=</span> <span class=\"token boolean\">true</span>\n\n    <span class=\"token property\">tags</span> <span class=\"token punctuation\">=</span> local.tags\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h4 id=\"versionstf\" style=\"position:relative;\"><a href=\"#versionstf\" aria-label=\"versionstf permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>versions.tf</h4>\n<div class=\"gatsby-highlight\" data-language=\"hcl\"><pre class=\"language-hcl\"><code class=\"language-hcl\"><span class=\"token keyword\">terraform</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">required_version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 1.0\"</span>\n\n    <span class=\"token keyword\">required_providers</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">aws</span> <span class=\"token punctuation\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">source</span>  <span class=\"token punctuation\">=</span> <span class=\"token string\">\"hashicorp/aws\"</span>\n            <span class=\"token property\">version</span> <span class=\"token punctuation\">=</span> <span class=\"token string\">\">= 5.0\"</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>To run this code, execute:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token comment\"># terraform init</span>\n<span class=\"token comment\"># terraform plan</span>\n<span class=\"token comment\"># terraform apply</span></code></pre></div>\n<h3 id=\"-deploying-prometheus-ethtool-exporter\" style=\"position:relative;\"><a href=\"#-deploying-prometheus-ethtool-exporter\" aria-label=\" deploying prometheus ethtool exporter permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Deploying Prometheus Ethtool Exporter</h3>\n<p><a href=\"https://linux.die.net/man/8/ethtool\" target=\"_blank\" rel=\"noopener noreferrer\">Ethtool</a> is a Linux tool for configuring and gathering information about Ethernet devices on worker nodes. We will use ethtool's output to detect packet loss and convert it to Prometheus format with a Prometheus ethtool exporter utility.</p>\n<p>Deploy the exporter using:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">-f</span> https://raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml</code></pre></div>\n<h3 id=\"-deploy-adot-collector-to-scrape-ethtool-metrics\" style=\"position:relative;\"><a href=\"#-deploy-adot-collector-to-scrape-ethtool-metrics\" aria-label=\" deploy adot collector to scrape ethtool metrics permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üì¶ Deploy ADOT Collector to Scrape Ethtool Metrics</h3>\n<p>In this step, we will deploy the ADOT collector and configure it to ingest metrics to Amazon Managed Service for Prometheus. We will use the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/opentelemetry.html\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon EKS add-on for ADOT operator</a> to send the metrics <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent\" target=\"_blank\" rel=\"noopener noreferrer\">linklocal_allowance_exceeded</a> to Amazon Managed Service for Prometheus for monitoring CoreDNS.</p>\n<h4 id=\"create-an-iam-role-and-amazon-eks-service-account\" style=\"position:relative;\"><a href=\"#create-an-iam-role-and-amazon-eks-service-account\" aria-label=\"create an iam role and amazon eks service account permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Create an IAM Role and Amazon EKS Service Account</h4>\n<p>We will deploy the ADOT collector to run under the identity of a Kubernetes <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\" target=\"_blank\" rel=\"noopener noreferrer\">service account</a> <code class=\"language-text\">adot-collector</code>. <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\" target=\"_blank\" rel=\"noopener noreferrer\">IAM roles for service accounts (IRSA)</a> let you associate the <code class=\"language-text\">AmazonPrometheusRemoteWriteAccess</code> role with a Kubernetes service account, thereby providing IAM permissions to any pod utilizing the service account to ingest the metrics to Amazon Managed Service for Prometheus.</p>\n<p>You need <code class=\"language-text\">kubectl</code> and <code class=\"language-text\">eksctl</code> CLI tools to run the script. They must be configured to access your Amazon EKS cluster.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">eksctl create iamserviceaccount <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--name</span> adot-collector <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--namespace</span> default <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--region</span> eu-west-1 <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--cluster</span> coredns-monitoring-demo <span class=\"token punctuation\">\\</span>\n--attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--approve</span> <span class=\"token punctuation\">\\</span>\n--override-existing-serviceaccounts</code></pre></div>\n<h4 id=\"install-adot-add-on\" style=\"position:relative;\"><a href=\"#install-adot-add-on\" aria-label=\"install adot add on permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install ADOT Add-on</h4>\n<p>You can check the list of add-ons enabled for different versions of Amazon EKS using the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">aws eks describe-addon-versions --addon-name adot --kubernetes-version <span class=\"token number\">1.28</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--query</span> <span class=\"token string\">\"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\"</span> <span class=\"token parameter variable\">--output</span> text</code></pre></div>\n<p>Run the following command to install the ADOT add-on, replacing the <code class=\"language-text\">--addon-version</code> flag based on your Amazon EKS cluster version as shown in the step above.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">aws eks create-addon --addon-name adot --addon-version v0.66.0-eksbuild.1 --cluster-name coredns-monitoring-demo</code></pre></div>\n<p>Verify that the ADOT add-on is ready using the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl get po <span class=\"token parameter variable\">-n</span> opentelemetry-operator-system</code></pre></div>\n<p>The following procedure uses an example YAML file with <code class=\"language-text\">deployment</code> as the mode value. This is the default mode and deploys the ADOT Collector similarly to a standalone application. This configuration receives OTLP metrics from the sample application and Amazon Managed Service for Prometheus metrics scraped from pods on the cluster.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">curl</span> <span class=\"token parameter variable\">-o</span> collector-config-amp.yaml https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml</code></pre></div>\n<p>In <code class=\"language-text\">collector-config-amp.yaml</code>, replace the following with your own values:</p>\n<ul>\n<li><code class=\"language-text\">mode: deployment</code></li>\n<li><code class=\"language-text\">serviceAccount: adot-collector</code></li>\n<li><code class=\"language-text\">endpoint: \"\"</code></li>\n<li><code class=\"language-text\">region: \"\"</code></li>\n<li><code class=\"language-text\">name: adot-collector</code></li>\n</ul>\n<p>Apply the configuration:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">-f</span> collector-config-amp.yaml</code></pre></div>\n<p>Once the ADOT collector is deployed, the metrics will be stored successfully in Amazon Prometheus.</p>\n<h3 id=\"-visualize-ethtool-metrics-in-amazon-managed-grafana\" style=\"position:relative;\"><a href=\"#-visualize-ethtool-metrics-in-amazon-managed-grafana\" aria-label=\" visualize ethtool metrics in amazon managed grafana permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìà Visualize Ethtool Metrics in Amazon Managed Grafana</h3>\n<p>Configure the Amazon Managed Service for Prometheus workspace as a datasource inside the Amazon Managed Grafana console.</p>\n<p>Let's explore the metrics in Amazon Managed Grafana now: Click the explore button, and search for <code class=\"language-text\">ethtool</code>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 45.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAABLklEQVR42m2QW2rDMBREvY3Yji3JkiNZsiLJbyctIdCSr0CX0d/u/6MTm5S2GA6X4UpzX1GwVlZOSaO146Ki7EBZSWi5iD9IVavKKkTdXe5f0/tnlKQ547oybZrSXZwBiH1WxAnZxfkmeNpnPElJhN+lPKIY5TVbkMqqyolSs0IWXCFmOf8NSicpBRFlgjAldVMIs2LqxtTBHjvnh2dsne8BhA+jNh4NsEgkmMgILw8GCy8oH4amnZtmgoDTL6zCuR7mEEZUf5jzvMiJwJBPc4VCUtqDtFxoXA5DbpLuGQ5GcF4Y4F9KqDB/yHpirMTC684/gj2EXDOPzjDjelBoAnAPH+b5dO37sxAaQ635f+A/mkfT/Hp0XT+cu/4E2m6+XN5ut/v55Qq9JjcJzfgNOSlWDJU98DgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"apm\" title=\"\" src=\"/static/8073f7721006157bf3b6efc69fec4184/c5bb3/apm.png\" srcset=\"/static/8073f7721006157bf3b6efc69fec4184/04472/apm.png 170w,\n/static/8073f7721006157bf3b6efc69fec4184/9f933/apm.png 340w,\n/static/8073f7721006157bf3b6efc69fec4184/c5bb3/apm.png 680w,\n/static/8073f7721006157bf3b6efc69fec4184/b12f7/apm.png 1020w,\n/static/8073f7721006157bf3b6efc69fec4184/b5a09/apm.png 1360w,\n/static/8073f7721006157bf3b6efc69fec4184/07a9c/apm.png 1440w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Let's build a dashboard for the linklocal_allowance_exceeded metric by using the query</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">rate<span class=\"token punctuation\">(</span>node_net_ethtool<span class=\"token punctuation\">{</span>device<span class=\"token operator\">=</span><span class=\"token string\">\"eth0\"</span>,type<span class=\"token operator\">=</span><span class=\"token string\">\"linklocal_allo\nwance_exceeded\"</span><span class=\"token punctuation\">}</span> <span class=\"token punctuation\">[</span>30s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 53.529411764705884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA6ElEQVR42p2SaU7EMAyFcwVmaRpncewsRAX+cP/D4SadzqgDCCF9spyXPtuKq3xIBvB0nl9O+sD5Yg5HPfupo024XEFNJqwHwAOzjQ6zxEfFONoRoxqSxGeG4XtclJbqx+vfGeY+0n/N4NkGBk+SdOiW05NIj6KGoIhL5OLE79AIFmGLUTBdhD3a+wdr5xSz9eyxCi4kyc3tVUGi7fQcHA9EyfVddqHa2yel11yXlBtiKmXJpXFuAXOIRa4iVeI26u4gVbBRlfbBdemFSa8jjSbb8vYRDn/BBHiVsa2UDGm220p154+v/QUx8kjqifT8IgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"result\" title=\"\" src=\"/static/65e84ae8ccc9fd90579aa4af904c0687/c5bb3/result.png\" srcset=\"/static/65e84ae8ccc9fd90579aa4af904c0687/04472/result.png 170w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/9f933/result.png 340w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/c5bb3/result.png 680w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/b12f7/result.png 1020w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/b5a09/result.png 1360w,\n/static/65e84ae8ccc9fd90579aa4af904c0687/07a9c/result.png 1440w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>We can see that there were no packets dropped as the value is zero. You can further extend this by configuring alerts in the alert manager in Amazon Managed Service for Prometheus to send notifications.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h2>\n<p>In this post, we showed how to monitor and create alerts for CoreDNS throttling issues using AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus, and Amazon Managed Grafana. By monitoring the coreDNS metrics, customers can proactively detect packet drops and take preventive actions.</p>\n<p><strong>References:</strong></p>\n<ul>\n<li><a href=\"https://www.datadoghq.com/blog/coredns-monitoring-tools/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.datadoghq.com/blog/coredns-monitoring-tools/</a></li>\n<li><a href=\"https://cilium.io/blog/2019/12/18/how-to-debug-dns-issues-in-k8s/\" target=\"_blank\" rel=\"noopener noreferrer\">https://cilium.io/blog/2019/12/18/how-to-debug-dns-issues-in-k8s/</a></li>\n<li><a href=\"https://sysdig.com/blog/how-to-monitor-coredns/\" target=\"_blank\" rel=\"noopener noreferrer\">https://sysdig.com/blog/how-to-monitor-coredns/</a></li>\n<li><a href=\"https://www.datadoghq.com/blog/coredns-metrics/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.datadoghq.com/blog/coredns-metrics/</a></li>\n<li><a href=\"https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/\" target=\"_blank\" rel=\"noopener noreferrer\">https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/</a></li>\n</ul>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":8,"rawMarkdownBody":"\n## üìö Introduction\n\nRunning DNS-intensive workloads can sometimes lead to intermittent [CoreDNS](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#coredns) failures caused by DNS throttling. These issues can have a significant impact on your applications.\n\nSuch disruptions can hinder the reliability and performance of your services, making it mandatory to have a monitoring solution in place. AWS offers a suite of open-source tools‚Ää‚Äî‚Ää[CloudWatch](https://aws.amazon.com/cloudwatch/), [Fluentd](https://www.fluentd.org/), and [Grafana](https://grafana.com/)‚Ää‚Äî‚Ääthat can be integrated to monitor CoreDNS.\n\n## üß© Introduction to Kubernetes DNS\n\nKubernetes relies on [DNS](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#introduction) for service discovery within clusters. When applications running in pods need to communicate with each other, they often refer to services by their domain names rather than IP addresses.\n\nThis is where Kubernetes DNS comes into play. It ensures that these domain names are resolved to the correct IP addresses, allowing pods and services to communicate.\n\nIn Kubernetes, each pod is assigned a temporary IP address. However, these IP addresses are dynamic and can change over time, making it challenging for applications to keep track of them. Kubernetes addresses this challenge by assigning fully qualified domain names ([FQDNs](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#dns-records)) to pods and services.\n\nCoreDNS, the default DNS provider in Kubernetes, is responsible for handling DNS queries within the cluster. It maps these FQDNs to the corresponding IP addresses, enabling communication between pods and services.\n\n## üõ†Ô∏è CoreDNS in Kubernetes\n\nCoreDNS plays an important role in providing DNS services within Kubernetes clusters. As the default DNS provider since Kubernetes v1.13, CoreDNS simplifies cluster networking by enabling clients to access services using DNS names rather than IP addresses. It resolves domain name requests and facilitates service discovery within the cluster.\n\n### ‚öôÔ∏è How CoreDNS Operates\n\nCoreDNS operates as a resolver and forwarder for DNS requests within Kubernetes clusters. When a pod needs to communicate with another service, it sends a DNS query to CoreDNS, specifying the domain name of the target service. CoreDNS then resolves this query by mapping the domain name to the corresponding IP address using its internal records.\n\nFor external domain names that CoreDNS is not authoritative for, it forwards the DNS query to public resolvers or upstream DNS servers for resolution.\n\nTo enhance performance and reduce latency, CoreDNS can cache DNS responses for frequently accessed domain names. This caching mechanism improves the responsiveness of DNS queries and reduces the load on upstream DNS servers.\n\nCoreDNS achieves this functionality through its modular architecture and extensible plugin system, allowing operators to customize and optimize DNS resolution according to their specific requirements.\n\n## üöÄ Mitigating CoreDNS Throttling in Amazon EKS\n\nIn Amazon EKS clusters, CoreDNS and DNS throttling issues can be challenging to identify and troubleshoot. While many users focus on monitoring CoreDNS logs and metrics, they often overlook the hard limit of 1024 [packets per second (PPS)](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html#vpc-dns-limits) enforced at the Elastic Network Interface (ENI) level. Understanding how this limit can lead to throttling issues requires insight into the typical DNS resolution flow of a Kubernetes pod.\n\nIn a Kubernetes environment, pods must resolve domain names for both internal and external services to enable communication. This resolution process involves routing DNS queries through the worker node's ENI, particularly when resolving external endpoints. Even for internal endpoints, if the CoreDNS pod is not co-located with the querying pod, DNS packets still traverse the worker node's ENI.\n\nConsider a scenario where there is a sudden surge in DNS queries, causing the PPS to approach the hard limit of 1024. This situation can result in DNS throttling, impacting all microservices running on the affected worker node. Unfortunately, troubleshooting such issues can be hard because the focus tends to be on CoreDNS pods rather than ENI metrics.\n\nTo mitigate DNS throttling issues in EKS clusters, it is important to monitor packet drops occurring at the ENI level continuously. This monitoring allows for early detection and prevention of potential outages. In this blog post, we introduce a solution that leverages network performance metrics to identify DNS throttling issues effectively.\n\n### üõ°Ô∏è Solution\n\nAn easy way to identify the DNS throttling issues in worker nodes is by capturing the `linklocal_allowance_exceeded` metric provided by the Elastic Network Adapter (ENA) driver and other metrics as well.\n\nThe [`linklocal_allowance_exceeded`](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent) metric indicates the number of packets dropped because the PPS of the traffic to local proxy services exceeded the maximum for the network interface. This impacts traffic to the DNS service, the Instance Metadata Service, and the Amazon Time Sync Service.\n\nInstead of tracking this event in real-time, we can stream this metric to [Amazon Managed Service for Prometheus](https://aws.amazon.com/prometheus/) and visualize it in [Amazon Managed Grafana](https://aws.amazon.com/grafana/).\n\n\n![adot](adot.jpg)\n\n\n## üõ†Ô∏è Hands-on: Collect and Visualize CoreDNS Metrics in AWS EKS\n\n### üìä CoreDNS Prometheus Plugin\n\nThe [CoreDNS Prometheus plugin](https://coredns.io/plugins/metrics/) exposes metrics in the [OpenMetrics](https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md) format, a text-based standard that evolved from the [Prometheus format](https://prometheus.io/docs/instrumenting/exposition_formats/#text-based-format). In a Kubernetes cluster, the plugin is enabled by default, so you can begin monitoring [many key metrics](https://www.datadoghq.com/blog/coredns-metrics) as soon as you launch your cluster.\n\nBy default, the Prometheus plugin writes metrics to a `/metrics` endpoint on port `9153` on each CoreDNS pod.\n\n### üèóÔ∏è Create an Amazon Managed Service for Prometheus Workspace and Managed Service for Grafana\n\nIn this step, we will create a workspace for Amazon Managed Service for Prometheus and Managed Service for Grafana. The configuration in these files creates:\n\n- AMP workspace\n- AMP alert manager definition\n\n#### `main.tf`\n\n```hcl\nmodule \"prometheus\" {\n    source = \"terraform-aws-modules/managed-service-prometheus/aws\"\n\n    workspace_alias = \"demo-coredns\"\n\n    alert_manager_definition = <<-EOT\n    alertmanager_config: |\n        route:\n            receiver: 'default'\n        receivers:\n            - name: 'default'\n    EOT\n\n    rule_group_namespaces = {}\n}\n```\n\n#### `versions.tf`\n\n```hcl\nterraform {\n    required_version = \">= 1.3\"\n\n    required_providers {\n        aws = {\n            source  = \"hashicorp/aws\"\n            version = \">= 5.32\"\n        }\n    }\n}\n```\n\nTo run the Terraform code, execute:\n\n```sh\n# terraform init\n# terraform plan\n# terraform apply\n```\n\n### üñ•Ô∏è Create a Default Grafana Workspace\n\nThe below configuration files will create a default Grafana workspace using defaults provided by the module.\n\n#### `main.tf`\n\n```hcl\nprovider \"aws\" {\n    region = local.region\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n\nlocals {\n    region      = \"eu-west-1\"\n    name        = \"amg-ex-${replace(basename(path.cwd), \"_\", \"-\")}\"\n    description = \"AWS Managed Grafana service for ${local.name}\"\n\n    vpc_cidr = \"10.0.0.0/16\"\n    azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n}\n\nmodule \"managed_grafana\" {\n    source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n    name                      = local.name\n    associate_license         = false\n    description               = local.description\n    account_access_type       = \"CURRENT_ACCOUNT\"\n    authentication_providers  = [\"AWS_SSO\"]\n    permission_type           = \"SERVICE_MANAGED\"\n    data_sources              = [\"CLOUDWATCH\", \"PROMETHEUS\", \"XRAY\"]\n    notification_destinations = [\"SNS\"]\n    stack_set_name            = local.name\n    grafana_version           = \"9.4\"\n\n    configuration = jsonencode({\n        unifiedAlerting = {\n            enabled = true\n        },\n        plugins = {\n            pluginAdminEnabled = false\n        }\n    })\n\n    vpc_configuration = {\n        subnet_ids = module.vpc.private_subnets\n    }\n    security_group_rules = {\n        egress_postgresql = {\n            description = \"Allow egress to PostgreSQL\"\n            from_port   = 5432\n            to_port     = 5432\n            protocol    = \"tcp\"\n            cidr_blocks = module.vpc.private_subnets_cidr_blocks\n        }\n    }\n\n    workspace_api_keys = {\n        viewer = {\n            key_name        = \"viewer\"\n            key_role        = \"VIEWER\"\n            seconds_to_live = 3600\n        }\n        editor = {\n            key_name        = \"editor\"\n            key_role        = \"EDITOR\"\n            seconds_to_live = 3600\n        }\n        admin = {\n            key_name        = \"admin\"\n            key_role        = \"ADMIN\"\n            seconds_to_live = 3600\n        }\n    }\n\n    create_iam_role                = true\n    iam_role_name                  = local.name\n    use_iam_role_name_prefix       = true\n    iam_role_description           = local.description\n    iam_role_path                  = \"/grafana/\"\n    iam_role_force_detach_policies = true\n    iam_role_max_session_duration  = 7200\n    iam_role_tags                  = { role = true }\n\n    tags = local.tags\n}\n\nmodule \"managed_grafana_default\" {\n    source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n    name              = \"${local.name}-default\"\n    associate_license = false\n\n    tags = local.tags\n}\n\nmodule \"managed_grafana_disabled\" {\n    source = \"terraform-aws-modules/managed-service-grafana/aws\"\n\n    name   = local.name\n    create = false\n}\n\nmodule \"vpc\" {\n    source  = \"terraform-aws-modules/vpc/aws\"\n    version = \"~> 5.0\"\n\n    name = local.name\n    cidr = local.vpc_cidr\n\n    azs             = local.azs\n    private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n    public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n\n    enable_nat_gateway = false \n    single_nat_gateway = true\n\n    tags = local.tags\n}\n```\n\n#### versions.tf\n\n```hcl\nterraform {\n    required_version = \">= 1.0\"\n\n    required_providers {\n        aws = {\n            source  = \"hashicorp/aws\"\n            version = \">= 5.0\"\n        }\n    }\n}\n```\n\nTo run this code, execute:\n\n```shell\n# terraform init\n# terraform plan\n# terraform apply\n```\n\n### üöÄ Deploying Prometheus Ethtool Exporter\n\n[Ethtool](https://linux.die.net/man/8/ethtool) is a Linux tool for configuring and gathering information about Ethernet devices on worker nodes. We will use ethtool's output to detect packet loss and convert it to Prometheus format with a Prometheus ethtool exporter utility.\n\nDeploy the exporter using:\n\n```sh\nkubectl apply -f https://raw.githubusercontent.com/Showmax/prometheus-ethtool-exporter/master/deploy/k8s-daemonset.yaml\n```\n\n### üì¶ Deploy ADOT Collector to Scrape Ethtool Metrics\n\nIn this step, we will deploy the ADOT collector and configure it to ingest metrics to Amazon Managed Service for Prometheus. We will use the [Amazon EKS add-on for ADOT operator](https://docs.aws.amazon.com/eks/latest/userguide/opentelemetry.html) to send the metrics [linklocal_allowance_exceeded](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html#linux-metrics-enabled-by-CloudWatch-agent) to Amazon Managed Service for Prometheus for monitoring CoreDNS.\n\n#### Create an IAM Role and Amazon EKS Service Account\n\nWe will deploy the ADOT collector to run under the identity of a Kubernetes [service account](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) `adot-collector`. [IAM roles for service accounts (IRSA)](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html) let you associate the `AmazonPrometheusRemoteWriteAccess` role with a Kubernetes service account, thereby providing IAM permissions to any pod utilizing the service account to ingest the metrics to Amazon Managed Service for Prometheus.\n\nYou need `kubectl` and `eksctl` CLI tools to run the script. They must be configured to access your Amazon EKS cluster.\n\n```sh\neksctl create iamserviceaccount \\\n--name adot-collector \\\n--namespace default \\\n--region eu-west-1 \\\n--cluster coredns-monitoring-demo \\\n--attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \\\n--approve \\\n--override-existing-serviceaccounts\n```\n\n#### Install ADOT Add-on\n\nYou can check the list of add-ons enabled for different versions of Amazon EKS using the following command:\n\n```sh\naws eks describe-addon-versions --addon-name adot --kubernetes-version 1.28 \\\n    --query \"addons[].addonVersions[].[addonVersion, compatibilities[].defaultVersion]\" --output text\n```\n\nRun the following command to install the ADOT add-on, replacing the `--addon-version` flag based on your Amazon EKS cluster version as shown in the step above.\n\n```sh\naws eks create-addon --addon-name adot --addon-version v0.66.0-eksbuild.1 --cluster-name coredns-monitoring-demo\n```\n\nVerify that the ADOT add-on is ready using the following command:\n\n```sh\nkubectl get po -n opentelemetry-operator-system\n```\n\nThe following procedure uses an example YAML file with `deployment` as the mode value. This is the default mode and deploys the ADOT Collector similarly to a standalone application. This configuration receives OTLP metrics from the sample application and Amazon Managed Service for Prometheus metrics scraped from pods on the cluster.\n\n```sh\ncurl -o collector-config-amp.yaml https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-amp.yaml\n```\n\nIn `collector-config-amp.yaml`, replace the following with your own values:\n\n- `mode: deployment`\n- `serviceAccount: adot-collector`\n- `endpoint: \"\"`\n- `region: \"\"`\n- `name: adot-collector`\n\nApply the configuration:\n\n```sh\nkubectl apply -f collector-config-amp.yaml\n```\n\nOnce the ADOT collector is deployed, the metrics will be stored successfully in Amazon Prometheus.\n\n### üìà Visualize Ethtool Metrics in Amazon Managed Grafana\n\nConfigure the Amazon Managed Service for Prometheus workspace as a datasource inside the Amazon Managed Grafana console.\n\nLet's explore the metrics in Amazon Managed Grafana now: Click the explore button, and search for `ethtool`.\n\n![apm](./apm.png)\n\nLet's build a dashboard for the linklocal_allowance_exceeded metric by using the query\n\n```shell\nrate(node_net_ethtool{device=\"eth0\",type=\"linklocal_allo\nwance_exceeded\"} [30s])\n```\n\n![result](./result.png)\n\nWe can see that there were no packets dropped as the value is zero. You can further extend this by configuring alerts in the alert manager in Amazon Managed Service for Prometheus to send notifications.\n\n## Conclusion\n\nIn this post, we showed how to monitor and create alerts for CoreDNS throttling issues using AWS Distro for OpenTelemetry (ADOT), Amazon Managed Service for Prometheus, and Amazon Managed Grafana. By monitoring the coreDNS metrics, customers can proactively detect packet drops and take preventive actions.\n\n**References:**\n\n- https://www.datadoghq.com/blog/coredns-monitoring-tools/\n- https://cilium.io/blog/2019/12/18/how-to-debug-dns-issues-in-k8s/\n- https://sysdig.com/blog/how-to-monitor-coredns/\n- https://www.datadoghq.com/blog/coredns-metrics/\n- https://aws.amazon.com/blogs/mt/monitoring-coredns-for-dns-throttling-issues-using-aws-open-source-monitoring-services/\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1431},"frontmatter":{"id":"8fb13d41ebd7961bec03c200","path":"/blog/monitoring-coredns-dns-performance/","humanDate":"Oct 21, 2024","fullDate":"2024-10-21","title":"Everything You Need to Know About Monitoring CoreDNS for DNS Performance","keywords":["CoreDNS","Amazon EKS","Kubernetes","Monitoring"],"excerpt":"Ensure reliable DNS resolution in Amazon Kubernetes clusters by monitoring CoreDNS performance. This guide covers essential metrics and best practices for effective DNS monitoring.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADDElEQVR42h2S60+aBxTG+cv2oTNbl7abXUzpXC3etS1e26ogioBQQC5KZfWGYJSh9VKlRlBkWulMF7fZqivN1mTZvPC+XBSsqY2b+e3tPjzJyfnwO8/z5Mj20+c8f3WA0TVJi3UGdVeIemOQarWHZvsqSn2ISu081R0hFPeGabRGqXkQpVofQV4f4KtqL+XmOLfcR5TYRGRv9s7xLfxFY2eABn2Ajt4YLbYwtaoeWh2L1JmilGnmUKjnuFzqolgTotH+QjqwRIHSy5WKfqq6fudO7xHFH4HTS3Hk5VqaDEMYesPUtfuoumtB7/SjNo9QpLRS2TbNrY5Z5DUeLt50kF/RTYlqhoI7Xq7fD/JpoY284iFKHWlkT9ZEnKObuMZ3iG4kCMfeouv/lcHZOM2OCPWmefq+j9H68EcUrSGKNFFq7Vs0u99Q63zNbVucks6X3DD8JkVOSQ6fnzCz/o+kM9Zff2B1+4zI9jmhjSwNbQ8prrVRpwtQpfbySb6Ka41P6Jz8F2Mgi24sS9PQEXWPclS5sty0JpGNrx7TM5lgYjnNytYpj+azxHZOefrzKVPRJP6VUyzTJ4yuvKPFk6GhL0WBXuCiKsHXehGlO81tV4oyR5Iii9Th/cG33HVto2x5xsRigtWtD6ztnOEe2OFqXhcVhcP4nopMxE4wPz7kijbBDUsCy4RIpVMgT7UvuUtTak/xrVkClplfMjAr0NT1CtfYH/iW3+NdPKS5fAzFhS4ufTlI30KO4XCONl+GS+0HjCwJRDczTD0T+KJ9l0LzR2CSb0wSsKFbKlO7Qan2FwbnkyxsvCe4fozJt4vJvsnoUoaR6DEaCVbZneJC8z6uOYGf4imGQwk+b91Dbkr+/zLyTgHZ47UTWgf+xOIXsE1lGY1kmVzeoz+4iyd8wPgPAlrP39R/J3JvIE2+QeQzCVLm3Ody2740i5Q7pbgPBAoMCWTBF+/wRU6wT+WkXg7xLOYw+kV0Iwk0HkHaZTD409S4k5IyqDyHEixJvk7kmlGC9SRRWEWuGwWu6hL8B/hEfHqMLUR0AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/bf9e127d7b6dc07f97525a890e662947/e7e88/coredns-cover.png","srcSet":"/static/bf9e127d7b6dc07f97525a890e662947/1d7e8/coredns-cover.png 750w,\n/static/bf9e127d7b6dc07f97525a890e662947/f874f/coredns-cover.png 1080w,\n/static/bf9e127d7b6dc07f97525a890e662947/365c0/coredns-cover.png 1366w,\n/static/bf9e127d7b6dc07f97525a890e662947/e7e88/coredns-cover.png 1440w","sizes":"100vw"},"sources":[{"srcSet":"/static/bf9e127d7b6dc07f97525a890e662947/ea0da/coredns-cover.webp 750w,\n/static/bf9e127d7b6dc07f97525a890e662947/d1e72/coredns-cover.webp 1080w,\n/static/bf9e127d7b6dc07f97525a890e662947/c101e/coredns-cover.webp 1366w,\n/static/bf9e127d7b6dc07f97525a890e662947/5eda1/coredns-cover.webp 1440w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.54375}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/local-kubernetes-development-tools/","title":"Exploring Local Kubernetes Development Tools and Solutions","date":"2024-10-22 12:34:00"},"excerpt":"Improving your k8s development experience locally üå† üóØ Introduction Local Kubernetes development tools play an important role in‚Ä¶","html":"<blockquote>\n<p><strong>Improving your k8s development experience locally üå†</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üóØ Introduction</h2>\n<p>Local Kubernetes development tools play an important role in simplifying the process of developing applications for Kubernetes clusters. These tools help developers to connect their local environment to Kubernetes clusters seamlessly, facilitating efficient testing and debugging. In this blog post, we will explore various local Kubernetes development solutions and tools that can elevate your development workflow and productivity. Let's get started!</p>\n<h3 id=\"why-you-need-local-k8s-development-tools\" style=\"position:relative;\"><a href=\"#why-you-need-local-k8s-development-tools\" aria-label=\"why you need local k8s development tools permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Why You Need Local k8s Development Tools</h3>\n<p>The increasing complexity of Kubernetes has made software development more challenging. It seems that developing and debugging Kubernetes-based apps is often overlooked by its creators, who primarily designed it as a production system. Kubernetes expects you to provide production-ready OCI images, discouraging modifications to running containers. However, in reality, creating production-ready software isn't straightforward.</p>\n<p>Now, more than ever, having a local Kubernetes development solution is crucial. Before we explore different tools, let's understand why. There are several compelling reasons for wanting a local Kubernetes cluster:</p>\n<ul>\n<li><strong>Test Deployment Methods</strong>: Ensure they run smoothly before going live.</li>\n<li><strong>Check Application Interactions</strong>: Test how your application interacts with mounted volumes and manifest files.</li>\n<li><strong>Service Integration</strong>: Ensure your service works seamlessly with other services and communicates effectively when deployed to a Kubernetes cluster.</li>\n</ul>\n<p>In today's development landscape, merely spinning up your own service for testing isn't sufficient. You need to ensure that your service works seamlessly with other services and communicates effectively when deployed to a Kubernetes cluster. That's why having the option of a local Kubernetes cluster has become more important than ever.</p>\n<p>To support you during your daily development and debugging tasks, we'll explore three categories of tools or problems:</p>\n<ol>\n<li><strong>Tools to Speed Up Development Iteration Cycles</strong> üöÄ</li>\n<li><strong>Debugging with a Debugger (During Development)</strong> üêû</li>\n<li><strong>Tools for Debugging Problems in Production</strong> üîß</li>\n</ol>\n<p>But remember, this article isn't a deep dive into each tool; it's an overview to get you started on the right path.</p>\n<h2 id=\"Ô∏è-speeding-up-development-iteration-cycles\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-speeding-up-development-iteration-cycles\" aria-label=\"Ô∏è speeding up development iteration cycles permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚ôªÔ∏è Speeding Up Development Iteration Cycles</h2>\n<p>To ensure consistency between development and production environments, testing code within a Kubernetes cluster is essential. Use a remote staging or development cluster provided by your organization, or set up a local Kubernetes cluster.</p>\n<p>The \"development iteration cycle\" refers to the duration between code changes and running it within a container in the cluster. Manual processes like building a new image with a new tag and updating the referenced image in Deployment or StatefulSet can be time-consuming.</p>\n<p>Fortunately, automation tools like <a href=\"https://devspace.sh/\" target=\"_blank\" rel=\"noopener noreferrer\">DevSpace</a>, <a href=\"https://tilt.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">Tilt</a>, and <a href=\"https://skaffold.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">Skaffold</a> simplify these tasks. They monitor local source code folders, rebuild Docker images upon changes, and update Kubernetes manifests in the cluster. These tools allow code synchronization into running containers without restart for interpreted languages supporting hot-reloading. While their configurations vary, experimentation is needed to determine the best fit.</p>\n<p>For rapid development iterations on specific microservices, <a href=\"https://www.telepresence.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Telepresence</a> is invaluable. It installs other microservices into the cluster while replacing the selected one with a locally running application. Telepresence injects a proxy pod into the cluster, forwarding traffic to the local app and redirecting outbound traffic back into the cluster.</p>\n<p>Similar functionality is offered by <a href=\"https://learn.microsoft.com/en-us/visualstudio/bridge/overview?view=vs-2022\" target=\"_blank\" rel=\"noopener noreferrer\">Bridge to Kubernetes</a>, available in VS Code or Visual Studio IDE.</p>\n<p>For local cluster setup, options include <a href=\"https://minikube.sigs.k8s.io/docs/\" target=\"_blank\" rel=\"noopener noreferrer\">Minikube</a>, <a href=\"https://microk8s.io/\" target=\"_blank\" rel=\"noopener noreferrer\">MicroK8S</a>, <a href=\"https://kind.sigs.k8s.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Kind</a>, and lightweight Kubernetes distributions like <a href=\"https://k3s.io/\" target=\"_blank\" rel=\"noopener noreferrer\">K3S</a>/<a href=\"https://k3d.io/\" target=\"_blank\" rel=\"noopener noreferrer\">K3D</a> by Rancher.</p>\n<h3 id=\"minikube\" style=\"position:relative;\"><a href=\"#minikube\" aria-label=\"minikube permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Minikube</h3>\n<p>Minikube has support for all three major operating systems: Windows, macOS, and Linux. This means you likely don't have to worry if you plan on rolling out Minikube organization-wide since pretty much any PC is able to run it. On top of that, you also get great platform support in terms of how Minikube should be run, given that it supports many different drivers, like Docker, kvm2, and VirtualBox.</p>\n<h3 id=\"kind\" style=\"position:relative;\"><a href=\"#kind\" aria-label=\"kind permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Kind</h3>\n<p>Like Minikube, Kind supports all three major platforms. It works by spinning up Docker containers to act as nodes in your cluster, which are based on an image created by Kind. However, if you want to use your own image, that's also possible using the <code class=\"language-text\">--image</code> flag.</p>\n<h3 id=\"k3s\" style=\"position:relative;\"><a href=\"#k3s\" aria-label=\"k3s permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>K3s</h3>\n<p>K3s is the first tool on this list that only supports running on Linux due to the fact that K3s isn't actually made to be a development solution. Rather, it was developed as a low-resource alternative to Kubernetes (hence the name K3s, which is a play on the abbreviation K8s).</p>\n<h3 id=\"microk8s\" style=\"position:relative;\"><a href=\"#microk8s\" aria-label=\"microk8s permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>MicroK8s</h3>\n<p>MicroK8s again supports the three main operating systems, and you will find easy-to-follow installation instructions on their website. Once installed, you'll see that this is a tool that's made for development, and you'll be heavily using the CLI. Even when running simple <code class=\"language-text\">kubectl</code> commands, you need to prefix it with <code class=\"language-text\">microk8s</code>.</p>\n<h3 id=\"okteto\" style=\"position:relative;\"><a href=\"#okteto\" aria-label=\"okteto permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Okteto</h3>\n<p><a href=\"https://okteto.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Okteto</a> accelerates the development workflow of Kubernetes applications. You write your code locally and Okteto detects the changes and instantly updates your Kubernetes applications. Okteto allows you to develop inside a container. When you run <code class=\"language-text\">okteto up</code>, your Kubernetes deployment is replaced by a development container that contains your development tools (e.g., Maven and JDK, or npm, Python, Go compiler, debuggers, etc.). This development container can use any Docker image. The development container inherits the same secrets, configmaps, volumes, or any other configuration value of the original Kubernetes deployment.</p>\n<h3 id=\"cloud-code-intellij-plugin\" style=\"position:relative;\"><a href=\"#cloud-code-intellij-plugin\" aria-label=\"cloud code intellij plugin permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Cloud Code IntelliJ Plugin</h3>\n<p>If you use IntelliJ as a development IDE and you prefer \"clicking\" over command-line tools, <a href=\"https://cloud.google.com/code\" target=\"_blank\" rel=\"noopener noreferrer\">Cloud Code</a> is something for you. There is also the Cloud Code plugin for Microsoft Visual Studio Code.</p>\n<p>Cloud Code comes with a set of tools to help you write, run, and debug cloud-native applications quickly and easily. It can be integrated with popular tools like Skaffold, Jib, <code class=\"language-text\">kubectl</code>, or <code class=\"language-text\">kustomize</code>.</p>\n<p>With Google's Cloud Code, you can run and debug your application on Kubernetes the same as you would do it during local development without any third-party platform. You need to click the Run or Debug button on the configuration built using the template Cloud Code: Kubernetes as shown below.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 488px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 8.823529411764705%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAIAAADXZGvcAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAaUlEQVR42g3ISQ7CMAxA0d6LOtTxkHhIihALEOX+1yDS11v8bWfUHp/rJ90tUiyk26p5NM/l+twMScEJuJanFCWsUpC2W0NRe38vi5Fjxnx4DrXwnDHOHKflRNb7wWB1J4QXg1YkKUf9AxC9IYkGwgi/AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"IntelliJ\" title=\"\" src=\"/static/8921b8a48a17ace8f15802b2be944bc3/bd48c/intelij.png\" srcset=\"/static/8921b8a48a17ace8f15802b2be944bc3/04472/intelij.png 170w,\n/static/8921b8a48a17ace8f15802b2be944bc3/9f933/intelij.png 340w,\n/static/8921b8a48a17ace8f15802b2be944bc3/bd48c/intelij.png 488w\" sizes=\"(max-width: 488px) 100vw, 488px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>With Cloud Code, you can easily explore all your Kubernetes clusters that are configured inside the local Kubernetes context. You can verify a list of workloads, services, ingresses, config maps, secrets, and others. You can easily stream logs, view detailed descriptions, and open a terminal for selected pods. All information is exposed as a drop-down list box in the tree structure as you see in the picture below.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 494px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 124.11764705882354%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAIAAAC+dZmEAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB/0lEQVR42o2U607jMBCF+1yUNLETX8d2LoUuK7RCCMRqEWjf/9+esasWok1TadomqT+f4+NxNrXs/rx/vL79Dv0Q0jDd/0jjJFolOi2VqRp5W4ul2txUdejHOExxGMHjm9IAEv9dJhnGB3yr7bi/3x8eoKyMgzJkd6Jdh0sZT9AfpjtHEZpV016lXGq7awB/fP4FbHwAiSenygN4zLbOlZ98g0WrNZFwJqbBxx5TuJC4KHbG4SL2I0/t+Dlmn8PSmMZpxI7YLEV8hzyRdkSx59vYe8wyTK0yM1hJC1iFyABg5O8DXyjrykTQpMSm5rYxmQ5UW4ahYz1+J4psG8r9uD858jGhQc5wVQv4Ofx8hGauhFvRqZINVw6/KoPz9Wa+AVJIsqyQbfMsoXchls2f7fwc3gohvOGQEtsuIWGd2nmp9CrcCK8pOwfMgcUEC602UK6WmiSvR1ZSYp+/wCNkLQX0b7MEIxVYwtDHX0/IFlJg4PPK9mzQzDiRzy+vlNvA5g6/trexb0h1vDsgXoQEvpHdeZ+W4G0t4Flbj07AOq3nHkAbKevX4bLpKsNYdl5wLK+EfDblCgzPnfEGyhRQ5VSWNoalJf0jDM0y+tgG39TWlLFgw6sN2F4cj8sh/wc+Gg4ROXfaXY5qbrv0Broar77bK8gzjFRguyz7QkIz+B8Jho0ci4OI3wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"IntelliJ2\" title=\"\" src=\"/static/de7b6176f04bc0eadd25fd9a4702a240/d72d4/intelij2.png\" srcset=\"/static/de7b6176f04bc0eadd25fd9a4702a240/04472/intelij2.png 170w,\n/static/de7b6176f04bc0eadd25fd9a4702a240/9f933/intelij2.png 340w,\n/static/de7b6176f04bc0eadd25fd9a4702a240/d72d4/intelij2.png 494w\" sizes=\"(max-width: 494px) 100vw, 494px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"improving-k8s-command-line-experience\" style=\"position:relative;\"><a href=\"#improving-k8s-command-line-experience\" aria-label=\"improving k8s command line experience permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Improving K8S Command Line Experience</h2>\n<ul>\n<li><a href=\"https://github.com/ahmetb/kubectx\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kubectx+kubens</strong></a>: Swiftly switch between clusters and namespaces, and merge kube config files for seamless context switching.</li>\n<li><a href=\"https://github.com/cloudnativelabs/kube-shell\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kube-shell</strong></a>: Integrated shell for Kubernetes CLI.</li>\n<li><a href=\"https://github.com/c-bata/kube-prompt\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kube-prompt</strong></a>: Interactive client with auto-complete.</li>\n<li><a href=\"https://github.com/derailed/k9s\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>K9S</strong></a>: Terminal UI for Kubernetes clusters.</li>\n<li><a href=\"https://github.com/jonmosco/kube-ps1\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kube-ps1</strong></a>: Kubernetes prompt info for bash and zsh.</li>\n<li><a href=\"https://github.com/stern/stern\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Stern</strong></a>: Multi-pod and container log tailing.</li>\n<li><a href=\"https://github.com/boz/kail\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Kail</strong></a>: Kubernetes log viewer.</li>\n<li><a href=\"https://github.com/pulumi/kubespy\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>KubeSpy</strong></a>: Real-time observation tools for Kubernetes resources.</li>\n<li><a href=\"https://krew.sigs.k8s.io/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kubectl plugins (Krew)</strong></a>: Package manager for kubectl plugins with an index of available plugins.</li>\n<li><a href=\"https://github.com/alexellis/arkade\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Arkade</strong></a>: Single-command installation for Kubernetes applications.</li>\n<li><a href=\"https://github.com/txn2/kubefwd\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kubefwd</strong></a>: Bulk port forwarding for local development.</li>\n</ul>\n<h3 id=\"Ô∏è-guitui-tools\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-guitui-tools\" aria-label=\"Ô∏è guitui tools permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üñ•Ô∏è GUI/TUI Tools</h3>\n<ul>\n<li><a href=\"https://github.com/kubernetes/dashboard\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>K8S Dashboard</strong></a></li>\n<li><a href=\"https://github.com/vmware-tanzu/octant\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Octant</strong></a></li>\n<li><a href=\"https://github.com/harbur/kubernetic\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Kubernetic</strong></a></li>\n<li><a href=\"https://docs.portainer.io/user/kubernetes/dashboard\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Portainer</strong></a></li>\n<li><a href=\"https://github.com/kubenav/kubenav\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>KubeNav</strong></a></li>\n<li><a href=\"https://github.com/MuhammedKalkan/OpenLens\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>OpenLens</strong></a></li>\n<li><a href=\"https://www.okteto.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Okteto</strong></a></li>\n</ul>\n<h2 id=\"-debugging-with-a-debugger\" style=\"position:relative;\"><a href=\"#-debugging-with-a-debugger\" aria-label=\" debugging with a debugger permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üêû Debugging with a Debugger</h2>\n<p>One significant challenge when working in Kubernetes, as opposed to local or native development, is the difficulty in debugging containerized code with a debugger. However, it is still feasible to use debuggers through remote debugging. You'll need to find a specific solution that suits your programming language and preferred IDE or debugger.</p>\n<h3 id=\"remote-debugging-approaches\" style=\"position:relative;\"><a href=\"#remote-debugging-approaches\" aria-label=\"remote debugging approaches permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Remote Debugging Approaches</h3>\n<h4 id=\"server-on-host\" style=\"position:relative;\"><a href=\"#server-on-host\" aria-label=\"server on host permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Server-on-Host</h4>\n<p>On the host machine (e.g., in the IDE), you initiate a debug server. You then incorporate the debug client into your application's code to connect to the debug server on your host. Since applications or ports on your host aren't reachable from within a cluster, you'll require a solution that sets up a proxy or reverse tunnel. Some solutions like <a href=\"https://www.telepresence.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Telepresence</a> or VS Code's <a href=\"https://learn.microsoft.com/en-us/visualstudio/bridge/overview?view=vs-2022\" target=\"_blank\" rel=\"noopener noreferrer\">Bridge to Kubernetes</a> have this proxy feature built-in, while others, such as <a href=\"https://github.com/omrikiei/ktunnel\" target=\"_blank\" rel=\"noopener noreferrer\">ktunnel</a>, are dedicated solutions.</p>\n<p>For instance, PyCharm IDE for Python utilizes this approach. You can refer to this example using <a href=\"https://github.com/omrikiei/ktunnel\" target=\"_blank\" rel=\"noopener noreferrer\">ktunnel</a>.</p>\n<h4 id=\"server-in-container\" style=\"position:relative;\"><a href=\"#server-in-container\" aria-label=\"server in container permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Server-in-Container</h4>\n<p>You embed a debugging server into your application code running in a container within a Pod, operating on a specific port. Then, you utilize <code class=\"language-text\">kubectl port-forward</code> to create a connection from your host to that port, allowing you to connect from your debugger/IDE, acting as the debugger client.</p>\n<p>Examples of this approach include debugging NodeJS applications by starting Node with the <code class=\"language-text\">--inspect</code> switch or debugging Python applications with VS Code using <a href=\"https://github.com/microsoft/debugpy/\" target=\"_blank\" rel=\"noopener noreferrer\">debugpy</a> and following its README instructions.</p>\n<h2 id=\"-debugging-problems-in-production\" style=\"position:relative;\"><a href=\"#-debugging-problems-in-production\" aria-label=\" debugging problems in production permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîß Debugging Problems in Production</h2>\n<p>When encountering issues in production environments, swift and accurate identification of the root cause is paramount. To aid in this endeavor, several specialized tools offer advanced debugging capabilities tailored for Kubernetes environments:</p>\n<ul>\n<li><a href=\"https://github.com/inspektor-gadget/inspektor-gadget\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>Inspektor Gadget</strong></a>: This tool suite provides a comprehensive set of utilities for debugging and inspecting Kubernetes applications. It enables detailed examination of various aspects such as TCP traffic, process management within pods, and file access tracing, facilitating precise diagnosis of issues.</li>\n<li><a href=\"https://github.com/kubeshark/kubeshark\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kubeshark</strong></a>: Designed specifically for Kubernetes, kubeshark serves as a graphical API traffic sniffer. It offers real-time visualization of API communication between microservices, akin to TCPDump and Wireshark but optimized for Kubernetes environments.</li>\n<li><a href=\"https://github.com/lightrun-platform/koolkits\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>koolkits</strong></a>: Leveraging Kubernetes' ephemeral debug container feature, koolkits supplies prebuilt OCI images customized for debugging purposes. These images come equipped with a range of essential tools tailored for debugging applications written in popular languages like Python, Node.js, or Java.</li>\n<li><a href=\"https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>kubectl debug ephemeral command</strong></a>: This command allows for the creation of ephemeral debug containers directly within Kubernetes clusters. By spawning temporary debugging environments, developers gain immediate access to the cluster's resources for in-depth investigation and diagnosis of issues.</li>\n<li><a href=\"https://github.com/nicolaka/netshoot\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>netshoot</strong></a>: As a versatile troubleshooting tool, netshoot serves as a comprehensive Docker and Kubernetes network diagnostic container. Equipped with a plethora of network troubleshooting utilities, netshoot enables engineers to perform detailed analysis and troubleshooting of network-related issues within Kubernetes clusters.</li>\n</ul>\n<p>With these advanced debugging tools at their disposal, Kubernetes operators and developers can efficiently diagnose and resolve production issues, ensuring optimal performance and reliability of their applications.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion</h2>\n<p>Before starting development, it is worth spending some time discovering useful tools for managing the Kubernetes cluster. As you see, there is a wide selection of such Kubernetes development tools, starting from simple command-line solutions to more advanced GUI or web-based interfaces. Once we have selected such tools, we may proceed to the second phase‚Ää‚Äî‚Ääa setup of local or remote Kubernetes cluster for development.</p>\n<p>For more information, you can check out the <a href=\"https://kubernetes.io/docs/home/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes Documentation</a> and <a href=\"https://kubernetes.io/docs/tasks/tools/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes Tools</a>.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/daemonless-kaniko-container-images/","title":"Building Container Images in Kubernetes Cluster with Kaniko","date":"2024-10-21 22:22:00"},"excerpt":"Daemonless Docker Image Building in k8s¬†‚ò∏Ô∏è üìå Introduction Kaniko is an open-source tool developed by Google that enables building container‚Ä¶","html":"<blockquote>\n<p><strong>Daemonless Docker Image Building in k8s¬†‚ò∏Ô∏è</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Introduction</h2>\n<p><a href=\"https://github.com/GoogleContainerTools/kaniko\" target=\"_blank\" rel=\"noopener noreferrer\">Kaniko</a> is an open-source tool developed by Google that enables building container images from a Dockerfile inside a Kubernetes cluster without requiring a Docker daemon. Kaniko executes each command in the Dockerfile in the user space using an executor image, which runs inside a container, such as a Kubernetes pod. This allows building container images in environments where the user doesn't have root access, like a Kubernetes cluster. In this blog post, we will explore how to use Kaniko to build container images in a Kubernetes cluster without a Docker daemon.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 52.352941176470594%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjklEQVR42p2R70/TQBzG+5/72uA7JegLo28MIYBA0hBUlN8QQkAmmVkIs7CtY7TrunZbe13v+uFuG5IYXdRLnlxy1z73PJ+vxbRVKK2Cgr9f1hS332vyyL8bFhJ5tUxY3SPupyT9mG4YIAY9yNP/MFQ5w7Nn3JVWqLseNafKjeNw26hBNphiqNNn+sFBDGkfhmLSSGYg9EGmL0T0qKSrE4o/G0oJfnOsjgehX5Dnj4yURma+UVIPR02GZFBOOJpNSX6eWQ/D7AbjC6ORkd7b7R6BL0g1NiEK5C+zMCamWdIbtzRtLdNRCUFwW2jw0KhFXP8ISDSmLXuT8ukFYqh/9AJk9Zi8WSXqJgRBSJoOR2FGyAYZfjvE6n22ibY3uf6ec3OpeD37nqdPXlK58Gh9WaN1uEWsU8SVCrH9iuhom42VPd68eEulVB8xN8nOT77xfGYOq7k6z9WnMuvv4OuuwPm4w+XCErXdU9y1JZrrNq69irtzzJ0LrbrmvX9AZ2MBr9zAdRS+q4hLJ3Q+LHIPEuv7q0d8groAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"kaniko\" title=\"\" src=\"/static/7f674431801748e12a68c2b774ef9ff1/c5bb3/kaniko.png\" srcset=\"/static/7f674431801748e12a68c2b774ef9ff1/04472/kaniko.png 170w,\n/static/7f674431801748e12a68c2b774ef9ff1/9f933/kaniko.png 340w,\n/static/7f674431801748e12a68c2b774ef9ff1/c5bb3/kaniko.png 680w,\n/static/7f674431801748e12a68c2b774ef9ff1/b12f7/kaniko.png 1020w,\n/static/7f674431801748e12a68c2b774ef9ff1/c1b63/kaniko.png 1200w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-benefits-of-kaniko\" style=\"position:relative;\"><a href=\"#-benefits-of-kaniko\" aria-label=\" benefits of kaniko permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Benefits of Kaniko</h2>\n<p>Kaniko offers several benefits for building images in Kubernetes:</p>\n<ul>\n<li><strong>No Docker daemon required</strong>: Kaniko eliminates the need for a Docker daemon in a Kubernetes cluster, reducing security risks and overhead.</li>\n<li><strong>Improved security</strong>: By building images in userspace without privileges, Kaniko reduces the attack surface compared to using Docker.</li>\n<li><strong>Kubernetes integration</strong>: Kaniko is specifically designed to build images within a Kubernetes pod, seamlessly integrating into Kubernetes workflows.</li>\n<li><strong>Caching</strong>: During builds, Kaniko caches image layers, enabling faster image rebuilding.</li>\n<li><strong>Debugging</strong>: Kaniko provides robust debugging tools for troubleshooting builds, enhancing the development process.</li>\n</ul>\n<h2 id=\"Ô∏è-how-kaniko-works\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-how-kaniko-works\" aria-label=\"Ô∏è how kaniko works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚öôÔ∏è How Kaniko Works</h2>\n<p>Kaniko builds container images by parsing the Dockerfile and executing each command within a container isolated from the host environment. Instead of using a Docker daemon, Kaniko simulates the Docker builder by providing its own implementations of Docker commands like <code class=\"language-text\">ADD</code>, <code class=\"language-text\">COPY</code>, <code class=\"language-text\">RUN</code>, etc.</p>\n<p>Each command gets executed in its own scratch container based on the base image. This allows Kaniko to capture changes made by each command and construct the final image layer by layer. Kaniko also intelligently caches image layers to optimize rebuild time. The hashing of commands and layers allows for avoiding redundant build steps.</p>\n<p>For more detailed information, you can refer to the <a href=\"https://github.com/GoogleContainerTools/kaniko#readme\" target=\"_blank\" rel=\"noopener noreferrer\">Kaniko documentation</a>.</p>\n<h2 id=\"-kaniko-vs-dind\" style=\"position:relative;\"><a href=\"#-kaniko-vs-dind\" aria-label=\" kaniko vs dind permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üÜö Kaniko vs DinD</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABxElEQVR42nVTbU7CQBCt+osLeAePYIz34RYkXsR/fsZTEDSgqIQfJJTIR5BQCgXaQihud3yv7hJQnOR1tzNv387O7DoOrNFo5D3Pk263m7ZaLfF9X+I41svlUmazWVKv10+q1eoJYkm/3xeMejAYyGKxkCiKUq21wJ93rE0mkwuBff2YpGnKX21AgTPCcPR6vdaGk7n4ocZGMAiCggmusEBhgaIyFinu3m63TwnDUbAvywNnRed4PC78yZC7DYdDpi/z+VzbFDqdzhlh/6fTqe71esxqf4ao3Tlq9YC6XaF+NyDfhWF4BdzCf4njHhOc08cYOcjqhmu4lhpW78DA2hGQc3bt0GDbcoa7q4NdrtGtN+xURlcrOOozOv7COXyV+Gcs2zh9HMkh1/jK1KCWw6uRtVRrW3H57ds26yOH3N8+B8r0slvZyO6hRgpBFUehevr4VI2+p/yRr4LpbBPjSO72Wmo5SDe1mfFuEaskkSiOJQ7ncv/uyqPb5aWXwdBj93npJQHH8m2m1NoceZ/xKEuIBmNfRv5IFhD6rxSbI9dqtddSqSTFYlHjCfJViOu6GThvNl2gmcHF/3bcAjGNeyp4jq/fZ44LVaL5K5cAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"DinD\" title=\"\" src=\"/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/c5bb3/dind.png\" srcset=\"/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/04472/dind.png 170w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/9f933/dind.png 340w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/c5bb3/dind.png 680w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/b12f7/dind.png 1020w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/b5a09/dind.png 1360w,\n/static/b8c0f57f3e4fb32829c0a2c595ae4ee3/2cefc/dind.png 1400w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>DinD (Docker in Docker) technology shares the host's Docker daemon with the container it's running in. This means that it has full access to Docker on the host, potentially impacting the host's Docker environment, which can be really dangerous. But Kaniko is more secure because it doesn't need access to the host's Docker daemon inside the container, reducing potential security risks.</p>\n<p>On the other hand, Kaniko is primarily useful for building a Docker image, while DinD has a broader range of uses, with building images being just one of them. You can perform various tasks with DinD, such as managing containers on the daemon host and monitoring their status.</p>\n<h2 id=\"-kaniko-vs-buildpacks\" style=\"position:relative;\"><a href=\"#-kaniko-vs-buildpacks\" aria-label=\" kaniko vs buildpacks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üÜö Kaniko vs Buildpacks</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABq0lEQVR42q1TbU7CQBCtHsI7cARjvI+3MOEi/IPwQw8hIRESECQRA1QKFCq0RaBQPna745t+CELkl5O8dHbn7duZnammwUzTvCOY67qBruvU6/Wo0+mo2WxGi8ViW6lUUo1GIzWfz7er1YrAUTGHLMsK+CxraIlBKE2RiSAIiCGlVFgz+OANI+YoxFXCA0ScTPpH0HGce95EBhv4EpnJ6XQqfN+XvN/tdq8Z7C+XSwmOYA5EpOd5G95njZMMJ5OJaLfb1O/3w7JwmI4zxKUETlgyLmGh0wyHw+EtbnywbTsLYg7r3GAwyIKcxxtmarXaFQOcDDLPcwxgTm48Hmf5LGskehcxztlljHMW6SCLHDr3gvJKQDkB3ibyfb8cx0p+5O9je5RYg7U0kOi/jLU0KHMnpVLqF4QQco3Y88dQvpmf3FnpuFPJXWY75rMGa2kghIN5MFchtrsdrVdLenzV6endIDSAzJFFnregHWLH/HikgrMlK4y1D4Evx+aRomSMlFJ/l1yv16vFYpEKhYJqNpvh78SzyGC/hW+r1QrRxvowngAxZRgGjUaj6jcocgiZIHL6CQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Buildpacks\" title=\"\" src=\"/static/073eca87c29c2dab8529e3190decedb2/c5bb3/buildpacks.png\" srcset=\"/static/073eca87c29c2dab8529e3190decedb2/04472/buildpacks.png 170w,\n/static/073eca87c29c2dab8529e3190decedb2/9f933/buildpacks.png 340w,\n/static/073eca87c29c2dab8529e3190decedb2/c5bb3/buildpacks.png 680w,\n/static/073eca87c29c2dab8529e3190decedb2/b12f7/buildpacks.png 1020w,\n/static/073eca87c29c2dab8529e3190decedb2/b5a09/buildpacks.png 1360w,\n/static/073eca87c29c2dab8529e3190decedb2/2cefc/buildpacks.png 1400w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Buildpacks are highly automated and aim to make image building easier, without requiring you to write a Dockerfile for your project. In contrast, Kaniko requires manual Dockerfile creation and configuration.</p>\n<p>On the other hand, Kaniko is a more low-level project that allows you to customize your project extensively, making your build process highly customizable. In comparison, the level of customization in Buildpacks can be somewhat challenging and occasionally impossible.</p>\n<h2 id=\"-using-kaniko-in-kubernetes\" style=\"position:relative;\"><a href=\"#-using-kaniko-in-kubernetes\" aria-label=\" using kaniko in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèó Using Kaniko In Kubernetes</h2>\n<p>To use Kaniko in Kubernetes, a pod specification is created with Kaniko as the container image, and the Dockerfile is mounted as a volume. Upon running the pod, Kaniko will proceed to build the image from the Dockerfile and push it to the designated registry.</p>\n<h3 id=\"example-pod-specification\" style=\"position:relative;\"><a href=\"#example-pod-specification\" aria-label=\"example pod specification permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Example Pod Specification</h3>\n<p>An example pod specification for running Kaniko is as follows:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> gcr.io/kaniko<span class=\"token punctuation\">-</span>project/executor<span class=\"token punctuation\">:</span>latest\n        <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"--dockerfile=/Dockerfile\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--destination=myregistry/myimage\"</span><span class=\"token punctuation\">]</span>\n        <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile\n                <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /Dockerfile\n    <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile\n            <span class=\"token key atrule\">configMap</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile<span class=\"token punctuation\">-</span>configmap\n    <span class=\"token key atrule\">restartPolicy</span><span class=\"token punctuation\">:</span> Never</code></pre></div>\n<p>The Dockerfile is stored in a ConfigMap which gets mounted by Kaniko to build the image.</p>\n<p>Kaniko provides a secure and efficient way to build container images within a Kubernetes cluster. By avoiding privileged Docker daemons, Kaniko simplifies image building while improving security. The caching and Kubernetes integration make Kaniko a natural fit for automating image creation as part of a CD pipeline.</p>\n<h2 id=\"-tutorial-build-container-images-with-kaniko-in-kubernetes\" style=\"position:relative;\"><a href=\"#-tutorial-build-container-images-with-kaniko-in-kubernetes\" aria-label=\" tutorial build container images with kaniko in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Tutorial: Build Container Images with Kaniko in Kubernetes</h2>\n<p>Kaniko is a tool that allows building container images from a Dockerfile inside a Kubernetes cluster without needing Docker. In this tutorial, we'll walk through an example of using Kaniko to build and push an image to a registry from a Kubernetes pod.</p>\n<h3 id=\"prerequisites\" style=\"position:relative;\"><a href=\"#prerequisites\" aria-label=\"prerequisites permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Prerequisites</h3>\n<ul>\n<li>Kubernetes cluster</li>\n<li>Docker Hub account for pushing the built image</li>\n</ul>\n<h3 id=\"1-write-a-dockerfile\" style=\"position:relative;\"><a href=\"#1-write-a-dockerfile\" aria-label=\"1 write a dockerfile permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>1. Write a Dockerfile</h3>\n<p>First, we'll write a simple Dockerfile that defines our example image:</p>\n<div class=\"gatsby-highlight\" data-language=\"dockerfile\"><pre class=\"language-dockerfile\"><code class=\"language-dockerfile\"><span class=\"token instruction\"><span class=\"token keyword\">FROM</span> alpine:3.12</span>\n<span class=\"token instruction\"><span class=\"token keyword\">RUN</span> apk add --update nginx <span class=\"token operator\">\\</span>\n &amp;&amp; rm -rf /var/cache/apk/*</span>\n<span class=\"token instruction\"><span class=\"token keyword\">RUN</span> echo <span class=\"token string\">'This image is created by kaniko'</span> > /usr/share/nginx/html/index.html</span>\n<span class=\"token instruction\"><span class=\"token keyword\">EXPOSE</span> 80</span>\n<span class=\"token instruction\"><span class=\"token keyword\">CMD</span> [<span class=\"token string\">\"nginx\"</span>, <span class=\"token string\">\"-g\"</span>, <span class=\"token string\">\"daemon off;\"</span>]</span></code></pre></div>\n<p>This Dockerfile starts from the alpine base image, installs nginx, copies over a custom <code class=\"language-text\">index.html</code>, exposes port 80, and sets the container command.</p>\n<h3 id=\"2-create-a-configmap-for-the-dockerfile\" style=\"position:relative;\"><a href=\"#2-create-a-configmap-for-the-dockerfile\" aria-label=\"2 create a configmap for the dockerfile permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>2. Create a ConfigMap for the Dockerfile</h3>\n<p>Next, we'll create a ConfigMap that contains this Dockerfile so that we can mount it into the Kaniko pod later:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl create configmap dockerfile-config --from-file<span class=\"token operator\">=</span>Dockerfile</code></pre></div>\n<h3 id=\"3-define-a-pod-spec-for-kaniko\" style=\"position:relative;\"><a href=\"#3-define-a-pod-spec-for-kaniko\" aria-label=\"3 define a pod spec for kaniko permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>3. Define a Pod Spec for Kaniko</h3>\n<p>Now we can define a pod spec in a YAML file with Kaniko as the container:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> kaniko\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> gcr.io/kaniko<span class=\"token punctuation\">-</span>project/executor<span class=\"token punctuation\">:</span>latest\n        <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"--dockerfile=/Dockerfile\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--context=/workspace\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--destination=mydockerhubusername/nginx-image\"</span><span class=\"token punctuation\">]</span>\n        <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile \n                <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /Dockerfile\n    <span class=\"token key atrule\">restartPolicy</span><span class=\"token punctuation\">:</span> Never\n    <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile\n            <span class=\"token key atrule\">configMap</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dockerfile<span class=\"token punctuation\">-</span>config</code></pre></div>\n<p>The key parts are:</p>\n<ul>\n<li>Mounting our ConfigMap containing the Dockerfile to <code class=\"language-text\">/Dockerfile</code></li>\n<li>Setting the Dockerfile path in the <code class=\"language-text\">args</code></li>\n<li>Specifying the destination image repository and tag</li>\n</ul>\n<h3 id=\"4-run-the-kaniko-pod\" style=\"position:relative;\"><a href=\"#4-run-the-kaniko-pod\" aria-label=\"4 run the kaniko pod permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>4. Run the Kaniko Pod</h3>\n<p>We can now create the pod to trigger the Kaniko build:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl create <span class=\"token parameter variable\">-f</span> kaniko.yaml</code></pre></div>\n<p>Once launched, you can watch the pod's logs to see the build process:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl logs <span class=\"token parameter variable\">-f</span> kaniko</code></pre></div>\n<p>After the build completes, the image will be pushed to the destination registry specified.</p>\n<h3 id=\"5-verify-the-built-image\" style=\"position:relative;\"><a href=\"#5-verify-the-built-image\" aria-label=\"5 verify the built image permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>5. Verify the Built Image</h3>\n<p>Finally, we can pull and run a container from the image built by Kaniko to verify it works as expected:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> pull mydockerhubusername/nginx-image\n<span class=\"token function\">docker</span> run <span class=\"token parameter variable\">-p</span> <span class=\"token number\">80</span>:80 mydockerhubusername/nginx-image</code></pre></div>\n<p>When you visit <code class=\"language-text\">localhost</code>, you should see the custom <code class=\"language-text\">index.html</code> from the image served by nginx!</p>\n<p>And that's it! We used Kaniko to build and push a Docker image from a Kubernetes pod, without needing direct access to Docker. Kaniko is a handy tool to integrate image building into a Kubernetes-based CI/CD pipeline.</p>\n<h2 id=\"-common-use-cases-and-examples\" style=\"position:relative;\"><a href=\"#-common-use-cases-and-examples\" aria-label=\" common use cases and examples permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Common Use Cases and Examples</h2>\n<ul>\n<li>‚úÖ <strong>Kubernetes CI/CD pipelines</strong>: Kaniko can be used to build application container images as part of a continuous integration and deployment workflow in Kubernetes. For example, building images within a Kubernetes cluster after application code is pushed to a git repository.</li>\n<li>‚úÖ <strong>Building images in serverless architectures</strong>: When running containerized workloads on serverless platforms like AWS Fargate, Kaniko allows building images as part of the serverless workflow without needing a dedicated Docker environment.</li>\n<li>‚úÖ <strong>Building images in constrained environments</strong>: Kaniko can build images in environments that don't allow running privileged containers like a Docker daemon. For example on managed Kubernetes services that have security restrictions.</li>\n<li>‚úÖ <strong>Debugging Dockerfiles</strong>: Kaniko can be used to debug Dockerfile commands and scripts by building images step-by-step.</li>\n<li>‚úÖ <strong>Reproducing builds</strong>: The cache digest produced by Kaniko makes builds reproducible by allowing exactly the same image to be rebuilt multiple times.</li>\n<li>‚úÖ <strong>Self-hosted image registries</strong>: Kaniko can push images to private registries and doesn't depend on hub.docker.com for hosting images.</li>\n<li>‚úÖ <strong>Custom base images</strong>: Kaniko allows building custom base images efficiently from scratch before using them in application images.</li>\n<li>‚úÖ <strong>Multi-stage builds</strong>: Kaniko supports multi-stage Dockerfiles out of the box for creating final production images.</li>\n<li>‚úÖ <strong>Scratch image builds</strong>: Images can be built from scratch without needing a base image.</li>\n</ul>\n<p>Kaniko fits nicely into Kubernetes and CI/CD workflows, allows building images in restricted environments, and provides reproducibility and debugging for Dockerfile builds.</p>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèÅ Conclusion</h2>\n<p>Kaniko enables building container images within a Kubernetes cluster without privileged access or external Docker daemons. It offers improved security, simpler setup, and easier integration with existing Kubernetes workflows.</p>\n<p>By using Kaniko, the build and push process can be entirely self-contained within the cluster, eliminating the need for external dependencies and simplifying build orchestration. This approach paves the way for faster and more integrable builds in CI/CD pipelines with security as a guiding principle.</p>\n<p><strong>Thank You üñ§</strong></p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}