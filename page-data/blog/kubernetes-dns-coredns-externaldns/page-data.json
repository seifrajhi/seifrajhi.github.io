{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/kubernetes-dns-coredns-externaldns/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>The ABCs of Kubernetes DNS üê≥</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üî• Introduction</h2>\n<p>Kubernetes, an open-source platform for automating containerized applications, relies on Domain Name System (DNS) to facilitate communication between its various components. Two essential tools for managing DNS within a Kubernetes cluster are <strong>CoreDNS</strong> and <strong>ExternalDNS</strong>. In this blog post, we will take a straightforward look at these tools, their functions, and how they can benefit your Kubernetes environment.</p>\n<h2 id=\"-how-coredns-and-externaldns-work\" style=\"position:relative;\"><a href=\"#-how-coredns-and-externaldns-work\" aria-label=\" how coredns and externaldns work permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üï∏ How CoreDNS and ExternalDNS Work</h2>\n<p>Kubernetes relies on the Domain Name System (DNS) to enable seamless communication between its various components, such as pods and services. When a new Kubernetes service is created, the platform automatically generates a DNS record for it, allowing other pods to easily locate and connect to the service. Kubernetes also offers support for <strong>ExternalDNS</strong>, which simplifies the process of creating and managing DNS records for services that need to be accessible externally. This makes it easier for external clients to access the services within the cluster.</p>\n<p>In simpler terms:</p>\n<ul>\n<li>Kubernetes uses DNS to help pods and services find and communicate with each other using hostnames.</li>\n<li>When a Kubernetes service is created, a DNS record is automatically generated for it.</li>\n<li>Kubernetes supports ExternalDNS, which helps manage DNS records for services that need to be accessible outside the cluster.</li>\n</ul>\n<h3 id=\"externaldns\" style=\"position:relative;\"><a href=\"#externaldns\" aria-label=\"externaldns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ExternalDNS</h3>\n<p>In short, <strong>ExternalDNS</strong> is a pod running in your EKS cluster that watches over all your ingresses. When it detects an ingress with a host specified, it automatically picks up the hostname as well as the endpoint and creates a record for that resource in <a href=\"https://aws.amazon.com/route53/\" target=\"_blank\" rel=\"noopener noreferrer\">Route53</a>. If the host is changed or deleted, ExternalDNS will reflect the change immediately in Route53.</p>\n<p>This system allows for automatically creating and managing DNS records for services exposed externally with the supported DNS providers. It enables external clients to access the services running inside the cluster by resolving the service's hostname to the external IP address of the Kubernetes cluster.</p>\n<h3 id=\"coredns\" style=\"position:relative;\"><a href=\"#coredns\" aria-label=\"coredns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>CoreDNS</h3>\n<p>This is a DNS server explicitly built for Kubernetes and is now the default DNS server in Kubernetes 1.14 and later. <strong>CoreDNS</strong> is a flexible, extensible DNS server that can perform service discovery and name resolution within the cluster, and with some configuration changes, it can leverage external DNS providers.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 6.470588235294117%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAABCAYAAADeko4lAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAQklEQVR42h2MMQ4AIQjA7v/fhIhRlEFN3HrBoWmnfmaGquLuzDmfExGh1sq9l4h4ZLfWKKUwxmDvzTmHtRb56b3zA+NTS3Dqu3z3AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"CoreDNS\" title=\"\" src=\"/static/e0e1e0f7b24457d00cbc355c32ad765f/c5bb3/coreDNS.png\" srcset=\"/static/e0e1e0f7b24457d00cbc355c32ad765f/04472/coreDNS.png 170w,\n/static/e0e1e0f7b24457d00cbc355c32ad765f/9f933/coreDNS.png 340w,\n/static/e0e1e0f7b24457d00cbc355c32ad765f/c5bb3/coreDNS.png 680w,\n/static/e0e1e0f7b24457d00cbc355c32ad765f/b12f7/coreDNS.png 1020w,\n/static/e0e1e0f7b24457d00cbc355c32ad765f/b5a09/coreDNS.png 1360w,\n/static/e0e1e0f7b24457d00cbc355c32ad765f/f4b34/coreDNS.png 1457w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 31.176470588235293%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA0UlEQVR42p2RxwrEMAxE/f+fl0I66YU0QkglZZYRBHLYw7IDxrIlP49ldd83kiSBYRiwbRuWZcE0TQRBANd1kec51nVFGIZSwzzr+r7HMAxwHAe6rkttFEVQy7JIkKapgDzPk0NxHCPLMvi+LxcyT6imaei6Dk3TSJ5Arud5BlmKm7yhbVvZ3LYN1HVdMtMdC8uyFBcchBOy7zuO48BbqqoqcUj7FFvw6B3XdS3OOYqiwHme+CaFH0QXBLKffD7797zkL+A0TdI/uns+YBzHr8APQgTHXGnqICgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Ingress\" title=\"\" src=\"/static/a652aaa19f4b64fab1dbfd4628f736c0/c5bb3/ingress.png\" srcset=\"/static/a652aaa19f4b64fab1dbfd4628f736c0/04472/ingress.png 170w,\n/static/a652aaa19f4b64fab1dbfd4628f736c0/9f933/ingress.png 340w,\n/static/a652aaa19f4b64fab1dbfd4628f736c0/c5bb3/ingress.png 680w,\n/static/a652aaa19f4b64fab1dbfd4628f736c0/b12f7/ingress.png 1020w,\n/static/a652aaa19f4b64fab1dbfd4628f736c0/b5a09/ingress.png 1360w,\n/static/a652aaa19f4b64fab1dbfd4628f736c0/29007/ingress.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"why-externaldns-is-a-valuable-addition-to-k8s-cluster\" style=\"position:relative;\"><a href=\"#why-externaldns-is-a-valuable-addition-to-k8s-cluster\" aria-label=\"why externaldns is a valuable addition to k8s cluster permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Why ExternalDNS is a Valuable Addition to K8s Cluster</h3>\n<p>Kubernetes's built-in DNS system, known as Kube-DNS or CoreDNS, is responsible for resolving DNS names for Kubernetes services and pods within a cluster. However, organizations often opt for an external DNS system due to several advantages:</p>\n<ul>\n<li><strong>Advanced features</strong>: External DNS systems offer additional functionalities such as global load balancing, automatic failover, and DNS-based traffic management. They also include built-in security features like DNSSEC to protect against tampering and spoofing attacks, which are crucial for organizations managing traffic across multiple regions, handling high traffic loads, or managing sensitive data.</li>\n<li><strong>Consistent DNS infrastructure</strong>: An external DNS system allows organizations to maintain a consistent DNS infrastructure across all their applications, whether running on Kubernetes or not. This simplifies management and enhances security.</li>\n<li><strong>Granular control</strong>: External DNS provides granular and dynamic control over DNS records or text instructions stored on DNS servers. Its primary role is to act as a bridge, enabling the use of specialized DNS providers outside of Kubernetes. External DNS can handle millions of DNS records and offer more options for managing them.</li>\n<li><strong>Scalability</strong>: As the number of services and pods within a Kubernetes cluster grows, the Kube-DNS system can become a bottleneck. An external DNS system can handle a much larger number of DNS queries, ensuring that the DNS system does not become a bottleneck for the rest of the cluster.</li>\n<li><strong>Flexibility</strong>: Using External DNS with Kubernetes offers greater flexibility in the choice of DNS server types. Depending on your requirements and preferences, you can select from various open-source DNS options like CoreDNS, SkyDNS, or Knot DNS, as well as commercial DNS solutions such as <a href=\"https://cloud.google.com/dns\" target=\"_blank\" rel=\"noopener noreferrer\">Google Cloud DNS</a>, <a href=\"https://aws.amazon.com/route53/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Route 53</a>, BIND, or Microsoft DNS.</li>\n</ul>\n<p>Integrating an external DNS system with Kubernetes provides organizations with a more advanced and flexible DNS infrastructure and management. It is a recommended practice to use an external DNS when deploying Kubernetes in production, as several popular external DNS providers can work with Kubernetes.</p>\n<h2 id=\"set-up-externaldns-in-the-eks-cluster\" style=\"position:relative;\"><a href=\"#set-up-externaldns-in-the-eks-cluster\" aria-label=\"set up externaldns in the eks cluster permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Set up ExternalDNS in the EKS Cluster</h2>\n<p>The setup can be divided into two parts: setting up permissions (to give your service access to Route53) and deploying the ExternalDNS.</p>\n<h3 id=\"Ô∏è-setting-up-route53-permissions-for-your-externaldns\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-setting-up-route53-permissions-for-your-externaldns\" aria-label=\"Ô∏è setting up route53 permissions for your externaldns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Setting up Route53 Permissions for Your ExternalDNS</h3>\n<p>In this tutorial, we will make use of an IAM role with an ID provider.</p>\n<p>The main idea here is to give the ExternalDNS pod the permission to create, update, and delete Route53 records in your AWS account. To do so, we need to use an identity provider in the AWS IAM service. An identity provider allows an external user to assume roles in your AWS account by setting up a trust relationship.</p>\n<h4 id=\"setting-up-the-identity-provider\" style=\"position:relative;\"><a href=\"#setting-up-the-identity-provider\" aria-label=\"setting up the identity provider permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Setting up the Identity Provider</h4>\n<p>To create an identity provider, you need three things: a type of identity provider, an audience, and a provider URL.</p>\n<p>In this tutorial, we will use OpenID Connect for the provider type and <code class=\"language-text\">sts.amazonaws.com</code> for the audience. The provider URL varies; to get your provider URL, you can use the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">aws eks describe-cluster <span class=\"token parameter variable\">--name</span> <span class=\"token operator\">&lt;</span>CLUSTER_NAME<span class=\"token operator\">></span> <span class=\"token parameter variable\">--query</span> <span class=\"token string\">\"cluster.identity.oidc.issuer\"</span> <span class=\"token parameter variable\">--output</span> text</code></pre></div>\n<p>The output should look something like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">https://oidc.eks.<span class=\"token operator\">&lt;</span>region<span class=\"token operator\">></span>.amazonaws.com/id/EXAMPLE86F27C29EF05B482628D9790EA7066.</code></pre></div>\n<p>You now have everything you need to set up your identity provider! Head over to <a href=\"https://console.aws.amazon.com/iam/home?#/providers\" target=\"_blank\" rel=\"noopener noreferrer\">the identity provider section of IAM in the AWS console</a> and create a new provider.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 32.35294117647059%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAqUlEQVR42oWPwQ6DIBBE+f+v1GoKB6qsgKJi6YskjUmbdg5kYfftDGrfd+fcNE3e+5xzKeU4DmNM0zT3UxS0yjeplBKwiMAvy1Jhamut1hqM7TFGWhRsf16kGN22jcZ7H6+cIYQKex/a9tZ1/TAMuFwn1WeYCq/rKuLIJTFp64x1nL15iA/V/xeMCD/PM4FHJ3j6ELnwBcL+h5nDH348xS7+wiPOJMo5vwBhplypyjgd9wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"OIDC\" title=\"\" src=\"/static/34936790f09c523d255f1f0fc78c5f49/c5bb3/oidc.png\" srcset=\"/static/34936790f09c523d255f1f0fc78c5f49/04472/oidc.png 170w,\n/static/34936790f09c523d255f1f0fc78c5f49/9f933/oidc.png 340w,\n/static/34936790f09c523d255f1f0fc78c5f49/c5bb3/oidc.png 680w,\n/static/34936790f09c523d255f1f0fc78c5f49/b12f7/oidc.png 1020w,\n/static/34936790f09c523d255f1f0fc78c5f49/b5a09/oidc.png 1360w,\n/static/34936790f09c523d255f1f0fc78c5f49/29007/oidc.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Now that you have an identity provider, all that's left to do is create an IAM role with Route53 permissions and a trust relationship with your brand-new provider.</p>\n<p>First, create a new role in IAM and trust your provider by selecting Web Identity and inputting your provider information.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 28.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAxklEQVR42o1Pyw6CMBDk/7/Imz9gYsKJmKggRKGlD/sEQ6lTEK86h8nsbmc7m+kF0zTFX5jnuDvcjRvDlBBCyAghlFLOedu2jDG0tqcfQId5Rh9amhdccSuTGR5r7TiOSqnnAimld66iPi/FqWpvRBMTmdSC94iZpt5jaVbXNfxCCJgh1rLrOsHZ8cz3+aOoaNGIC/Fl01XlFT8hI/wptlD41WIT2Dn3FalrjTVGJ7JK63UKHoYBM5ydEdrjYJyNlWBkjn/jDS3hV9id1U80AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Identity\" title=\"\" src=\"/static/2d236f25f2462608816e93ad54578c8f/c5bb3/identity.png\" srcset=\"/static/2d236f25f2462608816e93ad54578c8f/04472/identity.png 170w,\n/static/2d236f25f2462608816e93ad54578c8f/9f933/identity.png 340w,\n/static/2d236f25f2462608816e93ad54578c8f/c5bb3/identity.png 680w,\n/static/2d236f25f2462608816e93ad54578c8f/b12f7/identity.png 1020w,\n/static/2d236f25f2462608816e93ad54578c8f/b5a09/identity.png 1360w,\n/static/2d236f25f2462608816e93ad54578c8f/29007/identity.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Once this has been completed, click create a new policy and input the following in JSON:</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"Version\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"2012-10-17\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"Statement\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">\"Effect\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Allow\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"Action\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">\"route53:ChangeResourceRecordSets\"</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"Resource\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">\"arn:aws:route53:::hostedzone/*\"</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">\"Effect\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Allow\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"Action\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">\"route53:ListHostedZones\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"route53:ListResourceRecordSets\"</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"Resource\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">\"*\"</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>Then attach the <a href=\"https://console.aws.amazon.com/iam/home?region=eu-west-3#/policies/arn%3Aaws%3Aiam%3A%3Aaws%3Apolicy%2FAmazonEKSClusterPolicy\" target=\"_blank\" rel=\"noopener noreferrer\">AmazonEKSClusterPolicy</a> to the role as well.</p>\n<p>Once the role is created, keep the ARN; you will need it later.</p>\n<h3 id=\"-installing-the-externaldns\" style=\"position:relative;\"><a href=\"#-installing-the-externaldns\" aria-label=\" installing the externaldns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Installing the ExternalDNS</h3>\n<p>We will install the ExternalDNS using Helm. If you do not have Helm installed on your machine, you can find instructions to <a href=\"https://helm.sh/docs/intro/install/\" target=\"_blank\" rel=\"noopener noreferrer\">install Helm</a>.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm <span class=\"token function\">install</span> <span class=\"token operator\">&lt;</span>RELEASE_NAME<span class=\"token operator\">></span> stable/external-dns <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">provider</span><span class=\"token operator\">=</span>aws <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> domainFilters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>DOMAIN_FILTER<span class=\"token operator\">></span><span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">policy</span><span class=\"token operator\">=</span>sync <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">registry</span><span class=\"token operator\">=</span>txt <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">txtOwnerId</span><span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>HOSTED_ZONE_ID<span class=\"token operator\">></span> <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">interval</span><span class=\"token operator\">=</span>3m <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">rbac.create</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">rbac.serviceAccountName</span><span class=\"token operator\">=</span>external-dns <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--set</span> rbac.serviceAccountAnnotations.eks<span class=\"token punctuation\">\\</span>.amazonaws<span class=\"token punctuation\">\\</span>.com/role-arn<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>ROLE_ARN<span class=\"token operator\">></span></code></pre></div>\n<p>Where:</p>\n<ul>\n<li><code class=\"language-text\">RELEASE_NAME</code>: Name of the Helm release, can be anything you want (e.g., <code class=\"language-text\">external-dns</code>).</li>\n<li><code class=\"language-text\">DOMAIN_FILTER</code>: Name of your Route53 hosted zone. If <code class=\"language-text\">*.example.com</code>, it would be <code class=\"language-text\">example.com</code>. You can find information about the domain filter in the AWS console (Route53).</li>\n<li><code class=\"language-text\">HOSTED_ZONE_ID</code>: ID of your hosted zone in AWS. You can find this information in the AWS console (Route53).</li>\n<li><code class=\"language-text\">ROLE_ARN</code>: ARN of the role you created earlier in the tutorial.</li>\n</ul>\n<h3 id=\"-using-the-externaldns\" style=\"position:relative;\"><a href=\"#-using-the-externaldns\" aria-label=\" using the externaldns permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üåê Using the ExternalDNS</h3>\n<p>To create a new Route53 record for your services, all you need to do is add the annotation: <code class=\"language-text\">external-dns.alpha.kubernetes.io/hostname</code>.</p>\n<h4 id=\"example-of-a-loadbalancer-service\" style=\"position:relative;\"><a href=\"#example-of-a-loadbalancer-service\" aria-label=\"example of a loadbalancer service permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Example of a LoadBalancer Service:</h4>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Service\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> test\n    <span class=\"token key atrule\">annotations</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">external-dns.alpha.kubernetes.io/hostname</span><span class=\"token punctuation\">:</span> myservice.example.com \n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> LoadBalancer\n    <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token number\">80</span>\n        <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> http\n        <span class=\"token key atrule\">targetPort</span><span class=\"token punctuation\">:</span> <span class=\"token number\">80</span>\n    <span class=\"token key atrule\">selector</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">app</span><span class=\"token punctuation\">:</span> test</code></pre></div>\n<h4 id=\"for-an-ingress\" style=\"position:relative;\"><a href=\"#for-an-ingress\" aria-label=\"for an ingress permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>For an Ingress:</h4>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> extensions/v1beta1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Ingress\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">annotations</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">alb.ingress.kubernetes.io/scheme</span><span class=\"token punctuation\">:</span> internet<span class=\"token punctuation\">-</span>facing\n        <span class=\"token key atrule\">external-dns.alpha.kubernetes.io/hostname</span><span class=\"token punctuation\">:</span> myservice.example.com \n        <span class=\"token key atrule\">kubernetes.io/ingress.class</span><span class=\"token punctuation\">:</span> alb\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> test\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">http</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">paths</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">backend</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token key atrule\">serviceName</span><span class=\"token punctuation\">:</span> test\n                    <span class=\"token key atrule\">servicePort</span><span class=\"token punctuation\">:</span> <span class=\"token number\">80</span>\n                <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> /</code></pre></div>\n<h2 id=\"-summary\" style=\"position:relative;\"><a href=\"#-summary\" aria-label=\" summary permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìå Summary</h2>\n<p>The Kubernetes DNS system, CoreDNS, and ExternalDNS enable seamless communication within clusters. They create DNS records for Services and Pods, allowing consistent access via DNS names instead of IP addresses. Understanding and customizing DNS resolution is crucial for effective management within a Kubernetes cluster.</p>\n<hr>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":6,"rawMarkdownBody":"\n> **The ABCs of Kubernetes DNS üê≥**\n\n## üî• Introduction\n\nKubernetes, an open-source platform for automating containerized applications, relies on Domain Name System (DNS) to facilitate communication between its various components. Two essential tools for managing DNS within a Kubernetes cluster are **CoreDNS** and **ExternalDNS**. In this blog post, we will take a straightforward look at these tools, their functions, and how they can benefit your Kubernetes environment.\n\n## üï∏ How CoreDNS and ExternalDNS Work\n\nKubernetes relies on the Domain Name System (DNS) to enable seamless communication between its various components, such as pods and services. When a new Kubernetes service is created, the platform automatically generates a DNS record for it, allowing other pods to easily locate and connect to the service. Kubernetes also offers support for **ExternalDNS**, which simplifies the process of creating and managing DNS records for services that need to be accessible externally. This makes it easier for external clients to access the services within the cluster.\n\nIn simpler terms:\n\n- Kubernetes uses DNS to help pods and services find and communicate with each other using hostnames.\n- When a Kubernetes service is created, a DNS record is automatically generated for it.\n- Kubernetes supports ExternalDNS, which helps manage DNS records for services that need to be accessible outside the cluster.\n\n### ExternalDNS\n\nIn short, **ExternalDNS** is a pod running in your EKS cluster that watches over all your ingresses. When it detects an ingress with a host specified, it automatically picks up the hostname as well as the endpoint and creates a record for that resource in [Route53](https://aws.amazon.com/route53/). If the host is changed or deleted, ExternalDNS will reflect the change immediately in Route53.\n\nThis system allows for automatically creating and managing DNS records for services exposed externally with the supported DNS providers. It enables external clients to access the services running inside the cluster by resolving the service's hostname to the external IP address of the Kubernetes cluster.\n\n### CoreDNS\n\nThis is a DNS server explicitly built for Kubernetes and is now the default DNS server in Kubernetes 1.14 and later. **CoreDNS** is a flexible, extensible DNS server that can perform service discovery and name resolution within the cluster, and with some configuration changes, it can leverage external DNS providers.\n\n![CoreDNS](./coreDNS.png)\n\n![Ingress](./ingress.png)\n\n### Why ExternalDNS is a Valuable Addition to K8s Cluster\n\nKubernetes's built-in DNS system, known as Kube-DNS or CoreDNS, is responsible for resolving DNS names for Kubernetes services and pods within a cluster. However, organizations often opt for an external DNS system due to several advantages:\n\n- **Advanced features**: External DNS systems offer additional functionalities such as global load balancing, automatic failover, and DNS-based traffic management. They also include built-in security features like DNSSEC to protect against tampering and spoofing attacks, which are crucial for organizations managing traffic across multiple regions, handling high traffic loads, or managing sensitive data.\n- **Consistent DNS infrastructure**: An external DNS system allows organizations to maintain a consistent DNS infrastructure across all their applications, whether running on Kubernetes or not. This simplifies management and enhances security.\n- **Granular control**: External DNS provides granular and dynamic control over DNS records or text instructions stored on DNS servers. Its primary role is to act as a bridge, enabling the use of specialized DNS providers outside of Kubernetes. External DNS can handle millions of DNS records and offer more options for managing them.\n- **Scalability**: As the number of services and pods within a Kubernetes cluster grows, the Kube-DNS system can become a bottleneck. An external DNS system can handle a much larger number of DNS queries, ensuring that the DNS system does not become a bottleneck for the rest of the cluster.\n- **Flexibility**: Using External DNS with Kubernetes offers greater flexibility in the choice of DNS server types. Depending on your requirements and preferences, you can select from various open-source DNS options like CoreDNS, SkyDNS, or Knot DNS, as well as commercial DNS solutions such as [Google Cloud DNS](https://cloud.google.com/dns), [Amazon Route 53](https://aws.amazon.com/route53/), BIND, or Microsoft DNS.\n\nIntegrating an external DNS system with Kubernetes provides organizations with a more advanced and flexible DNS infrastructure and management. It is a recommended practice to use an external DNS when deploying Kubernetes in production, as several popular external DNS providers can work with Kubernetes.\n\n## Set up ExternalDNS in the EKS Cluster\n\nThe setup can be divided into two parts: setting up permissions (to give your service access to Route53) and deploying the ExternalDNS.\n\n### üõ†Ô∏è Setting up Route53 Permissions for Your ExternalDNS\n\nIn this tutorial, we will make use of an IAM role with an ID provider.\n\nThe main idea here is to give the ExternalDNS pod the permission to create, update, and delete Route53 records in your AWS account. To do so, we need to use an identity provider in the AWS IAM service. An identity provider allows an external user to assume roles in your AWS account by setting up a trust relationship.\n\n#### Setting up the Identity Provider\n\nTo create an identity provider, you need three things: a type of identity provider, an audience, and a provider URL.\n\nIn this tutorial, we will use OpenID Connect for the provider type and `sts.amazonaws.com` for the audience. The provider URL varies; to get your provider URL, you can use the following command:\n\n```shell\naws eks describe-cluster --name <CLUSTER_NAME> --query \"cluster.identity.oidc.issuer\" --output text\n```\n\nThe output should look something like this:\n\n```shell\nhttps://oidc.eks.<region>.amazonaws.com/id/EXAMPLE86F27C29EF05B482628D9790EA7066.\n```\n\nYou now have everything you need to set up your identity provider! Head over to [the identity provider section of IAM in the AWS console](https://console.aws.amazon.com/iam/home?#/providers) and create a new provider.\n\n![OIDC](./oidc.png)\n\nNow that you have an identity provider, all that's left to do is create an IAM role with Route53 permissions and a trust relationship with your brand-new provider.\n\nFirst, create a new role in IAM and trust your provider by selecting Web Identity and inputting your provider information.\n\n![Identity](./identity.png)\n\nOnce this has been completed, click create a new policy and input the following in JSON:\n\n```json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"route53:ChangeResourceRecordSets\"\n            ],\n            \"Resource\": [\n                \"arn:aws:route53:::hostedzone/*\"\n            ]\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"route53:ListHostedZones\",\n                \"route53:ListResourceRecordSets\"\n            ],\n            \"Resource\": [\n                \"*\"\n            ]\n        }\n    ]\n}\n```\n\nThen attach the [AmazonEKSClusterPolicy](https://console.aws.amazon.com/iam/home?region=eu-west-3#/policies/arn%3Aaws%3Aiam%3A%3Aaws%3Apolicy%2FAmazonEKSClusterPolicy) to the role as well.\n\nOnce the role is created, keep the ARN; you will need it later.\n\n### üöÄ Installing the ExternalDNS\n\nWe will install the ExternalDNS using Helm. If you do not have Helm installed on your machine, you can find instructions to [install Helm](https://helm.sh/docs/intro/install/).\n\n```shell\nhelm install <RELEASE_NAME> stable/external-dns \\\n--set provider=aws \\\n--set domainFilters[0]=<DOMAIN_FILTER>\\\n--set policy=sync \\\n--set registry=txt \\\n--set txtOwnerId=<HOSTED_ZONE_ID> \\\n--set interval=3m \\\n--set rbac.create=true \\\n--set rbac.serviceAccountName=external-dns \\\n--set rbac.serviceAccountAnnotations.eks\\.amazonaws\\.com/role-arn=<ROLE_ARN>\n```\n\nWhere:\n\n- `RELEASE_NAME`: Name of the Helm release, can be anything you want (e.g., `external-dns`).\n- `DOMAIN_FILTER`: Name of your Route53 hosted zone. If `*.example.com`, it would be `example.com`. You can find information about the domain filter in the AWS console (Route53).\n- `HOSTED_ZONE_ID`: ID of your hosted zone in AWS. You can find this information in the AWS console (Route53).\n- `ROLE_ARN`: ARN of the role you created earlier in the tutorial.\n\n### üåê Using the ExternalDNS\n\nTo create a new Route53 record for your services, all you need to do is add the annotation: `external-dns.alpha.kubernetes.io/hostname`.\n\n#### Example of a LoadBalancer Service:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n    name: test\n    annotations:\n        external-dns.alpha.kubernetes.io/hostname: myservice.example.com \nspec:\n    type: LoadBalancer\n    ports:\n    - port: 80\n        name: http\n        targetPort: 80\n    selector:\n        app: test\n```\n\n#### For an Ingress:\n\n```yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n    annotations:\n        alb.ingress.kubernetes.io/scheme: internet-facing\n        external-dns.alpha.kubernetes.io/hostname: myservice.example.com \n        kubernetes.io/ingress.class: alb\n    name: test\nspec:\n    rules:\n    - http:\n            paths:\n            - backend:\n                    serviceName: test\n                    servicePort: 80\n                path: /\n```\n\n## üìå Summary\n\nThe Kubernetes DNS system, CoreDNS, and ExternalDNS enable seamless communication within clusters. They create DNS records for Services and Pods, allowing consistent access via DNS names instead of IP addresses. Understanding and customizing DNS resolution is crucial for effective management within a Kubernetes cluster.\n\n---\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1217},"frontmatter":{"id":"312a65d89f3184da8828a9f5","path":"/blog/kubernetes-dns-coredns-externaldns/","humanDate":"Oct 29, 2024","fullDate":"2024-10-29","title":"Kubernetes & DNS: A Guide to CoreDNS and ExternalDNS in AWS EKS clusterüê≥","keywords":["Kubernetes","DNS","CoreDNS","ExternalDNS","k8s","DevOps","AWS EKS","AWS"],"excerpt":"Dive into the essentials of Kubernetes DNS with this guide on CoreDNS and ExternalDNS, covering the basics and advanced configuration in AWS EKS cluster.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAgAD/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAWC5cqiv/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAECEQMSIf/aAAgBAQABBQKSsrjRjk92Wf/EABYRAQEBAAAAAAAAAAAAAAAAAAABIf/aAAgBAwEBPwGNf//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAECAQE/AWf/xAAbEAABBAMAAAAAAAAAAAAAAAABAAIQESExgf/aAAgBAQAGPwK27jDbXQiI/8QAGxAAAgIDAQAAAAAAAAAAAAAAAREAITFBUYH/2gAIAQEAAT8hEyFoy6FDol408mNBoQT07Ad2Z//aAAwDAQACAAMAAAAQ3N//xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQMBAT8QW4QT/8QAFhEBAQEAAAAAAAAAAAAAAAAAAREA/9oACAECAQE/EHC6m//EABwQAQEAAgIDAAAAAAAAAAAAAAERACExQVFhcf/aAAgBAQABPxCnIDTUF837gzCisFTbtmMdAKCtyZwCNbRvLy8d4IAYxv2xLSRm3P/Z"},"images":{"fallback":{"src":"/static/cad30f55e5f5b2778695783477cc7ffd/c07d5/kubernetes-dns-cover.jpg","srcSet":"/static/cad30f55e5f5b2778695783477cc7ffd/7284f/kubernetes-dns-cover.jpg 750w,\n/static/cad30f55e5f5b2778695783477cc7ffd/29ba9/kubernetes-dns-cover.jpg 1080w,\n/static/cad30f55e5f5b2778695783477cc7ffd/2baac/kubernetes-dns-cover.jpg 1366w,\n/static/cad30f55e5f5b2778695783477cc7ffd/c07d5/kubernetes-dns-cover.jpg 1400w","sizes":"100vw"},"sources":[{"srcSet":"/static/cad30f55e5f5b2778695783477cc7ffd/57584/kubernetes-dns-cover.webp 750w,\n/static/cad30f55e5f5b2778695783477cc7ffd/984df/kubernetes-dns-cover.webp 1080w,\n/static/cad30f55e5f5b2778695783477cc7ffd/1e947/kubernetes-dns-cover.webp 1366w,\n/static/cad30f55e5f5b2778695783477cc7ffd/67855/kubernetes-dns-cover.webp 1400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6664285714285714}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/container-runtimes-cri-overview/","title":"Container Runtimes and CRI: A Technical Overview üõ†Ô∏è","date":"2024-10-29 19:06:00"},"excerpt":"A Deep Dive into the Evolution Overview üëÄ Containerization technologies have revolutionized the way we build, deploy, and manage‚Ä¶","html":"<blockquote>\n<p><strong>A Deep Dive into the Evolution</strong></p>\n</blockquote>\n<h2 id=\"overview-\" style=\"position:relative;\"><a href=\"#overview-\" aria-label=\"overview  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Overview üëÄ</h2>\n<p>Containerization technologies have revolutionized the way we build, deploy, and manage applications. Docker, Kubernetes, and other popular containerization tools have made it possible to deliver applications more quickly, reliably, and efficiently than ever before.</p>\n<p>At the heart of containerization technology are a number of building blocks, including container runtimes and the Container Runtime Interface (CRI).</p>\n<p>Container runtimes are responsible for creating, running, and managing containers. They provide a layer of abstraction between the host operating system and the container, allowing containers to be isolated from each other and from the host.</p>\n<p>The CRI is a standard interface that allows different container runtimes to be used with Kubernetes. This makes it easier to switch between different container runtimes without having to make major changes to Kubernetes.</p>\n<p>In this blog post, we will explore the evolution of container runtimes and the CRI in more detail.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 25.294117647058822%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABMklEQVR42lWPbUvCYBSG/fuBFAR+C6wPISQEQW+gIykyTcnM0nRTtz068WVuc2vO1K4ee4E6cHHf53C4DydmjTziOwnOLhVq6gDNGErG6P0JotPF7hm0NRMhhviuw5Nhc9qdsxAartBRBxGvqk6hkMdxHGKzIGI7vsXtTQ7D8hjbHp4/5y1cUK3VMTptBiOHnjVEbeoYPQtVCCzTxOoPaLZHCF16q08YhsROsmWSaYW91BW7ySyJA0Vqhv3jIrnzC57vrjFlYEvTUTIlavUGZXk83/N5sBzEi0a/a9AwTOabwKN0i8NUg0q9Q7HSplTtcP/4rdPJhND3cF2Xmecxm/nSe9j2VH4Q4gcBU9vGkfMNURQRyysBxVwAfLBe86+WqxXvy+WXLjf6w+pP/+tXks3uJyyTap9qsOK2AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cris\" title=\"\" src=\"/static/046aac5d02b575e8156934d91d50b016/c5bb3/cris.png\" srcset=\"/static/046aac5d02b575e8156934d91d50b016/04472/cris.png 170w,\n/static/046aac5d02b575e8156934d91d50b016/9f933/cris.png 340w,\n/static/046aac5d02b575e8156934d91d50b016/c5bb3/cris.png 680w,\n/static/046aac5d02b575e8156934d91d50b016/b12f7/cris.png 1020w,\n/static/046aac5d02b575e8156934d91d50b016/b5a09/cris.png 1360w,\n/static/046aac5d02b575e8156934d91d50b016/aa440/cris.png 1500w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\"><a href=\"https://landscape.cncf.io/guide#runtime--container-runtime\">Source</a></div>\n<p>Now, welcome to the world of containers!</p>\n<p>Lots of applications can run containers, whereas every application would have a slightly different opinion about what a container runtime should do and support. For example, systemd is able to run containers via <a href=\"https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html\" target=\"_blank\" rel=\"noopener noreferrer\">systemd-nspawn</a>, and <a href=\"https://nixos.org/\" target=\"_blank\" rel=\"noopener noreferrer\">NixOS</a> has integrated <a href=\"https://nixos.org/nixos/manual/#ch-containers\" target=\"_blank\" rel=\"noopener noreferrer\">container management</a> as well. Not to mention all the other existing container runtimes like <a href=\"https://cri-o.io/\" target=\"_blank\" rel=\"noopener noreferrer\">CRI-O</a>, <a href=\"https://katacontainers.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Kata Containers</a>, <a href=\"https://firecracker-microvm.github.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Firecracker</a>, <a href=\"https://github.com/google/gvisor\" target=\"_blank\" rel=\"noopener noreferrer\">gVisor</a>, <a href=\"https://containerd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">containerd</a>, <a href=\"https://linuxcontainers.org/\" target=\"_blank\" rel=\"noopener noreferrer\">LXC</a>, <a href=\"https://github.com/opencontainers/runc\" target=\"_blank\" rel=\"noopener noreferrer\">runc</a>, <a href=\"https://nabla-containers.github.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Nabla Containers</a> and many more.</p>\n<p>A lot of them are now part of the <a href=\"https://www.cncf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Cloud Native Computing Foundation (CNCF)</a> and their <a href=\"https://landscape.cncf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">huge landscape</a>.</p>\n<h2 id=\"a-brief-history-\" style=\"position:relative;\"><a href=\"#a-brief-history-\" aria-label=\"a brief history  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>A Brief History üìú</h2>\n<p>After the invention of cgroups back in 2008, a project called Linux Containers (LXC) started to pop up in the wild, which should revolutionize the container world. LXC combined cgroup and namespace technologies to provide an isolated environment for running applications. You may know that we sometimes live in a parallel world. This means that Google started its own containerization project in 2007 called <a href=\"https://github.com/google/lmctfy\" target=\"_blank\" rel=\"noopener noreferrer\">Let Me Contain That For You (LMCTFY)</a>, which works mainly at the same level as LXC does. With LMCTFY, Google tried to provide a stable and API-driven configuration without users having to understand the details of cgroups and its internals.</p>\n<p>If we now look back into 2013, we see that there was a tool written called Docker, which was built on top of the already existing LXC stack. One invention of Docker was that the user is now able to package containers into images to move them between machines. Docker were the first ones who tried to make containers a standard software unit, as they state in their <a href=\"https://github.com/moby/moby/blob/0db56e6c519b19ec16c6fbd12e3cee7dfa6018c5/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">¬´Standard Container Manifesto¬ª</a>.</p>\n<p>Some years later, they began to work on <a href=\"https://github.com/docker/libcontainer\" target=\"_blank\" rel=\"noopener noreferrer\">libcontainer</a>, a <a href=\"https://golang.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Go</a> native way to spawn and manage containers. LMCTFY was abandoned during that time too, whereas the core concepts and major benefits of LMCTFY were ported into libcontainer and Docker.</p>\n<p>We are now back in 2015, where projects like Kubernetes hit version 1.0. A lot of stuff was ongoing during that time: The CNCF was founded as part of the <a href=\"https://www.linuxfoundation.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Linux Foundation</a> with the target to promote containers. The <a href=\"https://www.opencontainers.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Open Container Initiative (OCI)</a> was founded in 2015 as well, as an open governance structure around the container ecosystem.</p>\n<h2 id=\"open-container-initiative-oci-Ô∏è\" style=\"position:relative;\"><a href=\"#open-container-initiative-oci-%EF%B8%8F\" aria-label=\"open container initiative oci Ô∏è permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Open Container Initiative (OCI) üõ†Ô∏è</h2>\n<p>OCI, short for the Open Container Initiative, is indeed a community project that was established in 2015 to address the need for containerization standards. It is a collaborative effort within the container ecosystem to develop open industry standards for container formats and runtime. The OCI's primary goal is to ensure interoperability between container technologies, making it easier to create and run containerized applications across different platforms and container runtimes.</p>\n<p><strong>Key points about OCI include:</strong></p>\n<ul>\n<li><strong>Standardization:</strong> OCI defines open standards for container images and runtimes. This includes the OCI Image Format specification for container images and the OCI Runtime Specification for container runtimes.</li>\n<li><strong>Interoperability:</strong> By adhering to OCI specifications, container runtimes, and container images from various vendors can work seamlessly together. This promotes compatibility and flexibility in choosing containerization tools.</li>\n<li><strong>Ecosystem Benefits:</strong> OCI standards have been widely adopted in the container ecosystem. This adoption has led to the development of a rich ecosystem of container tools, orchestrators, and platforms that are OCI-compliant.</li>\n</ul>\n<p>On the other side of the container engine is the container runtime controlled through the Open Container Initiative specs. There are two specifications produced by the OCI: OCI-runtime and OCI-image. These specs work together to define how to start containers through the container runtime.</p>\n<p>The OCI runtime spec defines how to interact with a container runtime to control the lifecycle of a container. While it might seem redundant (given that CRI seems to define the same thing), it adds another layer of contract definition to the architecture. As with CRI, this layer of contract gives some guarantees to the system regarding how the developer's code will run.</p>\n<p>The container engine provides the runtime with a filesystem bundle (conforming to the OCI-image spec) to run. Within this filesystem bundle are all the files needed in the runtime and a configuration specifying what to run in the container (also known as its entrypoint).</p>\n<p>For some extremely dense reading, the specs can be found <a href=\"https://github.com/opencontainers/runtime-spec\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> and <a href=\"https://github.com/opencontainers/image-spec\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p>\n<p>If we give an example of OCI Runtime, a simple picture is to imagine a technology such as USB that many vendors produce, whether any version of PC or OS can use USB. That's because they follow USB standards, which OCI Runtime is a similar standard. Same thing, but only used with Container Runtimes.</p>\n<h3 id=\"what-is-container-runtime\" style=\"position:relative;\"><a href=\"#what-is-container-runtime\" aria-label=\"what is container runtime permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>What is Container Runtime?</h3>\n<p>Container runtimes are described as the software responsible for executing containerized applications. They take container images (which specify how an application should look) and launch applications within containers, providing them with the necessary resources.</p>\n<p><strong>Problem Addressed by Container Runtimes:</strong></p>\n<ul>\n<li><strong>Standardization:</strong> Container runtimes ensure that containerized applications are launched in a standardized manner across different environments.</li>\n<li><strong>Security:</strong> They establish security boundaries to prevent unauthorized access to containerized applications.</li>\n<li><strong>Isolation:</strong> They ensure isolation to protect applications from interfering with each other, even if one of them crashes.</li>\n<li><strong>Resource Allocation:</strong> They allocate and manage resources like CPU, storage, and memory for containerized applications.</li>\n</ul>\n<p><strong>How Container Runtimes Help:</strong></p>\n<ul>\n<li><strong>Standardization:</strong> Container runtimes launch applications in a consistent way, regardless of the environment, ensuring predictability.</li>\n<li><strong>Security:</strong> Some container runtimes, like CRI-O and gVisor (via \"runsc\"), emphasize security and harden the security boundaries.</li>\n<li><strong>Isolation:</strong> Container runtimes enforce isolation to prevent interference between applications.</li>\n<li><strong>Resource Allocation:</strong> They set resource limits to prevent one application from consuming all available resources, which could affect other applications.</li>\n</ul>\n<p><strong>Technical Overview:</strong></p>\n<p>Container runtimes vary in their capabilities and focus:</p>\n<ul>\n<li><a href=\"https://containerd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Containerd</a> and <a href=\"https://cri-o.io/\" target=\"_blank\" rel=\"noopener noreferrer\">CRI-O</a>: These are standard container runtime implementations.</li>\n<li><a href=\"https://katacontainers.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Kata</a>: Allows running containers as virtual machines (VMs), expanding the use of containers to other technologies.</li>\n<li><a href=\"https://gvisor.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">gVisor</a> (via runsc): Provides an additional security layer between containers and the host operating system, enhancing security.</li>\n<li><a href=\"https://github.com/opencontainers/runc\" target=\"_blank\" rel=\"noopener noreferrer\">runc</a>: runc is a separate container runtime associated with the Open Container Initiative (OCI) standard. It serves as the reference implementation of the OCI runtime specification and is used to run containers in a standardized way.</li>\n<li><a href=\"https://github.com/containers/crun\" target=\"_blank\" rel=\"noopener noreferrer\">crun</a>: A fast and lightweight fully featured OCI runtime and C library for running containers.</li>\n</ul>\n<p>The CRI interface is built on gRPC and Protobuf over a Unix socket. The spec can be found on <a href=\"https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/cri/runtime/v1alpha2/api.proto\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>.</p>\n<h2 id=\"putting-it-all-together-kubernetes-and-cri-\" style=\"position:relative;\"><a href=\"#putting-it-all-together-kubernetes-and-cri-\" aria-label=\"putting it all together kubernetes and cri  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Putting it all together: Kubernetes and CRI üöÄ</h2>\n<p>The CRI gives Kubernetes the flexibility to run a variety of container managers and container runtimes.</p>\n<p>In Kubernetes, a container runtime is responsible for managing the lifecycle of containers. It is the component that actually runs the container images and provides an interface between Kubernetes and the container.</p>\n<p>Kubernetes could use any container runtime that implements CRI to manage pods, containers, and container images. Docker is the most common container runtime used in production Kubernetes environments, but containerd (initiated by Docker Inc. &#x26; donated to CNCF in March of 2017) may prove to be a better option. For more details, you could refer to the <a href=\"https://kubernetes.io/blog/2017/11/containerd-container-runtime-options-kubernetes/\" target=\"_blank\" rel=\"noopener noreferrer\">official blog</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACGElEQVR42nVSy28SQRzm7+rBVIW6NB489Wg8mZjIQQ+2phJpU2NpYqymxCoLook9NOmBRAuilcfCJjTQXaBBU7CV5+6wFGaLwHZmHw6PEj345TfJ95vM93uOySDQjYVsYJqhr7PvZhM+64VRYTcV81DsWyoxNivrI89sB35V04jOZAwxn92dimzOxL1mxmNhPOYYfTVGm4Mu895rC0OTG0vcey3unWG8l2Luu9y/YgKknOu6PuIqVlWMxxxh4o44RkhT1YnEpOqDGO9PUpYvr2bD9HaJz7dFKrRpCbgec4GwWLgS3Jj++MKZ/waV3lzUR0Xc+80ykWi6btKG2b4KhQcJ/2LyU1Q8LndaDj5kTwc+FNPZdn0583mZC/qrhz2MXn5PrOajR2fSRDzInJa4peTTFW6Nb2aJ2zirAljtIqhoag5UMqAsdOU+7uVB7qiZxxoalz0SM8K+jbHfjswnASd2Jevuzcs7cwvsSlGWboTeTO04l9JB0AXPOXoj52spcLCiSeYfp8XF2Or9PUeqzhN3naNt4UehUnRQHtZwnxyNbNTQjb8xFnPS4Z34w1vhe8kGN5i8jokRkqwdONhnHn7rSXydzmytsS474/wp/xr3PIpxrqIyqAotETQBhFCGcqt52oFnYqeREvgSrBSk4zKs1n+LJ3Kli/vDn3WxZ9IARljpKUAQG1IDAFCr1epCXW7LqI+M/+APe2whY5M0R5AAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"kubelet\" title=\"\" src=\"/static/84d5d4c213fe186b062ae18bded93dae/c5bb3/kubelet.png\" srcset=\"/static/84d5d4c213fe186b062ae18bded93dae/04472/kubelet.png 170w,\n/static/84d5d4c213fe186b062ae18bded93dae/9f933/kubelet.png 340w,\n/static/84d5d4c213fe186b062ae18bded93dae/c5bb3/kubelet.png 680w,\n/static/84d5d4c213fe186b062ae18bded93dae/b12f7/kubelet.png 1020w,\n/static/84d5d4c213fe186b062ae18bded93dae/2bef9/kubelet.png 1024w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"docker-shim-deprecated-from-k8s-124-Ô∏è\" style=\"position:relative;\"><a href=\"#docker-shim-deprecated-from-k8s-124-%EF%B8%8F\" aria-label=\"docker shim deprecated from k8s 124 Ô∏è permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Docker Shim Deprecated from K8s 1.24 ‚ö†Ô∏è</h2>\n<p>In version 1.24, Kubernetes is no longer supported Docker as a container runtime. Docker is being phased out in favor of runtimes that use the Container Runtime Interface (CRI), which was built for Kubernetes. If you're a Kubernetes end-user, you won't notice much of a difference.</p>\n<p>This does not imply that Docker is dead, nor does it imply that you can't or shouldn't use it as a development tool. Docker is still a helpful tool for creating containers, and the images generated by the docker build may be used in your Kubernetes cluster.</p>\n<p>If you wish to create your cluster, you'll have to make certain adjustments to avoid cluster failure. As Docker will be deprecated from K8s 1.24, you'll have to transition to one of the other compatible container runtimes, such as containerd or CRI-O. Simply ensure that the runtime you select supports the current settings of the Docker daemon (such as logging).</p>\n<h3 id=\"demo-cri-o-and-k8s\" style=\"position:relative;\"><a href=\"#demo-cri-o-and-k8s\" aria-label=\"demo cri o and k8s permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Demo: CRI-O and K8s</h3>\n<p>CRI-O may pull from any container registry and supports OCI container images. It's a lightweight alternative as a Kubernetes runtime.</p>\n<p><strong>Features:</strong></p>\n<ul>\n<li>OCI compatible runtime</li>\n<li>containers/storage</li>\n<li>containers/image</li>\n<li>networking (CNI)</li>\n<li>container monitoring</li>\n<li>Several essential Linux functions support security</li>\n</ul>\n<p><strong>How does CRI-O work?</strong></p>\n<p>It is a Kubernetes CRI implementation that allows OCI-compatible runtimes to be used. It's a lighter alternative to using Docker as the runtime for Kubernetes. It enables Kubernetes to use any OCI-compliant container runtime for pod execution. It now supports runc and Kata Containers as container runtimes, and any OCI-compliant runtime can theoretically be plugged in.</p>\n<p><strong>Architecture:</strong></p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACm0lEQVR42l2Ra08TURCG+VHGRCSaEA2FUlqCpff7bne3e+l2u70X2tLSrb2BFIoogmCkKuonEROIiR/4S5jYeF5PSVRgksmZzEyeM+/M2Bi1s42MuZERUMyopFtfQlJmoQhhZDURqTgHNRaBLkehSQxSShTZhABVZKDTWBEZ0ipI+NpJzIz9tU+VsLnbNlDt75Fiu4d7NhdMfg4eJYNAMo+HiwGM29x4YPcjrBdhFzSYvCwm5t24M+cmnMDibF2b/Qc8bUnm5UKKNqrEGmAx7QmB1XPwxOJQqwb0ehNuQUE0VYCTV2ChPVKK1jkR0/4oSSZEnLSV/8DvVLIscZgNCcQlxPHY6UdQTcMrJsDnSnDQnMkdhFfSEIin4Iyp4CnQ6o9g0hUkCTV2G5g0J1QR1ohIFiICnrAiHi36YA1xMLmCuD9nx4TNgQmrA7YQjwVGhC3M05jDpJslHH9L8o+tjFmjQBsjE7+cxPGXU2zuH6K+0Uez/xLPdl/D6G2jReNRLlN7iv7BW5ycn6M7uCDNzjY+l9zXgHTCEdASjpHRZI3NHfiVFEKJNKR8ie4zDx/9yEWlysUK1OXa1T4ZLYv1vQGp10o4LjE3J1RkDsX2Bll7votXR++xtXcIH93Z3Zl5jFPJI5+i8h30KKP9juCjetroEIYN4ttNyUmzqvCQilVSanax/+4DXrw5gr5iIKDoYJJZBOkx5EIZWnkVeqWOWHYZxUYbRn+XKDJPj3INeLGTMauqBAujEDsXR+9ggFS9g3jZQLaxduVatQm91kKSvkJhBVyujFJnE2v7AyLJwq0r99JTRpofLuW0y3Yle7m9mv+ZjnO/CvnEUBbCQzbgHPIRL3XP1Sswvt8C44UU9UNTOGKkBXw0ZMsI9gcX2MQVCZvL7AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cri-o\" title=\"\" src=\"/static/39f8ccd779450831bdb5b49cdeab6430/c5bb3/cri-o.png\" srcset=\"/static/39f8ccd779450831bdb5b49cdeab6430/04472/cri-o.png 170w,\n/static/39f8ccd779450831bdb5b49cdeab6430/9f933/cri-o.png 340w,\n/static/39f8ccd779450831bdb5b49cdeab6430/c5bb3/cri-o.png 680w,\n/static/39f8ccd779450831bdb5b49cdeab6430/b12f7/cri-o.png 1020w,\n/static/39f8ccd779450831bdb5b49cdeab6430/b5a09/cri-o.png 1360w,\n/static/39f8ccd779450831bdb5b49cdeab6430/29007/cri-o.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>The following are the architectural elements:</p>\n<ul>\n<li>To deploy a pod, Kubernetes communicates with the kubelet.</li>\n<li>Pods are a Kubernetes notion that consists of one or more containers in the same cgroup that share the same IPC, NET, and PID namespaces.</li>\n<li>To launch a new pod, the kubelet sends a request to the CRI-O daemon using the Kubernetes CRI.</li>\n<li>CRI-O pulls the image from a container registry using the containers/image library.</li>\n<li>Using the containers/storage library, the downloaded image is unpacked into the container's root filesystems and stored in COW file systems.</li>\n<li>After the container's rootfs have been constructed, CRI-O creates an OCI runtime specification JSON file that describes how to use the OCI Generate tools to run the container.</li>\n<li>The specification is then used by CRI-O to launch an OCI Compatible Runtime, which runs the container processes. The OCI Runtime by default is runc.</li>\n<li>A separate conmon process monitors each container. The pty of the container process's PID1 is held by the conmon process. It manages the container's logging and keeps track of the container's exit code.</li>\n<li>CNI is used to set up the pod's networking, therefore any CNI plugin can be used with CRI-O.</li>\n</ul>\n<h2 id=\"conclusion-\" style=\"position:relative;\"><a href=\"#conclusion-\" aria-label=\"conclusion  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion üéØ</h2>\n<p>Container runtimes and CRIs have evolved rapidly in recent years, driven by the need to support new features and use cases. This overview has provided a high-level overview of the current state of the art, but there is still much more to explore.</p>\n<p>As Kubernetes continues to mature and new container technologies emerge, we can expect to see continued innovation in the container runtime and CRI space.</p>\n<p>I hope this blog post has given you a better understanding of container runtimes and CRIs, and their role in the Kubernetes ecosystem.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/prometheus-manage-memory-overload/","title":"Prometheus Restart Troubles: Managing Memory Overload üß†","date":"2024-10-29 19:00:00"},"excerpt":"When Prometheus Can't Keep Up with the WAL üìà üìó Introduction Have you ever had Prometheus crash due to an out-of-memory error while trying‚Ä¶","html":"<blockquote>\n<p><strong>When Prometheus Can't Keep Up with the WAL üìà</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìó Introduction</h2>\n<p>Have you ever had Prometheus crash due to an out-of-memory error while trying to catch up by reading the Write-Ahead Log (WAL)? It's a frustrating problem, but let's check it out.</p>\n<p>Prometheus is great for monitoring, but when it restarts, it needs to process data from the Write-Ahead Log (WAL), which can be memory-intensive. This often leads to OOMKilled crashes, especially if Prometheus is already running close to its memory limits.</p>\n<p>The issue usually stems from either collecting too much data or running too close to memory limits. This has been a long-standing concern, with <a href=\"https://github.com/prometheus/prometheus/issues/6934\" target=\"_blank\" rel=\"noopener noreferrer\">reports dating back to an open issue since 2020 on GitHub</a>, highlighting the significant challenges faced by users in managing Prometheus' memory during WAL replay.</p>\n<h3 id=\"Ô∏è-the-problem\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-the-problem\" aria-label=\"Ô∏è the problem permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚ÅâÔ∏è The Problem</h3>\n<br>\n<div style=\"width:100%;height:0;padding-bottom:100%;position:relative;\"><iframe src=\"https://giphy.com/embed/ka55CqnDNjQ7iIKtRa\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe></div>\n<p>While upgrading <a href=\"https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack\" target=\"_blank\" rel=\"noopener noreferrer\">the Helm chart of kube-prometheus-stack</a>, we noticed several pods were not ready, including <code class=\"language-text\">prometheus-prometheus-operator-prometheus-0</code>, which showed a status of <code class=\"language-text\">3/4 Running</code> with a recent termination due to being OOMKilled.</p>\n<p>The logs revealed the root cause:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token assign-left variable\">ts</span><span class=\"token operator\">=</span><span class=\"token number\">2024</span>‚Äì06‚Äì14T09:49:10.383Z <span class=\"token assign-left variable\">caller</span><span class=\"token operator\">=</span>head.go:840 <span class=\"token assign-left variable\">level</span><span class=\"token operator\">=</span>info <span class=\"token assign-left variable\">component</span><span class=\"token operator\">=</span>tsdb <span class=\"token assign-left variable\">msg</span><span class=\"token operator\">=</span><span class=\"token string\">\"Deletion of corrupted mmap chunk files failed, discarding chunk files completely\"</span> <span class=\"token assign-left variable\">err</span><span class=\"token operator\">=</span><span class=\"token string\">\"cannot handle error: iterate on on-disk chunks: out of sequence m-mapped chunk for series ref 946594555, last chunk: [1718071739971, 1718075459971], new: [1718049629971, 1718053199971]\"</span></code></pre></div>\n<p>It seems like it's stuck in the running state, where the pod is not yet ready. Let's describe the pod to see what is wrong:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">State:       Running\n    Started:   Tue, <span class=\"token number\">14</span> Jun <span class=\"token number\">2024</span> <span class=\"token number\">10</span>:04:03 +0200\nLast State:  Terminated\n    Reason:    OOMKilled</code></pre></div>\n<p>Ah, there it is. Prometheus is indeed running, but it got terminated due to an OOMKill‚Ää‚Äî‚Äärunning out of memory. It seems Prometheus is in the midst of recovering from the Write Ahead Log (WAL), which might be causing the memory spike. This could stem from an error during recovery or a restart, where Prometheus doesn't have enough memory to write everything into the WAL.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 403px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAETklEQVR42j1UWW8aVxSe39Y+9KWLKlVtErUPkaomVaSmah8aJVGjpG6b2E2Mi+M4xgxmWMbBNg7YMUsAwwAzhmEWZmUblmHYHcxix3GITS+21Kuro6tP59O53znfvVDArU/HF4U9g5SEZdIkJU0gXhwkEs4kL5CVC1AgjHzMKOCwkrb4X85A6ZhZYUwl3qRlUU1Gtcz/216WUEV8Uc/YVAmpiLYCYw74ft/Bv99wXW/lNxhsAaIwExPT468f0piuLFirMqpK9qpk5ViHj9oLUPGcuFUrYmzCyYafO7w/YOrPBueVuryWCs9DVAROBGejnr/J8KySXgEVVAmtCkiIJ7f4iltUySxby7kU0Un4zQ7vDamthx0/1mVHKvwUIsNG4vW0234rtHU/RxtVGa1IqCqYQyz+ItffkKoy7+pUYq1aSkpYbK4/rZEl2Ha7U1gjATm5a8xRyzpEb99cbOVWK6JdlWyq7Gh3amytR+cLjTJeENxU1MARBjq6jAefJ3eX5BSSCOohfs9Cpcw30Vf/+rytggPcucyvdDRqPB4fDzta1g30p6LLPE/vbG9YzfO7Qa/X4woF3KGtGchrngpa7j/QzU4/+Svunp40WXScvBuejcda4XWJg2vZVRY3ra0uuV+uP53X7Xi2TPDy5oZ1d/sf6M6lz+9e/vzulU9vfvaxZebXRt7eVHFQ9nDQBhKq58MTkkhgZ4XAnDtumEnuBDzWZHQt7p+DbnzzydT1y1PXLt27+vXmszsVydZp5EYfzjp1ucgipTRS4ixlDlGYpQy5WEqbsuRigV7WJEvU8wTyOh+zkQU+ZuBiBnHPmKVWMrQ1Q6HZlFlKPJdJVCYRmbQUeE9RDAjnbhMTsMIiXudDSEjagL1U2drIO4A8TbarnPFNlXhTp1tq/OTt/vFh5/3JAAg5Ox2dHO+/P24fDeonRxodNUBsDKEiOjwwzcTmNcmaZpxBmtCatUn2GejaZI1Gp2fjybnRaLXb+xPkpE8E5wF5hQg+jnge0Zg+wyA+ivYQVJwVx+fM0WgkSRKO44qiYBjmdrt4ngP4mwaTCOigVASO+x+5LL/FXj0gcEuI4XPcniCJp6cT8tHR0fr6+tzcHIh4HO8eHACw28mrYPjhBYjGYIk0PDLOOreftUoBlkmR4a1GtQSSNE1LJpN+vz8ajQ6HwwvZvW6lIGw08i/I3aeQlECwGPwT6tVvb3aaOUIWlbwE8hiW9fn8HMcPBoML/cN+66BdKIrrRQ5uAm8Dcgh9GLBN3Z55bFmzdfvduFLoD/oH3bZaKfZ7vbPTD4D57m2vnPPmWXOec5ZEB3h5YDQT8r3vvvzj6le/fPFRwIk2h4NKtXJw0K3VtGZdPXx7JHFUu16qFXeVtBF8FSXeDDwDnAfIqcgCdPvat3O3bkxdu5wmiXCzpeSwfNpRU5nDXmPQ2y/ncA5fLPJIVV5Vz90KvoqyYAPXjvl0/wFaJpw38r5EpwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cardinality\" title=\"\" src=\"/static/4457980b0539bcef67ad94fef9940f92/045fd/cardinality.png\" srcset=\"/static/4457980b0539bcef67ad94fef9940f92/04472/cardinality.png 170w,\n/static/4457980b0539bcef67ad94fef9940f92/9f933/cardinality.png 340w,\n/static/4457980b0539bcef67ad94fef9940f92/045fd/cardinality.png 403w\" sizes=\"(max-width: 403px) 100vw, 403px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>One potential solution could be allocating more memory to Prometheus and analyzing why the WAL is getting clogged up. Essentially, we need to investigate what changed to suddenly cause this spike in memory usage in our once serene environment.</p>\n<p>The issue persisted due to the WAL replay process requiring 2‚Äì3 times more memory than the running Prometheus instance. Despite running smoothly with around 30Gi of memory usage, the WAL replay process demanded over 50+Gi, ultimately leading to OOMKilled crashes during startup. Simply increasing the RAM limit wasn't a viable solution, as the excessive memory usage occurred specifically during the replay phase.</p>\n<p>This problem aligns with a longstanding issue on GitHub since 2020, where users have consistently reported challenges managing Prometheus' memory during WAL replay. We encountered similar difficulties during our upgrade process, highlighting the critical need for resolution.</p>\n<h3 id=\"-understanding-memory-overheads-in-wal-replay\" style=\"position:relative;\"><a href=\"#-understanding-memory-overheads-in-wal-replay\" aria-label=\" understanding memory overheads in wal replay permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üí° Understanding Memory Overheads in WAL Replay</h3>\n<p>In the past, WAL replay often caused significant overhead, leading to unexpected out-of-memory (OOM) situations. For instance, if your Prometheus was already running at 70% of its memory limit and the overhead during replay surged by 300%, it could easily lead to crashes. Additionally, increased CPU usage during replay, especially in low CPU environments like Kubernetes, could slow down processes like garbage collection, resulting in slower memory release.</p>\n<p>However, recent benchmarks of Prometheus versions at Google show a different picture. While there's been a noticeable 2x increase in CPU usage during replay, the memory overhead, including heap and working sets, is only around 1‚Äì5%. This raises the question: are the reported OOM issues symptoms of a larger problem, with the replay OOM merely surfacing it?</p>\n<p>Currently, two prevalent scenarios appear:</p>\n<ol>\n<li><strong>Excessive Data Collection</strong>: If your Prometheus setup scrapes too many series or samples, it's prone to OOM crashes during replay, regardless of the memory overhead.</li>\n<li><strong>Running Close to Memory Limits</strong>: Even a slight overhead during replay can trigger OOM crashes if Prometheus is already running near its memory limit, such as at 95%.</li>\n</ol>\n<p>These issues often revolve around cardinality‚Ää‚Äî‚Ääthe combination of all label values per metric. High cardinality metrics, like those tracking multiple URLs or response codes, can quickly escalate memory usage. In short, much of Prometheus' memory woes can be attributed to cardinality.</p>\n<h3 id=\"-how-does-remote-write-work\" style=\"position:relative;\"><a href=\"#-how-does-remote-write-work\" aria-label=\" how does remote write work permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîÑ How Does Remote Write Work?</h3>\n<p>The remote write reads data from Prometheus' <a href=\"https://en.wikipedia.org/wiki/Write-ahead_logging\" target=\"_blank\" rel=\"noopener noreferrer\">write ahead log</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 66.47058823529413%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB5klEQVR42o1TW27bMBDULX2XFvB10u9eoCdwPwLUhtPWgWS9bb1JihJJTXepGE0BJw0BYiVod3ZmZxXgzrF2Qd1ptJ3AOckQpznCc4I0KzGIEYOc8NYJ7gI6h7hUiOIMSRyh6zpoPSLPMzRNDaH0xwCXZVkBjUHb9OjaAX0vIaT2V6oJYlCQxHKxhgrc/xku1sLJAVkSo41O0NEvjOFP6CyCjp9hRQ83T3CjglPybUCWFSeJ7zwrgTTPcb1c4MwMOEtkrI94UcHRjX8Bl9eALLXve2QEspBcQ51LAmuaBo7mydcS81vu7d0D0jMMmeQM1c4ImFlVVR7QcXdi6KbRd7yBlWXpFfCzoYY5NW7q2isZhw5lGiMtCggaT8AsuOBCjIyxvDNw5KihaObZs2rbFkIITNNExij/PjAByuM5Nk8/UP8+Qj09IuCPh8MBYRiuLhOQ1QrNC8gwDKiJjZTSN82y7N8ZUlxk768jxgFLYDAGXl02sOSg0tozYqY+Ut7i1jUxVYH5tPduf3BtBLEcoWlFOPKZSb4ixmyGOj5Cffu6bsA9QJZ6W2pfTCDR8wlVWeC432P7+RO+PDygul6RniMUJJtz8Krm3T9Fk9zdboc4Tih+x2azwXa79e5G0dmPiHPu/Xp/ADqn7Ii5/yOKAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"wal\" title=\"\" src=\"/static/ae8f0b6c864a690e0f78a8be41523357/c5bb3/wal.png\" srcset=\"/static/ae8f0b6c864a690e0f78a8be41523357/04472/wal.png 170w,\n/static/ae8f0b6c864a690e0f78a8be41523357/9f933/wal.png 340w,\n/static/ae8f0b6c864a690e0f78a8be41523357/c5bb3/wal.png 680w,\n/static/ae8f0b6c864a690e0f78a8be41523357/b12f7/wal.png 1020w,\n/static/ae8f0b6c864a690e0f78a8be41523357/d9b5d/wal.png 1224w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Data generated by scrape is written to the WAL, so this essentially gives us a 2- to 3-hour buffer on disk of data for remote write. The RW system now has a subroutine that reads the WAL and passes the data back to remote write.</p>\n<p>Remote write still has a small in-memory buffer, and the routine reading the WAL pauses where it is if it's not able to append new data to the buffer. This means we no longer drop data if the buffer is full, and the buffer doesn't need to be large enough to handle a longer outage.</p>\n<p>As long as the remote endpoint isn't down for hours, remote write no longer loses data (with some caveats, like Prometheus restarts), since the WAL is truncated every two hours or so.</p>\n<h3 id=\"Ô∏è-issue-resolutions\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-issue-resolutions\" aria-label=\"Ô∏è issue resolutions permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Issue Resolutions</h3>\n<p>If you've never experienced this issue before (lucky you!), here's a handy solution I found effective. Since Prometheus may not be up and running to utilize PromQL for detecting potential issues, we need an alternative method to identify high cardinality. One approach is to get hands-on with some kubectl exec magic:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl <span class=\"token builtin class-name\">exec</span> <span class=\"token parameter variable\">-it</span> <span class=\"token parameter variable\">-n</span> monitoring pods/prometheus-prometheus-kube-prometheus-prometheus-0 -- <span class=\"token function\">sh</span></code></pre></div>\n<p>Then, run the Prometheus TSDB analysis:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">/prometheus $ promtool tsdb analyze <span class=\"token builtin class-name\">.</span></code></pre></div>\n<p>This analysis will provide insights into metrics with high cardinality, like <code class=\"language-text\">haproxy_server_http_responses_total</code>, which might be causing memory issues. In such cases, updating or optimizing the problematic metric, such as haproxy, can alleviate memory strain.</p>\n<p>Alternatively, consider increasing Prometheus' memory allocation or deploying it to a specific node group with ample memory resources.</p>\n<p>Here are some additional strategies to mitigate memory overhead and OOM crashes:</p>\n<ul>\n<li><strong>Verify Memory Overhead</strong>: Ensure that the memory overhead during replay is within acceptable limits (e.g., 10‚Äì15%). Running Prometheus close to its memory limit is risky due to dynamic garbage collection and limited room for unexpected cardinality spikes or queries.</li>\n<li><strong>Optimize Storage and Scraping</strong>: Regularly optimize Prometheus' storage, scraping, and remote write configurations to reduce memory usage. Upgrading to newer releases can often provide optimizations in this regard.</li>\n<li><strong>Automate Recovery from OOM</strong>: Implement auto-recovery mechanisms to handle OOM crash loops, such as automatically deleting the Write-Ahead Log (WAL) on OOM events. This ensures smoother recovery from memory-related issues.</li>\n<li><strong>Implement Scraping Limits</strong>: Consider introducing forceful scrape limits to prevent Prometheus from scraping targets when memory usage exceeds a certain threshold. This proactive approach can help avoid memory-intensive situations and potential OOM crashes.</li>\n</ul>\n<p>By implementing these strategies, you can effectively manage Prometheus' memory challenges and ensure smooth operation in your monitoring environment.</p>\n<h3 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîö Conclusion</h3>\n<p>Dealing with Prometheus OOM errors during WAL replay can be challenging. By understanding the root causes, such as excessive data collection and high cardinality metrics, and implementing solutions like optimizing storage and scraping configurations, increasing memory allocations, and setting up auto-recovery mechanisms, you can mitigate these issues.</p>\n<p><strong>Thank You üñ§</strong></p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}