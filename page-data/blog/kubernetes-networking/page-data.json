{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/kubernetes-networking/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>A Guide to Network Management in Kubernetes 🕸</strong></p>\n</blockquote>\n<h2 id=\"-overview\" style=\"position:relative;\"><a href=\"#-overview\" aria-label=\" overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>📌 Overview</h2>\n<p>Kubernetes networking is a complex and fascinating topic, with many moving parts. <code class=\"language-text\">Kube-Proxy</code> and <code class=\"language-text\">CNI</code> are two essential components of Kubernetes networking, working together to enable excellent communication between various components.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/components/#kube-proxy\" target=\"_blank\" rel=\"noopener noreferrer\">Kube-Proxy</a> is a network proxy that runs on each node in a Kubernetes cluster. It is responsible for maintaining network connectivity between services and pods. Kube-Proxy does this by translating service definitions into actionable networking rules.</p>\n<p><a href=\"https://www.cni.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">CNI</a>, The Container Network Interface (CNI) is a specification for configuring networking resources in Kubernetes. CNI provides a dynamic framework for provisioning IP addresses, establishing cross-host connectivity, and configuring overlay or underlay networks.</p>\n<p>This blog post will explore the inner workings of <strong>Kube-Proxy</strong> and <strong>CNI</strong>, and dive into how they integrate with Kubernetes. We will also discuss different Kubernetes network plugins.</p>\n<h2 id=\"-kube-proxy-kubernetes-networkproxy\" style=\"position:relative;\"><a href=\"#-kube-proxy-kubernetes-networkproxy\" aria-label=\" kube proxy kubernetes networkproxy permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>↳ Kube-Proxy: Kubernetes network proxy</h2>\n<p>In Kubernetes, the ephemeral nature of Pods means their IP addresses can change, making it challenging to establish stable connections 🤔. This is where the Service object comes into play. Services provide a consistent IP address to access Pods and are linked to a group of Pods. When traffic arrives at a Service, it is intelligently directed to the relevant backend Pods.</p>\n<p>But how does this mapping of <em><code class=\"language-text\">Service to Pod</code></em> actually function at the networking level? This is where Kube-Proxy excel.</p>\n<p>Kube-Proxy serves as a vital Kubernetes agent that resides on each node within the cluster. Its primary role involves monitoring changes to Service objects and their corresponding endpoints. It then translates these changes into tangible network rules within the node.</p>\n<p>Typically, Kube-Proxy operates within your cluster as a DaemonSet. However, depending on your cluster's installation type, it can also be directly installed as a Linux process on the node. Regardless of the setup, Kube-Proxy is the unsung hero ensuring that your network traffic efficiently reaches the right destinations in your Kubernetes cluster.</p>\n<h3 id=\"-how-kube-proxy-works\" style=\"position:relative;\"><a href=\"#-how-kube-proxy-works\" aria-label=\" how kube proxy works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>💭 How Kube-proxy works</h3>\n<p>Once <code class=\"language-text\">kube-proxy</code> is installed, it establishes authentication with the <code class=\"language-text\">API server</code>. As new <strong>Services</strong> or <strong>endpoints</strong> are introduced or removed, the API server promptly communicates these changes to Kube-Proxy.</p>\n<p>Kube-Proxy takes these updates and translates them into <code class=\"language-text\">Network Address Translation (NAT)</code> rules within the node.</p>\n<blockquote>\n<p>These NAT rules are essentially mappings, linking Service IP addresses to Pod IP addresses.</p>\n</blockquote>\n<p>When traffic is directed towards a Service, it adheres to these rules, leading it to the appropriate backend Pod.</p>\n<p>To illustrate this process further, let's consider an example:</p>\n<p>Imagine we have a Service named <code class=\"language-text\">SVC01</code> with a <code class=\"language-text\">ClusterIP</code> type. When <code class=\"language-text\">SVC01</code> is created, the API server examines which Pods should be associated with this Service by matching labels to the Service's label selector. In our case, let's call these Pods <code class=\"language-text\">Pod01</code> and <code class=\"language-text\">Pod02</code>. Subsequently, the API server creates an abstraction known as an <code class=\"language-text\">endpoint</code>, representing the IP address of each of these Pods. So, <code class=\"language-text\">SVC01</code> becomes linked to <code class=\"language-text\">2 endpoints</code>, denoted as <code class=\"language-text\">EP01</code> and <code class=\"language-text\">EP02</code>.</p>\n<p>In the final step, the API server maps the IP address of <code class=\"language-text\">SVC01</code> to the IP addresses of <code class=\"language-text\">EP01</code> and <code class=\"language-text\">EP02</code>, solidifying the connection between the Service and its associated endpoints.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 33.529411764705884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+0lEQVR42qWRXUvDMBSG9///hjfqLjbHUJDBmFsLUxA/YHNTu7bJSddaaSfDi87m9TTJwBtFNPD0TUv78Oa0hS9La234z2rFUQQhBSJOIkKSJMiyFFVVmRc223c8hBme5SuehCN2uPtllCMvtlYopIRiyWw2R1luUNeaZTvsatt0RQUOBwF6HqE7luhcCJMnnrI5kWgPBe4fUyvU5qgMZ+PY88GXJgNZsCTG2WVqOB4scNC/wdH5HKfTNT9bo+dzoeDFCr+bxX6WoSq5YWg+6k6UoTMmRpp907Q9Im6Y/U6Y5m8YXoXw7xS8W3IoB8FnRtcCK57xj8K//uVPmpIOaxoCqQQAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/5da025a9baa720d754be3a179a090889/c5bb3/step1.png\" srcset=\"/static/5da025a9baa720d754be3a179a090889/04472/step1.png 170w,\n/static/5da025a9baa720d754be3a179a090889/9f933/step1.png 340w,\n/static/5da025a9baa720d754be3a179a090889/c5bb3/step1.png 680w,\n/static/5da025a9baa720d754be3a179a090889/b12f7/step1.png 1020w,\n/static/5da025a9baa720d754be3a179a090889/00172/step1.png 1044w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 101.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC2UlEQVR42o2S+08TQRDH++9qTIyCqDEBfjDCDyaIMTEGNUZAAYG29kGQiNLS8i4SUSn23V7be7W00Mfd9fp1Z/sA0QMmmczuzu5n5zu7NlzRTNNErVbD0dERJEmCLMsoFAqoVCpoNBp8T7PZhO0qsHq9ziHkBKCDhmGgWq12Lzg+PuZ7LwXSwWw2yyukQ7FYDMlkEoIgIJVK8UjWucwSSFWQkSyqhEwURUQiEQ6lmEgk+BoZtYP2XgosFos4OTnh43Q63QURlJzWOkBVVS+XTA0nybqu8zHJ7ciORqO8ero8n8/zsa1VjbWTaZqOPJNGkugwVUz9pFgqlbqwKz3KX/1UFRQLMgOVUS6X+Qt3Xr1jNsNoYDUUx8pOGr7QWU+d8TT8u2ksb8bwKfgb2z8yp+Wfu9Sm6QbsXyOY8wmY92XaLsC+mm25P9tdt68KmGPzhWCcfaMGhzTPgW06A3oDCbjXRXjWc/BuiHD603g9v4m3rl2Mu7/BFRRYjvJ5uNby+LyVYiDzv+1pA+MMmOdAcjcDOP0pOHxJFpNsLdvNudZyDJi8GOhciTBpAhz+zKkzec5Ajsez6yR9cS1uDaS/tRsWsR1WsBOW287GByK29gUWpda8nds6ULAfkf55lC6QmlpXBWhKCnohA4O5JiehlRR+pl7I8bmuspxKuRS0I8nyi9l0rY7M7CNkx/uw8eQ69p7fhDzRi9zyOGq6CcE5AnmyD+sj17D19Abkd33ILLyAaQU0dA3ix8cQpx8gPzOAkuMhqvZ+FAIzqBsm5IVnkKZOczXHIJQvb6yBpqEjMTuMX2M9yE0PoOoZwsl8P9TANLSGiYxrFIcve5CZ6kfVPYSKfRDy8gVAkqw4hyFO3EH01W2I7++jMnMXysoEl6x6R6FM9uJw7FYr9+EepKUxayC9svLdh/S6B/GgG2JoCWpoEYXoHhpmE+rPIIQNL8t5ILVzSngbTQvgH1/tx1WQgHerAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/4b8d8cbb049ae99e91ee2d8690609698/c5bb3/step2.png\" srcset=\"/static/4b8d8cbb049ae99e91ee2d8690609698/04472/step2.png 170w,\n/static/4b8d8cbb049ae99e91ee2d8690609698/9f933/step2.png 340w,\n/static/4b8d8cbb049ae99e91ee2d8690609698/c5bb3/step2.png 680w,\n/static/4b8d8cbb049ae99e91ee2d8690609698/f3c12/step2.png 764w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 77.05882352941177%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBUlEQVR42pWTe0/bMBTF+/2/wTT+GJo0prUpUEqHttHnoIWUMaYQdTQJ6SNpHm3apKEPqcmZrzdKGRvLLB3ZubZ/PvfGTiFhi+MYYRhiPB7D87xHPcWjKOLrUklgtHg4HGI0GsF1Xfi+j8lkgiAIHsVXq1UyIDmZz+eYTqdQVRWKoqDdbqPT6aDVanGHy+WSgxMBHcfhKZMjXdc5kNTr9aBpGndMzbbtZEBKj1wsFgsOkmUZ3W6XwyRJwmw246JMUg9F/7uiKGbpeHBYnQhOqQeBz50R5L6OVOsU/qOFYYCxN8JdOGV/1+MwOoDcUUlIqXt7t30XkmJBVu0/6lq18P12iPqXG4hXGqbh/OfW3w7lwDhaoXzRg1A1sf/ZxN6GdmsG6431ON9w8K6ow7D99f0kPQHWLvvI1QcoNAY4ZCqcWXh/7uBIdLkON+JCWcfADdbAJw4jBqwy4P7JAPm6yTZa2K3o2M5d4nX+Cm8/tFjcYhrwuUyJgH4S4MOm3InBnGjIFBUIJY3FbD5XOLORYQ7NfwFrXw3kTi3sVXWkP90gc9zmLgmYLalIH7NYsY38qYlspfN8ylTD0kUX6Uofb45aeCk0sSWI2D74hhfpBh9vZUW8Yt9CuYOdjwoM5xmHcRyxK2GjKZsQpR6a130mA03pV0+SDYgUl/s4Z2smwd36QWwCfwCnOmCrnTCkZwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/fdf3dd3d45f21eaafabdd5e911f94490/c5bb3/step3.png\" srcset=\"/static/fdf3dd3d45f21eaafabdd5e911f94490/04472/step3.png 170w,\n/static/fdf3dd3d45f21eaafabdd5e911f94490/9f933/step3.png 340w,\n/static/fdf3dd3d45f21eaafabdd5e911f94490/c5bb3/step3.png 680w,\n/static/fdf3dd3d45f21eaafabdd5e911f94490/63ec5/step3.png 812w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>All of this configuration is currently only part of the control plane. We want this mapping to be actually implemented on the network. Once it is applied, traffic coming to the IP of <code class=\"language-text\">SVC01</code> will be forwarded to <code class=\"language-text\">EP01</code> or <code class=\"language-text\">EP02</code>.</p>\n<p>So here comes the <code class=\"language-text\">Kube-Proxy</code>. The API server will advertise these updates to the Kube-proxy on each node. Which will apply it as internal rules to the node.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 107.05882352941177%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsTAAALEwEAmpwYAAACDElEQVR42u2U23KbMBCG/f4P0ptO0+Immd502sSJ3fS+U3fqA+EMNoiDwcEG/u7KkBjbuM19NfOPpNXup5VY0cOJ9vS0gW6LZ2m19APl+fYotrc/qapK9u4yxsWtgQ93llR/6Egp93Zto36gwxerVtwJ4K73/BgfhyauvtlS729UXHydoX+n1zYHVyMDQZi24jqBLgH79yYuRxQ8cvD282+8+fQD777MJIztl0MGvipDa5cJ6frBw/V30oNb26gfmf+SYXOHEd2RSkfUoAweodyqNH+UUgZko6Mrgzn8v2XYtO22QBBlEPEaSbZBnOZIWDQOkzV8WguTDNuiOP+VW9mSsmyNKBRIkhhJHEOIAGmaoqzQ2U4C+QgcI4TAePwLs/kcP8dj6LqBzWaDgohlVZ0HZlmGKIoQUyaBiCDCUM7LstxtQMrzXK5HtOb7QvYhbcqbHAGD5RKGrsssJjONxoacM7Bpq9VK2izThKoa0DRTzrM0fT7ZC9D3YZLjdDol57kcc+Ah0LYsWlcxmUwIqMl5J5ABnuvCdVw4tg3TMFolkRKQfXjNdRzZywzpuo6BQQCLADYFNOoCclaNzgMPnP8DXwf0uWz4o5CTVZcMO+8DuWwan8ZPp9I5WTb8CjiAqz+mF8JvNq0dm1bQz4BtvL7vU+z9JHqHATbV1mKx6Hz8nIVLtep5XuvJNcA/4b1AfdLTvWQAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/7ae096e07f595ac802b4837c7ec36a3b/c5bb3/step4.png\" srcset=\"/static/7ae096e07f595ac802b4837c7ec36a3b/04472/step4.png 170w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/9f933/step4.png 340w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/c5bb3/step4.png 680w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/b12f7/step4.png 1020w,\n/static/7ae096e07f595ac802b4837c7ec36a3b/e996b/step4.png 1050w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 118.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAYAAAD6S912AAAACXBIWXMAAAsTAAALEwEAmpwYAAACzUlEQVR42p2USVPbQBCF+f8/I7kSKhWMj4EkEEwOBOeAXdjaV8v7osXy8vJ6hIWN7VBBVV2zqOfr19Mzc4IDX75YoDuYvGmd3ghJOt9Ze7I9WK/Xqu30xvhy7aDy0yvt/MYtTcbVmo/TSwMtu6/WrJ7XHgfeEHQbFFYLUb2LUP0V4YJ9mavehTi9sv4fKIDP3y18PK/jQ+UBny51NVetvRMoJv2zKwNn30z23fcq9LkwLO2i1lG2GVfvOgTaBA7eBkYC/GGhcuOwCLayynOr7NpG9dbF6VcN7X8p3HzL5QqzOMVkmiJOMnU0pBVLs5z/MkxmKWazBHm+OH5sdtUCczqnSYIkiZGmKdsEw+GQ4JiKDq87CqRIxHGMRqOBZrOJVquFx8dHuK6LjHD5vzpAPXlJc1nagjdlnhetQDfqpD+fz9V8lhXbkHMsc3mevwDFwbFteIzuOi50w2ErZivIdsFGTFn8fM+FZbkwLYdjB2EQKJ8SKICAk57nw7R9RFGk5l4DZQ8leBSGTN+H7dC3EyLw/V2gRLXpqLVb0LU2fDocA8q8QzMNA6ZpUIS3r1CiymQYSLRQ9aUAh4FumU0YFuqCHSA31GeULtP06eQ4jEgn7whQ5uW/Y7swdKo0dLW+LMpqtUKDR+L3/T2enp6KyG8Bqcgm8E+9jvrDg8qwBC6ZsqHrymzLZqoe0/COAlUBVUAPHaYstrOH+XPKvW5EdQGPg48uKycbH89me0DxFYhmci/9QI3FSqAcZqmYToWWaaHd1lg9E+PRiPd1Hyh+ciJMZtPWNFWQ8Xi8C+x2u8p5RMhwOFB9Uf46ZVnY7/fV/8lkovoSVHx3gG3eVSmIzogttnJ35Ui8VjgYDNTd1rQiC+kbzE7mS6B0FoTKvRRFWZYV95ljOQHbn4xFgPhNp1OlbHP/914bcZJC9JjGRtHhp22t1MsNkYdj+7X5C0y1GDiub7LUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/21a523135ce7fd8705e614f56cb2fb8e/c5bb3/step5.png\" srcset=\"/static/21a523135ce7fd8705e614f56cb2fb8e/04472/step5.png 170w,\n/static/21a523135ce7fd8705e614f56cb2fb8e/9f933/step5.png 340w,\n/static/21a523135ce7fd8705e614f56cb2fb8e/c5bb3/step5.png 680w,\n/static/21a523135ce7fd8705e614f56cb2fb8e/cc488/step5.png 928w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Now traffic destined for the <code class=\"language-text\">SVC01</code> IP will follow this <a href=\"https://en.wikipedia.org/wiki/Network_address_translation#DNAT\" target=\"_blank\" rel=\"noopener noreferrer\">DNAT</a> rule and get forwarded to the Pods.</p>\n<blockquote>\n<p>Remember that <code class=\"language-text\">EP01</code> and <code class=\"language-text\">EP02</code> are basically the IPs of the Pods.</p>\n</blockquote>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 81.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACkklEQVR42oWU3WsTQRTF+09rC5UiClJQEF98FQsRamlU2pfqm7QqVfuhtmlNNtnv2d1kk2yT0DTZzfGeMbtJK8WBy87unPu7d+6dnQXIGI/Ht1qWZchHmqYY8XuaiaVTk/k41WscC3TwPA+ObWvzXBeu68CWOa3b7RbAVqsFs9GAYxrwrQY8qw67YcA2GwjDEJPJRIDpGCpswv/2AeH2M/x6/QTV8lN0dp7D/rmPbq9fAONOAuvHF7S2HuO09ABnrx4ifrcK7/MWoriDSZb+BfpRG+HeJnrrd2G9vANVWsSwvAzn8KMAB9eAztEu+pv34JWWYK0tIllfRLi7gTDuzoAqiuF/eoukvILB9ir6W4+QvLkPW5xvAu3jPbQ2VmCVlnH+Ygn22l0Ee+UZkMVUKoAya1DnR3BOD2CffId/dginUUM3SWbAOIZdr8E/PxQ7gvp9DK9yANc4QxQ1dQN1U1zHQc0wYFoO6qYF11cIRMBmzTcllqa40rRAaq7CCCqI9NNXCpE0JWNT2BnbsvB+Zwdf9/dhSRdd6W7g+7rj/wAlONeUBMvNFyuA+tiI4+nJCYxaTTswQCBRbwXKmiJ0ateAqQAVUw4CNKNIQ2kU0DmZB0oN/w+UpjATHmJHxJZkZ5mmdqSw0+kUwGazqbOnnvWlUcf34mDz96KQizpTydJnZMmYa71erwC2220dmEGpC0RTrVYxHA61lslpIH8pRqCIcIL5fhPIbKmlXVxcIJEjxeCj0WgGzKY1NOTYMDLn3Ab/Wda0J47zQGZUr9f1jphtpVLRiTCwPocUTqY3ytXVFfr9Pi4vL/Wi/i51ycdkOqcz4YPBoLiR8ltpYV7IGpnSEG6Dwpsj1xHGBnLr+bWVjz8TP6jysrG2ogAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/9446bade439e11c0df96a1816c63a91e/c5bb3/step6.png\" srcset=\"/static/9446bade439e11c0df96a1816c63a91e/04472/step6.png 170w,\n/static/9446bade439e11c0df96a1816c63a91e/9f933/step6.png 340w,\n/static/9446bade439e11c0df96a1816c63a91e/c5bb3/step6.png 680w,\n/static/9446bade439e11c0df96a1816c63a91e/d48f1/step6.png 796w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 91.1764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACuklEQVR42n2U2W/TQBDG+z+jVpxC8MgTCHgoUishHioRLqkSfQAUQAJVaikE1MQ5nMNXEjvxbceJnXzMbJqkJqErTXazO/PztzO7uwVqaZoiDCNEcYIwHgkT4yhGkiRYtPF4THPkN6J+lIhejMmP17ht8Y/v+9BUBXqrgV5HRl+RYbTqUFoyLNNaAh3HQUeuQ638JPsFpUx9+Qxqsw6b1pbAIAihylUMDx9A2t/B2e42rJe3oX8twLK9FdAPoZS+w3tzD9LeNhrPb2D09i7UH59he+ElIG1XbUjw3t2HX7gJ99UdxIXr6H05WANqpW/wCregv9iBvH8N7sEOjLNiHuiTQr0tw/y0B/vjLoYfnmFw9ATq8XsCuiugF0A5P0Xv6CmUw8eovX4I/fARtD/HBAxWwDAIIEkSzssVSNUaFFWD0e1B0zRYVj6HmqqKtS5Zv98XY538HNteAWOq3OnJCYrFIur1unDo9eaOm4A9BhpdMoPAXei6ngcGVGWl0xGmKsocyI7/BV7ALmxNIR8bgyZN2kK71YJUqYggDr4KaJCyzUDPEwuWaYotcO4GBGJHk+aWQAriuT6lg81kIxE8Z/+rsN1uo9FooEPbZquUy0KR67o5hc1mEy3ahUpKZVlGk4x9IqpDDuiRSl4IqOI85q1OJhO6kuES6NH6YDAQxn7sPxwOxdVdu3q1Wk2o4r5Wq+N3qSQqfVkhb4uPV4VyLMtNVKtVlCmGP5BTOJ1OMc2yeU/m+BHGk4ycQpFDcdepAHO1M5h2SI/CBLPZFFk2FQo5bgnMt5lwcrwRYnpxHMcWX2d1URzDDRLEyUT4zWaztegNwHlLU1Y6woR6Dhxf/GflV7UckJVw9fhKpWkmQH6YwCVQECVC+fwxCcVJMOioLYqxEci54ApzBbMs25CMlR/nM6YULHK3AP4FrRNL46ULoeMAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/95b897d26d864ac2a8a437b40acd8fd4/c5bb3/step7.png\" srcset=\"/static/95b897d26d864ac2a8a437b40acd8fd4/04472/step7.png 170w,\n/static/95b897d26d864ac2a8a437b40acd8fd4/9f933/step7.png 340w,\n/static/95b897d26d864ac2a8a437b40acd8fd4/c5bb3/step7.png 680w,\n/static/95b897d26d864ac2a8a437b40acd8fd4/5d72a/step7.png 834w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Now of course I tried to keep the scenario as simple as possible. This is just to focus on the important part of the Kube-Proxy.</p>\n<p>There are a couple of points that are worth mentioning:</p>\n<ul>\n<li><strong>IP and port mappings:</strong> Services and endpoints in Kubernetes represent IP and port mappings, ensuring proper routing of traffic to specific combinations of IP addresses and ports within the cluster.</li>\n<li><strong>ClusterIP and DNAT translation:</strong> ClusterIP services use DNAT (Destination Network Address Translation) on the source node, keeping their IPs hidden from external access. They function as internal NAT rules, exclusively accessible within the cluster.</li>\n<li><strong>Service types and rode rules</strong>: Different service types can lead to the installation of distinct rules within nodes. These rules may be organized into chains, specific sets of rules with defined order in the traffic path.</li>\n<li><strong>Random pod selection:</strong> By default, NAT rules select a random Pod to handle incoming traffic. However, this behavior can vary depending on the chosen Kube-Proxy mode, which determines the load balancing strategy for routing traffic to Pods.</li>\n</ul>\n<h2 id=\"-understanding-kube-proxy-modes\" style=\"position:relative;\"><a href=\"#-understanding-kube-proxy-modes\" aria-label=\" understanding kube proxy modes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>💭 Understanding Kube-Proxy modes</h2>\n<p>Kube-Proxy operates in various modes, each with its approach to implementing NAT rules. To grasp their workings and nuances, let's explore these modes:</p>\n<h3 id=\"-iptables-mode\" style=\"position:relative;\"><a href=\"#-iptables-mode\" aria-label=\" iptables mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>✅ IPtables mode</h3>\n<p>This is the default and widely used mode. Kube-Proxy relies on <code class=\"language-text\">IPtables</code>, a Linux feature for packet processing and filtering. In this mode, Kube-Proxy inserts <code class=\"language-text\">Service-to-Pod NAT</code> rules into IPtables, redirecting traffic from Service IP to Pod IP.</p>\n<p>However, IPtables can become less efficient with a large number of rules, as its sequential algorithm results in O(n) performance. It also lacks specific load balancing algorithms, using a random equal-cost distribution.</p>\n<p>Now the Kube-Proxy role can be described more as the \"installer\" of the rules.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 608px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 112.3529411764706%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC9klEQVR42q1Va2/aQBDs//9HqRSitgkhgYQEMOD34/y2McaQR790uruA45BUaqUiDeu725udnTvDF9CnaRpkWYaiKN6hWq1Qr9eoqgqbupZ4msPI8xzb7Zap8IW/eDLwfSRxjDiKBFEY4m40wnW/j5vBABe9HmbTKdIkaXPaXKWkeEtYliVUEEgykx7huS5sy4JDMHQdnue1a0x0zI+pOKv/QNglY/CGnKzgmKWp5HF7Yg/FuNPRe0JqmSc58sasQ8TE3D4TmaYJi9S6pDwgAUzCax8IV1SZW5pOJtKi6zgwDQP+oUXewIQ8z2Q85shFP1W4pgEfwNezM4yGQwyur9E7P8fDeCxqWQUfGkcuvFwsJHLxP3oY0klxu1x1H3OJx8NhMkU5XGxIRW9vbjHXNMmJTgm5ZUUKXNtGQvKPSBP2TxGhRxsTGZfUOqPIMyqaylwSn7Sc5QUc14dl0zWxPQQqgu+HBAXdsOBR9INQwM8CT8k657leQF127mGYrvFo5JjZJR70DHN3jYVX01xG4xRzp4Jmr6BxPGDu7rHw1rSvQlrUb4RJ0dBiDTt+weXIxNQqiazAxWABO3mFGe5gqG0LPWikwNLfYDRT6I9drOrnN8KYCFldysSGCydI4RKCKIcX13tFTiWqWT2DiXk8tQo8mvROr3ZvhFHeYOmWeH15wXyuyTurL5eSkJUNbdxgSEp+DHVc3ZkYPLjUiSGkVvQEXe2QU96JwhXssIYTbSRaqoYZVND9CiZtYi+/E2H/3hLy67EjrYtSv0G+6vzaxKRQIxVG+IRlwB4doNi7XavEIT/ZZyt+Jm+fW0+XTFieEtKhfGa+HmwOsZFD2KtqWnX/RMhK3PQVDqmy+Tn7KUq7OX9FyNWZgI3vXU1x0ddwfjnB2bd73GmhePqB8NTDmVOLX0f/+Jnv4kiLcL9IiCjCzSSQO9rNYyw8+gvpKiyqLWxVwU9quXdHBGkDle+gsq0gpGc/ad7lMJxojfWmcw+BX/8B+89vrjteDLQppj0AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/3b7002549d26704094bc19d0b4628f5b/18872/iptables-modes.png\" srcset=\"/static/3b7002549d26704094bc19d0b4628f5b/04472/iptables-modes.png 170w,\n/static/3b7002549d26704094bc19d0b4628f5b/9f933/iptables-modes.png 340w,\n/static/3b7002549d26704094bc19d0b4628f5b/18872/iptables-modes.png 608w\" sizes=\"(max-width: 608px) 100vw, 608px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"-ipvs-mode\" style=\"position:relative;\"><a href=\"#-ipvs-mode\" aria-label=\" ipvs mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>✅ IPVS mode</h3>\n<p>IPVS (IP Virtual Server) is designed for load balancing and offers efficient lookup with O(1) complexity, ensuring consistent performance regardless of rule count. Kube-Proxy in this mode inserts rules into IPVS instead of IPtables.</p>\n<p>IPVS supports various load balancing algorithms like round robin and least connections. Note that IPVS may not be available on all Linux systems, unlike IPtables.</p>\n<h3 id=\"-kernelspace-mode\" style=\"position:relative;\"><a href=\"#-kernelspace-mode\" aria-label=\" kernelspace mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>✅ KernelSpace mode</h3>\n<p>This mode is exclusive to Windows nodes. Kube-Proxy utilizes Windows Virtual Filtering Platform (VFP) to insert packet filtering rules. VFP works similarly to IPtables on Linux, responsible for packet encapsulation and destination IP address replacement. If you're familiar with virtual machines on the Windows platform, think of VFP as an extension of the Hyper-V switch.</p>\n<h3 id=\"-userspace-mode\" style=\"position:relative;\"><a href=\"#-userspace-mode\" aria-label=\" userspace mode permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>✅ Userspace mode</h3>\n<p>In the early days, Kube-Proxy used the Userspace mode, where it managed connections by proxying them through a user-level process. While charming and simple, this mode is less efficient than others and is akin to riding a bike with training wheels.</p>\n<p>Each Kube-Proxy mode has its advantages and limitations, making the choice of mode an essential consideration based on your specific cluster's needs and infrastructure.</p>\n<p><strong>⛓ Checking Kube-Proxy mode</strong></p>\n<p>To determine the mode in which Kube-Proxy is running, you can use the <code class=\"language-text\">/proxyMode</code> endpoint, which Kube-Proxy exposes for querying information.</p>\n<p>Here's how you can do it:</p>\n<ul>\n<li><strong>SSH into a cluster node:</strong> Connect to one of the nodes within your Kubernetes cluster using SSH.</li>\n</ul>\n<p>*** Use curl to query Kube-Proxy:** Once connected, execute the following command using curl to query the Kube-Proxy mode:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">curl</span> <span class=\"token parameter variable\">-v</span> localhost:10249/proxyMode</code></pre></div>\n<p>This command will retrieve information about the Kube-Proxy mode, helping you verify which mode it is currently operating in.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.294117647058826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABCklEQVR42o2SR4rFMBBEfRrjnHNaOEeMDb7/UXqoBn2Y8OdrUUgbPVVXtXIcB1VVRV3XURRF5Ps+xXHMd0jccQZBQI7jkKZppOv6n1IAPM+TruuiaZqoaRrq+56KoqA0TVl5nrMABdA0zbdS7vtm0L7vtK4rn2VZvpyFYUhJkjAYDuHiI3AYBlqWhccGHBGoqvprHMMw/oUxcNs2yrKMhXEguEKWkOd5ZFkW6xPsm0M4g5BdXdevE27xiYw7BqIMuIREQfgAeY7jyFnCnTQQEDTbti23i0JQBiJAGa7rkm3b8iM/z0PzPPNoWA2xf2gVWQq4NBCjIS+xGj8fYlTZcRkoVkQ8ln34DvgFfOVej/PzS8AAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/fcb95fb20e18694c52ba207069d16f80/c5bb3/kp-mode.png\" srcset=\"/static/fcb95fb20e18694c52ba207069d16f80/04472/kp-mode.png 170w,\n/static/fcb95fb20e18694c52ba207069d16f80/9f933/kp-mode.png 340w,\n/static/fcb95fb20e18694c52ba207069d16f80/c5bb3/kp-mode.png 680w,\n/static/fcb95fb20e18694c52ba207069d16f80/b12f7/kp-mode.png 1020w,\n/static/fcb95fb20e18694c52ba207069d16f80/b5a09/kp-mode.png 1360w,\n/static/fcb95fb20e18694c52ba207069d16f80/1134b/kp-mode.png 1470w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Here you can see the last line that Kube-Proxy is using <code class=\"language-text\">iptables</code> mode.</p>\n<p><strong>Recap: Kubernetes Service and Kube-Proxy:</strong></p>\n<ul>\n<li>A Kubernetes Service operates akin to a proxy by providing a stable IP address for client connections. It directs traffic received at this IP to the corresponding backend Pod IP, effectively solving the issue of Pods' dynamic IP changes.</li>\n<li>In terms of load balancing, it depends on which aspect of Kube-Proxy is under consideration. The Kube-Proxy agent itself does not handle traffic or perform load balancing; it's solely part of the control plane responsible for creating Service rules. However, Kube-Proxy, through the rules it generates, facilitates load balancing by distributing traffic across multiple identical Pods associated with a specific Service. These Pods serve as replicas and collectively handle incoming requests.</li>\n</ul>\n<h2 id=\"-container-network-interface-cni\" style=\"position:relative;\"><a href=\"#-container-network-interface-cni\" aria-label=\" container network interface cni permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>↳ Container Network Interface CNI</h2>\n<p>Container Network Interface (CNI) is a framework that allows you to dynamically configure networking resources for your Kubernetes clusters. It uses a plugin architecture, so you can use the CNI plugins that best meet your needs.</p>\n<p>CNI can be used to configure both <code class=\"language-text\">overlay</code> and <code class=\"language-text\">underlay</code> networks:</p>\n<ul>\n<li><strong>Overlay networks</strong> encapsulate network traffic using a virtual interface such as <a href=\"https://datatracker.ietf.org/doc/html/rfc7348\" target=\"_blank\" rel=\"noopener noreferrer\">Virtual Extensible LAN (VXLAN)</a>.</li>\n<li><strong>Underlay networks</strong> work at the physical level and comprise switches and routers.</li>\n</ul>\n<p>Once you've chosen a network configuration type, the container runtime defines the network that containers will join. The runtime adds the interface to the container namespace via a call to the CNI plugin and allocates the connected subnetwork routes via calls to the I<code class=\"language-text\">P Address Management (IPAM)</code> plugin.</p>\n<p>CNI can be used with Kubernetes and other Kubernetes-based container orchestration platforms such as OpenShift. It uses a software-defined networking (SDN) approach to unify container communication throughout clusters.</p>\n<h2 id=\"-kubernetes-networking\" style=\"position:relative;\"><a href=\"#-kubernetes-networking\" aria-label=\" kubernetes networking permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>📍 Kubernetes networking</h2>\n<p>Kubernetes provides networking for containerized applications with a flat network structure. This eliminates the need to map host ports to container ports, enabling the operation of a distributed system without dynamic port allocation.</p>\n<p>The networking architecture in Kubernetes is based on the Container Network Interface (CNI) plugin specification. This plugin acts as a common interface between the Kubernetes runtime and the underlying network, supporting various networking solutions like Flannel, Calico, Weave Net, and Cilium.</p>\n<h3 id=\"how-kubernetes-networking-works\" style=\"position:relative;\"><a href=\"#how-kubernetes-networking-works\" aria-label=\"how kubernetes networking works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>How Kubernetes networking works?</h3>\n<p>When a Kubernetes Pod is created, the CNI plugin configures the network interface, assigning an IP address to the Pod. This facilitates communication within the Kubernetes Pod network, which is a flat network accessible to all Pods in the cluster.</p>\n<p>Additionally, Pods can interact with external applications through the Kubernetes Service network, a virtual network that exposes Pods to external entities.</p>\n<p>Kubernetes networking offers several benefits:</p>\n<ul>\n<li><code class=\"language-text\">Portability</code>: Kubernetes clusters can be deployed across different cloud providers and on-premises environments.</li>\n<li><code class=\"language-text\">Scalability</code>: It supports a large number of Pods within a Kubernetes cluster.</li>\n<li><code class=\"language-text\">Reliability</code>: Ensures consistent connectivity for Pods in a Kubernetes cluster.</li>\n</ul>\n<p>Both Linux container and container networking technology are continuing to evolve to meet the needs of applications running in various environments. CNI is an initiative of the Cloud-Native Computing Foundation (CNCF), which specifies the configuration of Linux container network interfaces.</p>\n<p>CNI was created to make networking solutions integratable with a range of container orchestration systems and runtimes. Instead of making the networking solutions pluggable, it defines a common interface standard for both the networking and container execution layers.</p>\n<div class=\"note\">\n    <p><strong>🔵 Note:</strong></p>\n    <p>CNI is not native to Kubernetes. Developers using the CNI standard can create network plugins to interoperate with a variety of container runtimes. CNI networks can use an encapsulated network model,\n    such as <a href=\"https://www.techtarget.com/whatis/definition/VXLAN\">Virtual Extensible LAN (VXLAN)</a>, or an unencapsulated - also known as decapsulated - network model, such as <a href=\"https://www.techtarget.com/searchnetworking/definition/BGP-Border-Gateway-Protocol\">Border Gateway Protocol (BGP).</a></p>\n</div>\n<p><strong>How CNI works?</strong></p>\n<p>CNI uses a plugin architecture to configure the Kubernetes cluster's networking. The CNI plugin is responsible for creating and configuring the network interface for each container. When a container is created,\nthe Kubernetes kubelet calls the CNI plugin to set up the network interface, assign an IP address, and add it to the Kubernetes network.</p>\n<p>The CNI plugin also interacts with the <code class=\"language-text\">IP Address Management (IPAM) plugin</code> to allocate IP addresses to containers. This involves managing the pool of available IP addresses and assigning them as needed. Once the network interface is established, the kubelet starts the container,\nenabling it to communicate with other containers on the Kubernetes network.</p>\n<p>CNI focuses on the connectivity of container networks and the removal of allocated resources upon the termination of containers. This focus makes CNI specifications simple and allows them to be widely adopted.\nFor additional information on CNI specifications, including third-party plugins and runtimes, refer to the <a href=\"https://github.com/containernetworking/cni\" target=\"_blank\" rel=\"noopener noreferrer\">CNI GitHub project</a>.</p>\n<h2 id=\"diverse-kubernetes-network-plugins-necessity\" style=\"position:relative;\"><a href=\"#diverse-kubernetes-network-plugins-necessity\" aria-label=\"diverse kubernetes network plugins necessity permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🧵Diverse Kubernetes network plugins necessity</h2>\n<p>Kubernetes relies on a rich ecosystem of network plugins, many of which are endorsed and widely adopted by major container orchestration platforms, with Kubernetes at the forefront.</p>\n<p>These plugins play a crucial role in enabling various container networking functions, all while adhering to the rigorous standards set forth in the Container Network Interface (CNI) specification. Given the inherent complexity of networking, CNI thoughtfully delineates specifications for multiple plugins, recognizing that user requirements can greatly vary.</p>\n<p>Within the realm of CNI, networks can be instantiated using two primary models: <code class=\"language-text\">encapsulated</code> and <code class=\"language-text\">unencapsulated</code>.</p>\n<p><strong>The encapsulated(Overlay) network model:</strong></p>\n<p>This model is represented by technologies like <code class=\"language-text\">VXLAN</code> and <code class=\"language-text\">IPsec</code>, overlays a logical Layer 2 network over an existing Layer 3 network topology. This approach simplifies routing complexity and minimizes overhead.</p>\n<p>It relies on UDP ports to disseminate encapsulation data among Kubernetes workers, creating a bridge connecting these workers and pods. Communication management within pods is then expertly handled by Docker or alternative container engines.</p>\n<p>This encapsulated network model proves particularly advantageous for scenarios that favor a Layer 2 bridge, especially those sensitive to Kubernetes worker latencies in a Layer 3 environment.</p>\n<p>For distributed data centers spanning distinct geographic locales, minimizing latency is pivotal in preventing network segmentation.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBklEQVR42jXQ6XOaQBgH4PzxzUwz03PamX5qTY2oSYwYcxgPkHCJBpRoVDzQOh7VoIgCi4BAIU3e2f3w7m+fmXf3wPO81niVrTO3VQJtPl0zcoZdXlBKrqr5kaJZRX6F8jLCbwq8TnYmxbZIdgaKDvz0AJhegh5W+O9c+RCppd5Hux9j9S+Xz5/SqgYsTgTvwq0PscbnlHSU0gp8+p46zJe/PoiT/9g9p+VbuocwAlyaQgSIkiBOAYjQZNWsisYxFrQxCpwQeqbSLpWJHM1QgvyCd06S0eDK8owYX7JaBNchIlhhTFurlo9/oVqU9E+CCC7rMD1PUNJD73VsJ0Fv0yXphlkkS3KE0Px7EAnCuBHgwS6EGW9YPSttz2kJIpZMVw+wbjpJSqHzLHdHZNFxhHSjxA7ClZPCfK3uub4Wys3ilB7FDT/KYlM2x1B3LNdeB9iy/bG3x8g2Upz+RishlIMo6cfV6FuENvderSsd/bwPY7sI+SeEsnG0DCPiaW5W66sB9vezYjVGVn+xHUgNYcIKk2mtp4sz1XMd/8Prgy0vAmE6fBqV+otWcwKaE9t/7Cv2a29bG0VeSfJGUW3L3NvANncAGJYJXNtwbbA3Tcd2nb3nOY73VgF2Xddzvcc+B+PRPHeF8Nd4DcMLAlloL3qZv52L5fBmLpw224/n2KjaW7+QAP8DdpD6TbpjqDAAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/fe31a7b21e4d40d9442e70ac58134af8/c5bb3/overlay.png\" srcset=\"/static/fe31a7b21e4d40d9442e70ac58134af8/04472/overlay.png 170w,\n/static/fe31a7b21e4d40d9442e70ac58134af8/9f933/overlay.png 340w,\n/static/fe31a7b21e4d40d9442e70ac58134af8/c5bb3/overlay.png 680w,\n/static/fe31a7b21e4d40d9442e70ac58134af8/442cb/overlay.png 752w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><strong>🧩 The unencapsulated(Underlay) network model:</strong></p>\n<p>This model extends a Layer 3 network to facilitate the routing of packets among containers. Unlike the encapsulated counterpart, this model does not introduce an isolated Layer 2 network or any associated overhead. However, it places the onus of managing necessary route distribution squarely on the shoulders of Kubernetes workers.</p>\n<p>To make this work, a network protocol is put into action, connecting Kubernetes workers and utilizing the Border Gateway Protocol (BGP) to efficiently propagate routing information to pods. Within these pods, the role of overseeing communication with workloads is assumed by Docker or a comparable container engine. The unencapsulated network model is ideally suited for scenarios favoring a routed Layer 3 network.</p>\n<p>Here, routes for Kubernetes workers undergo dynamic updates at the operating system level, effectively mitigating latency concerns. In essence, Kubernetes networking unfolds as a multifaceted landscape, offering a plethora of plugin choices while accommodating diverse network models tailored to the distinct needs of your containerized workloads.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 62.35294117647059%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACNElEQVR42rWSu24TURCGN4kDVcjTIBoKngABLwCPgERB7MZPAFEsOgSKQDSuXFmKXLiIkYKwZBs7rO+3vcfX9W1t79kd/lmwsSJajjQ+Z2e++WfO+EiNjhW+vHapdC27hUKB8vl8YKZpUr/fd9frNfVuzNiPmnV6VRZUKpVcjudyOSoWi8xQr9cT8/mccyKSphknM0dQuVxZtdstbzAYeIC8RqPh1Wq1lRCCTF0/UzTjzTzg5JWqqlsODNt6tVqRpmlhiX+IfIBlFyI0HA6Dqs1mk2RZdglLVfWYrqunfOYOu91uwDBbrVbZBBdWFCUSCE4mE9J13eVrMszGZ/Y5C1xFV2OGZb1dLBZkGIYLP3U6nS0HDTEej/8KMogPlysy1Gq1guqaqojhzKH09+KH1MXFe8yKiwiO8Q2QQ6PRiHcxnU63gq9ZHXNxUN3HNyeRaVm+rirL9o1N58nMl8/nHz9xMcSWMJ8Z8Nyhj9xl0ICmnUgQC/NssPOVvXq9LjBP8buTUTDDxcx+5zjOGZ+R6PIVMW9RqVQERD3btoXv+6wRkZD4HMA12v2Kq083f8pyuXTgv0J1GfYK8ZfYf4L/Bm5tWRZBiFDIRuwSbAnxF9LO2sObe4D5PcUzeILzQzQUkm4t+A4h8gjMYwg9A3f/j38vAPAM7qRSqeNkMnkPzv10Oh3KZrOHXCCTyRyxP5FIHLFtzpy34aLR6H48Hj9mQ/zu7eoHDHJn/+puhwvtcAfS/1y/APcSnUvnKJ2PAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/27ed908cc7970fd2efa2a90f6893ba20/c5bb3/underlay.png\" srcset=\"/static/27ed908cc7970fd2efa2a90f6893ba20/04472/underlay.png 170w,\n/static/27ed908cc7970fd2efa2a90f6893ba20/9f933/underlay.png 340w,\n/static/27ed908cc7970fd2efa2a90f6893ba20/c5bb3/underlay.png 680w,\n/static/27ed908cc7970fd2efa2a90f6893ba20/17a7a/underlay.png 753w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-cni-withcilium\" style=\"position:relative;\"><a href=\"#-cni-withcilium\" aria-label=\" cni withcilium permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🐝 CNI with Cilium</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 148px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEfklEQVR42oWUf0xTVxTHr+DPSTZwK0rf79tXSlveax+PtpQKjyJFfkpqUlEmbAMHBFwcbkia4RSNm1GYxOCSzbhplJk0OJdtcdsfJOjmtigYf0ydJluWaYxZXHRbWAIyzu5rwUHdspe83Lx7z/mc7/lxH0IIzYl/VVWdJ4riglAIJSKUsyjgz+5uqJYjpUXq2+ip5SlAbPRzm802n9gnxPk/BtQNUCgUStRXWclpHjxoBrhiGB8+LkJubvbr+n5k6vz/gKikRFzAM45igZJCaK7q2/h81teTF54BGE4ZhctL4LVW+TpKXq5Rimc1lektl+XA4inwLCDSNG2uvoqCFNrZUw0fn26B9q3Be1aLcvibIwLApSWT1wc4cHjd/eEK5dbFVjscq3WClOVpmeH/CJgwFeWJhubSq1fuboHvf+0YP/fDK1BWWfiFN0/pr6l13NQC6kCB233izuYMgDAeh7AInZXOO2ixN3VG+rOAievqis6M/PQq/PhH+OHQpU2QX5b3yRq7MtiVod6uk7K/cue6I9darQCdeGIibIG2MuU7oi8pHqi/0SKnpmZ4WzaV3e59t+ZeXdPK8z6rc+Ca3QmArRO3rDIUO12f1gWUL4/XWO9tXyX9wjq85f+W8iOVDs6RLMvKh9ku5zCW1b561T1035wJvwsZY6OiHTYr6git5vRKruJzdjXvM0mi6Lhux4DTTfF4XZ1d/X44OOKfbN+fN2ZyuA4dkJU/b1hkeF9S/spQ5ffqq7b8tmtDBDpq+yDPV7B/xpjFN8WRXLPR9/PhqwVw6LI2euiiH6qeXT4optv2uLKkIUumed+K/LKTOxoisKvho9HdTacm1pW3PEjBiJ3uwSOFsVuBkH+l5519nxfBsZuFE10f+EGVbUdLqtvurms/ChXrww8cUvqR1uo3x/Y0n5rc3tAPAa3ihO4HCB4b7CgQp6hs8SrPYHVj7gWtSOn3FQaHNuw9Cy/2XnrY2DMMBRU153OzPUeqArUjRfnlZy0Slmaom4PipjxB01C0lgDRiCi/qPLkht2nobnvxlhj97fgL117Bs1+EuOu36wuRzdCkVCiti3WJDuXZF2xqv5+sLkHAsGmMUc664uOCffcQlVtnPdfwOmLjiiedxg4bhmNuSDLsmkYW81megllNsxzmugnxalpiKUX62xCvCB9KudijFmaphcZOc65lGUFGvOdOjCN4zJiRnoJtulO0QFeinGqwWZLMhgMSYIgLJ1ROjSHxbiDALYyJsZOCcJ6GtOZDMYv04LgojBbSItCPWezLeMwV0qZOD/N8+0U5jsYnu8mNq00xm+R4FlRJHHMZkymHdMpMyZhp66SFrgW2sSvJKmv5USxjYuWAQcpjFczgrCDfC9kRdzBkxLRIq9xIn4hCjDyvIVADxiNxqd1+To8jUQjTm2cyVTCmPg15HwTqa2HBHiJ5rgSAtJ/svP1LAjQQhRrRGk9+kcVX0VSfkMHUSxbSOAMMcrX60fUKgzDGCmB69JV679+oyBU6k3QQXotybmJAN067G8U4WQNCNJOzAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/1158931f050c8b09edd6350c1eca9d0c/12f09/cilium.png\" srcset=\"/static/1158931f050c8b09edd6350c1eca9d0c/12f09/cilium.png 148w\" sizes=\"(max-width: 148px) 100vw, 148px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><a href=\"https://www.solo.io/topics/cilium/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium</a> is an open-source project that enables networking, security, and observability for Kubernetes clusters and other containerized environments.</p>\n<p>It is based on a technology called <a href=\"https://ebpf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">eBPF</a>, which can inject network control logic, security controls, and observability features directly into the Linux kernel.</p>\n<p><a href=\"https://docs.cilium.io/en/stable/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium CNI</a> is a powerful networking plugin for Kubernetes which provides enhanced security and networking capabilities for containerised applications. It leverages the power of eBPF (extended Berkeley Packet Filter), a highly efficient and programmable kernel-level technology, to deliver transparent network security and traffic monitoring features.</p>\n<p>Cilium uses VXLAN to form an overlay network and extended Berkeley Packet Filter to manage network connectivity and application rules. It supports both IPv4 and IPv6 addressing and uses BGP for unencapsulated routing. Cilium can support multiple Kubernetes clusters and, like Multus, provides multi-CNI capabilities.</p>\n<p>Cilium handles aspects of network management, such as network policies, through HTTP request filters. Policies can be written to YAML or JSON files, both of which provide network traffic enforcement for incoming and outgoing traffic.</p>\n<blockquote>\n<p>Cilium can run using VXLAN as an overlay network for encapsulation and routingor BGP routing as an underlay network. Cilium used to rely on metallb to power it's BGP features, but since Cilium 1.3 it is possible to use their own implementation built on GoBGP.</p>\n</blockquote>\n<p>Cilium Is the only CNI with L7 aware policies. This means you can write Kubernetes networking policies that understand DNS, HTTP, and even Kafka.</p>\n<p>For example, you can write a DNS L7 networking policy to:</p>\n<p><strong>🧩 Restrict DNS Resolution to Subset:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> cilium.io/v2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CiliumClusterwideNetworkPolicy\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dns<span class=\"token punctuation\">-</span>allow<span class=\"token punctuation\">-</span>list\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">endpointSelector</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token key atrule\">egress</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">toEndpoints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchLabels</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">io.kubernetes.pod.namespace</span><span class=\"token punctuation\">:</span> kube<span class=\"token punctuation\">-</span>system\n        <span class=\"token key atrule\">k8s-app</span><span class=\"token punctuation\">:</span> kube<span class=\"token punctuation\">-</span>dns\n      <span class=\"token key atrule\">toPorts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n          <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"53\"</span>\n            <span class=\"token key atrule\">protocol</span><span class=\"token punctuation\">:</span> UDP\n          <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">dns</span><span class=\"token punctuation\">:</span>\n              <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchPattern</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"*.abc.xyz\"</span>\n              <span class=\"token punctuation\">-</span> </code></pre></div>\n<p><strong>🧩 Allow POST HTTP requests to abc.xyz:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> cilium.io/v2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CiliumNetworkPolicy\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> http<span class=\"token punctuation\">-</span>post<span class=\"token punctuation\">-</span>abc<span class=\"token punctuation\">-</span>xyz\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">endpointSelector</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token key atrule\">egress</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">toPorts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"443\"</span>\n              <span class=\"token key atrule\">protocol</span><span class=\"token punctuation\">:</span> TCP\n      <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">http</span><span class=\"token punctuation\">:</span>\n          <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">method</span><span class=\"token punctuation\">:</span> POST\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">toFQDNs</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchPattern</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"*.abc.xyz\"</span></code></pre></div>\n<p><strong>🧩 Restrict Kafka Topic Access to the Following Pods:</strong></p>\n<p>Typically, we're forced to write networking policies like: \"Allow any application with the label kafka-consumer\" to speak to Kafka. This casts a rather wide net, when with L7 policies we can limit the access to individual topics depending on the labels. As such, we can say that only the \"beer-brewer\" can publish to the hops topic. Amazing, right?</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> cilium.io/v2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CiliumNetworkPolicy\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> beer<span class=\"token punctuation\">-</span>brewers\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">ingress</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">fromEndpoints</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchLabels</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">role</span><span class=\"token punctuation\">:</span> beer<span class=\"token punctuation\">-</span>brewer\n      <span class=\"token key atrule\">toPorts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">port</span><span class=\"token punctuation\">:</span> <span class=\"token number\">9092</span>\n              <span class=\"token key atrule\">protocol</span><span class=\"token punctuation\">:</span> TCP\n          <span class=\"token key atrule\">rules</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">kafka</span><span class=\"token punctuation\">:</span>\n              <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">role</span><span class=\"token punctuation\">:</span> produce\n                <span class=\"token key atrule\">topic</span><span class=\"token punctuation\">:</span> hops</code></pre></div>\n<h3 id=\"-developer-experience\" style=\"position:relative;\"><a href=\"#-developer-experience\" aria-label=\" developer experience permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🎩 Developer experience</h3>\n<p>Now don't worry if these resources look difficult, because Cilium has that covered too. All of these network policies can be visualised, modified, and event constructed through an entirely point and click visual builder.</p>\n<p>Check out the <a href=\"https://editor.networkpolicy.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium Editor</a> to see for yourself.</p>\n<h3 id=\"-installing-cilium\" style=\"position:relative;\"><a href=\"#-installing-cilium\" aria-label=\" installing cilium permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🐧 Installing Cilium</h3>\n<p>Cilium is installable as a Helm chart. So you'll first need to make the repository available:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm repo <span class=\"token function\">add</span> cilium https://helm.cilium.io/</code></pre></div>\n<p>Next, we can begin to understand and tweak the default values for the installation we require.</p>\n<p>The highlights are:</p>\n<p><strong>IPAM mode:</strong></p>\n<p>Cilium has a few different modes to manage IPAM.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.mode</span><span class=\"token operator\">=</span>cluster-pool\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4PodCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4MaskSize</span><span class=\"token operator\">=</span><span class=\"token number\">23</span></code></pre></div>\n<p>Cilium also has a preview feature where the IPAM mode can be set to <code class=\"language-text\">cluster-pool-v2beta</code>,\nwhich allows for dynamic, resource usage-based, allocation of node CIDRs.</p>\n<p><strong>eBPF and XDP:</strong></p>\n<p>eBPF is a relatively new technology that runs within the Linux kernel and enables the execution of eBPF programs, which run in a sandbox environment.</p>\n<p>These programs allow for user-land code to run within the kernel with unprecedented performance; extending the capabilities of the kernel.</p>\n<p>XDP leverages eBPF to provide a highly performant packet processing pipeline that runs as soon as the networking driver receives the packet. What does this actually mean? Well, with XDP - Cilium can help mitigate DDOS attacks by dropping packets before they even hit the traditional networking stack.</p>\n<p>Cilium's use of eBPF and XDP means we're not reliant on iptables, so we can actually disable the kube-proxy altogether. You'll need to do this with kubeadm and through Cilium's deploy.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">kubeProxyReplacement</span><span class=\"token operator\">=</span>probe</code></pre></div>\n<p><strong>Native routing:</strong></p>\n<p>As discussed above, Cilium doesn't need encapsulation to handle the routing of packets within our cluster; so let's ensure we enable it.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--nativeRoutingCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16</code></pre></div>\n<p><strong>Hubble:</strong></p>\n<p>As Hubble and Cilium observability is a big part of the appeal, let's not forget to enable it.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.relay.enabled</span><span class=\"token operator\">=</span>true\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.enabled</span><span class=\"token operator\">=</span>true\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.listenAddress</span><span class=\"token operator\">=</span><span class=\"token string\">\":4244\"</span>\n<span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.ui.enabled</span><span class=\"token operator\">=</span>true</code></pre></div>\n<p><strong>Complete install:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm repo <span class=\"token function\">add</span> cilium https://helm.cilium.io/\nhelm upgrade <span class=\"token parameter variable\">--install</span> cilium/cilium cilium <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--version</span> <span class=\"token number\">1.13</span>.4 <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--namespace</span> kube-system <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">image.repository</span><span class=\"token operator\">=</span>quay.io/cilium/cilium <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.mode</span><span class=\"token operator\">=</span>cluster-pool <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4PodCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16 <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.ipam.operator.clusterPoolIPv4MaskSize</span><span class=\"token operator\">=</span><span class=\"token number\">23</span> <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.nativeRoutingCIDR</span><span class=\"token operator\">=</span><span class=\"token number\">192.168</span>.0.0/16 <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.endpointRoutes.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.relay.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.listenAddress</span><span class=\"token operator\">=</span><span class=\"token string\">\":4244\"</span> <span class=\"token punctuation\">\\</span>\n                <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">global.hubble.ui.enabled</span><span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">kubeProxyReplacement</span><span class=\"token operator\">=</span>probe <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">k8sServiceHost</span><span class=\"token operator\">=</span><span class=\"token variable\">${PUBLIC_IPv4}</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">k8sServicePort</span><span class=\"token operator\">=</span><span class=\"token number\">6443</span></code></pre></div>\n<p>Cilium might be much newer to the Kubernetes CNI landscape, but in its short time,\nit has become the gold standard for Kubernetes networking.</p>\n<p>While Calico is also a great option, Cilium's adoption of eBPF and XDP provides a future-facing solution,\nenriched with the best debugging tool available (Hubble) and the best developer experience with the assistance of the Cilium Editor.</p>\n<h2 id=\"closing-thoughts\" style=\"position:relative;\"><a href=\"#closing-thoughts\" aria-label=\"closing thoughts permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Closing thoughts</h2>\n<p>Kubernetes networking is powered by two vital components: Kube-Proxy and CNI.</p>\n<p>Kube-Proxy maintains network rules and forwards traffic to Pods, while CNI provides a common interface to the underlying network. These components are essential for running containerized applications on Kubernetes.</p>\n<br>\n<p><strong><em>Until next time, つづく 🎉</em></strong></p>\n<blockquote>\n<p>💡 Thank you for Reading !! 🙌🏻😁📃, see you in the next blog.🤘  <em><strong>Until next time 🎉</strong></em></p>\n</blockquote>\n<p>🚀 Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>♻️ LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>♻️ X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ✌🏻</strong></p>\n<h1 align=\"center\">🔰 Keep Learning !! Keep Sharing !! 🔰</h1>\n<p><strong>📅 Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":13,"rawMarkdownBody":"\n> **A Guide to Network Management in Kubernetes 🕸**\n\n## 📌 Overview\n\nKubernetes networking is a complex and fascinating topic, with many moving parts. `Kube-Proxy` and `CNI` are two essential components of Kubernetes networking, working together to enable excellent communication between various components.\n\n[Kube-Proxy](https://kubernetes.io/docs/concepts/overview/components/#kube-proxy) is a network proxy that runs on each node in a Kubernetes cluster. It is responsible for maintaining network connectivity between services and pods. Kube-Proxy does this by translating service definitions into actionable networking rules.\n\n[CNI](https://www.cni.dev/), The Container Network Interface (CNI) is a specification for configuring networking resources in Kubernetes. CNI provides a dynamic framework for provisioning IP addresses, establishing cross-host connectivity, and configuring overlay or underlay networks.\n\nThis blog post will explore the inner workings of **Kube-Proxy** and **CNI**, and dive into how they integrate with Kubernetes. We will also discuss different Kubernetes network plugins.\n\n## ↳ Kube-Proxy: Kubernetes network proxy\n\nIn Kubernetes, the ephemeral nature of Pods means their IP addresses can change, making it challenging to establish stable connections 🤔. This is where the Service object comes into play. Services provide a consistent IP address to access Pods and are linked to a group of Pods. When traffic arrives at a Service, it is intelligently directed to the relevant backend Pods.\n\nBut how does this mapping of _`Service to Pod`_ actually function at the networking level? This is where Kube-Proxy excel.\n\nKube-Proxy serves as a vital Kubernetes agent that resides on each node within the cluster. Its primary role involves monitoring changes to Service objects and their corresponding endpoints. It then translates these changes into tangible network rules within the node.\n\nTypically, Kube-Proxy operates within your cluster as a DaemonSet. However, depending on your cluster's installation type, it can also be directly installed as a Linux process on the node. Regardless of the setup, Kube-Proxy is the unsung hero ensuring that your network traffic efficiently reaches the right destinations in your Kubernetes cluster.\n\n### 💭 How Kube-proxy works\n\nOnce `kube-proxy` is installed, it establishes authentication with the `API server`. As new **Services** or **endpoints** are introduced or removed, the API server promptly communicates these changes to Kube-Proxy.\n\nKube-Proxy takes these updates and translates them into `Network Address Translation (NAT)` rules within the node.\n\n> These NAT rules are essentially mappings, linking Service IP addresses to Pod IP addresses.\n\nWhen traffic is directed towards a Service, it adheres to these rules, leading it to the appropriate backend Pod.\n\nTo illustrate this process further, let's consider an example:\n\nImagine we have a Service named `SVC01` with a `ClusterIP` type. When `SVC01` is created, the API server examines which Pods should be associated with this Service by matching labels to the Service's label selector. In our case, let's call these Pods `Pod01` and `Pod02`. Subsequently, the API server creates an abstraction known as an `endpoint`, representing the IP address of each of these Pods. So, `SVC01` becomes linked to `2 endpoints`, denoted as `EP01` and `EP02`.\n\nIn the final step, the API server maps the IP address of `SVC01` to the IP addresses of `EP01` and `EP02`, solidifying the connection between the Service and its associated endpoints.\n\n![alt text](./step1.png)\n![alt text](./step2.png)\n![alt text](./step3.png)\n\n\nAll of this configuration is currently only part of the control plane. We want this mapping to be actually implemented on the network. Once it is applied, traffic coming to the IP of `SVC01` will be forwarded to `EP01` or `EP02`.\n\nSo here comes the `Kube-Proxy`. The API server will advertise these updates to the Kube-proxy on each node. Which will apply it as internal rules to the node.\n\n![alt text](./step4.png)\n![alt text](./step5.png)\n\nNow traffic destined for the `SVC01` IP will follow this [DNAT](https://en.wikipedia.org/wiki/Network_address_translation#DNAT) rule and get forwarded to the Pods. \n\n> Remember that `EP01` and `EP02` are basically the IPs of the Pods.\n\n![alt text](./step6.png)\n![alt text](./step7.png)\n\nNow of course I tried to keep the scenario as simple as possible. This is just to focus on the important part of the Kube-Proxy.\n\nThere are a couple of points that are worth mentioning:\n\n* **IP and port mappings:** Services and endpoints in Kubernetes represent IP and port mappings, ensuring proper routing of traffic to specific combinations of IP addresses and ports within the cluster.\n* **ClusterIP and DNAT translation:** ClusterIP services use DNAT (Destination Network Address Translation) on the source node, keeping their IPs hidden from external access. They function as internal NAT rules, exclusively accessible within the cluster.\n* **Service types and rode rules**: Different service types can lead to the installation of distinct rules within nodes. These rules may be organized into chains, specific sets of rules with defined order in the traffic path.\n* **Random pod selection:** By default, NAT rules select a random Pod to handle incoming traffic. However, this behavior can vary depending on the chosen Kube-Proxy mode, which determines the load balancing strategy for routing traffic to Pods.\n\n\n## 💭 Understanding Kube-Proxy modes\n\nKube-Proxy operates in various modes, each with its approach to implementing NAT rules. To grasp their workings and nuances, let's explore these modes:\n\n### ✅ IPtables mode\n\nThis is the default and widely used mode. Kube-Proxy relies on `IPtables`, a Linux feature for packet processing and filtering. In this mode, Kube-Proxy inserts `Service-to-Pod NAT` rules into IPtables, redirecting traffic from Service IP to Pod IP.\n\nHowever, IPtables can become less efficient with a large number of rules, as its sequential algorithm results in O(n) performance. It also lacks specific load balancing algorithms, using a random equal-cost distribution.\n\nNow the Kube-Proxy role can be described more as the \"installer\" of the rules.\n\n![alt text](./iptables-modes.png)\n\n### ✅ IPVS mode\n\nIPVS (IP Virtual Server) is designed for load balancing and offers efficient lookup with O(1) complexity, ensuring consistent performance regardless of rule count. Kube-Proxy in this mode inserts rules into IPVS instead of IPtables.\n\nIPVS supports various load balancing algorithms like round robin and least connections. Note that IPVS may not be available on all Linux systems, unlike IPtables.\n\n### ✅ KernelSpace mode\n\nThis mode is exclusive to Windows nodes. Kube-Proxy utilizes Windows Virtual Filtering Platform (VFP) to insert packet filtering rules. VFP works similarly to IPtables on Linux, responsible for packet encapsulation and destination IP address replacement. If you're familiar with virtual machines on the Windows platform, think of VFP as an extension of the Hyper-V switch.\n\n### ✅ Userspace mode\n\nIn the early days, Kube-Proxy used the Userspace mode, where it managed connections by proxying them through a user-level process. While charming and simple, this mode is less efficient than others and is akin to riding a bike with training wheels.\n\nEach Kube-Proxy mode has its advantages and limitations, making the choice of mode an essential consideration based on your specific cluster's needs and infrastructure.\n\n**⛓ Checking Kube-Proxy mode**\n\nTo determine the mode in which Kube-Proxy is running, you can use the `/proxyMode` endpoint, which Kube-Proxy exposes for querying information. \n\nHere's how you can do it:\n\n* **SSH into a cluster node:** Connect to one of the nodes within your Kubernetes cluster using SSH.\n*** Use curl to query Kube-Proxy:** Once connected, execute the following command using curl to query the Kube-Proxy mode:\n\n```shell\ncurl -v localhost:10249/proxyMode\n```\n\nThis command will retrieve information about the Kube-Proxy mode, helping you verify which mode it is currently operating in.\n\n![alt text](./kp-mode.png)\n\nHere you can see the last line that Kube-Proxy is using `iptables` mode.\n\n**Recap: Kubernetes Service and Kube-Proxy:**\n\n* A Kubernetes Service operates akin to a proxy by providing a stable IP address for client connections. It directs traffic received at this IP to the corresponding backend Pod IP, effectively solving the issue of Pods' dynamic IP changes.\n* In terms of load balancing, it depends on which aspect of Kube-Proxy is under consideration. The Kube-Proxy agent itself does not handle traffic or perform load balancing; it's solely part of the control plane responsible for creating Service rules. However, Kube-Proxy, through the rules it generates, facilitates load balancing by distributing traffic across multiple identical Pods associated with a specific Service. These Pods serve as replicas and collectively handle incoming requests.\n\n\n## ↳ Container Network Interface CNI\n\nContainer Network Interface (CNI) is a framework that allows you to dynamically configure networking resources for your Kubernetes clusters. It uses a plugin architecture, so you can use the CNI plugins that best meet your needs.\n\nCNI can be used to configure both `overlay` and `underlay` networks:\n\n* **Overlay networks** encapsulate network traffic using a virtual interface such as [Virtual Extensible LAN (VXLAN)](https://datatracker.ietf.org/doc/html/rfc7348).\n* **Underlay networks** work at the physical level and comprise switches and routers.\n\nOnce you've chosen a network configuration type, the container runtime defines the network that containers will join. The runtime adds the interface to the container namespace via a call to the CNI plugin and allocates the connected subnetwork routes via calls to the I`P Address Management (IPAM)` plugin.\n\nCNI can be used with Kubernetes and other Kubernetes-based container orchestration platforms such as OpenShift. It uses a software-defined networking (SDN) approach to unify container communication throughout clusters.\n\n\n## 📍 Kubernetes networking\n\nKubernetes provides networking for containerized applications with a flat network structure. This eliminates the need to map host ports to container ports, enabling the operation of a distributed system without dynamic port allocation.\n\nThe networking architecture in Kubernetes is based on the Container Network Interface (CNI) plugin specification. This plugin acts as a common interface between the Kubernetes runtime and the underlying network, supporting various networking solutions like Flannel, Calico, Weave Net, and Cilium.\n\n\n### How Kubernetes networking works?\n\nWhen a Kubernetes Pod is created, the CNI plugin configures the network interface, assigning an IP address to the Pod. This facilitates communication within the Kubernetes Pod network, which is a flat network accessible to all Pods in the cluster.\n\nAdditionally, Pods can interact with external applications through the Kubernetes Service network, a virtual network that exposes Pods to external entities.\n\nKubernetes networking offers several benefits:\n\n* `Portability`: Kubernetes clusters can be deployed across different cloud providers and on-premises environments.\n* `Scalability`: It supports a large number of Pods within a Kubernetes cluster.\n* `Reliability`: Ensures consistent connectivity for Pods in a Kubernetes cluster.\n\n\nBoth Linux container and container networking technology are continuing to evolve to meet the needs of applications running in various environments. CNI is an initiative of the Cloud-Native Computing Foundation (CNCF), which specifies the configuration of Linux container network interfaces.\n\nCNI was created to make networking solutions integratable with a range of container orchestration systems and runtimes. Instead of making the networking solutions pluggable, it defines a common interface standard for both the networking and container execution layers.\n\n\n<div class=\"note\">\n    <p><strong>🔵 Note:</strong></p>\n    <p>CNI is not native to Kubernetes. Developers using the CNI standard can create network plugins to interoperate with a variety of container runtimes. CNI networks can use an encapsulated network model,\n    such as <a href=\"https://www.techtarget.com/whatis/definition/VXLAN\">Virtual Extensible LAN (VXLAN)</a>, or an unencapsulated - also known as decapsulated - network model, such as <a href=\"https://www.techtarget.com/searchnetworking/definition/BGP-Border-Gateway-Protocol\">Border Gateway Protocol (BGP).</a></p>\n</div>\n\n\n\n**How CNI works?**\n\nCNI uses a plugin architecture to configure the Kubernetes cluster's networking. The CNI plugin is responsible for creating and configuring the network interface for each container. When a container is created,\nthe Kubernetes kubelet calls the CNI plugin to set up the network interface, assign an IP address, and add it to the Kubernetes network.\n\n\nThe CNI plugin also interacts with the `IP Address Management (IPAM) plugin` to allocate IP addresses to containers. This involves managing the pool of available IP addresses and assigning them as needed. Once the network interface is established, the kubelet starts the container,\nenabling it to communicate with other containers on the Kubernetes network.\n\nCNI focuses on the connectivity of container networks and the removal of allocated resources upon the termination of containers. This focus makes CNI specifications simple and allows them to be widely adopted.\nFor additional information on CNI specifications, including third-party plugins and runtimes, refer to the [CNI GitHub project](https://github.com/containernetworking/cni).\n\n\n## 🧵Diverse Kubernetes network plugins necessity\n\nKubernetes relies on a rich ecosystem of network plugins, many of which are endorsed and widely adopted by major container orchestration platforms, with Kubernetes at the forefront.\n\nThese plugins play a crucial role in enabling various container networking functions, all while adhering to the rigorous standards set forth in the Container Network Interface (CNI) specification. Given the inherent complexity of networking, CNI thoughtfully delineates specifications for multiple plugins, recognizing that user requirements can greatly vary.\n\nWithin the realm of CNI, networks can be instantiated using two primary models: `encapsulated` and `unencapsulated`.\n\n**The encapsulated(Overlay) network model:**\n\nThis model is represented by technologies like `VXLAN` and `IPsec`, overlays a logical Layer 2 network over an existing Layer 3 network topology. This approach simplifies routing complexity and minimizes overhead.\n\nIt relies on UDP ports to disseminate encapsulation data among Kubernetes workers, creating a bridge connecting these workers and pods. Communication management within pods is then expertly handled by Docker or alternative container engines.\n\nThis encapsulated network model proves particularly advantageous for scenarios that favor a Layer 2 bridge, especially those sensitive to Kubernetes worker latencies in a Layer 3 environment. \n\nFor distributed data centers spanning distinct geographic locales, minimizing latency is pivotal in preventing network segmentation.\n\n![alt text](./overlay.png)\n\n**🧩 The unencapsulated(Underlay) network model:**\n\nThis model extends a Layer 3 network to facilitate the routing of packets among containers. Unlike the encapsulated counterpart, this model does not introduce an isolated Layer 2 network or any associated overhead. However, it places the onus of managing necessary route distribution squarely on the shoulders of Kubernetes workers.\n\nTo make this work, a network protocol is put into action, connecting Kubernetes workers and utilizing the Border Gateway Protocol (BGP) to efficiently propagate routing information to pods. Within these pods, the role of overseeing communication with workloads is assumed by Docker or a comparable container engine. The unencapsulated network model is ideally suited for scenarios favoring a routed Layer 3 network.\n\nHere, routes for Kubernetes workers undergo dynamic updates at the operating system level, effectively mitigating latency concerns. In essence, Kubernetes networking unfolds as a multifaceted landscape, offering a plethora of plugin choices while accommodating diverse network models tailored to the distinct needs of your containerized workloads.\n\n![alt text](./underlay.png)\n\n## 🐝 CNI with Cilium\n\n![alt text](./cilium.png)\n\n\n[Cilium](https://www.solo.io/topics/cilium/) is an open-source project that enables networking, security, and observability for Kubernetes clusters and other containerized environments.\n\nIt is based on a technology called [eBPF](https://ebpf.io/), which can inject network control logic, security controls, and observability features directly into the Linux kernel.\n\n[Cilium CNI](https://docs.cilium.io/en/stable/) is a powerful networking plugin for Kubernetes which provides enhanced security and networking capabilities for containerised applications. It leverages the power of eBPF (extended Berkeley Packet Filter), a highly efficient and programmable kernel-level technology, to deliver transparent network security and traffic monitoring features.\n\nCilium uses VXLAN to form an overlay network and extended Berkeley Packet Filter to manage network connectivity and application rules. It supports both IPv4 and IPv6 addressing and uses BGP for unencapsulated routing. Cilium can support multiple Kubernetes clusters and, like Multus, provides multi-CNI capabilities.\n\nCilium handles aspects of network management, such as network policies, through HTTP request filters. Policies can be written to YAML or JSON files, both of which provide network traffic enforcement for incoming and outgoing traffic.\n\n > Cilium can run using VXLAN as an overlay network for encapsulation and routingor BGP routing as an underlay network. Cilium used to rely on metallb to power it's BGP features, but since Cilium 1.3 it is possible to use their own implementation built on GoBGP.\n\nCilium Is the only CNI with L7 aware policies. This means you can write Kubernetes networking policies that understand DNS, HTTP, and even Kafka.\n\nFor example, you can write a DNS L7 networking policy to:\n\n**🧩 Restrict DNS Resolution to Subset:**\n\n```yaml\napiVersion: cilium.io/v2\nkind: CiliumClusterwideNetworkPolicy\nmetadata:\n  name: dns-allow-list\nspec:\n  endpointSelector: {}\n  egress:\n    - toEndpoints:\n      - matchLabels:\n        io.kubernetes.pod.namespace: kube-system\n        k8s-app: kube-dns\n      toPorts:\n        - ports:\n          - port: \"53\"\n            protocol: UDP\n          rules:\n            dns:\n              - matchPattern: \"*.abc.xyz\"\n              - \n```\n\n**🧩 Allow POST HTTP requests to abc.xyz:**\n\n```yaml\napiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: http-post-abc-xyz\nspec:\n  endpointSelector: {}\n  egress:\n    - toPorts:\n        - ports:\n            - port: \"443\"\n              protocol: TCP\n      rules:\n        http:\n          - method: POST\n    - toFQDNs:\n        - matchPattern: \"*.abc.xyz\"\n```\n\n**🧩 Restrict Kafka Topic Access to the Following Pods:**\n\nTypically, we're forced to write networking policies like: \"Allow any application with the label kafka-consumer\" to speak to Kafka. This casts a rather wide net, when with L7 policies we can limit the access to individual topics depending on the labels. As such, we can say that only the \"beer-brewer\" can publish to the hops topic. Amazing, right?\n\n```yaml\napiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: beer-brewers\nspec:\n  ingress:\n    - fromEndpoints:\n        - matchLabels:\n            role: beer-brewer\n      toPorts:\n        - ports:\n            - port: 9092\n              protocol: TCP\n          rules:\n            kafka:\n              - role: produce\n                topic: hops\n```\n\n\n### 🎩 Developer experience\n\nNow don't worry if these resources look difficult, because Cilium has that covered too. All of these network policies can be visualised, modified, and event constructed through an entirely point and click visual builder.\n\nCheck out the [Cilium Editor](https://editor.networkpolicy.io/) to see for yourself.\n\n### 🐧 Installing Cilium\n\nCilium is installable as a Helm chart. So you'll first need to make the repository available:\n\n```shell\nhelm repo add cilium https://helm.cilium.io/\n```\n\nNext, we can begin to understand and tweak the default values for the installation we require.\n\nThe highlights are:\n\n**IPAM mode:**\n\nCilium has a few different modes to manage IPAM.\n\n```shell\n--set global.ipam.mode=cluster-pool\n--set global.ipam.operator.clusterPoolIPv4PodCIDR=192.168.0.0/16\n--set global.ipam.operator.clusterPoolIPv4MaskSize=23\n```\n\nCilium also has a preview feature where the IPAM mode can be set to `cluster-pool-v2beta`,\nwhich allows for dynamic, resource usage-based, allocation of node CIDRs.\n\n**eBPF and XDP:**\n\neBPF is a relatively new technology that runs within the Linux kernel and enables the execution of eBPF programs, which run in a sandbox environment.\n\nThese programs allow for user-land code to run within the kernel with unprecedented performance; extending the capabilities of the kernel.\n\nXDP leverages eBPF to provide a highly performant packet processing pipeline that runs as soon as the networking driver receives the packet. What does this actually mean? Well, with XDP - Cilium can help mitigate DDOS attacks by dropping packets before they even hit the traditional networking stack.\n\nCilium's use of eBPF and XDP means we're not reliant on iptables, so we can actually disable the kube-proxy altogether. You'll need to do this with kubeadm and through Cilium's deploy.\n\n```shell\n--set kubeProxyReplacement=probe\n```\n\n**Native routing:**\n\nAs discussed above, Cilium doesn't need encapsulation to handle the routing of packets within our cluster; so let's ensure we enable it.\n\n```shell\n--nativeRoutingCIDR=192.168.0.0/16\n```\n\n**Hubble:**\n\nAs Hubble and Cilium observability is a big part of the appeal, let's not forget to enable it.\n\n```shell\n--set global.hubble.relay.enabled=true\n--set global.hubble.enabled=true\n--set global.hubble.listenAddress=\":4244\"\n--set global.hubble.ui.enabled=true\n```\n\n**Complete install:**\n\n```shell\nhelm repo add cilium https://helm.cilium.io/\nhelm upgrade --install cilium/cilium cilium \\\n                --version 1.13.4 \\\n                --namespace kube-system \\\n                --set image.repository=quay.io/cilium/cilium \\\n                --set global.ipam.mode=cluster-pool \\\n                --set global.ipam.operator.clusterPoolIPv4PodCIDR=192.168.0.0/16 \\\n                --set global.ipam.operator.clusterPoolIPv4MaskSize=23 \\\n                --set global.nativeRoutingCIDR=192.168.0.0/16 \\\n                --set global.endpointRoutes.enabled=true \\\n                --set global.hubble.relay.enabled=true \\\n                --set global.hubble.enabled=true \\\n                --set global.hubble.listenAddress=\":4244\" \\\n                --set global.hubble.ui.enabled=true \\\n    --set kubeProxyReplacement=probe \\\n    --set k8sServiceHost=${PUBLIC_IPv4} \\\n    --set k8sServicePort=6443\n```\n\nCilium might be much newer to the Kubernetes CNI landscape, but in its short time,\nit has become the gold standard for Kubernetes networking.\n\nWhile Calico is also a great option, Cilium's adoption of eBPF and XDP provides a future-facing solution,\nenriched with the best debugging tool available (Hubble) and the best developer experience with the assistance of the Cilium Editor.\n\n## Closing thoughts\n\nKubernetes networking is powered by two vital components: Kube-Proxy and CNI.\n\nKube-Proxy maintains network rules and forwards traffic to Pods, while CNI provides a common interface to the underlying network. These components are essential for running containerized applications on Kubernetes.\n\n<br>\n\n**_Until next time, つづく 🎉_**\n\n> 💡 Thank you for Reading !! 🙌🏻😁📃, see you in the next blog.🤘  _**Until next time 🎉**_\n\n🚀 Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**♻️ LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**♻️ X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ✌🏻**\n\n<h1 align=\"center\">🔰 Keep Learning !! Keep Sharing !! 🔰</h1>\n\n**📅 Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":2995},"frontmatter":{"id":"0d690834e47b5f2d52075a36","path":"/blog/kubernetes-networking/","humanDate":"Oct 15, 2024","fullDate":"2024-10-15","title":"Kube-Proxy and CNI: The Hidden Components of Kubernetes Networking","keywords":["Kubernetes","Kube-Proxy","CNI","Kubernetes networking","Network management","Cluster communication","Container networking"],"excerpt":"Explore the essential yet often overlooked components of Kubernetes networking. This guide sheds light on Kube-Proxy and Container Network Interface CNI","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAgADBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHvOhsc4//EABgQAQEAAwAAAAAAAAAAAAAAAAABITFB/9oACAEBAAEFAsJuOo//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAXEAEAAwAAAAAAAAAAAAAAAAABEBEg/9oACAEBAAY/Aqwkf//EABkQAAMBAQEAAAAAAAAAAAAAAAABETFRYf/aAAgBAQABPyFxEa8GOMZjrhKwSKH/2gAMAwEAAgADAAAAEPAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxABAQACAwEAAAAAAAAAAAAAAREAMSFBcYH/2gAIAQEAAT8QXiA4tKV0TsxiuGKcGUlkBPuE4w3ezzAEGs//2Q=="},"images":{"fallback":{"src":"/static/9b2db3ad10894dbbfb2da5970f515dbc/29ba9/k8s-networking-cover.jpg","srcSet":"/static/9b2db3ad10894dbbfb2da5970f515dbc/7284f/k8s-networking-cover.jpg 750w,\n/static/9b2db3ad10894dbbfb2da5970f515dbc/29ba9/k8s-networking-cover.jpg 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/9b2db3ad10894dbbfb2da5970f515dbc/57584/k8s-networking-cover.webp 750w,\n/static/9b2db3ad10894dbbfb2da5970f515dbc/984df/k8s-networking-cover.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6666666666666666}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/pod-lifecycle-journey/","title":"The journey of a pod: The world of pod lifecycle","date":"2024-10-16 12:06:00"},"excerpt":"Key states of a Pod lifecycle 📚 Introduction The Pod lifecycle is crucial to managing containers in a Kubernetes environment. Understanding…"},"nextThought":{"frontmatter":{"path":"/blog/kubernetes-dns/","title":"Connecting the Dots: Understanding How Pods Talk in Kubernetes Networks","date":"2024-10-15 19:06:00"},"excerpt":"Kubernetes DNS Expedition🔥 📚 Introduction Kubernetes is an orchestration system for managing containerized applications. One of its key…"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}