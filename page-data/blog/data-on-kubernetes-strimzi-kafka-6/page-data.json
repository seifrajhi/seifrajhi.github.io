{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/data-on-kubernetes-strimzi-kafka-6/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>Kubernetes-native data streaming powered by Apache Kafka</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ† Introduction</h2>\n<p>In this part six of my series about data on Kubernetes, we will explore how Strimzi makes it easier to run Apache Kafka on Kubernetes.</p>\n<p>Strimzi provides a set of tools and operators that help manage Kafka clusters in a Kubernetes environment. <a href=\"https://strimzi.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Strimzi</a> simplifies the process, making it more accessible and manageable.</p>\n<p>We will cover the key features of Strimzi, its benefits, and how you can get started with deploying Kafka on Kubernetes.</p>\n<h2 id=\"-apache-kafka-overview\" style=\"position:relative;\"><a href=\"#-apache-kafka-overview\" aria-label=\" apache kafka overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ“œ Apache Kafka Overview</h2>\n<p>Apache Kafka is an open-source platform designed for building real-time data pipelines and streaming applications. It is highly scalable, fault-tolerant, and designed to handle large volumes of data with low latency.</p>\n<h3 id=\"-key-capabilities-and-features\" style=\"position:relative;\"><a href=\"#-key-capabilities-and-features\" aria-label=\" key capabilities and features permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ”‘ Key Capabilities and Features</h3>\n<ul>\n<li><strong>High throughput</strong>: Kafka can process millions of messages per second, making it suitable for high-volume data streams.</li>\n<li><strong>Scalability</strong>: Kafka can scale horizontally by adding more brokers to the cluster, ensuring it can handle increasing loads.</li>\n<li><strong>Durability</strong>: Data in Kafka is replicated across multiple brokers, ensuring it is not lost even if some brokers fail.</li>\n<li><strong>Low latency</strong>: Kafka is designed to deliver messages with minimal delay, making it ideal for real-time applications.</li>\n<li><strong>Fault tolerance</strong>: Kafka's architecture ensures that the system continues to operate even in the presence of failures.</li>\n</ul>\n<h3 id=\"-use-cases\" style=\"position:relative;\"><a href=\"#-use-cases\" aria-label=\" use cases permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ“ˆ Use Cases</h3>\n<ul>\n<li><strong>Real-time data streaming</strong>: Kafka is used to stream data in real-time from various sources like sensors, logs, and applications.</li>\n<li><strong>Event sourcing</strong>: Kafka can capture and store events, making it useful for event-driven architectures.</li>\n<li><strong>Log aggregation</strong>: Kafka collects and aggregates logs from different systems, providing a centralized log management solution.</li>\n<li><strong>Metrics collection</strong>: Kafka can gather and process metrics from various applications and systems for monitoring and analysis.</li>\n<li><strong>Data integration</strong>: Kafka acts as a central hub for integrating data from different sources and distributing it to various destinations.</li>\n</ul>\n<p><img src=\"/e653bb47e6033ee31233395b74fc61ea/use_cases.gif\" alt=\"use_cases\" loading=\"lazy\">\n          </p>\n<div class=\"image-title\"><a href=\"https://blog.amigoscode.com/p/kafka-explained\">Source: Amigoscode</a></div>\n<h3 id=\"ï¸-component-architecture\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-component-architecture\" aria-label=\"ï¸ component architecture permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ—ï¸ Component Architecture</h3>\n<ul>\n<li><strong>Brokers</strong>: Kafka brokers are servers that store and manage the data. They handle incoming data streams and distribute them to consumers.</li>\n<li><strong>Topics</strong>: Topics are categories or feeds to which data is sent. Each topic can have multiple partitions for parallel processing.</li>\n<li><strong>Partitions</strong>: Partitions are subsets of a topic. They allow Kafka to scale horizontally and provide fault tolerance.</li>\n<li><strong>Producers</strong>: Producers are applications that send data to Kafka topics.</li>\n<li><strong>Consumers</strong>: Consumers are applications that read data from Kafka topics.</li>\n<li><strong>ZooKeeper</strong>: ZooKeeper is used to manage and coordinate Kafka brokers. It handles tasks like leader election and configuration management.</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACNklEQVR42n2T65KaQBSEff9nSqWSNWsliIqsyh3BQW4DstxFxM6BqvzIms1UTTHA8J1Dd88M/xiPxwPX6xVd19F6+PN0fIHb7YaqqtG27bTv45jhk8E5R1kW6AiQ5RXyssGtv6MoCniehziO0fc9mr5BWibI6gvuQ/8MHIaBPiqRvecoqwqqbuPldYn5QgDzfFySBCnNsiynP1BNBYvlK9ayiOZaPwObpoVtajBVGdphC0lcwDQ07BUNm+0O8k6BoltTh6MMDvMh7U0cdIdk6jDLyxan4IKQF6jbDl6YIAls6NIPrBdf4BlrpBGDe47xayXjhTrVrBNOXoD3vMDJ59ioDJoT49rdMGNxDnmvw3JDHFkEWbHAggRLWcfP1RtkncEPORK2h7r+jr34DdyRoBs6TOeMmCcwLBcuyTFKMHPiBqp1hu2lCOKMgDbK1EN03MLaCygCDRn3EaYldCfAm2rjTH+jEcQioGlZEDc7rKQd6VphNgwPcrInx+7k0oPMKOD7PlabLV7mc+wOCjiZEJ5MSMs5hNevOKoSwigi5yu4LIAg6ZBVF+2o4VMGyeWIZ+Qem7RSaKZUJItdMOsNjrFF4B5QV/m0v6RMBhEHTzPc78PfwIQ6OVBHqqLQmk9ZHK8VxYcnKbyzR8JfUVA+08tlyuQYs0+DHYYhRFEk6GGCH49HuK47ARljU7G6rilaDTRNmwr+FzgeJ0EQYNv2BIlIp1HP0T3DMKZiI2y8lyRpOjEfj95vGtCEA4vw5qgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"architecture\" title=\"\" src=\"/static/925e848d9930f34df57dc09f148f80c4/c5bb3/architecture.png\" srcset=\"/static/925e848d9930f34df57dc09f148f80c4/04472/architecture.png 170w,\n/static/925e848d9930f34df57dc09f148f80c4/9f933/architecture.png 340w,\n/static/925e848d9930f34df57dc09f148f80c4/c5bb3/architecture.png 680w,\n/static/925e848d9930f34df57dc09f148f80c4/b12f7/architecture.png 1020w,\n/static/925e848d9930f34df57dc09f148f80c4/b5a09/architecture.png 1360w,\n/static/925e848d9930f34df57dc09f148f80c4/07a9c/architecture.png 1440w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-kafka-connect\" style=\"position:relative;\"><a href=\"#-kafka-connect\" aria-label=\" kafka connect permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ”„ Kafka Connect</h2>\n<p>Kafka Connect is a tool for streaming data between Apache Kafka and other systems. It simplifies the process of integrating Kafka with databases, key-value stores, search indexes, and file systems.</p>\n<h3 id=\"how-kafka-connect-streams-data\" style=\"position:relative;\"><a href=\"#how-kafka-connect-streams-data\" aria-label=\"how kafka connect streams data permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>How Kafka Connect Streams Data</h3>\n<p>Kafka Connect uses connectors to stream data in and out of Kafka. There are two types of connectors:</p>\n<ul>\n<li><strong>Source Connectors</strong>: These connectors pull data from external systems and write it to Kafka topics.</li>\n<li><strong>Sink Connectors</strong>: These connectors read data from Kafka topics and write it to external systems.</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 40.588235294117645%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB5UlEQVR42nWSXWvTYBTH82lkN34C7wTxI4h4NfBGpngzL/VyoFZhYLVuZVTt6nTLmIKjlVLsoK5Q1na4rXWz69u6tUlT2sQ0SdPkZ5ZeDeaB88A55+HHefkLXDDXfxvdY3LVLXqa7MeO60yqrsvh2R57rR3MkcllJpiqjNXexez8wtJ7frJQz7BSeO2BK348skcTsOOQ2BcRC0v8HWp+TukPqXeGNCWdoWEhqOs3sVeuYkWvoCWmJ8DqNkvJl7R6dU4aLURxDUVRMEyDeHGd6I8Qo7HB0HSY+9xkTpR5HOvwZVtGUMJT9J4LaM8EBqs3MAyXnwcpFr8HaHarFPNFZmZmCAQCqJrKZn6V5a0Qmt5H6qrcf1tjev6I24E/RNNdBHlxCtmD9TyXY9eR5QHp3QTh5AskrUXpoMzso1mCwSDj8Zh4QeR9KujBTqnUTnmwUOXu/CF3Ar+9zj2gsXYNFgTcNwJG/JY/8k4lQ2jzKXWpwnGlSuRdhGbzhH6/z7fcJ5bTk5FNy+HJxzMeRhTuhWU2sj0E29Qw20X/KLal+8B8LUMs98rbYQ1jaFIqlzAN079ysrzB1/0PqPrA/6vqFrW2TkvWsccOwmWyqUlHZCspFFXiXDHnu7Nt2weWWkWKjex/ZfMPTRcvbxQvv54AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"connect\" title=\"\" src=\"/static/2538460b4e7737fa1e15261a79d3fd69/c5bb3/connect.png\" srcset=\"/static/2538460b4e7737fa1e15261a79d3fd69/04472/connect.png 170w,\n/static/2538460b4e7737fa1e15261a79d3fd69/9f933/connect.png 340w,\n/static/2538460b4e7737fa1e15261a79d3fd69/c5bb3/connect.png 680w,\n/static/2538460b4e7737fa1e15261a79d3fd69/b12f7/connect.png 1020w,\n/static/2538460b4e7737fa1e15261a79d3fd69/7a18f/connect.png 1284w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"use-cases\" style=\"position:relative;\"><a href=\"#use-cases\" aria-label=\"use cases permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Use Cases</h3>\n<ul>\n<li><strong>Database integration</strong>: Kafka Connect can stream data from databases like MySQL, PostgreSQL, and MongoDB into Kafka for real-time processing.</li>\n<li><strong>Data Lake ingestion</strong>: Kafka Connect can ingest data into data lakes like Hadoop and Amazon S3 for long-term storage and analysis.</li>\n<li><strong>Search indexing</strong>: Kafka Connect can stream data into search indexes like Elasticsearch for real-time search and analytics.</li>\n<li><strong>File system integration</strong>: Kafka Connect can read data from file systems and write it to Kafka, or vice versa.</li>\n</ul>\n<h3 id=\"key-features\" style=\"position:relative;\"><a href=\"#key-features\" aria-label=\"key features permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Key Features</h3>\n<ul>\n<li><strong>Scalability</strong>: Kafka Connect can scale horizontally by adding more workers, ensuring it can handle large data volumes.</li>\n<li><strong>Fault tolerance</strong>: Kafka Connect ensures data is not lost even if some connectors or workers fail.</li>\n<li><strong>Configuration management</strong>: Kafka Connect allows you to manage connector configurations centrally, making it easy to deploy and manage connectors.</li>\n<li><strong>Monitoring and management</strong>: Kafka Connect provides tools for monitoring and managing connectors, ensuring they operate smoothly.</li>\n</ul>\n<h2 id=\"kafka-on-kubernetes\" style=\"position:relative;\"><a href=\"#kafka-on-kubernetes\" aria-label=\"kafka on kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Kafka on Kubernetes</h2>\n<h3 id=\"strimzi-overview\" style=\"position:relative;\"><a href=\"#strimzi-overview\" aria-label=\"strimzi overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Strimzi Overview</h3>\n<p><strong>Strimzi</strong> provides a way to run an Apache Kafka cluster on Kubernetes in various deployment configurations. It simplifies the process, making it quick and efficient to get Kafka up and running.</p>\n<h3 id=\"-secure-by-default\" style=\"position:relative;\"><a href=\"#-secure-by-default\" aria-label=\" secure by default permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ”’ Secure by Default</h3>\n<p>Strimzi comes with built-in security features to ensure your Kafka cluster is protected:</p>\n<ul>\n<li><strong>TLS, SCRAM-SHA, and OAuth authentication</strong>: These protocols help secure communication and authenticate users.</li>\n<li><strong>Automated certificate management</strong>: Strimzi handles certificate generation and renewal automatically.</li>\n</ul>\n<h3 id=\"ï¸-simple-yet-configurable\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-simple-yet-configurable\" aria-label=\"ï¸ simple yet configurable permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>âš™ï¸ Simple yet Configurable</h3>\n<p>Strimzi offers flexibility in how you deploy and manage your Kafka cluster:</p>\n<ul>\n<li><strong>NodePort, Load Balancer, and Ingress options</strong>: Choose the best networking option for your needs.</li>\n<li><strong>Rack awareness for High Availability (HA)</strong>: Distribute Kafka brokers across different racks to ensure high availability.</li>\n<li><strong>Use dedicated nodes for Kafka</strong>: Assign specific nodes in your Kubernetes cluster to run Kafka for better performance and isolation.</li>\n</ul>\n<h3 id=\"ï¸-kubernetes-native-experience\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-kubernetes-native-experience\" aria-label=\"ï¸ kubernetes native experience permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ› ï¸ Kubernetes-Native Experience</h3>\n<p>Strimzi integrates seamlessly with Kubernetes, providing a native experience:</p>\n<ul>\n<li><strong>Use <code class=\"language-text\">kubectl</code> to manage Kafka</strong>: Leverage familiar Kubernetes tools to manage your Kafka cluster.</li>\n<li><strong>Operator-based management</strong>: Strimzi uses operators to automate the deployment and management of Kafka. (An operator is a method of packaging, deploying, and managing a Kubernetes application.)</li>\n<li><strong>Manage Kafka using GitOps</strong>: Apply GitOps principles to manage your Kafka configurations and deployments through version control.</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAABgElEQVR42n1R207jMBDlB9hH/pJ92a8CPoJnWGkroKW0SVOaixvbje3ErhNn7JRpixT2AY5Go7Hl45lz5uLwPdq2ZYxprb33QoiqqgDg64OLH8hSqueXaVGQrnNRHM/nb9a2eD8MwyeZUhrHMea9MYfBHwY4BIDeGetkYygXQmkMWetdpWRjfQhjZ6UUjtTUdQ9hq1wuOqKcA68ao7Up8gwfaKM5RwW01nvwX8hpmuI8vCwel/Ty9+Tqz9Ov63/3UwqunS+j6Wy2SpKypIxxShnlVQjDSEZXzH7fu05od/PAbh/Y3V+esRqxlbYUttjppNhVBljdVbo/6z3LHg3rwXOSkc2KkUwq9bpcv2Q65vC0Fo+L7SzXC+oi1v3X+fjNqeogpFSsM5qWR5MaYwveYCQ5XyR5RhXZaVIZdN4YI6W01o7ktvdpTpZRtMkKVZvOwZYy3BMuKY5X75sNSiYlrxuN58lkgmaNY6MKdBLC0PswnND7Y6C7GHCqMZ8FI0IIH70KMxWxrGIRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"strimzi\" title=\"\" src=\"/static/90d3b6b0101a9992524a4ddfaa50abcd/c5bb3/strimzi.png\" srcset=\"/static/90d3b6b0101a9992524a4ddfaa50abcd/04472/strimzi.png 170w,\n/static/90d3b6b0101a9992524a4ddfaa50abcd/9f933/strimzi.png 340w,\n/static/90d3b6b0101a9992524a4ddfaa50abcd/c5bb3/strimzi.png 680w,\n/static/90d3b6b0101a9992524a4ddfaa50abcd/b12f7/strimzi.png 1020w,\n/static/90d3b6b0101a9992524a4ddfaa50abcd/b5a09/strimzi.png 1360w,\n/static/90d3b6b0101a9992524a4ddfaa50abcd/891d5/strimzi.png 1520w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\"><a href=\"https://strimzi.io\">Source</a></div>\n<h2 id=\"-kafka-operators\" style=\"position:relative;\"><a href=\"#-kafka-operators\" aria-label=\" kafka operators permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ§‘â€ğŸ’» Kafka Operators</h2>\n<p>Operators are a method used to package, deploy, and manage applications on Kubernetes. They extend the Kubernetes API, making it easier to handle administrative tasks for specific applications.</p>\n<p><strong>Strimzi operators</strong> are designed to manage Kafka deployments. They use custom resources to define the deployment configurations, which include settings for Kafka clusters, topics, users, and other components.</p>\n<p>Strimzi offers several operators to manage a Kafka cluster within a Kubernetes environment:</p>\n<ul>\n<li><strong>Cluster operator</strong>: Responsible for deploying and managing Apache Kafka clusters, Kafka Connect, Kafka MirrorMaker, Kafka Bridge, Kafka Exporter, Cruise Control, and the Entity Operator.</li>\n<li><strong>Entity operator</strong>: Includes the Topic Operator and User Operator.\n<ul>\n<li><strong>Topic operator</strong>: Handles the management of Kafka topics.</li>\n<li><strong>User operator</strong>: Takes care of managing Kafka users.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ï¸-hands-on-deploying-strimzi-on-aws-eks\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-hands-on-deploying-strimzi-on-aws-eks\" aria-label=\"ï¸ hands on deploying strimzi on aws eks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ› ï¸ Hands-on: Deploying Strimzi on AWS EKS</h2>\n<p>In this section, we'll walk through the steps to deploy Strimzi on Amazon Elastic Kubernetes Service (EKS). This will involve setting up an EKS cluster, installing Strimzi, and deploying a Kafka cluster.</p>\n<h3 id=\"prerequisites\" style=\"position:relative;\"><a href=\"#prerequisites\" aria-label=\"prerequisites permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Prerequisites</h3>\n<ul>\n<li><strong>AWS Account</strong></li>\n<li><strong>AWS CLI</strong>: Install and configure the <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\" target=\"_blank\" rel=\"noopener noreferrer\">AWS CLI</a>.</li>\n<li><strong>kubectl</strong>: Install <a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\" rel=\"noopener noreferrer\">kubectl</a> to interact with your Kubernetes cluster.</li>\n<li><strong>eksctl</strong>: Install <a href=\"https://eksctl.io/\" target=\"_blank\" rel=\"noopener noreferrer\">eksctl</a> to create and manage EKS clusters.</li>\n</ul>\n<h3 id=\"step-1-create-an-eks-cluster\" style=\"position:relative;\"><a href=\"#step-1-create-an-eks-cluster\" aria-label=\"step 1 create an eks cluster permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Step 1: Create an EKS Cluster</h3>\n<p>Create the EKS Cluster:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ eksctl create cluster <span class=\"token parameter variable\">--name</span> demo-kafka-strimzi <span class=\"token parameter variable\">--region</span> eu-west-1 <span class=\"token punctuation\">\\</span>\n--nodegroup-name linux-nodes --node-type t3.medium <span class=\"token parameter variable\">--nodes</span> <span class=\"token number\">3</span> <span class=\"token punctuation\">\\</span>\n--nodes-min <span class=\"token number\">1</span> --nodes-max <span class=\"token number\">4</span> <span class=\"token parameter variable\">--managed</span></code></pre></div>\n<p>This command creates an EKS cluster named <code class=\"language-text\">demo-kafka-strimzi</code> in the <code class=\"language-text\">eu-west-1</code> region with a managed node group.</p>\n<p>Verify the Cluster:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">kubectl get nodes</code></pre></div>\n<p>Ensure your nodes are in the Ready state.</p>\n<h3 id=\"step-2-install-strimzi\" style=\"position:relative;\"><a href=\"#step-2-install-strimzi\" aria-label=\"step 2 install strimzi permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Step 2: Install Strimzi</h3>\n<p>Download the Strimzi YAML files:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ <span class=\"token function\">curl</span> <span class=\"token parameter variable\">-L</span> <span class=\"token string\">\"https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.43.0/strimzi-topic-operator-0.43.0.yaml\"</span> <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">-o</span> strimzi-cluster-operator.yaml</code></pre></div>\n<p>Create Strimzi namespace:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl create namespace strimzi</code></pre></div>\n<p>Deploy the Strimzi Cluster Operator:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ <span class=\"token function\">sed</span> <span class=\"token parameter variable\">-i</span> <span class=\"token string\">'s/namespace: myproject/namespace: strimzi/g'</span> strimzi-cluster-operator.yaml\n$ kubectl apply <span class=\"token parameter variable\">-f</span> strimzi-cluster-operator.yaml <span class=\"token parameter variable\">--namespace</span> strimzi</code></pre></div>\n<p>Verify the Deployment:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">kubectl get pods <span class=\"token parameter variable\">-n</span> strimzi</code></pre></div>\n<p>Ensure the Strimzi Cluster Operator pods are running.</p>\n<h3 id=\"step-3-deploy-kafka-node-pool-and-a-kafka-cluster\" style=\"position:relative;\"><a href=\"#step-3-deploy-kafka-node-pool-and-a-kafka-cluster\" aria-label=\"step 3 deploy kafka node pool and a kafka cluster permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Step 3: Deploy Kafka Node Pool and a Kafka Cluster</h3>\n<p>Create a Kafka Cluster YAML file:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> kafka.strimzi.io/v1beta2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> KafkaNodePool\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dual<span class=\"token punctuation\">-</span>role\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">strimzi.io/cluster</span><span class=\"token punctuation\">:</span> strimzi<span class=\"token punctuation\">-</span>cluster\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">replicas</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">roles</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> controller\n        <span class=\"token punctuation\">-</span> broker\n    <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> jbod\n        <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">id</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span>\n                <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> persistent<span class=\"token punctuation\">-</span>claim\n                <span class=\"token key atrule\">size</span><span class=\"token punctuation\">:</span> 100Gi\n                <span class=\"token key atrule\">deleteClaim</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">false</span>\n                <span class=\"token key atrule\">kraftMetadata</span><span class=\"token punctuation\">:</span> shared\n<span class=\"token punctuation\">---</span>\n\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> kafka.strimzi.io/v1beta2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Kafka\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> strimzi<span class=\"token punctuation\">-</span>cluster\n    <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> strimzi\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">kafka</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">version</span><span class=\"token punctuation\">:</span> 3.0.0\n        <span class=\"token key atrule\">replicas</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span>\n        <span class=\"token key atrule\">listeners</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">plain</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n            <span class=\"token key atrule\">tls</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n        <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> persistent<span class=\"token punctuation\">-</span>claim\n            <span class=\"token key atrule\">size</span><span class=\"token punctuation\">:</span> 100Gi\n            <span class=\"token key atrule\">class</span><span class=\"token punctuation\">:</span> gp2\n            <span class=\"token key atrule\">deleteClaim</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">false</span>\n    <span class=\"token key atrule\">zookeeper</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">replicas</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span>\n        <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> persistent<span class=\"token punctuation\">-</span>claim\n            <span class=\"token key atrule\">size</span><span class=\"token punctuation\">:</span> 100Gi\n            <span class=\"token key atrule\">class</span><span class=\"token punctuation\">:</span> gp2\n            <span class=\"token key atrule\">deleteClaim</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">false</span>\n    <span class=\"token key atrule\">entityOperator</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">topicOperator</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n        <span class=\"token key atrule\">userOperator</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span></code></pre></div>\n<p>Deploy the Kafka Cluster:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl apply <span class=\"token parameter variable\">-f</span> kafka-cluster.yaml</code></pre></div>\n<p>Verify the Kafka Cluster:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl get pods <span class=\"token parameter variable\">-n</span> strimzi</code></pre></div>\n<p>Ensure all Kafka and Zookeeper pods are running.</p>\n<h3 id=\"-send-and-receive-messages\" style=\"position:relative;\"><a href=\"#-send-and-receive-messages\" aria-label=\" send and receive messages permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ“¤ Send and Receive Messages</h3>\n<p>With the cluster running, run a simple producer to send messages to a Kafka topic (the topic is automatically created):</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl <span class=\"token parameter variable\">-n</span> strimzi run kafka-producer <span class=\"token parameter variable\">-ti</span> <span class=\"token parameter variable\">--image</span><span class=\"token operator\">=</span>quay.io/strimzi/kafka:0.43.0-kafka-3.8.0 <span class=\"token parameter variable\">--rm</span><span class=\"token operator\">=</span>true <span class=\"token parameter variable\">--restart</span><span class=\"token operator\">=</span>Never -- bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 <span class=\"token parameter variable\">--topic</span> my-topic</code></pre></div>\n<p>Once everything is set up correctly, you'll see a prompt where you can type in your messages:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token operator\">></span>Hello Strimzi<span class=\"token operator\">!</span></code></pre></div>\n<p>And to receive them in a different terminal, run:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl <span class=\"token parameter variable\">-n</span> kafka run kafka-consumer <span class=\"token parameter variable\">-ti</span> <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--image</span><span class=\"token operator\">=</span>quay.io/strimzi/kafka:0.43.0-kafka-3.8.0 <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--rm</span><span class=\"token operator\">=</span>true <span class=\"token parameter variable\">--restart</span><span class=\"token operator\">=</span>Never -- bin/kafka-console-consumer.sh <span class=\"token punctuation\">\\</span>\n--bootstrap-server my-cluster-kafka-bootstrap:9092 <span class=\"token punctuation\">\\</span>\n<span class=\"token parameter variable\">--topic</span> my-topic --from-beginning</code></pre></div>\n<p>If everything works as expected, you'll be able to see the message you produced in the previous step:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token operator\">></span>Hello Strimzi<span class=\"token operator\">!</span></code></pre></div>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>ğŸ”š Conclusion</h2>\n<p>In this part 6 of the blog series, we introduced Kafka, its features, components, Kafka Connect, and Strimzi. We also explored how to use Strimzi operators to manage Kafka on Kubernetes, covering the setup of an EKS cluster on AWS, the installation of Strimzi, and the deployment of a Kafka cluster.</p>\n<p>Dive deeper by following the <a href=\"https://strimzi.io/documentation/\" target=\"_blank\" rel=\"noopener noreferrer\">official documentation</a> for more detailed information.</p>\n<p><strong>Stay tuned for next blogs in thisÂ seriesğŸ‰</strong></p>\n<p><strong>References:</strong></p>\n<ul>\n<li><a href=\"https://github.com/strimzi/strimzi-kafka-operator\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/strimzi/strimzi-kafka-operator</a></li>\n<li><a href=\"https://strimzi.io/\" target=\"_blank\" rel=\"noopener noreferrer\">https://strimzi.io/</a></li>\n<li><a href=\"https://medium.com/@howdyservices9/strimzi-deploy-kafka-in-kubernetes-dd740364861c\" target=\"_blank\" rel=\"noopener noreferrer\">https://medium.com/@howdyservices9/strimzi-deploy-kafka-in-kubernetes-dd740364861c</a></li>\n<li><a href=\"https://piotrminkowski.com/2023/11/06/apache-kafka-on-kubernetes-with-strimzi/\" target=\"_blank\" rel=\"noopener noreferrer\">https://piotrminkowski.com/2023/11/06/apache-kafka-on-kubernetes-with-strimzi/</a></li>\n<li><a href=\"https://blog.devgenius.io/kafka-on-kubernetes-using-strimzi-part-2-71a8ba8e9605\" target=\"_blank\" rel=\"noopener noreferrer\">https://blog.devgenius.io/kafka-on-kubernetes-using-strimzi-part-2-71a8ba8e9605</a></li>\n<li><a href=\"https://www.linkedin.com/posts/nelsonamigoscode_systemdesign-coding-interviewtips-activity-7231623516704378883-lmCL\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/posts/nelsonamigoscode_systemdesign-coding-interviewtips-activity-7231623516704378883-lmCL</a></li>\n<li><a href=\"https://aws.amazon.com/blogs/containers/deploying-and-scaling-apache-kafka-on-amazon-eks/\" target=\"_blank\" rel=\"noopener noreferrer\">https://aws.amazon.com/blogs/containers/deploying-and-scaling-apache-kafka-on-amazon-eks/</a></li>\n</ul>\n<p><strong>Thank You ğŸ–¤</strong></p>\n<br>\n<p><strong><em>Until next time, ã¤ã¥ã ğŸ‰</em></strong></p>\n<blockquote>\n<p>ğŸ’¡ Thank you for Reading !! ğŸ™ŒğŸ»ğŸ˜ğŸ“ƒ, see you in the next blog.ğŸ¤˜  <strong><em>Until next time ğŸ‰</em></strong></p>\n</blockquote>\n<p>ğŸš€ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>â™»ï¸ LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>â™»ï¸ X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end âœŒğŸ»</strong></p>\n<h1 align=\"center\">ğŸ”° Keep Learning !! Keep Sharing !! ğŸ”°</h1>\n<p><strong>ğŸ“… Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":7,"rawMarkdownBody":"\n> **Kubernetes-native data streaming powered by Apache Kafka**\n\n## ğŸ† Introduction\n\nIn this part six of my series about data on Kubernetes, we will explore how Strimzi makes it easier to run Apache Kafka on Kubernetes.\n\nStrimzi provides a set of tools and operators that help manage Kafka clusters in a Kubernetes environment. [Strimzi](https://strimzi.io/) simplifies the process, making it more accessible and manageable.\n\nWe will cover the key features of Strimzi, its benefits, and how you can get started with deploying Kafka on Kubernetes.\n\n## ğŸ“œ Apache Kafka Overview\n\nApache Kafka is an open-source platform designed for building real-time data pipelines and streaming applications. It is highly scalable, fault-tolerant, and designed to handle large volumes of data with low latency.\n\n### ğŸ”‘ Key Capabilities and Features\n\n- **High throughput**: Kafka can process millions of messages per second, making it suitable for high-volume data streams.\n- **Scalability**: Kafka can scale horizontally by adding more brokers to the cluster, ensuring it can handle increasing loads.\n- **Durability**: Data in Kafka is replicated across multiple brokers, ensuring it is not lost even if some brokers fail.\n- **Low latency**: Kafka is designed to deliver messages with minimal delay, making it ideal for real-time applications.\n- **Fault tolerance**: Kafka's architecture ensures that the system continues to operate even in the presence of failures.\n\n### ğŸ“ˆ Use Cases\n\n- **Real-time data streaming**: Kafka is used to stream data in real-time from various sources like sensors, logs, and applications.\n- **Event sourcing**: Kafka can capture and store events, making it useful for event-driven architectures.\n- **Log aggregation**: Kafka collects and aggregates logs from different systems, providing a centralized log management solution.\n- **Metrics collection**: Kafka can gather and process metrics from various applications and systems for monitoring and analysis.\n- **Data integration**: Kafka acts as a central hub for integrating data from different sources and distributing it to various destinations.\n\n![use_cases](./use_cases.gif)\n<div class=\"image-title\"><a href=\"https://blog.amigoscode.com/p/kafka-explained\">Source: Amigoscode</a></div>\n\n### ğŸ—ï¸ Component Architecture\n\n- **Brokers**: Kafka brokers are servers that store and manage the data. They handle incoming data streams and distribute them to consumers.\n- **Topics**: Topics are categories or feeds to which data is sent. Each topic can have multiple partitions for parallel processing.\n- **Partitions**: Partitions are subsets of a topic. They allow Kafka to scale horizontally and provide fault tolerance.\n- **Producers**: Producers are applications that send data to Kafka topics.\n- **Consumers**: Consumers are applications that read data from Kafka topics.\n- **ZooKeeper**: ZooKeeper is used to manage and coordinate Kafka brokers. It handles tasks like leader election and configuration management.\n\n![architecture](./architecture.png)\n\n## ğŸ”„ Kafka Connect\n\nKafka Connect is a tool for streaming data between Apache Kafka and other systems. It simplifies the process of integrating Kafka with databases, key-value stores, search indexes, and file systems.\n\n### How Kafka Connect Streams Data\n\nKafka Connect uses connectors to stream data in and out of Kafka. There are two types of connectors:\n\n- **Source Connectors**: These connectors pull data from external systems and write it to Kafka topics.\n- **Sink Connectors**: These connectors read data from Kafka topics and write it to external systems.\n\n![connect](./connect.png)\n\n### Use Cases\n\n- **Database integration**: Kafka Connect can stream data from databases like MySQL, PostgreSQL, and MongoDB into Kafka for real-time processing.\n- **Data Lake ingestion**: Kafka Connect can ingest data into data lakes like Hadoop and Amazon S3 for long-term storage and analysis.\n- **Search indexing**: Kafka Connect can stream data into search indexes like Elasticsearch for real-time search and analytics.\n- **File system integration**: Kafka Connect can read data from file systems and write it to Kafka, or vice versa.\n\n### Key Features\n\n- **Scalability**: Kafka Connect can scale horizontally by adding more workers, ensuring it can handle large data volumes.\n- **Fault tolerance**: Kafka Connect ensures data is not lost even if some connectors or workers fail.\n- **Configuration management**: Kafka Connect allows you to manage connector configurations centrally, making it easy to deploy and manage connectors.\n- **Monitoring and management**: Kafka Connect provides tools for monitoring and managing connectors, ensuring they operate smoothly.\n\n## Kafka on Kubernetes\n\n### Strimzi Overview\n\n**Strimzi** provides a way to run an Apache Kafka cluster on Kubernetes in various deployment configurations. It simplifies the process, making it quick and efficient to get Kafka up and running.\n\n### ğŸ”’ Secure by Default\n\nStrimzi comes with built-in security features to ensure your Kafka cluster is protected:\n\n- **TLS, SCRAM-SHA, and OAuth authentication**: These protocols help secure communication and authenticate users.\n- **Automated certificate management**: Strimzi handles certificate generation and renewal automatically.\n\n### âš™ï¸ Simple yet Configurable\n\nStrimzi offers flexibility in how you deploy and manage your Kafka cluster:\n\n- **NodePort, Load Balancer, and Ingress options**: Choose the best networking option for your needs.\n- **Rack awareness for High Availability (HA)**: Distribute Kafka brokers across different racks to ensure high availability.\n- **Use dedicated nodes for Kafka**: Assign specific nodes in your Kubernetes cluster to run Kafka for better performance and isolation.\n\n### ğŸ› ï¸ Kubernetes-Native Experience\n\nStrimzi integrates seamlessly with Kubernetes, providing a native experience:\n\n- **Use `kubectl` to manage Kafka**: Leverage familiar Kubernetes tools to manage your Kafka cluster.\n- **Operator-based management**: Strimzi uses operators to automate the deployment and management of Kafka. (An operator is a method of packaging, deploying, and managing a Kubernetes application.)\n- **Manage Kafka using GitOps**: Apply GitOps principles to manage your Kafka configurations and deployments through version control.\n\n![strimzi](./strimzi.png)\n<div class=\"image-title\"><a href=\"https://strimzi.io\">Source</a></div>\n\n## ğŸ§‘â€ğŸ’» Kafka Operators\n\nOperators are a method used to package, deploy, and manage applications on Kubernetes. They extend the Kubernetes API, making it easier to handle administrative tasks for specific applications.\n\n**Strimzi operators** are designed to manage Kafka deployments. They use custom resources to define the deployment configurations, which include settings for Kafka clusters, topics, users, and other components.\n\nStrimzi offers several operators to manage a Kafka cluster within a Kubernetes environment:\n\n- **Cluster operator**: Responsible for deploying and managing Apache Kafka clusters, Kafka Connect, Kafka MirrorMaker, Kafka Bridge, Kafka Exporter, Cruise Control, and the Entity Operator.\n- **Entity operator**: Includes the Topic Operator and User Operator.\n    - **Topic operator**: Handles the management of Kafka topics.\n    - **User operator**: Takes care of managing Kafka users.\n\n## ğŸ› ï¸ Hands-on: Deploying Strimzi on AWS EKS\n\nIn this section, we'll walk through the steps to deploy Strimzi on Amazon Elastic Kubernetes Service (EKS). This will involve setting up an EKS cluster, installing Strimzi, and deploying a Kafka cluster.\n\n### Prerequisites\n\n- **AWS Account**\n- **AWS CLI**: Install and configure the [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html).\n- **kubectl**: Install [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) to interact with your Kubernetes cluster.\n- **eksctl**: Install [eksctl](https://eksctl.io/) to create and manage EKS clusters.\n\n### Step 1: Create an EKS Cluster\n\nCreate the EKS Cluster:\n\n```shell\n$ eksctl create cluster --name demo-kafka-strimzi --region eu-west-1 \\\n--nodegroup-name linux-nodes --node-type t3.medium --nodes 3 \\\n--nodes-min 1 --nodes-max 4 --managed\n```\n\nThis command creates an EKS cluster named `demo-kafka-strimzi` in the `eu-west-1` region with a managed node group.\n\nVerify the Cluster:\n\n```shell\nkubectl get nodes\n```\n\nEnsure your nodes are in the Ready state.\n\n### Step 2: Install Strimzi\n\nDownload the Strimzi YAML files:\n\n```shell\n$ curl -L \"https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.43.0/strimzi-topic-operator-0.43.0.yaml\" \\\n-o strimzi-cluster-operator.yaml\n```\n\nCreate Strimzi namespace:\n\n```shell\n$ kubectl create namespace strimzi\n```\n\nDeploy the Strimzi Cluster Operator:\n\n```shell\n$ sed -i 's/namespace: myproject/namespace: strimzi/g' strimzi-cluster-operator.yaml\n$ kubectl apply -f strimzi-cluster-operator.yaml --namespace strimzi\n```\n\nVerify the Deployment:\n\n```shell\nkubectl get pods -n strimzi\n```\n\nEnsure the Strimzi Cluster Operator pods are running.\n\n### Step 3: Deploy Kafka Node Pool and a Kafka Cluster\n\nCreate a Kafka Cluster YAML file:\n\n```yaml\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaNodePool\nmetadata:\n    name: dual-role\n    labels:\n        strimzi.io/cluster: strimzi-cluster\nspec:\n    replicas: 1\n    roles:\n        - controller\n        - broker\n    storage:\n        type: jbod\n        volumes:\n            - id: 0\n                type: persistent-claim\n                size: 100Gi\n                deleteClaim: false\n                kraftMetadata: shared\n---\n\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n    name: strimzi-cluster\n    namespace: strimzi\nspec:\n    kafka:\n        version: 3.0.0\n        replicas: 3\n        listeners:\n            plain: {}\n            tls: {}\n        storage:\n            type: persistent-claim\n            size: 100Gi\n            class: gp2\n            deleteClaim: false\n    zookeeper:\n        replicas: 3\n        storage:\n            type: persistent-claim\n            size: 100Gi\n            class: gp2\n            deleteClaim: false\n    entityOperator:\n        topicOperator: {}\n        userOperator: {}\n```\n\nDeploy the Kafka Cluster:\n\n```shell\n$ kubectl apply -f kafka-cluster.yaml\n```\n\nVerify the Kafka Cluster:\n\n```shell\n$ kubectl get pods -n strimzi\n```\n\nEnsure all Kafka and Zookeeper pods are running.\n\n### ğŸ“¤ Send and Receive Messages\n\nWith the cluster running, run a simple producer to send messages to a Kafka topic (the topic is automatically created):\n\n```shell\n$ kubectl -n strimzi run kafka-producer -ti --image=quay.io/strimzi/kafka:0.43.0-kafka-3.8.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic\n```\n\nOnce everything is set up correctly, you'll see a prompt where you can type in your messages:\n\n```shell\n>Hello Strimzi!\n```\n\nAnd to receive them in a different terminal, run:\n\n```shell\n$ kubectl -n kafka run kafka-consumer -ti \\\n--image=quay.io/strimzi/kafka:0.43.0-kafka-3.8.0 \\\n--rm=true --restart=Never -- bin/kafka-console-consumer.sh \\\n--bootstrap-server my-cluster-kafka-bootstrap:9092 \\\n--topic my-topic --from-beginning\n```\n\nIf everything works as expected, you'll be able to see the message you produced in the previous step:\n\n```shell\n>Hello Strimzi!\n```\n\n## ğŸ”š Conclusion\n\nIn this part 6 of the blog series, we introduced Kafka, its features, components, Kafka Connect, and Strimzi. We also explored how to use Strimzi operators to manage Kafka on Kubernetes, covering the setup of an EKS cluster on AWS, the installation of Strimzi, and the deployment of a Kafka cluster.\n\nDive deeper by following the [official documentation](https://strimzi.io/documentation/) for more detailed information.\n\n**Stay tuned for next blogs in thisÂ seriesğŸ‰**\n\n**References:**\n\n- https://github.com/strimzi/strimzi-kafka-operator\n- https://strimzi.io/\n- https://medium.com/@howdyservices9/strimzi-deploy-kafka-in-kubernetes-dd740364861c\n- https://piotrminkowski.com/2023/11/06/apache-kafka-on-kubernetes-with-strimzi/\n- https://blog.devgenius.io/kafka-on-kubernetes-using-strimzi-part-2-71a8ba8e9605\n- https://www.linkedin.com/posts/nelsonamigoscode_systemdesign-coding-interviewtips-activity-7231623516704378883-lmCL\n- https://aws.amazon.com/blogs/containers/deploying-and-scaling-apache-kafka-on-amazon-eks/\n  \n**Thank You ğŸ–¤**\n\n<br>\n\n**_Until next time, ã¤ã¥ã ğŸ‰_**\n\n> ğŸ’¡ Thank you for Reading !! ğŸ™ŒğŸ»ğŸ˜ğŸ“ƒ, see you in the next blog.ğŸ¤˜  **_Until next time ğŸ‰_**\n\nğŸš€ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**â™»ï¸ LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**â™»ï¸ X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end âœŒğŸ»**\n\n<h1 align=\"center\">ğŸ”° Keep Learning !! Keep Sharing !! ğŸ”°</h1>\n\n**ğŸ“… Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1363},"frontmatter":{"id":"df4145f663f37c38db599e4d","path":"/blog/data-on-kubernetes-strimzi-kafka-6/","humanDate":"Oct 26, 2024","fullDate":"2024-10-26","title":"Data on Kubernetes: Part 6- Strimzi for running Apache Kafka","keywords":["AWS Kubernetes EKS","Strimzi","Apache Kafka","Data Streaming","Cloud-Native"],"excerpt":"Learn how to use Strimzi to run Apache Kafka on Kubernetes for efficient data streaming.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACdElEQVR42m2S6U9TURDF3/+rqEF2EdlJQAlLVNCALGEttNCySfeyE6CUspQutFTKImVrC7SC/Jz3jAkxfDiZN3Nnzr3nvFH6x6bo1I9iX9tgcSeIweKQGKBzeJTe0XGGp20YHbP0mia0s1mvj4XtAN90Boz2GUZtLpxuL+HLa0LnSZTajy1k5ebTMaSXQyc5xe9kaJtXBYW8zC8kr6SUOunJKymjqKKK1p5+VoIRSmpq+dDylS69USONP8DBdQZFN2URMoPcqGfouxU1102asa16GLE6GZycpstgpM80iXl5jbaBIfRmm9RMWjQ55qTHTMOXNsZc8yifu3spr6unoLSCyvpGmto7qapvosc4QXVDM9lFbyksr+TZ61ya2jp5npNP9psSTUmZzKm14soaTc37T60ogbMr9i5S7CduJCbFixSRK9WPBBHxJZa55+j+gUOJqqTYzS+O0ncCqWfuJM/wI5XW8mgyjWLzhDCvBXB4w1jXQ7g2I9g8ezg2wsz6DrA4Vpg3z2GfXccqtenVXWzSp56rfeq3XTi8B3HtAYpjY4+p5V0s7qDWZJjZFNIwvthP/HdwklPAb0XhsKaOAOAOxfHGzgmKMv/pFYF4QnAleVJTKpIT+LVCQsN+Is3cll/zI5jKcOTZ4jrrBSf7UVYO0lS3H9I+Hicstqir8hga4ePkr5e3sjY7tHT3EYpfYvdFeN7QhWM7yJL/goLmCI0DMe3yfzOPoTxOVGL/6SU6WZ/ukTFZdg/u6DHNJpf4K7YsLaMzL2J0Lshy78rPu2XvPPkfoVp4AqrBvuMzOkbMtA6Oa9EbPSEqWxCS14XEu6fm/gBv/t7ntF/VHAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/9ef02f7c716ad7d1b340e09cab4a9f12/04c7a/dok6.png","srcSet":"/static/9ef02f7c716ad7d1b340e09cab4a9f12/9ae6a/dok6.png 750w,\n/static/9ef02f7c716ad7d1b340e09cab4a9f12/0f80b/dok6.png 1080w,\n/static/9ef02f7c716ad7d1b340e09cab4a9f12/43124/dok6.png 1366w,\n/static/9ef02f7c716ad7d1b340e09cab4a9f12/04c7a/dok6.png 1600w","sizes":"100vw"},"sources":[{"srcSet":"/static/9ef02f7c716ad7d1b340e09cab4a9f12/8d8ff/dok6.webp 750w,\n/static/9ef02f7c716ad7d1b340e09cab4a9f12/fc98a/dok6.webp 1080w,\n/static/9ef02f7c716ad7d1b340e09cab4a9f12/1ab6d/dok6.webp 1366w,\n/static/9ef02f7c716ad7d1b340e09cab4a9f12/405ff/dok6.webp 1600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.560625}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/data-on-kubernetes-k8ssandra-7/","title":"Data on Kubernetes: Part 7â€Š-â€ŠK8ssandra: Bring Apache Cassandra to Kubernetes","date":"2024-10-26 15:06:00"},"excerpt":"K8ssandra: simple Cassandra management on Kubernetes ğŸ“ˆ ğŸ“š Introduction In this part of my data on Kubernetes series, I will look at how Kâ€¦"},"nextThought":{"frontmatter":{"path":"/blog/kubearmor-k8s-runtime-security/","title":"KubeArmor: A Cloud-Native Runtime Security Enforcement System","date":"2024-10-25 21:36:00"},"excerpt":"Shield Against Cloud-Native Threatsâ˜¸ï¸ ğŸ§° Introduction Cloud-native workloads are increasingly becoming the target of attackers. This isâ€¦"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}