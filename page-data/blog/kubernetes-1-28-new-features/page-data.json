{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/kubernetes-1-28-new-features/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>Kubernetes 1.28: What's New?</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>Kubernetes 1.28 is here, with 44 new or improved enhancements! This release includes a number of major features, such as built-in support for sidecar containers, job optimizations, and better proxies. These new features can help you improve the performance, efficiency, and security of your Kubernetes clusters.</p>\n<p>In this blog post, we will take a closer look at some of the key features of Kubernetes 1.28. We will also discuss how you can use these features to improve your Kubernetes deployments.</p>\n<p>Before updating, we recommend that you <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.28.md#urgent-upgrade-notes\" target=\"_blank\" rel=\"noopener noreferrer\">familiarize yourself with the CHANGELOG</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 57.64705882352942%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACNUlEQVR42oWTy2sTQRzH84/24EUU7x5760kRUS96KIhChdoSqSIVWhFbtQ1N4zaxSZp389xms5tsstnHzHzc3aRPRX/sD2bYmc98f6+EUop/OeF37vH2L2eklBfrxP+AgfIZKh1bmUglEIHAnfooqWKP7Or5P4CRSSVjRYHyqIksRZmiHZQZoZPSjki+26FSbRMIgW076D1rdk9eBSLxfJ9e+DNwBZYPA0/gYWELi4m06MkmJ/0CmWqGvLNHrpNnZ6dBo352HRjlIDJdt1h9fYjtGHwbeWR1Sb7qU+2GShwRKrqMoNRskGtl+VnPhmr7sxTMQp6FN1FDOhRYe97mezrLpt6iNoB23+PhusXdZ30WXw3oDoIISb7UIF3WyDm7cSoiRvRQIlr4yqUqNJrsk3xzTHItzdtsnUl4dSs9YeGBzupXmztP+yytmLHK4iRDzkxRNgqY4gbQEB0apNj+csziQpatHy02Cg5jAS8+DLm/bKBVXJY3Rzx+PwrzKinaGkX3gKp5ghtML6odA7tBjRaHrL3bZeneASXrmI81g94ofGwYcPvJWRzyrUc6mTCfpc4QTU/RELkwCnPeo+oS2BN16qRZ2Uzycn2DithjRetS0Wcd3ewH7Oam/Dr1qHTHVMo9bHfIgDY1ecRYnUOjkMOaTOWYM3XKp+19tj4fobt1tI5BrSdioJhX13EDmk2TkeUgPBhJA13V8JRzoTJxbcS4HLOrEyDClgiEnIPn4zbvDm6M42/76oaot+926AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Kubernetes\" title=\"\" src=\"/static/8153fc277fa5be1000be90fe29006dd9/c5bb3/kep1-28.png\" srcset=\"/static/8153fc277fa5be1000be90fe29006dd9/04472/kep1-28.png 170w,\n/static/8153fc277fa5be1000be90fe29006dd9/9f933/kep1-28.png 340w,\n/static/8153fc277fa5be1000be90fe29006dd9/c5bb3/kep1-28.png 680w,\n/static/8153fc277fa5be1000be90fe29006dd9/b12f7/kep1-28.png 1020w,\n/static/8153fc277fa5be1000be90fe29006dd9/c1b63/kep1-28.png 1200w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"-sidecar-containers\" style=\"position:relative;\"><a href=\"#-sidecar-containers\" aria-label=\" sidecar containers permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Sidecar Containers</h3>\n<p>Sidecar containers are a popular pattern for adding functionality to Kubernetes pods. They are often used for tasks such as service meshes, gathering metrics, and fetching secrets. However, implementing sidecar containers has not been easy.</p>\n<p>Until now, there was no way to tell Kubernetes that a container is a sidecar container. This meant that sidecar containers could be killed before the main container finished, or they could stay alive after messing up with jobs.</p>\n<p>Now, you can set the <code class=\"language-text\">restartPolicy</code> field to <code class=\"language-text\">Always</code> on an init container. This tells Kubernetes to treat the container as a sidecar container. Kubernetes will handle sidecar containers differently than regular containers:</p>\n<ul>\n<li>The kubelet will not wait for the container to finish. It will only wait until the startup has completed.</li>\n<li>The sidecar container will be restarted if it fails during startup, unless the pod's <code class=\"language-text\">restartPolicy</code> is <code class=\"language-text\">Never</code>. In this case, the entire pod will fail.</li>\n<li>The sidecar container will keep running as long as the main container is running.</li>\n<li>The sidecar container will be terminated once all regular containers have completed. This ensures that sidecar containers do not prevent jobs from completing after the main container has finished.</li>\n</ul>\n<p>Here is an example of how to use the <code class=\"language-text\">restartPolicy</code> field to create a sidecar container:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token punctuation\">...</span>\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">initContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> vault<span class=\"token punctuation\">-</span>agent\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> hashicorp/vault<span class=\"token punctuation\">:</span>1.12.1\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> istio<span class=\"token punctuation\">-</span>proxy\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> istio/proxyv2<span class=\"token punctuation\">:</span>1.16.0\n        <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"proxy\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"sidecar\"</span><span class=\"token punctuation\">]</span>\n        <span class=\"token key atrule\">restartPolicy</span><span class=\"token punctuation\">:</span> Always\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">...</span></code></pre></div>\n<h3 id=\"Ô∏è-optimizations-for-jobs\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-optimizations-for-jobs\" aria-label=\"Ô∏è optimizations for jobs permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚öôÔ∏è Optimizations for Jobs</h3>\n<p>Jobs in Kubernetes have received a lot of attention in this release. Jobs in Kubernetes can start a large number of repetitive parallel tasks at once, which is ideal for machine learning workloads. Kubernetes is becoming a major player in this area, thanks to its ongoing improvements to tools like jobs.</p>\n<p>We already discussed the <a href=\"https://github.com/kubernetes/enhancements/issues/753\" target=\"_blank\" rel=\"noopener noreferrer\">Sidecar Container feature</a>. This feature has a few surprises for job users, such as ensuring that sidecars do not prevent a job from completing.</p>\n<p><a href=\"https://github.com/kubernetes/enhancements/issues/3329\" target=\"_blank\" rel=\"noopener noreferrer\">The Retriable and Non-retriable Pod Failures for Jobs</a> and <a href=\"https://github.com/kubernetes/enhancements/issues/3850\" target=\"_blank\" rel=\"noopener noreferrer\">Backoff Limit Per Index For Indexed Jobs</a> enhancements will provide more granularity for handling job failures. Some failures are temporary or expected, and handling them differently can prevent a whole job from failing.</p>\n<p>Finally, the <a href=\"https://github.com/kubernetes/enhancements/issues/3939\" target=\"_blank\" rel=\"noopener noreferrer\">Allow for Recreation of Pods Once Fully Terminated in the Job Controller</a> provides more control options for handling jobs that have finished. This can help avoid some edge cases and race conditions.</p>\n<p>Once again, Kubernetes jobs continue to improve with each release, demonstrating the community's (machine learning) interest in this feature.</p>\n<h3 id=\"-kubernetes-packages-on-community-infrastructure\" style=\"position:relative;\"><a href=\"#-kubernetes-packages-on-community-infrastructure\" aria-label=\" kubernetes packages on community infrastructure permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üì¶ Kubernetes Packages on Community Infrastructure</h3>\n<p>The Kubernetes project is moving its package repositories to <a href=\"https://github.com/kubernetes/enhancements/issues/1731\" target=\"_blank\" rel=\"noopener noreferrer\">community-owned infrastructure</a>. This is to decouple the project from Google's infrastructure and make it more resilient and sustainable.</p>\n<p>The new repository is <a href=\"https://pkgs.k8s.io\" target=\"_blank\" rel=\"noopener noreferrer\">pkgs.k8s.io</a>. It adds to the existing repositories apt.kubernetes.io and yum.kubernetes.io. The old repositories will be deprecated at some point in the future.</p>\n<p>The Kubernetes team will publish a blog post with instructions on how to migrate to the new repositories around the time of the release.</p>\n<h3 id=\"-support-user-namespaces-in-pods\" style=\"position:relative;\"><a href=\"#-support-user-namespaces-in-pods\" aria-label=\" support user namespaces in pods permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîí Support User Namespaces in Pods</h3>\n<ul>\n<li><strong>SIG group:</strong> sig-node</li>\n<li><strong>Stage:</strong> Graduating to Alpha</li>\n<li><strong>Feature Gate:</strong> UserNamespacesStatelessPodsSupport</li>\n<li><strong>Default:</strong> false</li>\n</ul>\n<p>User namespaces is a Linux feature that allows you to run processes in pods with a different user than in the host. This can be used to improve the security of your Kubernetes cluster by limiting the damage that a compromised pod can do.</p>\n<p>For example, you could run a pod with the root user in the container, but as an unprivileged user in the host. This way, if the pod is compromised, the attacker would only have the privileges of the unprivileged user.</p>\n<p>To use user namespaces in Kubernetes, you need:</p>\n<ul>\n<li>At least a Linux 6.3 Kernel.</li>\n<li>A filesystem that supports idmap (i.e. ext4, btrfs, xfs, fat, ‚Ä¶).</li>\n<li>A container runtime with support for idmap (i.e. CRI-O 1.25, containerd 1.7).</li>\n</ul>\n<h3 id=\"-reserve-nodeport-ranges-for-dynamic-and-static-allocation\" style=\"position:relative;\"><a href=\"#-reserve-nodeport-ranges-for-dynamic-and-static-allocation\" aria-label=\" reserve nodeport ranges for dynamic and static allocation permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîß Reserve NodePort Ranges for Dynamic and Static Allocation</h3>\n<ul>\n<li><strong>SIG group:</strong> sig-network</li>\n<li><strong>Stage:</strong> Graduating to Beta</li>\n<li><strong>Feature Gate:</strong> ServiceNodePortStaticSubrange</li>\n<li><strong>Default:</strong> true</li>\n</ul>\n<p>When using a NodePort service, you may want to allocate a port statically, manually defining which port to use within the service-node-port-range (default 30000-32767).</p>\n<p>However, you may find that your port has been already assigned dynamically to another service. This new feature reserves the first ports in service-node-port-range to be assigned statically.</p>\n<p>The number of reserved ports is defined by this formula <code class=\"language-text\">min(max(16, nodeport-size / 32), 128)</code>, which returns a number between 16 and 128.</p>\n<p>For example, for the default range (30000-32767), it returns 86 ports. The range 30000-30085 will be reserved for static allocations, the rest for dynamic allocations.</p>\n<p>If you want to learn more, check this blog <a href=\"https://kubernetes.io/blog/2023/05/11/nodeport-dynamic-and-static-allocation/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes 1.27: Avoid Collisions Assigning Ports to NodePort Services</a>.</p>\n<h3 id=\"-rolling-upgrades\" style=\"position:relative;\"><a href=\"#-rolling-upgrades\" aria-label=\" rolling upgrades permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîÑ Rolling Upgrades</h3>\n<p>Three new enhancements will make upgrades more reliable, and will reduce downtime. Definitely a quality of life improvement for administrators, for whom leaving the app in maintenance mode is a big fear.</p>\n<p>With <a href=\"https://kubernetes.io/blog/kubernetes-1-28/#4020\" target=\"_blank\" rel=\"noopener noreferrer\">#4020 Unknown Version Interoperability Proxy</a>, rolling upgrades of the cluster components will be better handled. Rolling upgrades meaning that not all the same components are upgraded at once, rather one by one, keeping old and new coexisting. In this case, when traffic is sent to a Kubernetes component that is down, it will be redirected to a peer that is ready.</p>\n<p>Finally, <a href=\"https://kubernetes.io/blog/kubernetes-1-28/#3836\" target=\"_blank\" rel=\"noopener noreferrer\">#3836 Kube-proxy improved ingress connectivity reliability</a> and <a href=\"https://kubernetes.io/blog/kubernetes-1-28/#1669\" target=\"_blank\" rel=\"noopener noreferrer\">#1669 Proxy terminating endpoints</a> will reduce the amount of killed connections when doing rolling upgrades. When a Pod is terminated to leave room for the new version, all its connections are killed too, leaving customers unhappy. With these enhancements, these connections will be let alone, letting the Pod terminate gracefully.</p>\n<h3 id=\"-kube-proxy-improved-ingress-connectivity-reliability\" style=\"position:relative;\"><a href=\"#-kube-proxy-improved-ingress-connectivity-reliability\" aria-label=\" kube proxy improved ingress connectivity reliability permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üåê Kube-proxy Improved Ingress Connectivity Reliability</h3>\n<ul>\n<li><strong>SIG group:</strong> sig-network</li>\n<li><strong>Stage:</strong> Net New to Alpha</li>\n<li><strong>Feature Gate:</strong> KubeProxyDrainingTerminatingNodes</li>\n<li><strong>Default:</strong> false</li>\n</ul>\n<p>This enhancement adds some features to kube-proxy to better manage the health of connections.</p>\n<p>In particular:</p>\n<ul>\n<li>Once a node is terminating, kube-proxy won't immediately terminate all the connections and will let them terminate gracefully.</li>\n<li>A new <code class=\"language-text\">/livez</code> path is added where vendors and users can define a livenessProbe to determine kube-proxy health. This method is more specific than just checking if the node is terminating.</li>\n<li>Provide guidelines for vendors to implement those health checks (Aligning them into a standard is not a goal at this stage).</li>\n</ul>\n<h3 id=\"-consistent-reads-from-cache\" style=\"position:relative;\"><a href=\"#-consistent-reads-from-cache\" aria-label=\" consistent reads from cache permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìà Consistent Reads From Cache</h3>\n<ul>\n<li><strong>SIG group:</strong> sig-api-machinery</li>\n<li><strong>Stage:</strong> Net New to Alpha</li>\n<li><strong>Feature Gate:</strong> ConsistentListFromCache</li>\n<li><strong>Default:</strong> false</li>\n</ul>\n<p>This enhancement will improve the performance of some API requests like GET or LIST, by reading information from the watch cache of etcd, instead of reading it from etcd itself.</p>\n<p>This is possible thanks to WatchProgressRequest in etcd 3.4+, and will improve performance and scalability hugely on big deployments like 5k+ node clusters.</p>\n<p>If you want to read more about the technical details and how data consistency is ensured, <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-api-machinery/2340-Consistent-reads-from-cache/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">tap into the KEP</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIEBQH/xAAVAQEBAAAAAAAAAAAAAAAAAAAAA//aAAwDAQACEAMQAAAB3Kc6yeqiUkDoP//EABwQAAIBBQEAAAAAAAAAAAAAAAECAAMEEBESE//aAAgBAQABBQJm5C1yXlwu55mKCFz/AP/EABYRAQEBAAAAAAAAAAAAAAAAAAERIP/aAAgBAwEBPwFW4//EABcRAAMBAAAAAAAAAAAAAAAAAAERICH/2gAIAQIBAT8BxGP/xAAbEAEAAgIDAAAAAAAAAAAAAAABABEQICFRgf/aAAgBAQAGPwKPWB5onsBb0//EABwQAQEAAQUBAAAAAAAAAAAAAAERABAgITFBYf/aAAgBAQABPyE7ZaAfOkyvwZF6lxYADl2f/9oADAMBAAIAAwAAABAPDwD/xAAVEQEBAAAAAAAAAAAAAAAAAAAxIP/aAAgBAwEBPxAoj//EABcRAQADAAAAAAAAAAAAAAAAAAEgITH/2gAIAQIBAT8QBItmQ//EAB8QAQEAAgIBBQAAAAAAAAAAAAERACExURBBgZHh8P/aAAgBAQABPxCwFX9cCKBJEWcz5waCcOJ66E5jdMcig4nTd1evf6zQyTsxKRyeP//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Kubernetes Logo\" title=\"\" src=\"/static/2cccaa282f93543b811f1859782f90dc/7bf67/logo.jpg\" srcset=\"/static/2cccaa282f93543b811f1859782f90dc/651be/logo.jpg 170w,\n/static/2cccaa282f93543b811f1859782f90dc/d30a3/logo.jpg 340w,\n/static/2cccaa282f93543b811f1859782f90dc/7bf67/logo.jpg 680w,\n/static/2cccaa282f93543b811f1859782f90dc/4b190/logo.jpg 800w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèÅ Conclusion</h2>\n<p>Kubernetes is a powerful tool for managing containerized applications, and it's constantly evolving. I'm glad I could help you stay up-to-date on the latest features.</p>\n<p>I hope you found this blog helpful.</p>\n<p>If you have any other questions about Kubernetes, please don't hesitate to ask. I'm always happy to help.</p>\n<p>If you are interested in Kubernetes you may consider:</p>\n<ul>\n<li><a href=\"https://kubernetes.io/blog/\" target=\"_blank\" rel=\"noopener noreferrer\">Reading the Kubernetes blog</a>.</li>\n<li><a href=\"https://kubernetes.slack.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Tapping into the Kubernetes Slack</a>.</li>\n<li><a href=\"https://www.kubernetes.dev/docs/guide/\" target=\"_blank\" rel=\"noopener noreferrer\">Contributing to the Kubernetes project</a>.</li>\n</ul>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ üáµüá∏</em></strong></p>\n<p><br><br></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":6,"rawMarkdownBody":"> **Kubernetes 1.28: What's New?**\n\n## üìö Introduction\n\nKubernetes 1.28 is here, with 44 new or improved enhancements! This release includes a number of major features, such as built-in support for sidecar containers, job optimizations, and better proxies. These new features can help you improve the performance, efficiency, and security of your Kubernetes clusters.\n\nIn this blog post, we will take a closer look at some of the key features of Kubernetes 1.28. We will also discuss how you can use these features to improve your Kubernetes deployments.\n\nBefore updating, we recommend that you [familiarize yourself with the CHANGELOG](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.28.md#urgent-upgrade-notes).\n\n![Kubernetes](./kep1-28.png)\n\n### üöÄ Sidecar Containers\n\nSidecar containers are a popular pattern for adding functionality to Kubernetes pods. They are often used for tasks such as service meshes, gathering metrics, and fetching secrets. However, implementing sidecar containers has not been easy.\n\nUntil now, there was no way to tell Kubernetes that a container is a sidecar container. This meant that sidecar containers could be killed before the main container finished, or they could stay alive after messing up with jobs.\n\nNow, you can set the `restartPolicy` field to `Always` on an init container. This tells Kubernetes to treat the container as a sidecar container. Kubernetes will handle sidecar containers differently than regular containers:\n\n- The kubelet will not wait for the container to finish. It will only wait until the startup has completed.\n- The sidecar container will be restarted if it fails during startup, unless the pod's `restartPolicy` is `Never`. In this case, the entire pod will fail.\n- The sidecar container will keep running as long as the main container is running.\n- The sidecar container will be terminated once all regular containers have completed. This ensures that sidecar containers do not prevent jobs from completing after the main container has finished.\n\nHere is an example of how to use the `restartPolicy` field to create a sidecar container:\n\n```yaml\nkind: Pod\n...\nspec:\n    initContainers:\n    - name: vault-agent\n        image: hashicorp/vault:1.12.1\n    - name: istio-proxy\n        image: istio/proxyv2:1.16.0\n        args: [\"proxy\", \"sidecar\"]\n        restartPolicy: Always\n    containers:\n    ...\n```\n\n### ‚öôÔ∏è Optimizations for Jobs\n\nJobs in Kubernetes have received a lot of attention in this release. Jobs in Kubernetes can start a large number of repetitive parallel tasks at once, which is ideal for machine learning workloads. Kubernetes is becoming a major player in this area, thanks to its ongoing improvements to tools like jobs.\n\nWe already discussed the [Sidecar Container feature](https://github.com/kubernetes/enhancements/issues/753). This feature has a few surprises for job users, such as ensuring that sidecars do not prevent a job from completing.\n\n[The Retriable and Non-retriable Pod Failures for Jobs](https://github.com/kubernetes/enhancements/issues/3329) and [Backoff Limit Per Index For Indexed Jobs](https://github.com/kubernetes/enhancements/issues/3850) enhancements will provide more granularity for handling job failures. Some failures are temporary or expected, and handling them differently can prevent a whole job from failing.\n\nFinally, the [Allow for Recreation of Pods Once Fully Terminated in the Job Controller](https://github.com/kubernetes/enhancements/issues/3939) provides more control options for handling jobs that have finished. This can help avoid some edge cases and race conditions.\n\nOnce again, Kubernetes jobs continue to improve with each release, demonstrating the community's (machine learning) interest in this feature.\n\n### üì¶ Kubernetes Packages on Community Infrastructure\n\nThe Kubernetes project is moving its package repositories to [community-owned infrastructure](https://github.com/kubernetes/enhancements/issues/1731). This is to decouple the project from Google's infrastructure and make it more resilient and sustainable.\n\nThe new repository is [pkgs.k8s.io](https://pkgs.k8s.io). It adds to the existing repositories apt.kubernetes.io and yum.kubernetes.io. The old repositories will be deprecated at some point in the future.\n\nThe Kubernetes team will publish a blog post with instructions on how to migrate to the new repositories around the time of the release.\n\n### üîí Support User Namespaces in Pods\n\n- **SIG group:** sig-node\n- **Stage:** Graduating to Alpha\n- **Feature Gate:** UserNamespacesStatelessPodsSupport\n- **Default:** false\n\nUser namespaces is a Linux feature that allows you to run processes in pods with a different user than in the host. This can be used to improve the security of your Kubernetes cluster by limiting the damage that a compromised pod can do.\n\nFor example, you could run a pod with the root user in the container, but as an unprivileged user in the host. This way, if the pod is compromised, the attacker would only have the privileges of the unprivileged user.\n\nTo use user namespaces in Kubernetes, you need:\n\n- At least a Linux 6.3 Kernel.\n- A filesystem that supports idmap (i.e. ext4, btrfs, xfs, fat, ‚Ä¶).\n- A container runtime with support for idmap (i.e. CRI-O 1.25, containerd 1.7).\n\n### üîß Reserve NodePort Ranges for Dynamic and Static Allocation\n\n- **SIG group:** sig-network\n- **Stage:** Graduating to Beta\n- **Feature Gate:** ServiceNodePortStaticSubrange\n- **Default:** true\n\nWhen using a NodePort service, you may want to allocate a port statically, manually defining which port to use within the service-node-port-range (default 30000-32767).\n\nHowever, you may find that your port has been already assigned dynamically to another service. This new feature reserves the first ports in service-node-port-range to be assigned statically.\n\nThe number of reserved ports is defined by this formula `min(max(16, nodeport-size / 32), 128)`, which returns a number between 16 and 128.\n\nFor example, for the default range (30000-32767), it returns 86 ports. The range 30000-30085 will be reserved for static allocations, the rest for dynamic allocations.\n\nIf you want to learn more, check this blog [Kubernetes 1.27: Avoid Collisions Assigning Ports to NodePort Services](https://kubernetes.io/blog/2023/05/11/nodeport-dynamic-and-static-allocation/).\n\n### üîÑ Rolling Upgrades\n\nThree new enhancements will make upgrades more reliable, and will reduce downtime. Definitely a quality of life improvement for administrators, for whom leaving the app in maintenance mode is a big fear.\n\nWith [#4020 Unknown Version Interoperability Proxy](https://kubernetes.io/blog/kubernetes-1-28/#4020), rolling upgrades of the cluster components will be better handled. Rolling upgrades meaning that not all the same components are upgraded at once, rather one by one, keeping old and new coexisting. In this case, when traffic is sent to a Kubernetes component that is down, it will be redirected to a peer that is ready.\n\nFinally, [#3836 Kube-proxy improved ingress connectivity reliability](https://kubernetes.io/blog/kubernetes-1-28/#3836) and [#1669 Proxy terminating endpoints](https://kubernetes.io/blog/kubernetes-1-28/#1669) will reduce the amount of killed connections when doing rolling upgrades. When a Pod is terminated to leave room for the new version, all its connections are killed too, leaving customers unhappy. With these enhancements, these connections will be let alone, letting the Pod terminate gracefully.\n\n### üåê Kube-proxy Improved Ingress Connectivity Reliability\n\n- **SIG group:** sig-network\n- **Stage:** Net New to Alpha\n- **Feature Gate:** KubeProxyDrainingTerminatingNodes\n- **Default:** false\n\nThis enhancement adds some features to kube-proxy to better manage the health of connections.\n\nIn particular:\n\n- Once a node is terminating, kube-proxy won't immediately terminate all the connections and will let them terminate gracefully.\n- A new `/livez` path is added where vendors and users can define a livenessProbe to determine kube-proxy health. This method is more specific than just checking if the node is terminating.\n- Provide guidelines for vendors to implement those health checks (Aligning them into a standard is not a goal at this stage).\n\n### üìà Consistent Reads From Cache\n\n- **SIG group:** sig-api-machinery\n- **Stage:** Net New to Alpha\n- **Feature Gate:** ConsistentListFromCache\n- **Default:** false\n\nThis enhancement will improve the performance of some API requests like GET or LIST, by reading information from the watch cache of etcd, instead of reading it from etcd itself.\n\nThis is possible thanks to WatchProgressRequest in etcd 3.4+, and will improve performance and scalability hugely on big deployments like 5k+ node clusters.\n\nIf you want to read more about the technical details and how data consistency is ensured, [tap into the KEP](https://github.com/kubernetes/enhancements/blob/master/keps/sig-api-machinery/2340-Consistent-reads-from-cache/README.md).\n\n![Kubernetes Logo](./logo.jpg)\n\n## üèÅ Conclusion\n\nKubernetes is a powerful tool for managing containerized applications, and it's constantly evolving. I'm glad I could help you stay up-to-date on the latest features.\n\nI hope you found this blog helpful.\n\nIf you have any other questions about Kubernetes, please don't hesitate to ask. I'm always happy to help.\n\nIf you are interested in Kubernetes you may consider:\n\n* [Reading the Kubernetes blog](https://kubernetes.io/blog/).\n* [Tapping into the Kubernetes Slack](https://kubernetes.slack.com/).\n* [Contributing to the Kubernetes project](https://www.kubernetes.dev/docs/guide/).\n\n**_Until next time, „Å§„Å•„Åè üéâ üáµüá∏_**\n\n<br><br>\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1326},"frontmatter":{"id":"92886d614bc25356b5217864","path":"/blog/kubernetes-1-28-new-features/","humanDate":"Aug 16, 2023","fullDate":"2023-08-16","title":"Kubernetes 1.28: New Features for Sidecar Containers, Jobs, and Proxies","keywords":["Kubernetes","Kubernetes 1.28","Sidecar Containers","Jobs","Proxies"],"excerpt":"Explore the new features in Kubernetes 1.28, including built-in support for sidecar containers, job optimizations, and better proxies.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADYklEQVR42jWT+08UVxTH5z8wbfytbaJGSK2Pig9gC3ZF1n24r7kze++8dnZmZ3dmZxcLW6VaSABJKgK7mNo27S/2ZW1LUSyKVVIkhVBxbU2atD80rY9GITy0AVweKoa9vfNDfzg5Nyf3fnPu53wPBSGrQAg5hBgaAOAm5309vZdTYVV944uvzqHu3j7+ysCAZL7VWO5z2l6N0+uLyZ1SEpUMw1RBCNwk05aGpUUhhCQSLCl4RYQcdoejfHxy5uLnX39P/3P/fsfc3Gz31L/Ld9n3Ju5t0v7+qdoc0KRA5Wti0L6dZdk9EPj3sSztIcIgFApJVCgEeAACAVJ0Shy7t6Rky7aLV6+p12/ciPaNTp2p+2T6Uf2nsyvNZ/NY6lrARfp0YffBO7nq6Ic+mffsQnKNixOjPk6OkR45kRIiyYhoHBWFWNrPq4f2ywdPOLyRxlLny9SLRcpfn/Fdz/HH/fNPu4fzK98OP352+urcU5DBeLv+xwc19NpiMXUiqNS28+GatqilRSFB4Tk5yQhC3CXIul3Q6m2q0bgjFnt74ybjwW/q+/O4/+bCan9uCff+vIgv5/Ir3tZZvDl+ezDCVm2Ggm6XtLSXjx9GkI8IhCHDMkzwAMlVAPnLCZeSsN++0WH0VO6sfbj0UX8ek+4Kt24/wSO/L+PvRvKF1m/yeGtqcoZRGioQAuXWcFjW57G0KAIzRMJrwYW0zwYA2sHRdPF+dHxLWXr6T/nkIj5z7fHqpdwivjC2iL8cnF+FnUu4tHb8Vx+QdkNI2yxnWBpkKJAiMEUhrLO8Yng5xagWoocqBaPVlvAWvVSh/+DZEJ/JN519gjPn84VTlxYKdaeX8QZtcsqtnXIqirJTNJs8YjwdlOLvCJyoihSnJFQ+WieIxhFGjr17QDIaqhEKv+4qK1tnvECtsek5reLwxKNtyfGpreaDyT31ExM2pY/ndlGvMEipkMyWgJLOyHJdp86rpkK+zIgQBIDFgKbddgaJbyazv2RTXbe6oscGoqmOIUFqGdXE5kEu3DJqiM1DunGsh9PbhhrCySa/9QYJgp/neYIOhokgVIh/yKYgGjGMS5I0Z6J9JJvIjmXNzuttZuZmh9lynrjjilaTGT6aOplrNzrHsonjPzYTTG7EBF3Wlv2/Kf8Bp22RaTD6Y+EAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/2ac50f191258f2b3ab91c80147dd9535/bb8ee/kubernetes-1-28.png","srcSet":"/static/2ac50f191258f2b3ab91c80147dd9535/0dee1/kubernetes-1-28.png 750w,\n/static/2ac50f191258f2b3ab91c80147dd9535/8beaa/kubernetes-1-28.png 1080w,\n/static/2ac50f191258f2b3ab91c80147dd9535/bb8ee/kubernetes-1-28.png 1200w","sizes":"100vw"},"sources":[{"srcSet":"/static/2ac50f191258f2b3ab91c80147dd9535/a66aa/kubernetes-1-28.webp 750w,\n/static/2ac50f191258f2b3ab91c80147dd9535/65dd5/kubernetes-1-28.webp 1080w,\n/static/2ac50f191258f2b3ab91c80147dd9535/edb28/kubernetes-1-28.webp 1200w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/kubernetes-1-30-key-improvements/","title":"Kubernetes 1.30: Key Improvements You Need to¬†Know","date":"2024-04-19 20:00:00"},"excerpt":"v1.30 brings significant security enhancements and improved resource management ‚ò∏Ô∏è Introduction Kubernetes 1.30, set to be released on April‚Ä¶"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}