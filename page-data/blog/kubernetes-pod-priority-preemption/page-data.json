{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/kubernetes-pod-priority-preemption/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>A Guide to Managing Pod Priorities 📊</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🗯 Introduction</h2>\n<p>When running a Kubernetes cluster, it's important to ensure that your critical pods get the resources they need to function properly. This can be difficult to do if your cluster is under heavy load or if there are not enough resources available.</p>\n<p>One way to ensure that your critical pods get the resources they need is to use Kubernetes pod priority and preemption. Pod priority allows you to assign a numerical value to each pod, indicating its importance. Pods with higher priority will be scheduled before pods with lower priority, even if the lower-priority pods have been waiting longer.</p>\n<p>Pod preemption allows the scheduler to evict lower-priority pods from nodes in order to make room for higher-priority pods. This can be a useful way to ensure that your critical pods are always running, even if your cluster is under heavy load.</p>\n<p>In this tutorial, you will learn about pod priority, preemption, and pod PriorityClass. You will also learn how to use these features to ensure that your critical pods always get the resources they need.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.294117647058826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqElEQVR42mN4biyFQCbSz81kn5vKPjeWeWks+GFrzNWvX668+/Twz8/p+z8WLnhTvvRt2dJ3FUtfbLz04v6vnwwvjKVAyEgSROqLvVDjeaHJ/8JY8oW22McWoxtfnt/99n3H7a9qKc+UEp5opjxRTXoiF/NMO+HohjN3QZqfm8i80BF61d/wYtf6Fz11LwriXtirv9AV+9qp+vTjqZvf/+fNehbdftur7olB9jOn8scZk+9b598Maz7B8NxY+p2RxCsz2ScXT7369/vlt8+v/vx8vX31M02JL/WSXz8vm7D3d0DNrQVbNoU3X5ONfR7acn/upk1RbTdVYs8zvDWWOm0sl2ZufHjdyreXzzw9fvDFpTOvt658piXxJkLq46cdEw/+N8l7Ft56MaztcUz/16Cmx7GdF5yqX2gmXWT4ayrRqqMUmpb9+sjeJwd3vzxz9OrWDdfTw99oCr2yFHh+bvqVz2+b2pdlFi/NrduzvKkjvOWZd+S8wMQlhokHGfabqy5RE7/cWfP63+8Xr59++PDq+IWz4Y6ON/SlPlmIPVhtv/eg9685Yu8mi3dkZc+01gyrvRUV2RzunVo0aSLDVjPVl5r87+tyXjy8/fLpg9dfPz5+8yLe3XWhvtJ7c4nXi0ynT8u53m1+rc9p87INu/ZdbVzwwDX3uF/u6v557QwfjCVfgiP5hY3Ki2i3Fy3FTyc2vzWTXW+ifEFH4mGZXefM5VU1/aUVHT2Tl06cvXbijJUdXdPbu2a2961keGks+QqCDMReaQu+UuN+qS34yVjigKniCV2Zt+FqU+Ysqm6ZWV7f39a7qGfyyu7JK4Coa9Ky7snLGB6ayiKQmdxDc4X7ZvIvTWVWmqmfM1Z4bic7v7+tbfLq3inLOicu6ZiwGIiADBCasAQA8jJtysFkkuQAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"evicted\" title=\"\" src=\"/static/278f1480db9dd8ddcdccf94ce99836f5/c5bb3/evicted.png\" srcset=\"/static/278f1480db9dd8ddcdccf94ce99836f5/04472/evicted.png 170w,\n/static/278f1480db9dd8ddcdccf94ce99836f5/9f933/evicted.png 340w,\n/static/278f1480db9dd8ddcdccf94ce99836f5/c5bb3/evicted.png 680w,\n/static/278f1480db9dd8ddcdccf94ce99836f5/b12f7/evicted.png 1020w,\n/static/278f1480db9dd8ddcdccf94ce99836f5/c1b63/evicted.png 1200w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-kubernetes-pod-priority-enhancing-scheduling-efficiency\" style=\"position:relative;\"><a href=\"#-kubernetes-pod-priority-enhancing-scheduling-efficiency\" aria-label=\" kubernetes pod priority enhancing scheduling efficiency permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🚀 Kubernetes Pod Priority: Enhancing Scheduling Efficiency</h2>\n<p><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/\" target=\"_blank\" rel=\"noopener noreferrer\">Pod priority</a> is a Kubernetes scheduling feature that allows you to assign a numerical value to each pod, indicating its importance. Pods with higher priority will be scheduled before pods with lower priority, even if the lower-priority pods have been waiting longer.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#preemption\" target=\"_blank\" rel=\"noopener noreferrer\">Pod preemption</a> is a feature that allows the Kubernetes scheduler to evict lower-priority pods from nodes in order to make room for higher-priority pods. This can be useful for ensuring that your critical pods are always running, even if your cluster is under heavy load.</p>\n<p>There are two main concepts related to pod priority:</p>\n<ul>\n<li><strong><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass\" target=\"_blank\" rel=\"noopener noreferrer\">Pod priority class</a></strong>: A pod priority class is a non-namespaced object that defines a mapping from a name to the integer value of the priority. The higher the value, the higher the priority.</li>\n<li><strong><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#non-preempting-priority-class\" target=\"_blank\" rel=\"noopener noreferrer\">Pod preemption policy</a></strong>: The preemption policy determines whether or not Kubernetes will preempt lower-priority pods to make room for higher-priority pods. The default preemption policy is PreemptLowerPriority, which means that Kubernetes will preempt lower-priority pods if there are no resources available for higher-priority pods.</li>\n</ul>\n<h2 id=\"-pod-preemption-ensuring-high-priority-task-execution\" style=\"position:relative;\"><a href=\"#-pod-preemption-ensuring-high-priority-task-execution\" aria-label=\" pod preemption ensuring high priority task execution permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🛡 Pod Preemption: Ensuring High-Priority Task Execution</h2>\n<p>Within the Kubernetes ecosystem, the concept of Pod preemption emerges as a strategic feature designed to uphold optimal resource utilization. This functionality empowers Kubernetes to elegantly oust lower-priority pods from nodes whenever the scheduling queue harbors higher-priority counterparts demanding resources that are currently unavailable.</p>\n<h2 id=\"-kubernetes-pod-priority-class-fine-tuning-priority-assignment\" style=\"position:relative;\"><a href=\"#-kubernetes-pod-priority-class-fine-tuning-priority-assignment\" aria-label=\" kubernetes pod priority class fine tuning priority assignment permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🎯 Kubernetes Pod Priority Class: Fine-Tuning Priority Assignment</h2>\n<p>In the intricate dance of Kubernetes resource allocation, the Kubernetes Pod Priority Class takes center stage. This indispensable construct facilitates the allocation of specific priorities to pods, enabling meticulous control over task execution sequences.</p>\n<p>By harnessing the PriorityClass object (which operates outside the bounds of namespacing), administrators can seamlessly designate priorities for pods. The cornerstone of this assignment lies in the 'Value' parameter - a numerical indicator that effectively steers the order of execution. The range for this value spans from 1 to 1,000,000,000 (one billion), with a simple principle: the larger the value, the more pronounced the priority bestowed upon the pod.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> scheduling.k8s.io/v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> PriorityClass\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> high<span class=\"token punctuation\">-</span>priority\n<span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1000000</span>\n<span class=\"token key atrule\">preemptionPolicy</span><span class=\"token punctuation\">:</span> Never\n<span class=\"token key atrule\">globalDefault</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">false</span>\n<span class=\"token key atrule\">description</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"This priority class for backends\"</span></code></pre></div>\n<p>The name of the priorityclass (priorityClassName) will be used in the pod specification to set the priority. If you don't want the priority class to preempt the pods, you can set <code class=\"language-text\">PreemptionPolicy: Never</code>. By default, Priorityclasss use PreemptLowerPriority policy.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> nginx\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span> test\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> nginx\n        <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> nginx\n        <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> IfNotPresent\n    <span class=\"token key atrule\">priorityClassName</span><span class=\"token punctuation\">:</span> high<span class=\"token punctuation\">-</span>priority</code></pre></div>\n<h2 id=\"-shielding-critical-system-pods-in-kubernetes-high-priorityclasses\" style=\"position:relative;\"><a href=\"#-shielding-critical-system-pods-in-kubernetes-high-priorityclasses\" aria-label=\" shielding critical system pods in kubernetes high priorityclasses permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🛡 Shielding Critical System Pods in Kubernetes: High PriorityClasses</h2>\n<p>Securing pivotal pods from preemption within the Kubernetes ecosystem is a vital concern. To address this, Kubernetes has introduced two preconfigured high-priority classes, tailored to safeguard system-critical operations.</p>\n<ul>\n<li><strong>system-node-critical</strong>: This priority class is endowed with a numerical value of 2000001000. It is exclusively designated for static pods that play a crucial role in the system, such as etcd, kube-apiserver, kube-scheduler, and Controller Manager. The utilization of this priority class ensures that these fundamental components are shielded from preemption.</li>\n<li><strong>system-cluster-critical</strong>: Boasting a priority value of 2000000000, this priority class serves as the bastion for essential Addon Pods. Noteworthy components like coredns, calico controller, metrics server, and more align with this priority class. By aligning with the system-cluster-critical class, these Addon Pods are granted a robust shield against preemption, preserving the integrity of your Kubernetes cluster.</li>\n</ul>\n<h2 id=\"️-kubernetes-pod-priority--preemption-how-it-all-works\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-kubernetes-pod-priority--preemption-how-it-all-works\" aria-label=\"️ kubernetes pod priority  preemption how it all works permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>⚙️ Kubernetes Pod Priority &#x26; Preemption: How It All Works</h2>\n<p>When it comes to orchestrating the intricate ballet of Kubernetes pod allocation, the dynamic duo of Pod Priority and Preemption takes center stage. Let's delve into the inner workings of this process to uncover the magic behind efficient resource utilization.</p>\n<ul>\n<li><strong>Assigning Priority via PriorityClassName</strong>: Picture this - you've deployed a pod furnished with a PriorityClassName. As the pod takes its place in the Kubernetes environment, the priority admission controller steps in. This controller deftly extracts the priority value associated with the PriorityClassName, setting the stage for what's to come.</li>\n<li><strong>Scheduling Order Based on Priority</strong>: In the bustling queue of pending pods, the scheduler deftly orchestrates their sequence based on their assigned priorities. Here, the golden rule prevails: high-priority pods claim their rightful spot ahead of their lower-priority counterparts.</li>\n<li><strong>Preemption Logic Takes the Stage</strong>: But what if the spotlight shines on a high-priority pod without a suitable stage? In other words, if no nodes flaunt the resources required to host this eager pod, the preemption logic enters the scene. Like a seasoned theater director, the scheduler orchestrates the graceful eviction (preemption) of a low-priority pod from its node.</li>\n<li><strong>A Graceful Ballet of Eviction</strong>: As the curtain falls on the evicted pod's performance, it bows out with a gracious default termination time of 30 seconds. Yet, there's room for customization - if pods come prepared with a terminationGracePeriodSeconds specified for preStop container Lifecycle Hooks, this interval supersedes the default 30 seconds.</li>\n<li><strong>Scheduling Continues with Flexibility</strong>: But what if the stars fail to align even after preemption? Fear not, for Kubernetes is adept at adaptation. If scheduling constraints persist, the scheduler graciously adjusts its strategy, making room for the ensemble of lower-priority pods to claim their spotlight.</li>\n</ul>\n<h2 id=\"️-throttling-and-quality-of-service-qos-in-kubernetes-a-deep-dive\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-throttling-and-quality-of-service-qos-in-kubernetes-a-deep-dive\" aria-label=\"️ throttling and quality of service qos in kubernetes a deep dive permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>⛳️ Throttling and Quality of Service (QoS) in Kubernetes: A Deep Dive</h2>\n<p>At the core of efficient resource management in Kubernetes lies the concept of throttling - a strategic technique that curbs the processing speed of specific resources, such as network bandwidth or CPU usage. The essence of throttling is to create a balanced environment where high-priority tasks can progress while allowing room for other tasks to function, albeit at a reduced pace. In the realm of containers, resources can be broadly classified into compressible (throttle-able) and incompressible (non-throttle-able) categories, depending on whether they can be regulated.</p>\n<h3 id=\"understanding-throttlings-impact-on-pod-deployment\" style=\"position:relative;\"><a href=\"#understanding-throttlings-impact-on-pod-deployment\" aria-label=\"understanding throttlings impact on pod deployment permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Understanding Throttling's Impact on Pod Deployment</h3>\n<p>In the context of Kubernetes pods, throttling plays a significant role in shaping resource allocation and task execution. Imagine a scenario where a pod is fervently consuming a substantial chunk of a node's memory - this situation could impede the scheduling of new pods, potentially leading to deployment issues. Unlike CPUs, which can be slowed down to manage resource contention, memory lacks a similar mechanism. Consequently, an overzealous pod hogging memory can thwart the deployment of new pods, creating a bottleneck.</p>\n<h3 id=\"tackling-throttling-challenges\" style=\"position:relative;\"><a href=\"#tackling-throttling-challenges\" aria-label=\"tackling throttling challenges permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Tackling Throttling Challenges</h3>\n<p>To circumvent these challenges and ensure seamless pod deployment, Kubernetes offers several strategies:</p>\n<ul>\n<li><strong>Resource Management with LimitRange and ResourceQuota</strong>: Kubernetes provides tools like LimitRange and ResourceQuota to maintain control over resource allocation. These mechanisms enable administrators to rein in pods that exceed their allocated limits, preventing resource overutilization.</li>\n<li><strong>Precise Resource Requests and Limits</strong>: Crafting accurate resource requests and limits for containers can mitigate potential resource contention issues. By defining these parameters judiciously, you optimize resource utilization and foster smoother pod deployment.</li>\n<li><strong>Node Upgrades for Enhanced Capability</strong>: Upgrading the capabilities of your nodes can alleviate resource constraints and enhance the overall performance of your cluster. This proactive measure fortifies your infrastructure to accommodate varying resource demands.</li>\n</ul>\n<h3 id=\"diving-into-quality-of-service-qos-and-its-implications\" style=\"position:relative;\"><a href=\"#diving-into-quality-of-service-qos-and-its-implications\" aria-label=\"diving into quality of service qos and its implications permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Diving into Quality of Service (QoS) and Its Implications</h3>\n<p>As you delve deeper into the Kubernetes realm, Quality of Service (QoS) emerges as a pivotal concept closely intertwined with resource allocation. When you stipulate resource requests and limits for your containers, Kubernetes assigns a QoS tier based on your configuration. This tiered approach reflects the priority and potential behavior of your pods:</p>\n<ul>\n<li><strong>Guaranteed</strong>: Reserved for pods with identical resource requests and limits, the guaranteed QoS signifies high-priority tasks that are assured of the resources they need to operate optimally.</li>\n<li><strong>Burstable</strong>: Characterized by differing requests and limits, burstable pods enjoy minimal resource guarantees but have the potential to use additional resources if available. However, they might face termination if the node confronts resource scarcity.</li>\n<li><strong>Best-Effort</strong>: Pods falling under this QoS tier lack explicit resource requests and limits. As low-priority entities, best-effort pods might be terminated when incompressible resources become scarce.</li>\n</ul>\n<h3 id=\"navigating-qos-for-successful-pod-deployment\" style=\"position:relative;\"><a href=\"#navigating-qos-for-successful-pod-deployment\" aria-label=\"navigating qos for successful pod deployment permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Navigating QoS for Successful Pod Deployment</h3>\n<p>To troubleshoot pod deployment challenges arising from QoS considerations, it's prudent to:</p>\n<ul>\n<li>Assess the priority of your pod's resource requests and limits.</li>\n<li>Evaluate if other pods' configurations can be adjusted to optimize resource allocation.</li>\n<li>Draw insights from the earlier-discussed throttling strategies to fine-tune your pod deployment approach.</li>\n</ul>\n<h2 id=\"️-qos-vs-pods-priority-independent-forces-in-kubernetes\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-qos-vs-pods-priority-independent-forces-in-kubernetes\" aria-label=\"️ qos vs pods priority independent forces in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>☸️ QoS vs. Pods Priority: Independent Forces in Kubernetes</h2>\n<p>While QoS and Pods Priority might appear related, they operate separately in Kubernetes. QoS primarily helps Kubelet maintain node health by considering resource availability. In contrast, Pods Priority guides scheduler evictions, focusing solely on pods' priority classes. The scheduler evicts lower-priority pods to make room for higher-priority ones, ensuring efficient resource allocation.</p>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🔚 Conclusion</h2>\n<p>Navigating Kubernetes' intricate resource management involves understanding the nuances of Pod Priority, PriorityClass, and Preemption QoS. These mechanisms harmonize to optimize resource allocation, ensuring critical tasks take precedence while maintaining fairness. By comprehending the dynamic interplay between these elements, you're equipped to orchestrate a symphony of efficient container deployment, prioritization, and resource utilization within your Kubernetes ecosystem.</p>\n<h2 id=\"-references\" style=\"position:relative;\"><a href=\"#-references\" aria-label=\" references permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>📚 References</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes Pod Priority and Preemption</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass\" target=\"_blank\" rel=\"noopener noreferrer\">Pod Priority Class</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#non-preempting-priority-class\" target=\"_blank\" rel=\"noopener noreferrer\">Pod Preemption Policy</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes Quality of Service (QoS)</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/policy/limit-range/\" target=\"_blank\" rel=\"noopener noreferrer\">Resource Management with LimitRange and ResourceQuota</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\" target=\"_blank\" rel=\"noopener noreferrer\">Throttling in Kubernetes</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/\" target=\"_blank\" rel=\"noopener noreferrer\">Pod Priority and Preemption</a></li>\n</ul>\n<br>\n<p><strong>Thank you for Reading, see you in the next post. ✍</strong></p>\n<p><strong><em>Until next time, つづく 🎉</em></strong></p>\n<blockquote>\n<p>💡 Thank you for Reading !! 🙌🏻😁📃, see you in the next blog.🤘  <strong><em>Until next time 🎉</em></strong></p>\n</blockquote>\n<p>🚀 Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>♻️ LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>♻️ X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ✌🏻</strong></p>\n<h1 align=\"center\">🔰 Keep Learning !! Keep Sharing !! 🔰</h1>\n<p><strong>📅 Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":7,"rawMarkdownBody":"\n> **A Guide to Managing Pod Priorities 📊**\n\n## 🗯 Introduction\n\nWhen running a Kubernetes cluster, it's important to ensure that your critical pods get the resources they need to function properly. This can be difficult to do if your cluster is under heavy load or if there are not enough resources available.\n\nOne way to ensure that your critical pods get the resources they need is to use Kubernetes pod priority and preemption. Pod priority allows you to assign a numerical value to each pod, indicating its importance. Pods with higher priority will be scheduled before pods with lower priority, even if the lower-priority pods have been waiting longer.\n\nPod preemption allows the scheduler to evict lower-priority pods from nodes in order to make room for higher-priority pods. This can be a useful way to ensure that your critical pods are always running, even if your cluster is under heavy load.\n\nIn this tutorial, you will learn about pod priority, preemption, and pod PriorityClass. You will also learn how to use these features to ensure that your critical pods always get the resources they need.\n\n![evicted](./evicted.png)\n\n## 🚀 Kubernetes Pod Priority: Enhancing Scheduling Efficiency\n\n[Pod priority](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/) is a Kubernetes scheduling feature that allows you to assign a numerical value to each pod, indicating its importance. Pods with higher priority will be scheduled before pods with lower priority, even if the lower-priority pods have been waiting longer.\n\n[Pod preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#preemption) is a feature that allows the Kubernetes scheduler to evict lower-priority pods from nodes in order to make room for higher-priority pods. This can be useful for ensuring that your critical pods are always running, even if your cluster is under heavy load.\n\nThere are two main concepts related to pod priority:\n\n- **[Pod priority class](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass)**: A pod priority class is a non-namespaced object that defines a mapping from a name to the integer value of the priority. The higher the value, the higher the priority.\n- **[Pod preemption policy](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#non-preempting-priority-class)**: The preemption policy determines whether or not Kubernetes will preempt lower-priority pods to make room for higher-priority pods. The default preemption policy is PreemptLowerPriority, which means that Kubernetes will preempt lower-priority pods if there are no resources available for higher-priority pods.\n\n## 🛡 Pod Preemption: Ensuring High-Priority Task Execution\n\nWithin the Kubernetes ecosystem, the concept of Pod preemption emerges as a strategic feature designed to uphold optimal resource utilization. This functionality empowers Kubernetes to elegantly oust lower-priority pods from nodes whenever the scheduling queue harbors higher-priority counterparts demanding resources that are currently unavailable.\n\n## 🎯 Kubernetes Pod Priority Class: Fine-Tuning Priority Assignment\n\nIn the intricate dance of Kubernetes resource allocation, the Kubernetes Pod Priority Class takes center stage. This indispensable construct facilitates the allocation of specific priorities to pods, enabling meticulous control over task execution sequences.\n\nBy harnessing the PriorityClass object (which operates outside the bounds of namespacing), administrators can seamlessly designate priorities for pods. The cornerstone of this assignment lies in the 'Value' parameter - a numerical indicator that effectively steers the order of execution. The range for this value spans from 1 to 1,000,000,000 (one billion), with a simple principle: the larger the value, the more pronounced the priority bestowed upon the pod.\n\n```yaml\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n    name: high-priority\nvalue: 1000000\npreemptionPolicy: Never\nglobalDefault: false\ndescription: \"This priority class for backends\"\n```\n\nThe name of the priorityclass (priorityClassName) will be used in the pod specification to set the priority. If you don't want the priority class to preempt the pods, you can set `PreemptionPolicy: Never`. By default, Priorityclasss use PreemptLowerPriority policy.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n    name: nginx\n    labels:\n        env: test\nspec:\n    containers:\n    - name: nginx\n        image: nginx\n        imagePullPolicy: IfNotPresent\n    priorityClassName: high-priority\n```\n\n## 🛡 Shielding Critical System Pods in Kubernetes: High PriorityClasses\n\nSecuring pivotal pods from preemption within the Kubernetes ecosystem is a vital concern. To address this, Kubernetes has introduced two preconfigured high-priority classes, tailored to safeguard system-critical operations.\n\n- **system-node-critical**: This priority class is endowed with a numerical value of 2000001000. It is exclusively designated for static pods that play a crucial role in the system, such as etcd, kube-apiserver, kube-scheduler, and Controller Manager. The utilization of this priority class ensures that these fundamental components are shielded from preemption.\n- **system-cluster-critical**: Boasting a priority value of 2000000000, this priority class serves as the bastion for essential Addon Pods. Noteworthy components like coredns, calico controller, metrics server, and more align with this priority class. By aligning with the system-cluster-critical class, these Addon Pods are granted a robust shield against preemption, preserving the integrity of your Kubernetes cluster.\n\n## ⚙️ Kubernetes Pod Priority & Preemption: How It All Works\n\nWhen it comes to orchestrating the intricate ballet of Kubernetes pod allocation, the dynamic duo of Pod Priority and Preemption takes center stage. Let's delve into the inner workings of this process to uncover the magic behind efficient resource utilization.\n\n- **Assigning Priority via PriorityClassName**: Picture this - you've deployed a pod furnished with a PriorityClassName. As the pod takes its place in the Kubernetes environment, the priority admission controller steps in. This controller deftly extracts the priority value associated with the PriorityClassName, setting the stage for what's to come.\n- **Scheduling Order Based on Priority**: In the bustling queue of pending pods, the scheduler deftly orchestrates their sequence based on their assigned priorities. Here, the golden rule prevails: high-priority pods claim their rightful spot ahead of their lower-priority counterparts.\n- **Preemption Logic Takes the Stage**: But what if the spotlight shines on a high-priority pod without a suitable stage? In other words, if no nodes flaunt the resources required to host this eager pod, the preemption logic enters the scene. Like a seasoned theater director, the scheduler orchestrates the graceful eviction (preemption) of a low-priority pod from its node.\n- **A Graceful Ballet of Eviction**: As the curtain falls on the evicted pod's performance, it bows out with a gracious default termination time of 30 seconds. Yet, there's room for customization - if pods come prepared with a terminationGracePeriodSeconds specified for preStop container Lifecycle Hooks, this interval supersedes the default 30 seconds.\n- **Scheduling Continues with Flexibility**: But what if the stars fail to align even after preemption? Fear not, for Kubernetes is adept at adaptation. If scheduling constraints persist, the scheduler graciously adjusts its strategy, making room for the ensemble of lower-priority pods to claim their spotlight.\n\n## ⛳️ Throttling and Quality of Service (QoS) in Kubernetes: A Deep Dive\n\nAt the core of efficient resource management in Kubernetes lies the concept of throttling - a strategic technique that curbs the processing speed of specific resources, such as network bandwidth or CPU usage. The essence of throttling is to create a balanced environment where high-priority tasks can progress while allowing room for other tasks to function, albeit at a reduced pace. In the realm of containers, resources can be broadly classified into compressible (throttle-able) and incompressible (non-throttle-able) categories, depending on whether they can be regulated.\n\n### Understanding Throttling's Impact on Pod Deployment\n\nIn the context of Kubernetes pods, throttling plays a significant role in shaping resource allocation and task execution. Imagine a scenario where a pod is fervently consuming a substantial chunk of a node's memory - this situation could impede the scheduling of new pods, potentially leading to deployment issues. Unlike CPUs, which can be slowed down to manage resource contention, memory lacks a similar mechanism. Consequently, an overzealous pod hogging memory can thwart the deployment of new pods, creating a bottleneck.\n\n### Tackling Throttling Challenges\n\nTo circumvent these challenges and ensure seamless pod deployment, Kubernetes offers several strategies:\n\n- **Resource Management with LimitRange and ResourceQuota**: Kubernetes provides tools like LimitRange and ResourceQuota to maintain control over resource allocation. These mechanisms enable administrators to rein in pods that exceed their allocated limits, preventing resource overutilization.\n- **Precise Resource Requests and Limits**: Crafting accurate resource requests and limits for containers can mitigate potential resource contention issues. By defining these parameters judiciously, you optimize resource utilization and foster smoother pod deployment.\n- **Node Upgrades for Enhanced Capability**: Upgrading the capabilities of your nodes can alleviate resource constraints and enhance the overall performance of your cluster. This proactive measure fortifies your infrastructure to accommodate varying resource demands.\n\n### Diving into Quality of Service (QoS) and Its Implications\n\nAs you delve deeper into the Kubernetes realm, Quality of Service (QoS) emerges as a pivotal concept closely intertwined with resource allocation. When you stipulate resource requests and limits for your containers, Kubernetes assigns a QoS tier based on your configuration. This tiered approach reflects the priority and potential behavior of your pods:\n\n- **Guaranteed**: Reserved for pods with identical resource requests and limits, the guaranteed QoS signifies high-priority tasks that are assured of the resources they need to operate optimally.\n- **Burstable**: Characterized by differing requests and limits, burstable pods enjoy minimal resource guarantees but have the potential to use additional resources if available. However, they might face termination if the node confronts resource scarcity.\n- **Best-Effort**: Pods falling under this QoS tier lack explicit resource requests and limits. As low-priority entities, best-effort pods might be terminated when incompressible resources become scarce.\n\n### Navigating QoS for Successful Pod Deployment\n\nTo troubleshoot pod deployment challenges arising from QoS considerations, it's prudent to:\n\n- Assess the priority of your pod's resource requests and limits.\n- Evaluate if other pods' configurations can be adjusted to optimize resource allocation.\n- Draw insights from the earlier-discussed throttling strategies to fine-tune your pod deployment approach.\n\n## ☸️ QoS vs. Pods Priority: Independent Forces in Kubernetes\n\nWhile QoS and Pods Priority might appear related, they operate separately in Kubernetes. QoS primarily helps Kubelet maintain node health by considering resource availability. In contrast, Pods Priority guides scheduler evictions, focusing solely on pods' priority classes. The scheduler evicts lower-priority pods to make room for higher-priority ones, ensuring efficient resource allocation.\n\n## 🔚 Conclusion\n\nNavigating Kubernetes' intricate resource management involves understanding the nuances of Pod Priority, PriorityClass, and Preemption QoS. These mechanisms harmonize to optimize resource allocation, ensuring critical tasks take precedence while maintaining fairness. By comprehending the dynamic interplay between these elements, you're equipped to orchestrate a symphony of efficient container deployment, prioritization, and resource utilization within your Kubernetes ecosystem.\n\n## 📚 References\n\n- [Kubernetes Pod Priority and Preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/)\n- [Pod Priority Class](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass)\n- [Pod Preemption Policy](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#non-preempting-priority-class)\n- [Kubernetes Quality of Service (QoS)](https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/)\n- [Resource Management with LimitRange and ResourceQuota](https://kubernetes.io/docs/concepts/policy/limit-range/)\n- [Throttling in Kubernetes](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)\n- [Pod Priority and Preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/)\n\n<br>\n\n**Thank you for Reading, see you in the next post. ✍**\n\n**_Until next time, つづく 🎉_**\n\n> 💡 Thank you for Reading !! 🙌🏻😁📃, see you in the next blog.🤘  **_Until next time 🎉_**\n\n🚀 Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**♻️ LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**♻️ X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ✌🏻**\n\n<h1 align=\"center\">🔰 Keep Learning !! Keep Sharing !! 🔰</h1>\n\n**📅 Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1724},"frontmatter":{"id":"58962a1f6b69d7d3d69a8ee2","path":"/blog/kubernetes-pod-priority-preemption/","humanDate":"Oct 28, 2024","fullDate":"2024-10-28","title":"Kubernetes Pod Priority and Preemption: How to Ensure Your Critical Pods Get the Resources They Need 🚀","keywords":["Kubernetes","pod priority","SRE","DevOps","k8s"],"excerpt":"Learn how to manage pod priorities and preemption in Kubernetes to ensure that your critical applications receive the resources they need, even under resource constraints.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABoElEQVR42m2RQY/SUBSFCywggQSHIGZCDRV1KJ1iWyoMtHQAaSswUhpGJpM4bjSjm0k0cWPcujITI/9gEpf+CXf+rc/2JW7Uxcm77977zj3nXWm9jgjDEEVRuNtQCJ74/Ppxw8+bHd8+vCV8/IijQxVJkv5BJpMR+BOL/MlyiWlZmF2bo5PneB+/sPt6zfX7S67OIh7s3+H2XpmG0kDTNKykt9lsYhgG3W4XVVWp1+tCkG3bSLPZDCshs51j9Hefeb37TnT5Cd3sMfennM59DuR9ZFlmu92y2WyEoyAIiKKI0WgkhqS5wWCANB6P6ff6mOGKe5tXieUA9TgmjF8kzS4XFy/x+raw00v6HMdhOp3iuq6I03MymQjyarWK5HkeblIw/WdUvBXqoYGdWGm3WtxPrM3nT4WtlLBWq4mHKclwOBRqU4UpFosF+XweKZXp+z6tjsUtZ86eaqG2NUqlEuNkcvod7eSey+XIZrOUy2VRKxQKVCoVisWiiFOIxei6zjqO6egdmrpJ3nCQOzZvTldcnccs3R7awUNB9r9N/43feirZvM7WtFQAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/71d4a8ca1b253c6ea69991d2af1fde16/e916b/priority-cover.png","srcSet":"/static/71d4a8ca1b253c6ea69991d2af1fde16/e916b/priority-cover.png 600w","sizes":"100vw"},"sources":[{"srcSet":"/static/71d4a8ca1b253c6ea69991d2af1fde16/0483b/priority-cover.webp 600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.3333333333333333}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/kubernetes-cost-optimization/","title":"Kubernetes Cost Optimization Made Easy: Efficient Tools for Streamlining FinOps 💰","date":"2024-10-28 21:00:00"},"excerpt":"Efficient Tools for Streamlining FinOps 💸 🗯 Introduction As organizations embrace Kubernetes for their containerized workloads, the need…","html":"<blockquote>\n<p><strong>Efficient Tools for Streamlining FinOps 💸</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🗯 Introduction</h2>\n<p>As organizations embrace Kubernetes for their containerized workloads, the need for effective cost optimization becomes paramount. To navigate the complex landscape of cloud-native infrastructure, leveraging efficient tools is key to streamlining FinOps practices and maximizing cost savings. Fortunately, a range of efficient tools exists to streamline FinOps practices and drive significant savings.</p>\n<p>In this article, we will discuss cutting-edge solutions such as <a href=\"https://www.apptio.com/products/cloudability/\" target=\"_blank\" rel=\"noopener noreferrer\">Cloudability</a>, <a href=\"https://github.com/kube-green/kube-green\" target=\"_blank\" rel=\"noopener noreferrer\">Kube-Green</a>, <a href=\"https://cloudcustodian.io/docs/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">Cloud Custodian</a>, and <a href=\"https://www.kubecost.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubecost</a>. Discover how these tools empower businesses to gain cost visibility, optimize resource utilization, and achieve financial excellence in their Kubernetes deployments. Let's dive into the world of Kubernetes cost optimization made easy. 💸</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEoklEQVR42o2Ue0xbZRiHYUMzmU7iJZsxUWeIi8vmH6LOzGlMlATm0Bltll2ZmMmUqFvAMcGtMtzYYKwbyxCKlK1jsNVBKQWBUmhpKbdS2nIrl5ZubSm09NBSKDDac34eChM0U/dLTs7JOd/7nDdPvu8NCPiPAFhB3wLnn+Xy5m27Utjy4Pe/+sj/kcFYGfCwYTKZKwLmLzpOtfql+OySgkNFipno6jsI3p6QsLgo6H9BdEeBzEUQMPZEKoefdJBdQ8TVGpFjmL2XqiKwKvJo/EMBl0AIzOcJP4/NFui+LuvCSYWV4homybqRWW+6ehxBEUceqkO/J5FI9MZ32SU1X95sQ4rSDm6/iyw1uqlyyzSk4/BmqAkEfRiXuOQQgf8KY92oOBnzW60vvtmOzO4J8vchGmS9B3m3BTKtCTqFlkprsyHy5xIiiVMe5WfyeCuXa1pyN9CyJpZdOX5aaUOWzOBLaLGj0jSFarMHZm4pHLlcmAVS8mzTFKIvt2rfDQ+PpcseW8fgPftUKHON38DCjliIkcUMic6rcp0o70LDsTPUiYa7EJo8cLBvwJVbCKWiCwX6KSpBRGBbdLpo0+Y36+iydfVd+CyJ3aZ77pOCnff9LwJZIXtyqtypxc24xSqkkhstqBlyoU/cCl6/E2VjwLneCXzK0WDnYVbFptff66PLnuFwcqIUokpIVDZyd6o4n373iB/opDvclSdycy7fhvB0DnW80YpS8wwydZM432HD2bpehMak4WVGEnJLtbPnfr3tYBw+tYEu3RHzxUHAqYfh7qht4ze8xxc6LGCF7M2tch/na5HFa6S+VbpRLRFDKK1H9JUKHGOXYG9qHlp0FgyMgSyX66E2ODszLlzMD3snosli86hsw3dH47ma1X6gms8POXCp1M0RKCBv11ICmRbj165gUHoVBwp5tL8epGmUmPYBI26gd9hL0b5IYXUNYo8kdg1OgyFVGaIkRskqP3Cop+fFmMsCj7rgGtBwk5oT3wJPKsR1lQzhvCJsuVWI4p5B2Dw+2NwUnDMkpgCqrFZOCoRV8/DZMY8vzg/rME7uNk14nVGJ2ZT4fBb03ExICrPxvVKKD7hFSCmugbx/GC2jo1BYzdAQTuhtI5jTqKHXDKCrtdNHzAGKHut+P9Dqnt1Y0W4Ye5XxIzL2HyLfem0zPr5wHvtq/8AP/CrIOkcwaJ2ExuJDWb8Rl1RtqG3phixXSMnqBn1qA0Fq7KB/OiYMYyQ+6YfuS85aLx8gGtLSL+KF9Rt8kdm52HL1Khr6rZhPk57EUdpGTuUd6pciNXml0oiKTqDdQqFxcGKuvs/VXtFqYkUls9f/tRlre/F0vqBBJpQooTI6fPIBOxR6ArIeC0zjXjTrQV6odCFP4sA5npy6Lm63lTQOnEktVmxdG75v9YMGaYDYgLU6gmwZoZ10GJ1egcYIUecwZR73kvPmzYTPoTQ40qOTCt5+NOzg9rAdzOD7J2T5MA5YfhYzeU3Pqy0elZ2ch7rc9sm5SWKaJFV6Z2GeQBW6/Ij5IXjwxPlbp6Wy3lduK/Q/7TnF38xX6LZWt5oilq9ZmC7/mDCL+RN0z0odCBAxIgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"finops\" title=\"\" src=\"/static/32c0f5eeac6b9b3897edfe08986d69f0/c5bb3/finops.png\" srcset=\"/static/32c0f5eeac6b9b3897edfe08986d69f0/04472/finops.png 170w,\n/static/32c0f5eeac6b9b3897edfe08986d69f0/9f933/finops.png 340w,\n/static/32c0f5eeac6b9b3897edfe08986d69f0/c5bb3/finops.png 680w,\n/static/32c0f5eeac6b9b3897edfe08986d69f0/00d43/finops.png 1000w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"introduction-to-kube-green-\" style=\"position:relative;\"><a href=\"#introduction-to-kube-green-\" aria-label=\"introduction to kube green  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Introduction to Kube-Green 🍀</h2>\n<p>In the first paragraph of this tutorial, I will explain how Kube-Green was born and why it is useful for reducing the waste of resources.</p>\n<h3 id=\"the-idea-of-kube-green-\" style=\"position:relative;\"><a href=\"#the-idea-of-kube-green-\" aria-label=\"the idea of kube green  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>The Idea of Kube-Green 🗯</h3>\n<p>In a Kubernetes cluster, non-production namespaces typically operate during business hours, which amounts to approximately 40 hours per week out of a total of 168 weekly hours. However, it's common for resources to be allocated to pods in these namespaces even when they are not actively in use. This results in unnecessary consumption of CPU and memory resources.</p>\n<p><a href=\"https://github.com/kube-green/kube-green\" target=\"_blank\" rel=\"noopener noreferrer\">Kube-Green</a> offers a simple solution to address this issue by halting all pods within those namespaces, effectively optimizing resource utilization during non-business hours.</p>\n<h3 id=\"how-is-it-possible-\" style=\"position:relative;\"><a href=\"#how-is-it-possible-\" aria-label=\"how is it possible  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>How is it Possible? 🤔</h3>\n<p>Kube-Green is a Kubernetes controller, which defines a Custom Resource Definition (CRD) called <code class=\"language-text\">SleepInfo</code>. The <code class=\"language-text\">SleepInfo</code> CRD defines when to stop and restart the pods in a namespace. For example, in development namespaces, it is possible to stop all the pods during non-business hours: wake up every morning from Monday to Friday and stop every night from Monday to Friday.</p>\n<h3 id=\"hands-on-\" style=\"position:relative;\"><a href=\"#hands-on-\" aria-label=\"hands on  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Hands-On 👷</h3>\n<p>To follow this guide, you should have <a href=\"https://kubernetes.io/docs/tasks/tools/#kubectl\" target=\"_blank\" rel=\"noopener noreferrer\">kubectl</a> and <a href=\"https://kind.sigs.k8s.io/\" target=\"_blank\" rel=\"noopener noreferrer\">kind</a> installed locally.</p>\n<ul>\n<li>The Kubernetes command line tool: <a href=\"https://kubernetes.io/docs/tasks/tools/#kubectl\" target=\"_blank\" rel=\"noopener noreferrer\">kubectl</a></li>\n<li><a href=\"https://docs.docker.com/get-started/get-docker/\" target=\"_blank\" rel=\"noopener noreferrer\">Docker</a></li>\n<li>Kubernetes cluster</li>\n</ul>\n<p>Now you have all the tools needed, let's go!</p>\n<h3 id=\"️-install-the-cert-manager\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-install-the-cert-manager\" aria-label=\"️ install the cert manager permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>➡️ Install the Cert-Manager</h3>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 14.117647058823529%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAf0lEQVR42n2LSw4CMQxDm/SbtHQY1PtfEmVXFFI6CyQkFpaf7cSNAa8CbjK6Sd6Em/8KLn11668FnI7PqNSDcg36yFlHZa1HUmpBW8+2Ra23Lbovt+0w7+nD65YXH1k5obpyZqGehApK8yAterFBKILQ8gSWYXdXph+GfRfx+QbwHD+Omf+sOAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cert\" title=\"\" src=\"/static/cd60065cedd4846166653cbe457c2c5c/c5bb3/cert.png\" srcset=\"/static/cd60065cedd4846166653cbe457c2c5c/04472/cert.png 170w,\n/static/cd60065cedd4846166653cbe457c2c5c/9f933/cert.png 340w,\n/static/cd60065cedd4846166653cbe457c2c5c/c5bb3/cert.png 680w,\n/static/cd60065cedd4846166653cbe457c2c5c/b12f7/cert.png 1020w,\n/static/cd60065cedd4846166653cbe457c2c5c/b5a09/cert.png 1360w,\n/static/cd60065cedd4846166653cbe457c2c5c/29007/cert.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>With this command, the latest release of cert-manager will be installed. You can check the correct cert-manager deployment by verifying that all the pods are correctly running.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 10.588235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAASElEQVR42mOwN9X+qWum+UdLS/uPljYEa1OAGdSNjf9omJj81zIw+K8JpNUsLP4bGhr81zUx/q9haPhfW0vrP1AhUVhHR+c/AOF1PFsPoPibAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"get-ns\" title=\"\" src=\"/static/9617f5bc987191d334570611a02ffa45/c5bb3/get-ns.png\" srcset=\"/static/9617f5bc987191d334570611a02ffa45/04472/get-ns.png 170w,\n/static/9617f5bc987191d334570611a02ffa45/9f933/get-ns.png 340w,\n/static/9617f5bc987191d334570611a02ffa45/c5bb3/get-ns.png 680w,\n/static/9617f5bc987191d334570611a02ffa45/b12f7/get-ns.png 1020w,\n/static/9617f5bc987191d334570611a02ffa45/b5a09/get-ns.png 1360w,\n/static/9617f5bc987191d334570611a02ffa45/29007/get-ns.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"install-kube-green-\" style=\"position:relative;\"><a href=\"#install-kube-green-\" aria-label=\"install kube green  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install Kube-Green ㊙</h3>\n<p>Install Kube-Green with the default static install. <a href=\"https://kube-green.dev/docs/install/\" target=\"_blank\" rel=\"noopener noreferrer\">Click here</a> to see the different install methods supported.</p>\n<p>Install Kube-Green with this command:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">-f</span> https://github.com/kube-green/kube-green/releases/latest/download/kube-green.yaml</code></pre></div>\n<p>This command creates a <code class=\"language-text\">kube-green</code> namespace and deploys a <code class=\"language-text\">kube-green-controller-manager</code>. You can check that the pod is correctly running:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl <span class=\"token parameter variable\">-n</span> kube-green get pods</code></pre></div>\n<h3 id=\"️-setup-kube-green-in-dev-namespace\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-setup-kube-green-in-dev-namespace\" aria-label=\"️ setup kube green in dev namespace permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>➡️ Setup Kube-Green in Dev Namespace</h3>\n<p>To setup Kube-Green, the <code class=\"language-text\">SleepInfo</code> resource must be created in the <code class=\"language-text\">dev</code> namespace. The <code class=\"language-text\">SleepInfo</code> spec contains:</p>\n<ul>\n<li><code class=\"language-text\">weekdays</code>: day of the week. <code class=\"language-text\">*</code> is every day, <code class=\"language-text\">1</code> is Monday, <code class=\"language-text\">1-5</code> is from Monday to Friday.</li>\n<li><code class=\"language-text\">sleepAt</code>: time in hours and minutes (HH:mm) when the namespace will go to sleep. Valid values are, for example, <code class=\"language-text\">19:00</code> or <code class=\"language-text\">*:*</code> for every minute and every hour. Resources sleep will be deployments (setting replicas value to 0) and, if <code class=\"language-text\">suspendCronjobs</code> option is set to true, cron jobs will be suspended.</li>\n<li><code class=\"language-text\">wakeUpAt</code> (optional): time in hours and minutes (HH:mm) when the namespace should be restored to the initial state (before sleep). Valid values are, for example, <code class=\"language-text\">19:00</code> or <code class=\"language-text\">*:*</code> for every minute and every hour. If wake up value is not set, the pod in the namespace will not be restored. So, you will need to deploy the initial namespace configuration to restore it.</li>\n<li><code class=\"language-text\">timeZone</code> (optional, default to UTC): time zone in IANA specification. For example, for Italian hour, set <code class=\"language-text\">Europe/Rome</code>.</li>\n<li><code class=\"language-text\">suspendDeployments</code> (optional, default to true): if set to false, deployments will not be suspended.</li>\n<li><code class=\"language-text\">suspendCronJobs</code> (optional, default to false): if set to true, cronjobs will be suspended.</li>\n<li><code class=\"language-text\">excludeRef</code> (optional): an array of objects containing the resource to exclude from sleep. It can specify exactly the name of the specified resource or match based on the labels. The possible formats are:\n<ul>\n<li><code class=\"language-text\">apiVersion</code>: version of the resource. Now it supports \"apps/v1\", \"batch/v1beta1\" and \"batch/v1\".</li>\n<li><code class=\"language-text\">kind</code>: the kind of resource. Now it supports \"Deployment\" and \"CronJob\".</li>\n<li><code class=\"language-text\">name</code>: the name of the resource or</li>\n<li><code class=\"language-text\">matchLabels</code>: an object of strings with labels to identify resources. <a href=\"https://kube-green.dev/docs/sleepinfo/\" target=\"_blank\" rel=\"noopener noreferrer\">Click here</a> to see an example.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"example-\" style=\"position:relative;\"><a href=\"#example-\" aria-label=\"example  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Example 🏗</h3>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> kube<span class=\"token punctuation\">-</span>green.com/v1alpha1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> SleepInfo\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> working<span class=\"token punctuation\">-</span>hours\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">weekdays</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1-5\"</span>\n    <span class=\"token key atrule\">sleepAt</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"20:00\"</span>\n    <span class=\"token key atrule\">wakeUpAt</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"08:00\"</span>\n    <span class=\"token key atrule\">timeZone</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Europe/Rome\"</span></code></pre></div>\n<p>With this CRD, it's configured to sleep at 20:00 and wake up at 08:00 on weekdays only for Deployments.</p>\n<h2 id=\"introduction-to-opencost-by-kubecost-\" style=\"position:relative;\"><a href=\"#introduction-to-opencost-by-kubecost-\" aria-label=\"introduction to opencost by kubecost  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Introduction to OpenCost by Kubecost 💰</h2>\n<p><a href=\"https://github.com/kubecost/kubectl-cost\" target=\"_blank\" rel=\"noopener noreferrer\">kubectl-cost</a> is a <a href=\"https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/\" target=\"_blank\" rel=\"noopener noreferrer\">kubectl plugin</a> that provides easy CLI access to Kubernetes cost allocation metrics via the <a href=\"https://www.opencost.io/docs/api\" target=\"_blank\" rel=\"noopener noreferrer\">OpenCost API</a>. It allows developers, DevOps, and others to quickly determine the cost &#x26; efficiency for any Kubernetes workload.</p>\n<h3 id=\"opencost-setup\" style=\"position:relative;\"><a href=\"#opencost-setup\" aria-label=\"opencost setup permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>OpenCost Setup</h3>\n<p>OpenCost requires Prometheus for scraping metrics and data storage. Follow the steps below to install OpenCost.</p>\n<h3 id=\"quick-start-installation-\" style=\"position:relative;\"><a href=\"#quick-start-installation-\" aria-label=\"quick start installation  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Quick Start Installation 📁</h3>\n<p>These commands will get you started immediately with OpenCost.</p>\n<h4 id=\"install-prometheus\" style=\"position:relative;\"><a href=\"#install-prometheus\" aria-label=\"install prometheus permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install Prometheus</h4>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">helm <span class=\"token function\">install</span> my-prometheus <span class=\"token parameter variable\">--repo</span> https://prometheus-community.github.io/helm-charts prometheus <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--namespace</span> prometheus --create-namespace <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">pushgateway.enabled</span><span class=\"token operator\">=</span>false <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">alertmanager.enabled</span><span class=\"token operator\">=</span>false <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">-f</span> https://raw.githubusercontent.com/opencost/opencost/develop/kubernetes/prometheus/extraScrapeConfigs.yaml</code></pre></div>\n<h4 id=\"install-opencost\" style=\"position:relative;\"><a href=\"#install-opencost\" aria-label=\"install opencost permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install OpenCost</h4>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">--namespace</span> opencost <span class=\"token parameter variable\">-f</span> https://raw.githubusercontent.com/opencost/opencost/develop/kubernetes/opencost.yaml</code></pre></div>\n<h4 id=\"install-kubecost\" style=\"position:relative;\"><a href=\"#install-kubecost\" aria-label=\"install kubecost permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install Kubecost</h4>\n<p>This software requires that you have a running deployment of Kubecost in your cluster. The recommended path is to use Helm, but there are <a href=\"https://docs.kubecost.com/install\" target=\"_blank\" rel=\"noopener noreferrer\">alternative install options</a>.</p>\n<h5 id=\"helm-3\" style=\"position:relative;\"><a href=\"#helm-3\" aria-label=\"helm 3 permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Helm 3</h5>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">helm repo <span class=\"token function\">add</span> kubecost https://kubecost.github.io/cost-analyzer/\nhelm upgrade <span class=\"token parameter variable\">-i</span> --create-namespace kubecost kubecost/cost-analyzer <span class=\"token parameter variable\">--namespace</span> kubecost <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">kubecostToken</span><span class=\"token operator\">=</span><span class=\"token string\">\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"</span></code></pre></div>\n<h4 id=\"install-kubectl-cost\" style=\"position:relative;\"><a href=\"#install-kubectl-cost\" aria-label=\"install kubectl cost permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install kubectl-cost</h4>\n<h5 id=\"krew\" style=\"position:relative;\"><a href=\"#krew\" aria-label=\"krew permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Krew</h5>\n<p>If you have <a href=\"https://krew.sigs.k8s.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Krew</a>, the kubectl plugin manager, installed:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl krew <span class=\"token function\">install</span> cost</code></pre></div>\n<p>The Krew manifest can be found <a href=\"https://github.com/kubecost/kubectl-cost/blob/master/krew.yaml\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p>\n<h3 id=\"example-usage\" style=\"position:relative;\"><a href=\"#example-usage\" aria-label=\"example usage permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Example Usage</h3>\n<p>Kube-Green offers aggregation-based cost monitoring with subcommands like namespace, deployment, controller, label, pod, and node. These subcommands provide cost information aggregated by their respective names. There are two modes: rate (default) and non-rate (historical). Rate mode shows projected monthly cost based on activity, while non-rate mode displays total cost for the specified window duration.</p>\n<h4 id=\"show-the-projected-monthly-rate-for-each-namespace\" style=\"position:relative;\"><a href=\"#show-the-projected-monthly-rate-for-each-namespace\" aria-label=\"show the projected monthly rate for each namespace permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Show the Projected Monthly Rate for Each Namespace</h4>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl cost namespace --show-all-resources</code></pre></div>\n<p>Output:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">+-------------------+-----------+----------+----------+-------------+----------+----------+----------+-------------+--------------------+\n<span class=\"token operator\">|</span> NAMESPACE         <span class=\"token operator\">|</span> CPU       <span class=\"token operator\">|</span> CPU EFF. <span class=\"token operator\">|</span> MEMORY   <span class=\"token operator\">|</span> MEMORY EFF. <span class=\"token operator\">|</span> GPU      <span class=\"token operator\">|</span> PV       <span class=\"token operator\">|</span> NETWORK  <span class=\"token operator\">|</span> SHARED COST <span class=\"token operator\">|</span> MONTHLY RATE <span class=\"token punctuation\">(</span>ALL<span class=\"token punctuation\">)</span> <span class=\"token operator\">|</span>\n+-------------------+-----------+----------+----------+-------------+----------+----------+----------+-------------+--------------------+\n<span class=\"token operator\">|</span> kube-system       <span class=\"token operator\">|</span> <span class=\"token number\">29.366083</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.066780</span> <span class=\"token operator\">|</span> <span class=\"token number\">5.226317</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.928257</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">171.735257</span> <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> kubecost-stage    <span class=\"token operator\">|</span> <span class=\"token number\">6.602761</span>  <span class=\"token operator\">|</span> <span class=\"token number\">0.158069</span> <span class=\"token operator\">|</span> <span class=\"token number\">1.824703</span> <span class=\"token operator\">|</span> <span class=\"token number\">1.594699</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">2.569600</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">148.139922</span> <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> kubecost          <span class=\"token operator\">|</span> <span class=\"token number\">6.499445</span>  <span class=\"token operator\">|</span> <span class=\"token number\">0.116629</span> <span class=\"token operator\">|</span> <span class=\"token number\">1.442334</span> <span class=\"token operator\">|</span> <span class=\"token number\">1.461370</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">2.569600</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">147.654236</span> <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> default           <span class=\"token operator\">|</span> <span class=\"token number\">3.929377</span>  <span class=\"token operator\">|</span> <span class=\"token number\">0.000457</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.237937</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.283941</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">141.310171</span> <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> logging           <span class=\"token operator\">|</span> <span class=\"token number\">0.770976</span>  <span class=\"token operator\">|</span> <span class=\"token number\">0.003419</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.645843</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.260154</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">138.559676</span> <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> frontend-services <span class=\"token operator\">|</span> <span class=\"token number\">0.710425</span>  <span class=\"token operator\">|</span> <span class=\"token number\">0.003660</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.595008</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.244802</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">138.448290</span> <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> data-science      <span class=\"token operator\">|</span> <span class=\"token number\">0.000284</span>  <span class=\"token operator\">|</span> <span class=\"token number\">2.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.009500</span> <span class=\"token operator\">|</span> <span class=\"token number\">2.000000</span>    <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">137.142857</span>  <span class=\"token operator\">|</span>         <span class=\"token number\">137.152641</span> <span class=\"token operator\">|</span>\n+-------------------+-----------+----------+----------+-------------+----------+----------+----------+-------------+--------------------+\n<span class=\"token operator\">|</span> SUMMED            <span class=\"token operator\">|</span> <span class=\"token number\">47.879350</span> <span class=\"token operator\">|</span>          <span class=\"token operator\">|</span> <span class=\"token number\">9.981644</span> <span class=\"token operator\">|</span>             <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">5.139200</span> <span class=\"token operator\">|</span> <span class=\"token number\">0.000000</span> <span class=\"token operator\">|</span> <span class=\"token number\">960.000000</span>  <span class=\"token operator\">|</span>        <span class=\"token number\">1023.000194</span> <span class=\"token operator\">|</span>\n+-------------------+-----------+----------+----------+-------------+----------+----------+----------+-------------+--------------------+</code></pre></div>\n<h2 id=\"-introduction-to-cloud-custodian\" style=\"position:relative;\"><a href=\"#-introduction-to-cloud-custodian\" aria-label=\" introduction to cloud custodian permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🌐 Introduction to Cloud Custodian</h2>\n<p>Organizations can utilize <a href=\"https://cloudcustodian.io/docs/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">Custodian</a> as a powerful tool to effectively manage their cloud environments, with a strong emphasis on cost management. With Custodian, businesses can ensure compliance with security policies, enforce tag policies, perform garbage collection of unused resources, and actively manage costs — all within a unified and comprehensive solution.</p>\n<p>By incorporating Custodian into their cloud operations, organizations gain the ability to optimize resource utilization, eliminate unnecessary expenses, and achieve greater control over their cloud costs, ultimately contributing to improved financial efficiency and savings.</p>\n<h3 id=\"️-install-kubernetes-plugin\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-install-kubernetes-plugin\" aria-label=\"️ install kubernetes plugin permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🛠️ Install Kubernetes Plugin</h3>\n<p>The Kubernetes Provider (Alpha) is an optional package which can be installed to enable writing policies that interact with Kubernetes related resources.</p>\n<p>First, ensure you have installed <a href=\"https://cloudcustodian.io/docs/quickstart/index.html#install-cc\" target=\"_blank\" rel=\"noopener noreferrer\">the base Cloud Custodian application</a>. Cloud Custodian is a Python application and must run on an actively supported version.</p>\n<p>Once the base install is complete, you are now ready to install the Kubernetes provider package using one of the following options:</p>\n<h4 id=\"option-1-install-released-packages-to-local-python-environment\" style=\"position:relative;\"><a href=\"#option-1-install-released-packages-to-local-python-environment\" aria-label=\"option 1 install released packages to local python environment permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Option 1: Install Released Packages to Local Python Environment</h4>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">pip <span class=\"token function\">install</span> c7n\npip <span class=\"token function\">install</span> c7n_kube</code></pre></div>\n<h4 id=\"option-2-install-the-latest-from-the-repository\" style=\"position:relative;\"><a href=\"#option-2-install-the-latest-from-the-repository\" aria-label=\"option 2 install the latest from the repository permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Option 2: Install the Latest from the Repository</h4>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">git</span> clone https://github.com/cloud-custodian/cloud-custodian.git\npip <span class=\"token function\">install</span> <span class=\"token parameter variable\">-e</span> ./cloud-custodian\npip <span class=\"token function\">install</span> <span class=\"token parameter variable\">-e</span> ./cloud-custodian/tools/c7n_kube</code></pre></div>\n<h3 id=\"-connecting-to-your-cluster\" style=\"position:relative;\"><a href=\"#-connecting-to-your-cluster\" aria-label=\" connecting to your cluster permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🔗 Connecting to Your Cluster</h3>\n<p>The Custodian Kubernetes provider automatically uses your Kubectl configuration or the config file set by the environment variable <code class=\"language-text\">KUBECONFIG</code>. <a href=\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\" target=\"_blank\" rel=\"noopener noreferrer\">See the Kubernetes Docs</a> for more information.</p>\n<h3 id=\"-write-your-first-policy\" style=\"position:relative;\"><a href=\"#-write-your-first-policy\" aria-label=\" write your first policy permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>⚡ Write Your First Policy</h3>\n<p>A policy is the primary way that Custodian is configured to manage cloud resources. It is a YAML file that follows a predetermined schema to describe what you want Custodian to do.</p>\n<p>In the example below, we will write a policy that filters for pods with the label \"custodian\" and deletes it:</p>\n<p>First, let's create a pod resource that we want to target with the policy:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl run nginx <span class=\"token parameter variable\">--image</span><span class=\"token operator\">=</span>nginx <span class=\"token parameter variable\">--labels</span><span class=\"token operator\">=</span>name<span class=\"token operator\">=</span>custodian\nkubectl get pod <span class=\"token parameter variable\">-o</span> wide --show-labels</code></pre></div>\n<p>Output:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">NAME    READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES   LABELS\nnginx   <span class=\"token number\">1</span>/1     Running   <span class=\"token number\">0</span>          24s   <span class=\"token number\">10.0</span>.1.224   worker   <span class=\"token operator\">&lt;</span>none<span class=\"token operator\">></span>           <span class=\"token operator\">&lt;</span>none<span class=\"token operator\">></span>            <span class=\"token assign-left variable\">name</span><span class=\"token operator\">=</span>custodian</code></pre></div>\n<p>Now in the example below, we will write a policy that filters for pods with the label \"custodian\" and deletes it:</p>\n<p><strong>Filename: custodian.yml</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">policies</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> my<span class=\"token punctuation\">-</span>first<span class=\"token punctuation\">-</span>policy\n        <span class=\"token key atrule\">description</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">|</span><span class=\"token scalar string\">\n            Deletes pods with label name:custodian</span>\n        <span class=\"token key atrule\">resource</span><span class=\"token punctuation\">:</span> k8s.pod\n        <span class=\"token key atrule\">filters</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> value\n                <span class=\"token key atrule\">key</span><span class=\"token punctuation\">:</span> metadata.labels.name\n                <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> custodian\n        <span class=\"token key atrule\">actions</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> delete</code></pre></div>\n<p>Next, run the following command to execute the policy with Custodian:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">custodian run --output-dir<span class=\"token operator\">=</span>output custodian.yml --cache-period <span class=\"token number\">0</span> <span class=\"token parameter variable\">-v</span></code></pre></div>\n<h2 id=\"-introduction-to-cloudability\" style=\"position:relative;\"><a href=\"#-introduction-to-cloudability\" aria-label=\" introduction to cloudability permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🌟 Introduction to Cloudability</h2>\n<p><a href=\"https://www.apptio.com/products/cloudability/\" target=\"_blank\" rel=\"noopener noreferrer\">Apptio Cloudability</a> streamlines Kubernetes cost management by automatically discovering and mapping cloud resources associated with each cluster, providing comprehensive billing data. Their interactive tool empowers users to gain insights into cluster costs and resource consumption within a chosen timeframe.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 45.294117647058826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHurUwK/8QAGBAAAgMAAAAAAAAAAAAAAAAAABARIUH/2gAIAQEAAQUCLIe//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhAAAwAAAAAAAAAAAAAAAAAAAAEg/9oACAEBAAY/ApZ//8QAGxABAAICAwAAAAAAAAAAAAAAAQAhESAxUZH/2gAIAQEAAT8hs4JnoexC3of/2gAMAwEAAgADAAAAEG8f/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFREBAQAAAAAAAAAAAAAAAAAAACH/2gAIAQIBAT8QV//EAB0QAQABAwUAAAAAAAAAAAAAAAEAEBGxIVFxwfD/2gAIAQEAAT8Q1LAm62h4HUbIF5oTIYJ//9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Cloudability\" title=\"\" src=\"/static/55bbf8b29567b9fa7b8cddb55a8f5b26/7bf67/Cloudability.jpg\" srcset=\"/static/55bbf8b29567b9fa7b8cddb55a8f5b26/651be/Cloudability.jpg 170w,\n/static/55bbf8b29567b9fa7b8cddb55a8f5b26/d30a3/Cloudability.jpg 340w,\n/static/55bbf8b29567b9fa7b8cddb55a8f5b26/7bf67/Cloudability.jpg 680w,\n/static/55bbf8b29567b9fa7b8cddb55a8f5b26/990cb/Cloudability.jpg 1020w,\n/static/55bbf8b29567b9fa7b8cddb55a8f5b26/c44b8/Cloudability.jpg 1360w,\n/static/55bbf8b29567b9fa7b8cddb55a8f5b26/b17f8/Cloudability.jpg 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"-automatically-map-cluster-costs\" style=\"position:relative;\"><a href=\"#-automatically-map-cluster-costs\" aria-label=\" automatically map cluster costs permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🔍 Automatically Map Cluster Costs</h3>\n<p>Apptio Cloudability can automatically discover all the cloud resources backing each of your Kubernetes clusters and map this information back to detailed billing data. Users are provided with a specialized interactive tool that allows them to quickly understand the full cost of each cluster and underlying resource consumption within a definable time window.</p>\n<h3 id=\"-intelligently-allocate-spend\" style=\"position:relative;\"><a href=\"#-intelligently-allocate-spend\" aria-label=\" intelligently allocate spend permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>💡 Intelligently Allocate Spend</h3>\n<p>Sophisticated algorithms analyze resource utilization metrics on each node — CPU, memory, network, and disk — and evaluate pod-level Quality of Service settings so that these cluster costs can be split out and fairly allocated across Kubernetes constructs of Namespaces and Labels.</p>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🌟 Conclusion</h2>\n<p>In order to maximize the return on investment in cloud adoption, it is crucial to effectively manage Kubernetes costs. Conventional methods of calculating resource consumption and associated expenses often prove insufficient. As organizations progress, they may seek to enhance cost efficiency by utilizing resources strategically. 💮</p>\n<p>I hope this blog post has been helpful.</p>\n<br>\n<p><strong><em>Until next time, つづく 🎉</em></strong></p>\n<blockquote>\n<p>💡 Thank you for Reading !! 🙌🏻😁📃, see you in the next blog.🤘  <strong><em>Until next time 🎉</em></strong></p>\n</blockquote>\n<p>🚀 Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>♻️ LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>♻️ X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ✌🏻</strong></p>\n<h1 align=\"center\">🔰 Keep Learning !! Keep Sharing !! 🔰</h1>\n<p><strong>📅 Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/in-place-kubernetes-pod-resizing/","title":"In-Place Kubernetes Pod Resource Resizing Feature: A Deep Dive 🔍","date":"2024-10-28 17:30:00"},"excerpt":"In-Place Pod Resizing in Action ⚙️ 🎌 Kick-off Welcome to this exciting deep dive into one of the newest features in Kubernetes management…","html":"<blockquote>\n<p><strong>In-Place Pod Resizing in Action ⚙️</strong></p>\n</blockquote>\n<h2 id=\"-kick-off\" style=\"position:relative;\"><a href=\"#-kick-off\" aria-label=\" kick off permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🎌 Kick-off</h2>\n<p>Welcome to this exciting deep dive into one of the newest features in Kubernetes management — the <strong>In-Place Pod Resource Resizing</strong> feature!</p>\n<p>In-place pod resource resizing is a new feature in Kubernetes that allows you to resize the CPU and memory resources allocated to a pod without restarting it. This can be a major advantage for many applications, as it can help to improve performance and efficiency without causing any downtime.</p>\n<p>In this blog post, we will take a deep dive into the in-place pod resource resizing feature. We will discuss how it works, the benefits it offers, and how to use it. We will also show you how to resize a pod in-place in action.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 500px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC2UlEQVR42o1U70tTURi+f0L/QR/6AwoiiH5Anywiir4V9CGCMNA+RIJgDQwLEkQ/GELQF3XVQsyy2pRS04U/WqiRP2aIosvNbXduc7vb3b333Kdzzr3nbs4te8eBu/ec87zP+z7veyRUMdM0YZhkn5/5TPqrZlIFJGjEcK6wb1nNQi5kodsBTNsvgElJ4H2AAmg6sYGbM69wdrQTJz530NXOv28H3uDHTshhS8rYSqXMeJyMgsYJNw57n6B5YQiT8jq2cimEckn442tw/fLiyKfHuPXdA5XonHU4n64AaNhpTvgx/LILIVO1GZsWbRNOihldxY1pN65P9eBrbBUXxp87ZyXBjpvbDczOWi5CUDAIF0cYYULRNBIFBYNbCzg3+gyH+hvRMPfOKYEEYhd0aQmoqwd2d2Gwy7Z/M2ag2Z1Ey2uadlznvg0licv+Fzg23AbJfQfDkWAJoGCwtgbMzzv1ZEw6B3dxtC6Ma0/juPIoiuN3w9wnroRzaV7jrF5wBLVS1mnknh5AliEa4PeWhlP3I2h/m0afX4FnPIu2/hRO3otg5Y/GrxNzb2cURUmlgNpaIBbj6TL7OKNwQAY09jOPL3N5CpzF6YYI+r8pVo/SNJjKJWW2AfN5YGiIntBoHayNjoE0rrZEMTCZhS+Qg5euD9MKLjVHOWteM1JpUgT8yAgtStimbyKcMHCGsqntlPF+iqpKweq7EpxhSNb3NMdeQKFya6tVR6awbiU+E1Rx0RVFzcNtnKer5sE2ppZVu4WqzbIIs7IC9PUVm9x2L4c0+BdUTNC1tKk5D8e/HwfBcnER6O52WsekwOV5sYbHgYDiQC4HNDU5qbNAbIeULEterUii6vMlQFkLra9bY9jbC8TjQKHABUMmAwQCgMsF7OygkjJS+VvoHAgGLaHGxgCfD6inY+nxAKurxYn63wd2XzqsFMkkF+sgk6ruMFAGUA7O/lepHwP8C7nF1i4Jf/YXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"resize\" title=\"\" src=\"/static/ae6469f85d6a2da77b247cfb4f4a4f7c/0b533/resize.png\" srcset=\"/static/ae6469f85d6a2da77b247cfb4f4a4f7c/04472/resize.png 170w,\n/static/ae6469f85d6a2da77b247cfb4f4a4f7c/9f933/resize.png 340w,\n/static/ae6469f85d6a2da77b247cfb4f4a4f7c/0b533/resize.png 500w\" sizes=\"(max-width: 500px) 100vw, 500px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"-exploring-the-long-awaited-in-place-pod-resource-resizing-in-kubernetes-127\" style=\"position:relative;\"><a href=\"#-exploring-the-long-awaited-in-place-pod-resource-resizing-in-kubernetes-127\" aria-label=\" exploring the long awaited in place pod resource resizing in kubernetes 127 permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>📘 Exploring the Long-Awaited In-Place Pod Resource Resizing in Kubernetes 1.27</h3>\n<p>Like many, I have been waiting for the ability to resize Kubernetes pods without restarting them for several years. This feature is now available in <a href=\"https://kubernetes.io/docs/setup/release/notes/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes 1.27</a>, and I am excited to try it out.</p>\n<p>This feature, called in-place pod resource resizing, allows you to change the CPU and memory resources allocated to a pod without having to restart it. This is a major advantage for many applications, as it can help to improve performance and efficiency without causing any downtime.</p>\n<p>The way in-place pod resource resizing works is by making the pod spec resources mutable. This means that Kubernetes can update the underlying c-group allocation in-place. This is particularly useful in the case of scaling pods vertically, such as with Kubernetes' built-in <a href=\"https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler\" target=\"_blank\" rel=\"noopener noreferrer\">Vertical Pod Autoscaler (VPA)</a>.</p>\n<p>Vertical scaling proves indispensable in various use cases, especially with stateful database workloads experiencing bursty traffic, where service disruptions can be costly. Additionally, <a href=\"https://www.youtube.com/watch?v=jjfa1cVJLwc&#x26;t=818s\" target=\"_blank\" rel=\"noopener noreferrer\">an exciting talk at KubeCon North America 2022</a> showcased the utilization of this in-place feature with eBPF, adding to its versatility.</p>\n<p>In this blog post, I will show you how to try out in-place pod resource resizing. I will also discuss the new changes you'll see in the pod spec. There are many ways to do this; this is just one simple example.</p>\n<h3 id=\"-a-hands-on-guide-to-in-place-pod-resource-resizing-in-kubernetes\" style=\"position:relative;\"><a href=\"#-a-hands-on-guide-to-in-place-pod-resource-resizing-in-kubernetes\" aria-label=\" a hands on guide to in place pod resource resizing in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🏗 A Hands-On Guide to In-Place Pod Resource Resizing in Kubernetes</h3>\n<p>The new feature is introduced under the name <strong>InPlacePodVerticalScaling</strong>.</p>\n<p>Let's now start a test pod. Let's say that your application can safely change the amount of CPUs without restarting, but changing the amount of memory requires a restart. For example, a pod running a database has no problem with a CPU count change while running, but decreasing the amount of memory would cause unexpected behavior.</p>\n<p>To reflect this in the pod YAML, you need to set the <code class=\"language-text\">restartPolicy</code> to <code class=\"language-text\">RestartContainer</code> for the memory resource. Otherwise, the default behavior will be to attempt to update the resource in-place.</p>\n<p>Here is an example of a pod YAML that you can use:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 68.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAABRUlEQVR42qVT226CQBQURE2Dt1JBUJEFqtxBoib9///aTGdjtH1oUpGHk2x298zOmZkdbJNEGuERAzuFtk4x6FsfQSEtUWEW1Bhty/6AflzLKLtiKk79wVQt/ELaYY2J32AWnWGKth/gSpTSCSssg5IjF9Dc7HGorV/QlQ3SI6AVnTCPr5jFFxhKSydh8YKd3NbPAvKyjA4NxLGFlX1hdTzD8HKMNjnMfQkrrqlvBY17zwGS4ZKNW+qoRjf9ggxzjHcFdI4/9DLorMEvKf4FnBJEfDZI0hZeROCkhagumPOBhXpk3yFOd4Y7jmbuSujcHLopjE1Gk3JMyFSN30HDVE7YvCGzNzY/DpQhTvJjTheGKhoMOFZCGVDeGDkv5lC5PKbo4eGEdwJqHFd/1oA/c+imUi3soIIyx6I5Vtx0y979I7gZvgFYAGQTxnq6lgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"pod\" title=\"\" src=\"/static/a36b0cd2c702a14531a42b8b9bd867dc/c5bb3/pod.png\" srcset=\"/static/a36b0cd2c702a14531a42b8b9bd867dc/04472/pod.png 170w,\n/static/a36b0cd2c702a14531a42b8b9bd867dc/9f933/pod.png 340w,\n/static/a36b0cd2c702a14531a42b8b9bd867dc/c5bb3/pod.png 680w,\n/static/a36b0cd2c702a14531a42b8b9bd867dc/b12f7/pod.png 1020w,\n/static/a36b0cd2c702a14531a42b8b9bd867dc/b5a09/pod.png 1360w,\n/static/a36b0cd2c702a14531a42b8b9bd867dc/29007/pod.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>To apply the YAML and ensure it's running, follow these steps:</p>\n<ol>\n<li><strong>Save the YAML content to a file</strong>, for example, <code class=\"language-text\">test-pod.yaml</code>.</li>\n<li><strong>Apply the YAML</strong> to create the pod in your Kubernetes cluster.</li>\n<li><strong>Wait until the pod is ready and running</strong>:</li>\n</ol>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 26.47058823529412%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAv0lEQVR42pWQyRKCQAxEB0FgQD2poIKIIOJQIqKAu///T1htXM4uh65KKsnrJMwORK2FMVhfoGEvINkC8pA0EGBW/Jckmme6X9Wt8ARzdgKfltAmJbrJFYaXkcn8byhT3azWvS34pIBOUkZLqOMcrDd/AfsRxdE7/sGgHZ1vZngEH6ZohQcYwf55+gPeGCQE34D7FWQnRdNd09AXKPeLmxHsqDmHRtuZXg7FydCOLtBoU+6unrlKtY6ff/6hFeMO45iAlE/LdCgAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"apply\" title=\"\" src=\"/static/ad7d776e6114215c74b4b2b8c0165d6a/c5bb3/apply.png\" srcset=\"/static/ad7d776e6114215c74b4b2b8c0165d6a/04472/apply.png 170w,\n/static/ad7d776e6114215c74b4b2b8c0165d6a/9f933/apply.png 340w,\n/static/ad7d776e6114215c74b4b2b8c0165d6a/c5bb3/apply.png 680w,\n/static/ad7d776e6114215c74b4b2b8c0165d6a/b12f7/apply.png 1020w,\n/static/ad7d776e6114215c74b4b2b8c0165d6a/b5a09/apply.png 1360w,\n/static/ad7d776e6114215c74b4b2b8c0165d6a/29007/apply.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Under the pod spec, one of the new and notable features to observe is the <code class=\"language-text\">resizePolicy</code>. This section defines how the pod's resources can be resized and specifies the behavior for different resource types, such as memory and CPU.</p>\n<p>For memory resources, the <code class=\"language-text\">resizePolicy</code> indicates that changes to the memory allocation require a restart of the container. This is denoted by setting the <code class=\"language-text\">restartPolicy</code> to <code class=\"language-text\">RestartContainer</code> for the \"memory\" resource. In contrast, for CPU resources, a restart is not necessary during resizing, as indicated by the <code class=\"language-text\">restartPolicy</code> set to <code class=\"language-text\">NotRequired</code> for the \"cpu\" resource.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 32.94117647058823%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAoElEQVR42q3Ryw6CMBQE0EYBDWAIGlBEKPIoAsVWjPr/XzaWunANYTGZ3cncXGIWFUhwAzkulF3awYoarE/NMuCecngphxG1IGH9z1zQTTiCrEeo4iQdiFq6GtfOxbdxizi/IyuFbjd/wmcfWJceZsx1JoGbc4uCCdT1AyWT8Ku3Bu1MKnyATeU00FAPOdDf2WM7VMArX3Cvg15JAjYJ/AIUirIjczW/sgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"pod-resize\" title=\"\" src=\"/static/8ad89fa2a863c446eae064582084b46f/c5bb3/pod-resize.png\" srcset=\"/static/8ad89fa2a863c446eae064582084b46f/04472/pod-resize.png 170w,\n/static/8ad89fa2a863c446eae064582084b46f/9f933/pod-resize.png 340w,\n/static/8ad89fa2a863c446eae064582084b46f/c5bb3/pod-resize.png 680w,\n/static/8ad89fa2a863c446eae064582084b46f/b12f7/pod-resize.png 1020w,\n/static/8ad89fa2a863c446eae064582084b46f/b5a09/pod-resize.png 1360w,\n/static/8ad89fa2a863c446eae064582084b46f/29007/pod-resize.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Under the status field, new and noteworthy information includes the <code class=\"language-text\">allocatedResources</code> and <code class=\"language-text\">resources</code> fields. <code class=\"language-text\">allocatedResources</code> reflects the current resource allocation to the pod's containers, while <code class=\"language-text\">resources</code> represents the desired or to-be-updated resource specifications.</p>\n<p>This distinction provides real-time insights into resource utilization and allows effective monitoring and optimization of the pod's resource management. These fields are nested under <code class=\"language-text\">containerStatuses</code>, presenting a comprehensive view of each container's status and resource usage. Understanding this information is vital for fine-tuning resource allocation in the Kubernetes environment.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 45.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAv0lEQVR42qWSyw6CMBREiwQfAQ0xgDTIW6HI00T//78MzXgLG7fCYtJFb05mMsN4Lj77WyGZK6R2EZIpeeX8/inNryTb8mr00w5e0iLIOjhJA4M/QAfLxDwx2lGDrHgiLAa4aQ/zWq8BltLgFeyoxi5sYeUv+ijXAY9hAxXbUs68EtpS2K9DN25hUvSNvwI2AeeGEOY9gvuAQzyA2lrnUCcAT1s41LJOblXsxUDNV7sTcGkuZ5rO6faeXC6BqmRf48HjPEXUmagAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cpu-mem\" title=\"\" src=\"/static/6080ec0104832e08d9f74b51e2eee444/c5bb3/cpu-mem.png\" srcset=\"/static/6080ec0104832e08d9f74b51e2eee444/04472/cpu-mem.png 170w,\n/static/6080ec0104832e08d9f74b51e2eee444/9f933/cpu-mem.png 340w,\n/static/6080ec0104832e08d9f74b51e2eee444/c5bb3/cpu-mem.png 680w,\n/static/6080ec0104832e08d9f74b51e2eee444/b12f7/cpu-mem.png 1020w,\n/static/6080ec0104832e08d9f74b51e2eee444/b5a09/cpu-mem.png 1360w,\n/static/6080ec0104832e08d9f74b51e2eee444/29007/cpu-mem.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"cpu-resize\" style=\"position:relative;\"><a href=\"#cpu-resize\" aria-label=\"cpu resize permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>CPU Resize</h3>\n<p>To begin, let's adjust the CPU limits of the pod, increasing them from 2 to 3. We'll accomplish this using the command line by applying a patch:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 19.411764705882355%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAiElEQVR42n2P0QrDIAxF+w1anTWaDhu3l/3/38ldtBRayvZwuJcYjmT6iG9+nTEbZb5irVV6d7e3X0wipdUq2LaCI0speL0reGWIbGDOyLwg5U7U+c4j+LswUmj8JFBakFdC75EWkJKZhiDGMGS6O/Z6Jv2gz29CPakZY/fzNI9uTv0fZ5lzDl+eW2XxMn/ZYQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"check\" title=\"\" src=\"/static/b28b0ae003f90c89860865a77272f8e6/c5bb3/check.png\" srcset=\"/static/b28b0ae003f90c89860865a77272f8e6/04472/check.png 170w,\n/static/b28b0ae003f90c89860865a77272f8e6/9f933/check.png 340w,\n/static/b28b0ae003f90c89860865a77272f8e6/c5bb3/check.png 680w,\n/static/b28b0ae003f90c89860865a77272f8e6/b12f7/check.png 1020w,\n/static/b28b0ae003f90c89860865a77272f8e6/b5a09/check.png 1360w,\n/static/b28b0ae003f90c89860865a77272f8e6/29007/check.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Upon inspecting the pod now (using <code class=\"language-text\">kubectl get pod testinplace -o yaml</code>), it is probable (though not guaranteed) that you will observe the appearance of the <code class=\"language-text\">resize</code> field. Additionally, you will notice the pod spec resources displaying the updated value, while the pod status resources retain the previous value.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 84.70588235294117%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAABC0lEQVR42q2USW6EMBBF+wihBmNoBps56c79L2fpp0wvsscskBEST7/8n/14R5eaicEkUBFI4fOIA6dnq/gyIN8BdCpp7AVLJPRPg3IhkIhT4xmvjTB0DsRcBhThlFP9rBWO1SGECOdcCVBS7QSvvcI6K1TVxr6e8mE/p4oykLAvin0/MI4jiOgasPWc/svgc9yc8nLCrpUUR4W1bbAPlKVgZIOkKQjmQKc6S8wptWQPPx5uM6G7w8MMrB3jbaWEobaPeo+Hx0LmoZ4NF5WSE+ZCfo/KxrZyXFnKU+z88r1mD209doQSDzMwDnY5WMvbLAh9bddYQULv1TxkDH2DOC2Y5wXe+0vHL+/9H+4UqAaHbBuMAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"resized\" title=\"\" src=\"/static/ae92bf0867b1c10086bd3265e9a817db/c5bb3/resized.png\" srcset=\"/static/ae92bf0867b1c10086bd3265e9a817db/04472/resized.png 170w,\n/static/ae92bf0867b1c10086bd3265e9a817db/9f933/resized.png 340w,\n/static/ae92bf0867b1c10086bd3265e9a817db/c5bb3/resized.png 680w,\n/static/ae92bf0867b1c10086bd3265e9a817db/b12f7/resized.png 1020w,\n/static/ae92bf0867b1c10086bd3265e9a817db/b5a09/resized.png 1360w,\n/static/ae92bf0867b1c10086bd3265e9a817db/29007/resized.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>The duration for the pod to transition from <code class=\"language-text\">resize: InProgress</code> to <code class=\"language-text\">resize: complete</code> may vary depending on various factors. The time taken for the resizing process to finish could be different for different pods or environments.</p>\n<p>In case you encounter a different flag, such as <code class=\"language-text\">resize: Infeasible</code>, it indicates that the resizing process is not feasible. To address this, check your node's available resources to ensure they are sufficient to accommodate the requested changes. Insufficient resources may prevent the successful completion of the resizing operation.</p>\n<h3 id=\"memory-resize\" style=\"position:relative;\"><a href=\"#memory-resize\" aria-label=\"memory resize permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Memory Resize</h3>\n<p>Continuing with memory adjustments, let's raise the limits from 1G to 2G:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 16.470588235294116%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAjUlEQVR42lWOSw6DMAxEuUP8DRQSCGXR+98Oaeqki7aL0Ywta/ym157v5TCoGMwcpt0N7hkiOrKqRuYh7q4SWZCIkBKB6Ktpq+W+rhOt7XiGn+eBo9WRS1nRYt7C1zLjsWaUfcFWQzHnOZ67/hcy063eP1KQcBzIoGBO8Bxk+iEzk+GeO7EMyl7W97+Fb7Q9TX7byQ4KAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"mem-resize\" title=\"\" src=\"/static/20cf12e2b44f781630e3999632ef162b/c5bb3/mem-resize.png\" srcset=\"/static/20cf12e2b44f781630e3999632ef162b/04472/mem-resize.png 170w,\n/static/20cf12e2b44f781630e3999632ef162b/9f933/mem-resize.png 340w,\n/static/20cf12e2b44f781630e3999632ef162b/c5bb3/mem-resize.png 680w,\n/static/20cf12e2b44f781630e3999632ef162b/b12f7/mem-resize.png 1020w,\n/static/20cf12e2b44f781630e3999632ef162b/b5a09/mem-resize.png 1360w,\n/static/20cf12e2b44f781630e3999632ef162b/29007/mem-resize.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>The process remains identical to the previous step, involving the use of the <code class=\"language-text\">resize</code> tag and inspecting the pod status. To ensure that the resizing process is complete, verify the corresponding field or resource status. In my setup, this typically takes approximately 15 seconds to 1 minute, although it's essential to note that there's currently a bug that might cause it to take longer.</p>\n<p>After confirming the successful resizing completion, proceed to verify whether the restart occurred based on the flag we set earlier. The restart behavior should align with the specified flag, where memory changes triggered a container restart, while CPU changes did not necessitate a restart. This validation ensures that the In-Place Pod Resource Resizing feature is functioning as expected, allowing for seamless resource updates without unnecessary container disruptions.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 16.470588235294116%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAfklEQVR42n2NQQ7DIAwE8xCg1GAMhJAiIfX//0LaUtpDL+lh5dHKHm8t34c7CDdLsORgjIHRGnrmzXqx+uFPf5Ut1DbkeIA8Q2pDKOeUWziRNUkifMxr2dL36R/pFkodUs916JgR9gzigNyfU5oQUkLpHT7t4BTBOUMrdSl8AUPjU9xl/pwRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"checking\" title=\"\" src=\"/static/1cb62436359cdcff026dd877b0073ee3/c5bb3/checking.png\" srcset=\"/static/1cb62436359cdcff026dd877b0073ee3/04472/checking.png 170w,\n/static/1cb62436359cdcff026dd877b0073ee3/9f933/checking.png 340w,\n/static/1cb62436359cdcff026dd877b0073ee3/c5bb3/checking.png 680w,\n/static/1cb62436359cdcff026dd877b0073ee3/b12f7/checking.png 1020w,\n/static/1cb62436359cdcff026dd877b0073ee3/b5a09/checking.png 1360w,\n/static/1cb62436359cdcff026dd877b0073ee3/29007/checking.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Indeed, the process is complete! It's exciting to have experienced the new In-Place Pod Resource Resizing feature firsthand. The ability to resize resources without disrupting the pod is a game-changer, especially for stateful applications that require vertical pod autoscaling.</p>\n<h2 id=\"-takeaway\" style=\"position:relative;\"><a href=\"#-takeaway\" aria-label=\" takeaway permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>🔚 Takeaway</h2>\n<p>In this blog post, we have explored the new in-place pod resource resizing feature in Kubernetes. We have seen how this feature can be used to resize pods without having to restart them.</p>\n<p>In-place pod resource resizing is a powerful feature that can be used to improve the performance and efficiency of Kubernetes applications. It can also be used to reduce downtime and improve the overall reliability of Kubernetes clusters.</p>\n<p>I hope this blog post has been helpful.</p>\n<br>\n<p><strong><em>Until next time, つづく 🎉</em></strong></p>\n<blockquote>\n<p>💡 Thank you for Reading !! 🙌🏻😁📃, see you in the next blog.🤘  <strong><em>Until next time 🎉</em></strong></p>\n</blockquote>\n<p>🚀 Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>♻️ LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>♻️ X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ✌🏻</strong></p>\n<h1 align=\"center\">🔰 Keep Learning !! Keep Sharing !! 🔰</h1>\n<p><strong>📅 Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}