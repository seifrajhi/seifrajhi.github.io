{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/victoriametrics-time-series-db-prometheus-k8s/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>A great Time-Series database for monitoring and analytics üîÜ</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üí¨ Introduction</h2>\n<p><a href=\"https://victoriametrics.com/\" target=\"_blank\" rel=\"noopener noreferrer\">VictoriaMetrics</a> is a time-series database designed for high-performance monitoring and analytics. It is similar to Prometheus in many ways, but it offers several advantages, including better performance, scalability, and data compression. VictoriaMetrics is also open-source and free to use.</p>\n<p>VictoriaMetrics can monitor a wide range of systems, including Kubernetes clusters, servers, applications, infrastructure components, and even IoT devices.</p>\n<p>In this blog post, we will provide a comprehensive overview of VictoriaMetrics, covering the following topics:</p>\n<ul>\n<li>What is VictoriaMetrics and how does it work?</li>\n<li>How does VictoriaMetrics compare to Prometheus?</li>\n<li>How to implement Kubernetes monitoring with VictoriaMetrics</li>\n</ul>\n<p>This blog post is for anyone who wants to learn more about VictoriaMetrics or use it to improve their system monitoring capabilities. It is also a good resource for anyone who is considering using Prometheus and wants to compare the two solutions.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 37.05882352941176%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA/ElEQVR42m3Qv0uCcRDH8SszJJCGlsophHQoojKo0PDHoA0NQgUZLtkgITQ2REsQCDW0Bu2tQdbg0tTef+JYg2Xvo4/08NDBi+fL89zdc98zM3tEH596fqCHLfuNCZ23UUcBDRygimPUUETJC/bwjgG+8YVrzNlfeKNTXGFRzY9wgjbOcYFLT+5gB1019cQb/dljBHFMYgarmMYskjqnkMCUF+zjCYdYwR1uVeARQR4V7CKDsq7rg2SxjIXhdV7U9AFvaGnCpr5HsYQNNfLCeeS0t6zWsDZsuIlXTbiOe034X/i0Y4FVuHHEMBpMTONZE54FCixUbKF34Tz7AcCgKC/HXn1iAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"VictoriaMetrics Cover\" title=\"\" src=\"/static/da2ae9ac69337d23c8ce988e44792e61/c5bb3/vectoria-cover.png\" srcset=\"/static/da2ae9ac69337d23c8ce988e44792e61/04472/vectoria-cover.png 170w,\n/static/da2ae9ac69337d23c8ce988e44792e61/9f933/vectoria-cover.png 340w,\n/static/da2ae9ac69337d23c8ce988e44792e61/c5bb3/vectoria-cover.png 680w,\n/static/da2ae9ac69337d23c8ce988e44792e61/b12f7/vectoria-cover.png 1020w,\n/static/da2ae9ac69337d23c8ce988e44792e61/c1b63/vectoria-cover.png 1200w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><strong>TL;DR: VictoriaMetrics and Prometheus</strong></p>\n<p><strong>VictoriaMetrics</strong> and <strong>Prometheus</strong> are both time-series databases used for monitoring and analytics, but they have some key differences:</p>\n<p><strong>Main features of VictoriaMetrics Compared to Prometheus</strong></p>\n<ol>\n<li>\n<p><strong>Performance and Scalability</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Higher performance, better scalability, and more efficient data compression.</li>\n<li><strong>Prometheus</strong>: Good performance but can struggle with high cardinality metrics and large-scale environments.</li>\n</ul>\n</li>\n<li>\n<p><strong>Resource Usage</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Lower CPU, RAM, and disk IO usage, especially with <a href=\"https://docs.victoriametrics.com/vmagent/\" target=\"_blank\" rel=\"noopener noreferrer\">vmagent</a>.</li>\n<li><strong>Prometheus</strong>: Higher resource consumption, especially with high cardinality metrics.</li>\n</ul>\n</li>\n<li>\n<p><strong>Data Ingestion</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Supports both pull and push models natively.</li>\n<li><strong>Prometheus</strong>: Primarily pull-based; requires Pushgateway for push model.</li>\n</ul>\n</li>\n<li>\n<p><strong>High Availability</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Built-in support for high availability.</li>\n<li><strong>Prometheus</strong>: No native high availability; requires duplication and sharding.</li>\n</ul>\n</li>\n<li>\n<p><strong>Long-Term Storage</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Designed for long-term storage with efficient data retention.</li>\n<li><strong>Prometheus</strong>: Not intended for long-term storage; relies on external solutions.</li>\n</ul>\n</li>\n<li>\n<p><strong>Anomaly Detection</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Includes built-in anomaly detection features.</li>\n<li><strong>Prometheus</strong>: Does not have built-in anomaly detection.</li>\n</ul>\n</li>\n<li>\n<p><strong>Buffering</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Independent disk-backed buffers for each remote storage.</li>\n<li><strong>Prometheus</strong>: Single shared buffer for all remote storage systems.</li>\n</ul>\n</li>\n<li>\n<p><strong>Query Language</strong>:</p>\n<ul>\n<li><strong>VictoriaMetrics</strong>: Uses MetricsQL, which extends PromQL with additional features.</li>\n<li><strong>Prometheus</strong>: Uses PromQL.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"-victoriametrics-vs-prometheus-system-properties-comparison\" style=\"position:relative;\"><a href=\"#-victoriametrics-vs-prometheus-system-properties-comparison\" aria-label=\" victoriametrics vs prometheus system properties comparison permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìä VictoriaMetrics vs Prometheus: System Properties Comparison</h2>\n<p>VictoriaMetrics is a monitoring system that is fully compatible with Prometheus. It offers many of the same features as Prometheus, but with some additional benefits, such as higher performance and scalability.</p>\n<p>One key difference between VictoriaMetrics and Prometheus is that VictoriaMetrics includes an anomaly detection feature. This feature can be used to identify unusual changes in metrics data, which can be helpful for troubleshooting and identifying potential problems.</p>\n<p>While both <code class=\"language-text\">vmagent</code> and Prometheus may scrape Prometheus targets (aka <code class=\"language-text\">/metrics</code> pages) according to the provided Prometheus-compatible scrape configs and send data to multiple remote storage systems, <code class=\"language-text\">vmagent</code> has the following additional features:</p>\n<ul>\n<li><code class=\"language-text\">vmagent</code> usually requires lower amounts of CPU, RAM, and disk IO compared to Prometheus when scraping an enormous number of targets (more than 1000) or targets with a great number of exposed metrics.</li>\n<li><code class=\"language-text\">vmagent</code> provides independent disk-backed buffers for each configured remote storage (see <code class=\"language-text\">-remoteWrite.url</code>). This means that slow or temporarily unavailable storage doesn't prevent it from sending data to healthy storage in parallel. Prometheus uses a single shared buffer for all the configured remote storage systems (see <code class=\"language-text\">remote_write->url</code>) with a hardcoded retention of 2 hours.</li>\n<li><code class=\"language-text\">vmagent</code> may accept, relabel, and filter data obtained via multiple data ingestion protocols in addition to data scraped from Prometheus targets. That means it supports both pull and push protocols for data ingestion. <a href=\"https://docs.victoriametrics.com/vmagent.html#features\" target=\"_blank\" rel=\"noopener noreferrer\">See these docs for details</a>.</li>\n</ul>\n<p>Prometheus does not have a native High Availability mode: to have high availability, we had to duplicate our Prometheus instances. This implies that our targets were \"scraped\" by all our Prometheus instances (same for our rules and records). To avoid this, we had to use sharding, but this made the infrastructure more complex. More information on this subject in <a href=\"https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/high-availability.md\" target=\"_blank\" rel=\"noopener noreferrer\">this documentation</a> from the Prometheus operator.</p>\n<p>Prometheus is not designed to store metrics on a long-term basis, as mentioned in <a href=\"https://prometheus.io/docs/prometheus/latest/storage/#operational-aspects\" target=\"_blank\" rel=\"noopener noreferrer\">the documentation</a>:</p>\n<blockquote>\n<p>Prometheus's local storage is not intended to be durable long-term storage; external solutions offer extended retention and data durability.</p>\n</blockquote>\n<p>We worked around this limitation by using VictoriaMetrics (VMCluster) as a LongTermStorage via the <code class=\"language-text\">remote_write</code> protocol.</p>\n<p>All processes (scraping, ingest, storage, etc.) were, until now, managed in the same Prometheus instance, which implied a less flexible and vertical scaling only (since recently a <a href=\"https://prometheus.io/blog/2021/11/16/agent/\" target=\"_blank\" rel=\"noopener noreferrer\">Prometheus agent</a> is available for the \"scraping\" part).</p>\n<p>The RAM and CPU usage of a Prometheus instance is correlated to the number of metrics (and their cardinality) it has to manage. In our case, several Prometheus instances consumed more than 64 GB of RAM and 26 CPUs each, in order to absorb our peak loads. In a Kubernetes cluster, this high resource consumption can cause problems, especially for scheduling.</p>\n<p>The Write-Ahead Log (WAL) system can cause rather slow restarts if the Prometheus instance runs out of RAM and can cause the Prometheus instance to hang for varying lengths of time. During the replay of the WAL, Prometheus doesn't scrape anything, thus there is no alerting and no way of knowing if something is going on.</p>\n<h2 id=\"-the-cardinality-of-metrics\" style=\"position:relative;\"><a href=\"#-the-cardinality-of-metrics\" aria-label=\" the cardinality of metrics permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìà The Cardinality of Metrics</h2>\n<p>When our Kubernetes clusters manage a large number of pods, a constraint quickly appears: cardinality.</p>\n<blockquote>\n<p>The cardinality of a metric is the number of TimeSeries of that metric with single-valued labels.</p>\n</blockquote>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 87.05882352941177%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAABq0lEQVR42pVTi26DMAzk/790aoHSkqedxPOZBlUd61ikiOKa8/nOHlpr4r2XdV2FiKSfGKM45yTnvMeY2eIpJcF3/eAd8VqrDD3YExDEfT1HMeSXUgSf1aq/9eI5yNv5C7AT64DOs3xdg1ynKCHxMSASzzDMmVWmKtOS5HbPkqmeB2Su4gLLqozAJES2POYmswJOcxIf+FzLREXZFAUpMt2SApMkfW/PQpcxyqiAv7ZsLFVgJOOJRMSIt/acJytQqzIsTZZHlofbivwARNWkAPOSTeiL3vuK0WkSU1GtkqyuA0KeJqOyBvN4xBCsUOn1QHx8DBAUAptMGyBcB0tcGxtzyzTiHezdFOaig1vsPxjgQwcs73xkgB7zEu1Ot6gu0uEcAhSOoigXtFoNEKzgLi40HpAQImn/ZBpgHP6zKWgVrOGyj08Na9s0sBHRAhiTI0BgmvM7w815GAdAzOjh2CR1E46CbbL52zTDBzAF8VeXF92S8dNgo5WUt82IBs7GGoDLgwwQs1lqbzk/GdK5TentgY0PxdpGq5nY9hdFsMsfN+WsKegEYH0lvwFS9zueIsyF8QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Cardinality Example\" title=\"\" src=\"/static/203edc96f235ef0a301901fae893b443/c5bb3/labels.png\" srcset=\"/static/203edc96f235ef0a301901fae893b443/04472/labels.png 170w,\n/static/203edc96f235ef0a301901fae893b443/9f933/labels.png 340w,\n/static/203edc96f235ef0a301901fae893b443/c5bb3/labels.png 680w,\n/static/203edc96f235ef0a301901fae893b443/b12f7/labels.png 1020w,\n/static/203edc96f235ef0a301901fae893b443/3096d/labels.png 1319w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>In the example above, the <code class=\"language-text\">status_code</code> label has a cardinality of 5, <code class=\"language-text\">app</code> has a cardinality of 2, and the overall cardinality of the <code class=\"language-text\">server_responses</code> metric is 10. In this example, any Prometheus instance can handle this cardinality, but if you add, for example, the label <code class=\"language-text\">pod_name</code> or <code class=\"language-text\">client_IP</code> (or both) to the <code class=\"language-text\">server_responses</code> metric, the cardinality increases for each different client's calls and for each pod.</p>\n<p>You should read the excellent <a href=\"https://www.robustperception.io/cardinality-is-key\" target=\"_blank\" rel=\"noopener noreferrer\">article on cardinality</a> from \"Robust Perception\" for more details on this subject.</p>\n<p>At Bedrock, the high cardinality metrics come from our HAProxy ingress. For our needs, we retrieve several labels like the name of the ingress pod as well as its IP address, but more importantly, the name and IP address of the destination pod. In a cluster that can grow to more than 15,000 pods, the combination of unique labels (cardinality) is very significant for some of our ingress metrics.</p>\n<p>We found that Prometheus performed poorly when we had multiple metrics with high cardinalities (> 100,000), resulting in over-consumption of RAM. During a high load event, Prometheus could consume up to 200 GB of RAM before being OOMKilled. When this happened, we would go completely blind as we had no metrics or alerting. This also impacts scalability in our Kubernetes clusters, as we use <a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#scaling-on-custom-metrics\" target=\"_blank\" rel=\"noopener noreferrer\">Custom Metrics</a> very heavily in HPAs to scale the number of pods in our applications.</p>\n<p>There are many comparisons available online; here is a summary:</p>\n<ul>\n<li><a href=\"https://db-engines.com/en/system/Prometheus%3BVictoriaMetrics\" target=\"_blank\" rel=\"noopener noreferrer\">System Properties Comparison: Prometheus vs. VictoriaMetrics</a> - General information on both systems.</li>\n<li><a href=\"https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f\" target=\"_blank\" rel=\"noopener noreferrer\">Prometheus vs VictoriaMetrics Benchmark on Node Exporter Metrics</a> - VictoriaMetrics uses much less disk and memory.</li>\n<li><a href=\"https://docs.victoriametrics.com/FAQ.html#what-is-the-difference-between-vmagent-and-prometheus\" target=\"_blank\" rel=\"noopener noreferrer\">FAQ: Differences Between vmagent and Prometheus</a> - FAQ from VictoriaMetrics.</li>\n<li><a href=\"https://docs.victoriametrics.com/Single-server-VictoriaMetrics.html#prominent-features\" target=\"_blank\" rel=\"noopener noreferrer\">Prominent Features of VictoriaMetrics</a> - Documentation from VictoriaMetrics about its capabilities.</li>\n</ul>\n<p>In short, some of VictoriaMetrics' abilities include:</p>\n<ul>\n<li>Supports both Pull and Push models (unlike Prometheus, which requires Pushgateway for push).</li>\n<li>You can configure Prometheus with remote write to VictoriaMetrics, i.e., write data to VictoriaMetrics from Prometheus.</li>\n<li>VictoriaMetrics has a concept of \"namespaces\" - you can have isolated environments for metrics, see <a href=\"https://docs.victoriametrics.com/Cluster-VictoriaMetrics.html#multitenancy\" target=\"_blank\" rel=\"noopener noreferrer\">Multitenancy</a>.</li>\n<li>Has its own <a href=\"https://docs.victoriametrics.com/MetricsQL.html\" target=\"_blank\" rel=\"noopener noreferrer\">MetricsQL</a> with wider capabilities than PromQL.</li>\n<li>For acquaintance, there is a <a href=\"https://play.victoriametrics.com/select/accounting/1/6a716b0f-38bc-4856-90ce-448fd713e3fe/prometheus/graph/#/\" target=\"_blank\" rel=\"noopener noreferrer\">VictoriaMetrics playground</a>.</li>\n<li>For AWS, there is <a href=\"https://aws.amazon.com/marketplace/pp/prodview-4tbfq5icmbmyc\" target=\"_blank\" rel=\"noopener noreferrer\">Managed VictoriaMetrics</a>.</li>\n</ul>\n<h2 id=\"Ô∏è-victoriametrics-cluster-architecture\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-victoriametrics-cluster-architecture\" aria-label=\"Ô∏è victoriametrics cluster architecture permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèóÔ∏è VictoriaMetrics Cluster Architecture</h2>\n<p>VictoriaMetrics can be deployed as a single server or as a cluster version. I chose to <a href=\"https://docs.victoriametrics.com/guides/k8s-monitoring-via-vm-cluster.html\" target=\"_blank\" rel=\"noopener noreferrer\">deploy the VictoriaMetrics-cluster on k8s</a> using Helm charts.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 120%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAIAAAB1KUohAAAACXBIWXMAAAsTAAALEwEAmpwYAAABq0lEQVR42pWU646CQAyFef/3M4TEJeINkfUCKiAg7Jc5yewIuLr9UWvpaU87nfFut1ue51mWXS6X6/WKXVXV3YgM+9eVsiz7vvfSNJ3P519GoigKw5BvXdc9Hg9pK23bysAPGO2RuDdS13XTNBChPnq9Xvu+H8exGBVFoQAFU4AsT2CE6N1uFxtZrVbYZEFDEIALhojHj/53RmSTFT/9i+04gDJPYBuB99vIcrlEM0sX9hdYeADn85n5afjUH8So/18wQQBOpxPjYZhoUuBkVPZ4bM9DMFMNgmA2mwl2PB632+3hcKC4OBNtg4dgDVA9QwE80yYjxyba+G1wY+QJbHsTW1LIkBOwPdchGCaiRwrKMufNZgN5utBpobWVb8BgmNxisWA9qCbMR2DRpqBoa42V9CPaVIY2A2MrmbZOyAVPTFsDQ1OTyvQMed1K+cG8XBJOpTDCCVF8v99jkAgP5HWxLO2JiyGhiC6mdtP9NF15sN5JkvA80Lmt9tHFkMATwgSNb8V7MB2yKq++Kuk0mA9Mi3NCD27y9DP0L9Ej6dGb+766hmT87tqF/QHk/3mpUpkHFAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Components\" title=\"\" src=\"/static/dafaa456ba23d8e20569aaaea250fa74/c5bb3/components.png\" srcset=\"/static/dafaa456ba23d8e20569aaaea250fa74/04472/components.png 170w,\n/static/dafaa456ba23d8e20569aaaea250fa74/9f933/components.png 340w,\n/static/dafaa456ba23d8e20569aaaea250fa74/c5bb3/components.png 680w,\n/static/dafaa456ba23d8e20569aaaea250fa74/5b481/components.png 846w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 61.1764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAABzklEQVR42lVSa4+bMBDM//9XVaWrUumubS6UCwTMwzaY99M2j0AnwFXtfljZXs3OzHpPQog8z/u+77bQWq/rIvV4sfjF5lIP67pyUXz5bhj38LHFsizrFqcwDIMgiOOYcx5FkVJ6HMe8KG8utVwaRLlLs3sgLEKZyKdpQhX4AwxMlmXzPA9bKKXQyPd9dIw4dYPo528SMtF3bde1iLIsIRBI8J+SJCGEgB/6n8UWypUapleTOjTfCJZxmt/MEEYeywryXsqDWUoJJWizi4FnNJ7nR1W3dd2g0bOdUjj3vYTdQWsM6AAzxqBz14NXKN9radm9/LDgFucb4TgX9fMdTPIvM0wCAFrYRsYVVCgoPTBRJHklZS/yCgPXwwQL+l9mz/Mcx0nTFGPbvwpSp3kxHE5FsQ8GibDM8gS+CZ7/Y26apigKZJBv11oqDalhlDVNm2Q5MgmFGyZaD/tGHGDAtsVYd+U4owukaoXUmg77+nrDn2vZqb4DEtOBzQPsuq5hGLZtQzyWZBh0VnXna/jL5i6vzgbz49okybeL70XV+d1/u/H58blhsIppg63GbzQN7MVpdb6Qq82oKK93zpKK0OzdZlFam2704cXTNO/gP3NCo3Nj8pWGAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"VM on K8s\" title=\"\" src=\"/static/2290739ff77986c0b4ec581ad6e07f29/c5bb3/vm-k8s.png\" srcset=\"/static/2290739ff77986c0b4ec581ad6e07f29/04472/vm-k8s.png 170w,\n/static/2290739ff77986c0b4ec581ad6e07f29/9f933/vm-k8s.png 340w,\n/static/2290739ff77986c0b4ec581ad6e07f29/c5bb3/vm-k8s.png 680w,\n/static/2290739ff77986c0b4ec581ad6e07f29/b12f7/vm-k8s.png 1020w,\n/static/2290739ff77986c0b4ec581ad6e07f29/ee515/vm-k8s.png 1269w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<ul>\n<li><strong>vmstorage</strong>: Stores the raw data and returns the queried data on the given time range for the given label filters. This is the only stateful component in the cluster.</li>\n<li><strong>vminsert</strong>: Accepts the ingested data and spreads it among vmstorage nodes according to consistent hashing over metric name and all its labels.</li>\n<li><strong>vmselect</strong>: Performs incoming queries by fetching the needed data from all the configured vmstorage nodes.</li>\n<li><strong>vmauth</strong>: A simple auth proxy and router for the cluster. It reads auth credentials from the Authorization HTTP header (Basic Auth, Bearer token, and <a href=\"https://github.com/VictoriaMetrics/VictoriaMetrics/issues/1897\" target=\"_blank\" rel=\"noopener noreferrer\">InfluxDB authorization</a> is supported), matches them against configs, and proxies incoming HTTP requests to the configured targets.</li>\n<li><strong>vmagent</strong>: A tiny but mighty agent that helps you collect metrics from various sources and store them in VictoriaMetrics or any other Prometheus-compatible storage systems that support the remote_write protocol.</li>\n<li><strong>vmalert</strong>: Executes a list of the given alerting or recording rules against configured data sources. Sending alerting notifications, vmalert relies on configured <a href=\"https://github.com/prometheus/alertmanager\" target=\"_blank\" rel=\"noopener noreferrer\">Alertmanager</a>. Recording rules results are persisted via <a href=\"https://prometheus.io/docs/prometheus/latest/storage/#remote-storage-integrations\" target=\"_blank\" rel=\"noopener noreferrer\">remote write</a> protocol. vmalert is heavily inspired by Prometheus implementation and aims to be compatible with its syntax.</li>\n<li><strong>promxy</strong>: Used for querying the data from multiple clusters. It's a Prometheus proxy that makes many shards of Prometheus appear as a single API endpoint to the user.</li>\n</ul>\n<h2 id=\"cluster-resizing-and-scalability\" style=\"position:relative;\"><a href=\"#cluster-resizing-and-scalability\" aria-label=\"cluster resizing and scalability permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Cluster Resizing and Scalability</h2>\n<p>Cluster performance and capacity can be scaled up in two ways:</p>\n<ol>\n<li><strong>Vertical Scalability</strong>: By adding more resources (CPU, RAM, disk IO, disk space, etc.).</li>\n<li><strong>Horizontal Scalability</strong>: By adding more of each component to the cluster.</li>\n</ol>\n<p>The components can all be scaled individually, with the only stateful component being the <code class=\"language-text\">vmstorage</code> component. This makes it easier to maintain and scale clusters. Adding new components and updating <code class=\"language-text\">vminsert</code> configurations is all it takes to scale the storage layer. Nothing else is needed.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 43.529411764705884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB4ElEQVR42i2L204TURSG5yE04ExrT7QdppShVTBYajwlmhgT77gxbYeSqqWnPZ3jPsweZhgHCqUxJBoNJCTqhTdGDY/hhY/kCpB8WfnXv74l+GV6Cdu/H00fT46fHh49mRw9OojX98KKf1CLJg/iST0+fLg/qcWB6l37ywyywJYoLVGiEICv8OBuwCuclqmnep7KrnpWZlzlRCZYxqREwIfGK3sCVpizSGwZs6rvlqhdxFTldIXjZcYqHEqqeiC4Cg03IsggQMYKdWQsmEVsy8TIOyebn0iF90X0uXn65/3FKG0OU8Z59+vZ9jlKm6D93P09e3Wipy1boUbBgRdhlLPRgmMtMV6LrDIbZS1DIf5GbCwSlHfIakjXAlRw9KLrrUdsLdQLLrxcfQm9rLWTMXs5e5h3B3kH8kh27Tv+YMHpgyRjYCdtwmlYdEG79rNWP+cIb9Pmm9sGzLPBd/depN0chs+P/178G8i4dWMw3fx42vvWnkfdrPOD/wqfTbfmhu8yFtDN2EInZbUT427RDV7M9Kq/Jep6dXf2+ksnY2kiMlYDtx6Ds5009l5+wPVYmx91UibQTo6FljTWkgbMVmLcuIWaEtIgzKGWpDclHUq4NqVxQ7xsRF1LGACsDRH9B1ouzBhbYrhWAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Scalability\" title=\"\" src=\"/static/7ae9f27c556f6fa8346d55dc998d79db/c5bb3/scalability.png\" srcset=\"/static/7ae9f27c556f6fa8346d55dc998d79db/04472/scalability.png 170w,\n/static/7ae9f27c556f6fa8346d55dc998d79db/9f933/scalability.png 340w,\n/static/7ae9f27c556f6fa8346d55dc998d79db/c5bb3/scalability.png 680w,\n/static/7ae9f27c556f6fa8346d55dc998d79db/b12f7/scalability.png 1020w,\n/static/7ae9f27c556f6fa8346d55dc998d79db/e996b/scalability.png 1050w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"Ô∏è-implementation-of-victoriametrics\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-implementation-of-victoriametrics\" aria-label=\"Ô∏è implementation of victoriametrics permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Implementation of VictoriaMetrics</h2>\n<p>VictoriaMetrics has charts for each component to deploy in Kubernetes. See <a href=\"https://github.com/VictoriaMetrics/helm-charts/tree/master\" target=\"_blank\" rel=\"noopener noreferrer\">Victoria Metrics Helm Charts</a>. There are also charts to run <a href=\"https://github.com/VictoriaMetrics/operator\" target=\"_blank\" rel=\"noopener noreferrer\">VictoriaMetrics Operator</a> and <a href=\"https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">victoria-metrics-k8s-stack</a> ‚Äì an analog of the Kubernetes Prometheus Stack.</p>\n<p>We will use the <a href=\"https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">victoria-metrics-k8s-stack</a>, which \"under the hood\" will launch VictoriaMetrics Operator, Grafana, and kube-state-metrics. See its <a href=\"https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/Chart.yaml#L10C1-L10C13\" target=\"_blank\" rel=\"noopener noreferrer\">dependencies</a>.</p>\n<p>A VMCluster (Insert, Select, Storage) is deployed to manage access to metrics. The collection of metrics (push/pull) from exporters in Prometheus format is handled by the <code class=\"language-text\">vmagent</code>. Its configuration is done in the form of a Prometheus configuration file. It is able to:</p>\n<ul>\n<li>Manage the relabeling of metrics.</li>\n<li>Temporarily store the metrics it has collected if the VMCluster is unavailable or not able to send the metrics to the VMCluster.</li>\n<li>Limit the cardinality of metrics.</li>\n</ul>\n<p>One of the advantages of using this Helm chart is that it will deploy essential components to properly monitor a Kubernetes cluster such as <code class=\"language-text\">kube-state-metrics</code> or <code class=\"language-text\">prometheus-node-exporter</code>, but also scraping configurations for services such as <code class=\"language-text\">Kubelet</code>, <code class=\"language-text\">KubeApiServer</code>, <code class=\"language-text\">KubeControllerManager</code>, <code class=\"language-text\">KubeDNS</code>, <code class=\"language-text\">KubeEtcd</code>, <code class=\"language-text\">KubeScheduler</code>, <code class=\"language-text\">KubeProxy</code>.</p>\n<p>Alerting is also managed via a <code class=\"language-text\">VMAlert</code> component, which will execute the alerting and recording rules set by VictoriaMetrics. Notifications are managed by an <code class=\"language-text\">Alertmanager</code>, which is also deployable via this chart.</p>\n<p>This is what the monitoring and alerting stack based on this Helm chart looks like:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 111.76470588235294%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAAAsTAAALEwEAmpwYAAADTUlEQVR42oVUi27bOBDs/39YgaK4a3tFri/XdhzH1vtNihJJTWdXcRq7wZ3gBSVLnN2dmeWbIf+Gw/YOZvSIEfBhuYpw83z5TyOuq5u48el6MzoP7yNfRMxcXwMLt0AXMEaMN4Cbe4e3H0fk5YSMIR8vCzS8X1DUM5p21o2/A88xEWyw4TdgXnrUXURRTUhzpyByaeY5IsknBV2WRSNG6SRo+BC0MzO+AOyN15t5Xltue48zgXMmsGNkOwvazuF0LlGUDQZjkWQtNvsCj+cGo5uuAbPC4pzkcOMEFsUNge3PSAuHqhHQoMlGFzBxbTuD7aHCz/sSdWv4/wzzsuWqmdlm4GYCpwOO557ZW3zfVtjetyjrUT8UTqUDYx1BrYL1w8hk4RlQKFFAuZFKdw89AQ3bdeR1VvVEJP2YIY5o2wZV1WgR/Kn6V6KUBLT0YJJZkj+hGzwOp4ECWWZftPXDY08qZm1drCKCpGmCLC814UiuCzuidcMKWNYW37Y1AUf03LjZN3hg61Lh4WRYeaOtjy5q8qIasN2fsT9k5DWgt0DxcEJS7ghIS0DbiQogMZiIrueHQ3g2rdeJkGomJiyZsCXvhvxN5DRg1+X40p5eAhKAFkqLEafUYH9stdIkG2je8Dwtjqrujw0ek07FmWZPUKrvLcISV1HkSgtDKzRsr6UwA61jOSGTcie8iXD0MSs3+LFNsNllSNKSFTv6MF6LInaQEdIxog+bzutqnYiwtjv7FdA5h6apYMyAvu9g7Q1gP6yTIr6QjTLTx7OjCF4npK5rWqXVVcBur/CnbSZW5KjcqC+M9TwkLH0pz17f5eWgAoiilzkXCl4FFBN//lrg3Qf6ijyK175sKn3eH4X4GR//zfH+U0qe7f9X2Jug4yOGtrSAMU5HqqYgJY0uthFzSydCgZw2lzFbllcmRchfM4FghgdFhoZ8eaohe8Wferjyvut6hkGM/1FhxUqqZlQO3ZOqkalzPie50coEsO3lO6eTJJ6Vd2I14fj6+CqdjtlfnzN839W66Zj0eP9Pplw23YT7xw5/32XY0Kcyeg+nHh/ucvw8NKRquj6+pOWgFaxHvUxLQyEkpGLxZi1OaNezcXo6G0U8UVsOEHm+AP4C/dioWE9PyxIAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"VM on EKS\" title=\"\" src=\"/static/bc578fff8aec6b31f92918d32737886d/c5bb3/vm-eks.png\" srcset=\"/static/bc578fff8aec6b31f92918d32737886d/04472/vm-eks.png 170w,\n/static/bc578fff8aec6b31f92918d32737886d/9f933/vm-eks.png 340w,\n/static/bc578fff8aec6b31f92918d32737886d/c5bb3/vm-eks.png 680w,\n/static/bc578fff8aec6b31f92918d32737886d/076ca/vm-eks.png 914w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>If you want to keep historical metrics of your Kubernetes clusters, VictoriaMetrics provides a tool to manage the export and import of data from different TSDB: <a href=\"https://docs.victoriametrics.com/vmctl.html\" target=\"_blank\" rel=\"noopener noreferrer\">vmctl</a>.</p>\n<p>Let's go. Let's start by checking the chart itself: <code class=\"language-text\">victoria-metrics-k8s-stack</code>.</p>\n<h3 id=\"-victoriametrics-stack-helm-chart-installation\" style=\"position:relative;\"><a href=\"#-victoriametrics-stack-helm-chart-installation\" aria-label=\" victoriametrics stack helm chart installation permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üì¶ VictoriaMetrics Stack Helm Chart Installation</h3>\n<p>Add repositories with dependencies:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm repo <span class=\"token function\">add</span> grafana https://grafana.github.io/helm-charts\n<span class=\"token string\">\"grafana\"</span> has been added to your repositories\nhelm repo <span class=\"token function\">add</span> prometheus-community https://prometheus-community.github.io/helm-charts\n<span class=\"token string\">\"prometheus-community\"</span> has been added to your repositories</code></pre></div>\n<p>And VictoriaMetrics itself:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm repo <span class=\"token function\">add</span> vm https://victoriametrics.github.io/helm-charts/\n<span class=\"token string\">\"vm\"</span> has been added to your repositories\nhelm repo update</code></pre></div>\n<p>All values can be taken as follows:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm show values vm/victoria-metrics-k8s-stack <span class=\"token operator\">></span> default-values.yaml</code></pre></div>\n<p>Or just from the repository‚Ää‚Äî‚Ää<a href=\"https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/values.yaml\" target=\"_blank\" rel=\"noopener noreferrer\">values.yaml</a>.</p>\n<p>VictoriaMetrics has very good documentation, so during the process, we will often use the <a href=\"https://docs.victoriametrics.com/operator/api.html\" target=\"_blank\" rel=\"noopener noreferrer\">API Docs</a>.</p>\n<h3 id=\"create-a-configuration\" style=\"position:relative;\"><a href=\"#create-a-configuration\" aria-label=\"create a configuration permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Create a Configuration</h3>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">victoria-metrics-operator:\n    serviceAccount:\n        create: <span class=\"token boolean\">false</span>\n\nalertmanager:\n    enabled: <span class=\"token boolean\">true</span>\n\nvmalert:\n    annotations: <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n    enabled: <span class=\"token boolean\">true</span>\n\nvmagent:\n    enabled: <span class=\"token boolean\">true</span>\n\ngrafana:\n    enabled: <span class=\"token boolean\">true</span>\n    ingress:\n        enabled: <span class=\"token boolean\">true</span>\n        annotations:\n            kubernetes.io/ingress.class: alb\n            alb.ingress.kubernetes.io/target-type: <span class=\"token function\">ip</span>\n            alb.ingress.kubernetes.io/scheme: internet-facing\n        hosts:\n            - monitoring.dev.example.com</code></pre></div>\n<h3 id=\"-deploy-to-a-new-namespace\" style=\"position:relative;\"><a href=\"#-deploy-to-a-new-namespace\" aria-label=\" deploy to a new namespace permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üöÄ Deploy to a New Namespace</h3>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm upgrade <span class=\"token parameter variable\">--install</span> victoria-metrics-k8s-stack <span class=\"token parameter variable\">-n</span> monitoring --create-namespace vm/victoria-metrics-k8s-stack <span class=\"token parameter variable\">-f</span> monitoring-values.yaml</code></pre></div>\n<p>Get the pods lists by running these commands:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">kubectl get pods <span class=\"token parameter variable\">-A</span> <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> <span class=\"token string\">'victoria-metrics'</span>\n<span class=\"token comment\"># or list all resources of victoria-metrics</span>\nkubectl get all <span class=\"token parameter variable\">-n</span> monitoring <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> victoria</code></pre></div>\n<p>Get the application by running these commands:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm list <span class=\"token parameter variable\">-f</span> victoria-metrics <span class=\"token parameter variable\">-n</span> monitoring</code></pre></div>\n<p>See the history of versions of victoria-metrics application with command:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">helm <span class=\"token function\">history</span> victoria-metrics <span class=\"token parameter variable\">-n</span> monitoring</code></pre></div>\n<h2 id=\"-summarizing\" style=\"position:relative;\"><a href=\"#-summarizing\" aria-label=\" summarizing permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìã Summarizing</h2>\n<p>In this post, VictoriaMetrics is a high-performance time-series database that is well-suited for Kubernetes monitoring and analytics. It offers several advantages over Prometheus, including:</p>\n<ul>\n<li>Superior scalability and performance</li>\n<li>Long-term storage capabilities</li>\n<li>Seamless integration with Kubernetes</li>\n<li>Anomaly detection</li>\n</ul>\n<p>VictoriaMetrics can help organizations to improve their monitoring and analytics efforts, leading to more informed decision-making and improved system reliability.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":9,"rawMarkdownBody":"\n\n> **A great Time-Series database for monitoring and analytics üîÜ**\n\n## üí¨ Introduction\n\n[VictoriaMetrics](https://victoriametrics.com/) is a time-series database designed for high-performance monitoring and analytics. It is similar to Prometheus in many ways, but it offers several advantages, including better performance, scalability, and data compression. VictoriaMetrics is also open-source and free to use.\n\nVictoriaMetrics can monitor a wide range of systems, including Kubernetes clusters, servers, applications, infrastructure components, and even IoT devices.\n\nIn this blog post, we will provide a comprehensive overview of VictoriaMetrics, covering the following topics:\n\n- What is VictoriaMetrics and how does it work?\n- How does VictoriaMetrics compare to Prometheus?\n- How to implement Kubernetes monitoring with VictoriaMetrics\n\nThis blog post is for anyone who wants to learn more about VictoriaMetrics or use it to improve their system monitoring capabilities. It is also a good resource for anyone who is considering using Prometheus and wants to compare the two solutions.\n\n![VictoriaMetrics Cover](./vectoria-cover.png)\n\n**TL;DR: VictoriaMetrics and Prometheus**\n\n**VictoriaMetrics** and **Prometheus** are both time-series databases used for monitoring and analytics, but they have some key differences:\n\n**Main features of VictoriaMetrics Compared to Prometheus**\n\n1. **Performance and Scalability**:\n   - **VictoriaMetrics**: Higher performance, better scalability, and more efficient data compression.\n   - **Prometheus**: Good performance but can struggle with high cardinality metrics and large-scale environments.\n\n2. **Resource Usage**:\n   - **VictoriaMetrics**: Lower CPU, RAM, and disk IO usage, especially with [vmagent](https://docs.victoriametrics.com/vmagent/).\n   - **Prometheus**: Higher resource consumption, especially with high cardinality metrics.\n\n3. **Data Ingestion**:\n   - **VictoriaMetrics**: Supports both pull and push models natively.\n   - **Prometheus**: Primarily pull-based; requires Pushgateway for push model.\n\n4. **High Availability**:\n   - **VictoriaMetrics**: Built-in support for high availability.\n   - **Prometheus**: No native high availability; requires duplication and sharding.\n\n5. **Long-Term Storage**:\n   - **VictoriaMetrics**: Designed for long-term storage with efficient data retention.\n   - **Prometheus**: Not intended for long-term storage; relies on external solutions.\n\n6. **Anomaly Detection**:\n   - **VictoriaMetrics**: Includes built-in anomaly detection features.\n   - **Prometheus**: Does not have built-in anomaly detection.\n\n7. **Buffering**:\n   - **VictoriaMetrics**: Independent disk-backed buffers for each remote storage.\n   - **Prometheus**: Single shared buffer for all remote storage systems.\n\n8. **Query Language**:\n   - **VictoriaMetrics**: Uses MetricsQL, which extends PromQL with additional features.\n   - **Prometheus**: Uses PromQL.\n\n## üìä VictoriaMetrics vs Prometheus: System Properties Comparison\n\nVictoriaMetrics is a monitoring system that is fully compatible with Prometheus. It offers many of the same features as Prometheus, but with some additional benefits, such as higher performance and scalability.\n\nOne key difference between VictoriaMetrics and Prometheus is that VictoriaMetrics includes an anomaly detection feature. This feature can be used to identify unusual changes in metrics data, which can be helpful for troubleshooting and identifying potential problems.\n\nWhile both `vmagent` and Prometheus may scrape Prometheus targets (aka `/metrics` pages) according to the provided Prometheus-compatible scrape configs and send data to multiple remote storage systems, `vmagent` has the following additional features:\n\n- `vmagent` usually requires lower amounts of CPU, RAM, and disk IO compared to Prometheus when scraping an enormous number of targets (more than 1000) or targets with a great number of exposed metrics.\n- `vmagent` provides independent disk-backed buffers for each configured remote storage (see `-remoteWrite.url`). This means that slow or temporarily unavailable storage doesn't prevent it from sending data to healthy storage in parallel. Prometheus uses a single shared buffer for all the configured remote storage systems (see `remote_write->url`) with a hardcoded retention of 2 hours.\n- `vmagent` may accept, relabel, and filter data obtained via multiple data ingestion protocols in addition to data scraped from Prometheus targets. That means it supports both pull and push protocols for data ingestion. [See these docs for details](https://docs.victoriametrics.com/vmagent.html#features).\n\nPrometheus does not have a native High Availability mode: to have high availability, we had to duplicate our Prometheus instances. This implies that our targets were \"scraped\" by all our Prometheus instances (same for our rules and records). To avoid this, we had to use sharding, but this made the infrastructure more complex. More information on this subject in [this documentation](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/high-availability.md) from the Prometheus operator.\n\nPrometheus is not designed to store metrics on a long-term basis, as mentioned in [the documentation](https://prometheus.io/docs/prometheus/latest/storage/#operational-aspects):\n\n> Prometheus's local storage is not intended to be durable long-term storage; external solutions offer extended retention and data durability.\n\nWe worked around this limitation by using VictoriaMetrics (VMCluster) as a LongTermStorage via the `remote_write` protocol.\n\nAll processes (scraping, ingest, storage, etc.) were, until now, managed in the same Prometheus instance, which implied a less flexible and vertical scaling only (since recently a [Prometheus agent](https://prometheus.io/blog/2021/11/16/agent/) is available for the \"scraping\" part).\n\nThe RAM and CPU usage of a Prometheus instance is correlated to the number of metrics (and their cardinality) it has to manage. In our case, several Prometheus instances consumed more than 64 GB of RAM and 26 CPUs each, in order to absorb our peak loads. In a Kubernetes cluster, this high resource consumption can cause problems, especially for scheduling.\n\nThe Write-Ahead Log (WAL) system can cause rather slow restarts if the Prometheus instance runs out of RAM and can cause the Prometheus instance to hang for varying lengths of time. During the replay of the WAL, Prometheus doesn't scrape anything, thus there is no alerting and no way of knowing if something is going on.\n\n## üìà The Cardinality of Metrics\n\nWhen our Kubernetes clusters manage a large number of pods, a constraint quickly appears: cardinality.\n\n> The cardinality of a metric is the number of TimeSeries of that metric with single-valued labels.\n\n![Cardinality Example](./labels.png)\n\nIn the example above, the `status_code` label has a cardinality of 5, `app` has a cardinality of 2, and the overall cardinality of the `server_responses` metric is 10. In this example, any Prometheus instance can handle this cardinality, but if you add, for example, the label `pod_name` or `client_IP` (or both) to the `server_responses` metric, the cardinality increases for each different client's calls and for each pod.\n\nYou should read the excellent [article on cardinality](https://www.robustperception.io/cardinality-is-key) from \"Robust Perception\" for more details on this subject.\n\nAt Bedrock, the high cardinality metrics come from our HAProxy ingress. For our needs, we retrieve several labels like the name of the ingress pod as well as its IP address, but more importantly, the name and IP address of the destination pod. In a cluster that can grow to more than 15,000 pods, the combination of unique labels (cardinality) is very significant for some of our ingress metrics.\n\nWe found that Prometheus performed poorly when we had multiple metrics with high cardinalities (> 100,000), resulting in over-consumption of RAM. During a high load event, Prometheus could consume up to 200 GB of RAM before being OOMKilled. When this happened, we would go completely blind as we had no metrics or alerting. This also impacts scalability in our Kubernetes clusters, as we use [Custom Metrics](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#scaling-on-custom-metrics) very heavily in HPAs to scale the number of pods in our applications.\n\nThere are many comparisons available online; here is a summary:\n\n- [System Properties Comparison: Prometheus vs. VictoriaMetrics](https://db-engines.com/en/system/Prometheus%3BVictoriaMetrics) - General information on both systems.\n- [Prometheus vs VictoriaMetrics Benchmark on Node Exporter Metrics](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) - VictoriaMetrics uses much less disk and memory.\n- [FAQ: Differences Between vmagent and Prometheus](https://docs.victoriametrics.com/FAQ.html#what-is-the-difference-between-vmagent-and-prometheus) - FAQ from VictoriaMetrics.\n- [Prominent Features of VictoriaMetrics](https://docs.victoriametrics.com/Single-server-VictoriaMetrics.html#prominent-features) - Documentation from VictoriaMetrics about its capabilities.\n\nIn short, some of VictoriaMetrics' abilities include:\n\n- Supports both Pull and Push models (unlike Prometheus, which requires Pushgateway for push).\n- You can configure Prometheus with remote write to VictoriaMetrics, i.e., write data to VictoriaMetrics from Prometheus.\n- VictoriaMetrics has a concept of \"namespaces\" - you can have isolated environments for metrics, see [Multitenancy](https://docs.victoriametrics.com/Cluster-VictoriaMetrics.html#multitenancy).\n- Has its own [MetricsQL](https://docs.victoriametrics.com/MetricsQL.html) with wider capabilities than PromQL.\n- For acquaintance, there is a [VictoriaMetrics playground](https://play.victoriametrics.com/select/accounting/1/6a716b0f-38bc-4856-90ce-448fd713e3fe/prometheus/graph/#/).\n- For AWS, there is [Managed VictoriaMetrics](https://aws.amazon.com/marketplace/pp/prodview-4tbfq5icmbmyc).\n\n## üèóÔ∏è VictoriaMetrics Cluster Architecture\n\nVictoriaMetrics can be deployed as a single server or as a cluster version. I chose to [deploy the VictoriaMetrics-cluster on k8s](https://docs.victoriametrics.com/guides/k8s-monitoring-via-vm-cluster.html) using Helm charts.\n\n![Components](./components.png)\n\n![VM on K8s](./vm-k8s.png)\n\n- **vmstorage**: Stores the raw data and returns the queried data on the given time range for the given label filters. This is the only stateful component in the cluster.\n- **vminsert**: Accepts the ingested data and spreads it among vmstorage nodes according to consistent hashing over metric name and all its labels.\n- **vmselect**: Performs incoming queries by fetching the needed data from all the configured vmstorage nodes.\n- **vmauth**: A simple auth proxy and router for the cluster. It reads auth credentials from the Authorization HTTP header (Basic Auth, Bearer token, and [InfluxDB authorization](https://github.com/VictoriaMetrics/VictoriaMetrics/issues/1897) is supported), matches them against configs, and proxies incoming HTTP requests to the configured targets.\n- **vmagent**: A tiny but mighty agent that helps you collect metrics from various sources and store them in VictoriaMetrics or any other Prometheus-compatible storage systems that support the remote_write protocol.\n- **vmalert**: Executes a list of the given alerting or recording rules against configured data sources. Sending alerting notifications, vmalert relies on configured [Alertmanager](https://github.com/prometheus/alertmanager). Recording rules results are persisted via [remote write](https://prometheus.io/docs/prometheus/latest/storage/#remote-storage-integrations) protocol. vmalert is heavily inspired by Prometheus implementation and aims to be compatible with its syntax.\n- **promxy**: Used for querying the data from multiple clusters. It's a Prometheus proxy that makes many shards of Prometheus appear as a single API endpoint to the user.\n\n##  Cluster Resizing and Scalability\n\nCluster performance and capacity can be scaled up in two ways:\n\n1. **Vertical Scalability**: By adding more resources (CPU, RAM, disk IO, disk space, etc.).\n2. **Horizontal Scalability**: By adding more of each component to the cluster.\n\nThe components can all be scaled individually, with the only stateful component being the `vmstorage` component. This makes it easier to maintain and scale clusters. Adding new components and updating `vminsert` configurations is all it takes to scale the storage layer. Nothing else is needed.\n\n![Scalability](./scalability.png)\n\n## üõ†Ô∏è Implementation of VictoriaMetrics\n\nVictoriaMetrics has charts for each component to deploy in Kubernetes. See [Victoria Metrics Helm Charts](https://github.com/VictoriaMetrics/helm-charts/tree/master). There are also charts to run [VictoriaMetrics Operator](https://github.com/VictoriaMetrics/operator) and [victoria-metrics-k8s-stack](https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/README.md) ‚Äì an analog of the Kubernetes Prometheus Stack.\n\nWe will use the [victoria-metrics-k8s-stack](https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/README.md), which \"under the hood\" will launch VictoriaMetrics Operator, Grafana, and kube-state-metrics. See its [dependencies](https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/Chart.yaml#L10C1-L10C13).\n\nA VMCluster (Insert, Select, Storage) is deployed to manage access to metrics. The collection of metrics (push/pull) from exporters in Prometheus format is handled by the `vmagent`. Its configuration is done in the form of a Prometheus configuration file. It is able to:\n\n- Manage the relabeling of metrics.\n- Temporarily store the metrics it has collected if the VMCluster is unavailable or not able to send the metrics to the VMCluster.\n- Limit the cardinality of metrics.\n\nOne of the advantages of using this Helm chart is that it will deploy essential components to properly monitor a Kubernetes cluster such as `kube-state-metrics` or `prometheus-node-exporter`, but also scraping configurations for services such as `Kubelet`, `KubeApiServer`, `KubeControllerManager`, `KubeDNS`, `KubeEtcd`, `KubeScheduler`, `KubeProxy`.\n\nAlerting is also managed via a `VMAlert` component, which will execute the alerting and recording rules set by VictoriaMetrics. Notifications are managed by an `Alertmanager`, which is also deployable via this chart.\n\nThis is what the monitoring and alerting stack based on this Helm chart looks like:\n\n![VM on EKS](./vm-eks.png)\n\nIf you want to keep historical metrics of your Kubernetes clusters, VictoriaMetrics provides a tool to manage the export and import of data from different TSDB: [vmctl](https://docs.victoriametrics.com/vmctl.html).\n\nLet's go. Let's start by checking the chart itself: `victoria-metrics-k8s-stack`.\n\n### üì¶ VictoriaMetrics Stack Helm Chart Installation\n\nAdd repositories with dependencies:\n\n```shell\nhelm repo add grafana https://grafana.github.io/helm-charts\n\"grafana\" has been added to your repositories\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n\"prometheus-community\" has been added to your repositories\n```\n\nAnd VictoriaMetrics itself:\n\n```shell\nhelm repo add vm https://victoriametrics.github.io/helm-charts/\n\"vm\" has been added to your repositories\nhelm repo update\n```\n\nAll values can be taken as follows:\n\n```shell\nhelm show values vm/victoria-metrics-k8s-stack > default-values.yaml\n```\n\nOr just from the repository‚Ää‚Äî‚Ää[values.yaml](https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/values.yaml).\n\nVictoriaMetrics has very good documentation, so during the process, we will often use the [API Docs](https://docs.victoriametrics.com/operator/api.html).\n\n### Create a Configuration\n\n```shell\nvictoria-metrics-operator:\n    serviceAccount:\n        create: false\n\nalertmanager:\n    enabled: true\n\nvmalert:\n    annotations: {}\n    enabled: true\n\nvmagent:\n    enabled: true\n\ngrafana:\n    enabled: true\n    ingress:\n        enabled: true\n        annotations:\n            kubernetes.io/ingress.class: alb\n            alb.ingress.kubernetes.io/target-type: ip\n            alb.ingress.kubernetes.io/scheme: internet-facing\n        hosts:\n            - monitoring.dev.example.com\n```\n\n### üöÄ Deploy to a New Namespace\n\n```shell\nhelm upgrade --install victoria-metrics-k8s-stack -n monitoring --create-namespace vm/victoria-metrics-k8s-stack -f monitoring-values.yaml\n```\n\nGet the pods lists by running these commands:\n\n```shell\nkubectl get pods -A | grep 'victoria-metrics'\n# or list all resources of victoria-metrics\nkubectl get all -n monitoring | grep victoria\n```\n\nGet the application by running these commands:\n\n```shell\nhelm list -f victoria-metrics -n monitoring\n```\n\nSee the history of versions of victoria-metrics application with command:\n\n```shell\nhelm history victoria-metrics -n monitoring\n```\n\n## üìã Summarizing\n\nIn this post, VictoriaMetrics is a high-performance time-series database that is well-suited for Kubernetes monitoring and analytics. It offers several advantages over Prometheus, including:\n\n- Superior scalability and performance\n- Long-term storage capabilities\n- Seamless integration with Kubernetes\n- Anomaly detection\n\nVictoriaMetrics can help organizations to improve their monitoring and analytics efforts, leading to more informed decision-making and improved system reliability.\n\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1986},"frontmatter":{"id":"a9ef55f0888732dd0fdcb668","path":"/blog/victoriametrics-time-series-db-prometheus-k8s/","humanDate":"Oct 27, 2024","fullDate":"2024-10-27","title":"VictoriaMetrics: A Guide, Comparing It to Prometheus, and Implementing Kubernetes Monitoring","keywords":["VictoriaMetrics","Prometheus","Kubernetes","Time-Series Database","Monitoring"],"excerpt":"Explore the capabilities of VictoriaMetrics as a powerful time-series database, its comparison with Prometheus, and how to effectively implement monitoring in Kubernetes.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAFABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBf/EABYBAQEBAAAAAAAAAAAAAAAAAAMEBf/aAAwDAQACEAMQAAABx7B3mJND/8QAFxAAAwEAAAAAAAAAAAAAAAAAAAERIf/aAAgBAQABBQJYyH//xAAYEQACAwAAAAAAAAAAAAAAAAAAAQMREv/aAAgBAwEBPwGNKzKP/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAECMf/aAAgBAgEBPwHJHTP/xAAXEAADAQAAAAAAAAAAAAAAAAAAEDFR/9oACAEBAAY/AtIv/8QAGBABAQEBAQAAAAAAAAAAAAAAAREAQVH/2gAIAQEAAT8hkGEccA+NG//aAAwDAQACAAMAAAAQ++//xAAXEQEBAQEAAAAAAAAAAAAAAAABABEx/9oACAEDAQE/EHDSMeX/xAAYEQACAwAAAAAAAAAAAAAAAAAAEQEhMf/aAAgBAgEBPxBWQN6f/8QAGxABAAEFAQAAAAAAAAAAAAAAAQARITFBUXH/2gAIAQEAAT8QaEirofYHYLosAMT/2Q=="},"images":{"fallback":{"src":"/static/bdc3bc74ff1ad424698cbf42ce569f78/d5941/vm-cover.jpg","srcSet":"/static/bdc3bc74ff1ad424698cbf42ce569f78/22f46/vm-cover.jpg 750w,\n/static/bdc3bc74ff1ad424698cbf42ce569f78/08066/vm-cover.jpg 1080w,\n/static/bdc3bc74ff1ad424698cbf42ce569f78/9779d/vm-cover.jpg 1366w,\n/static/bdc3bc74ff1ad424698cbf42ce569f78/d5941/vm-cover.jpg 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/bdc3bc74ff1ad424698cbf42ce569f78/15271/vm-cover.webp 750w,\n/static/bdc3bc74ff1ad424698cbf42ce569f78/3dab2/vm-cover.webp 1080w,\n/static/bdc3bc74ff1ad424698cbf42ce569f78/01f8f/vm-cover.webp 1366w,\n/static/bdc3bc74ff1ad424698cbf42ce569f78/d4634/vm-cover.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.25}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/eks-node-viewer-visualizing-node-usage/","title":"eks-node-viewer: A Tool for Visualizing Dynamic Node Usage in EKS Clusters¬†üöÄ","date":"2024-10-27 18:40:00"},"excerpt":"Optimizing AWS Kubernetes Cluster üîä Introduction EKS Node Viewer is a tool for visualizing dynamic node usage within a Kubernetes cluster‚Ä¶"},"nextThought":{"frontmatter":{"path":"/blog/securing-monitoring-stack-dead-man-switch/","title":"Never Get Caught Blind: Securing Your Monitoring Stack with a Dead Man Switch üëÄ","date":"2024-10-27 18:06:00"},"excerpt":"Who Watches the Watchers and the Monitoring Stack? üëÆ üí¨ Introduction Nowadays, monitoring systems play an important role in ensuring the‚Ä¶"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}