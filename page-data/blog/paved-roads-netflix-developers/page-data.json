{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/paved-roads-netflix-developers/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>Exploring how Netflix balances developer autonomy with structured support</strong></p>\n</blockquote>\n<h2 id=\"‚ÑπÔ∏è-overview\" style=\"position:relative;\"><a href=\"#%E2%84%B9%EF%B8%8F-overview\" aria-label=\"‚ÑπÔ∏è overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚ÑπÔ∏è Overview</h2>\n<p>Step onto the paved golden road of freedom and responsibility in the world of Netflix engineering, where innovation takes center stage. At Netflix, engineers are embraced by a culture that fosters creativity and provides the autonomy to choose the ideal tools for their tasks where <a href=\"https://www.oreilly.com/videos/oscon-2017/9781491976227/9781491976227-video306724/\" target=\"_blank\" rel=\"noopener noreferrer\">the golden road</a> of freedom and responsibility paves the way for extraordinary innovation.</p>\n<p><a href=\"https://netflixtechblog.com/how-we-build-code-at-netflix-c5d9bd727f15\" target=\"_blank\" rel=\"noopener noreferrer\">This culture of freedom and responsibility</a> fuels the development process, where engineers are encouraged to push boundaries and deliver exceptional streaming experiences to millions of viewers worldwide.</p>\n<h2 id=\"-goals--objectives\" style=\"position:relative;\"><a href=\"#-goals--objectives\" aria-label=\" goals  objectives permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üéØ Goals &#x26; Objectives</h2>\n<p>In this blog post, we invite you to join us on a captivating exploration of the Netflix engineering landscape. As we discover the secrets behind Netflix's success, we'll dive into the methods, practices, and cutting-edge technologies that shape their groundbreaking solutions.</p>\n<h3 id=\"paving-the-roads-to-innovation-netflixs-culture-of-freedom-and-responsibility\" style=\"position:relative;\"><a href=\"#paving-the-roads-to-innovation-netflixs-culture-of-freedom-and-responsibility\" aria-label=\"paving the roads to innovation netflixs culture of freedom and responsibility permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Paving the Roads to Innovation: Netflix's Culture of Freedom and Responsibility</h3>\n<p>Netflix, a trailblazer in the streaming industry, has built its success on a foundation of paved roads that lead to innovation. At the heart of this success lies Netflix's unique culture of freedom and responsibility, which empowers engineers to chart their own paths and drive remarkable advancements in the field of technology.</p>\n<p>Within Netflix's engineering teams, the concept of freedom is not just a buzzword; it is a core value that permeates every aspect of their work. Engineers are encouraged to think outside the box, challenge conventional norms, and explore new horizons. This freedom extends to their choice of tools, allowing them to select the technologies that best align with their goals and preferences. Whether it's experimenting with emerging frameworks or utilizing cutting-edge cloud services, Netflix engineers have the freedom to innovate and bring their ideas to life.</p>\n<p>However, this freedom is not without responsibility. Netflix understands that true innovation comes with accountability. Engineers are entrusted with the responsibility of delivering exceptional experiences to millions of viewers worldwide. This responsibility drives them to uphold high standards of quality, efficiency, and reliability. They work collaboratively within centralized teams, leveraging shared practices and resources to ensure the smooth functioning of their services.</p>\n<p>To pave these roads to innovation, Netflix has adopted a microservices architecture, replacing their monolithic, datacenter-based application. This transformational shift enables independent operation, allowing teams to make changes at their own pace while maintaining loose coupling. By breaking down their systems into smaller, specialized services, Netflix engineers can iterate rapidly, respond to customer needs more effectively, and scale their infrastructure seamlessly.</p>\n<p>Netflix's commitment to paving these roads goes beyond technology. The company invests in fostering a culture that values continuous learning, experimentation, and personal growth. Engineers are encouraged to share knowledge, collaborate across teams, and embrace failures as opportunities for improvement. This collaborative and growth-oriented culture ensures that the roads to innovation remain open, vibrant, and ever-evolving.</p>\n<p>Below are some of the engineering strategies that pave the way for innovation at Netflix:</p>\n<ul>\n<li>üì¶ <strong>Pipelines and Building Blocks</strong></li>\n<li>‚û∞ <strong>Use Templates And Keep It DRY</strong></li>\n<li>üõü <strong>Drone Extensions To The Rescue</strong></li>\n<li>‚úÇÔ∏è <strong>Decoupling CI / CD from Deployment</strong></li>\n<li>üí∞ <strong>Cost Effectiveness &#x26; Specialized Hardware</strong></li>\n</ul>\n<div style=\"width:100%;height:0;padding-bottom:100%;position:relative;\"><iframe src=\"https://giphy.com/embed/ZFFO5yvRnnJZJPJAki\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe></div>\n<h3 id=\"driving-innovation-netflixs-migration-to-aws-and-microservices-architecture\" style=\"position:relative;\"><a href=\"#driving-innovation-netflixs-migration-to-aws-and-microservices-architecture\" aria-label=\"driving innovation netflixs migration to aws and microservices architecture permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Driving Innovation: Netflix's Migration to AWS and Microservices Architecture</h3>\n<p>One concrete example of Netflix's paved road in their AWS Java deployment is their migration from a monolithic, datacenter-based application to a microservices architecture. This transformation allowed Netflix to unlock the full potential of cloud-based technologies and paved the way for greater flexibility, scalability, and innovation.</p>\n<p>In the past, Netflix operated a monolithic Java application hosted in traditional data centers. However, recognizing the limitations and the need for agility, they embarked on a journey to <a href=\"https://about.netflix.com/en/news/completing-the-netflix-cloud-migration\" target=\"_blank\" rel=\"noopener noreferrer\">migrate their streaming service to AWS</a>.</p>\n<p>By embracing AWS and adopting a microservices architecture, Netflix engineers gained the freedom to operate independently and make changes at their own pace. Each microservice became a specialized building block responsible for specific functionalities, such as user authentication, recommendation algorithms, or video playback. This decoupling of services enabled teams to iterate rapidly, innovate faster, and respond to customer needs more efficiently.</p>\n<p>Netflix's paved road in their AWS Java deployment involved leveraging a range of AWS services to support their microservices architecture. They utilized Amazon EC2 for scalable compute resources, Amazon S3 for reliable and scalable storage, Amazon RDS for managed databases, and Amazon DynamoDB for NoSQL data storage. They also made extensive use of AWS Lambda for serverless computing, which further optimized their resource utilization and enhanced scalability.</p>\n<p>With this paved road in place, Netflix engineers could focus on building and optimizing individual microservices, rather than being burdened by managing and scaling an entire monolithic application. They had the freedom to choose the most suitable tools and technologies for each microservice, ensuring they could deliver exceptional streaming experiences to their millions of viewers worldwide.</p>\n<p>Overall, Netflix's journey towards a microservices architecture within AWS showcases their commitment to paving a road of freedom, enabling engineers to embrace cloud technologies and deliver groundbreaking innovations in the streaming industry.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 416px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 204.1176470588235%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAApCAYAAAA1bQl+AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFiUlEQVR42qVXyVIjRxDla3zyd3mJCfvG1RGOcPhg3xwcHAQHBmMzhE2AWQazeGCGfZUASWhtSa0Nrd0Sixakfq6XomQ1QnOwm6ipVnXV68x8LzN7RqCuttNGy2nxFh2nA0f9/ddrhIffmDOYiI/DfrTwS3IKe4U9pBIpxIwYDMNAPB6HaZpIJBIyp9Pp3kilUrLHsqwuYLVVxffB7/DlyecYPRjFF2efYTozhXKxjIODAzkQiUQENJ/Py30mkxFwn8+HsPpdKBTQ6XS6gPzHbtt4tfE1PvnpU/xw+iMarTqMmIF3795hb28P+/v72NraErBoNIrFxUWsrq7Ks42NDWxvb+Ph4aELyJjx8hcC+GbrWxTvS7DKVs+im5sbmYvFotzncjm5L5XLMmhdNpuVtZ6FztNfu9PG/7kcx+kC6otmm2YSJfW2XC4rb2bgGTM9c3Cd1nLQwkIhL7FmHEc0Mi/GJ5FI4qZgK3cslEslYa/UNxPAtm1UKhWU6bZa43x1dSVuuwBD4QiCAS/++PkVLs/ey1qtWkWz2RSrWq2uVnnw9vYW9/f3uLu7kzVaSyvdFsaSmJ8Zw69fjeD38VGkc2VMvZ7Ewp8LmJycxMTEBLxeL87OzoTp5eVlzM/PC+OUEVXgAowpqeTzOawvvYYR8clao9GQQeseHupot7vEtZotsbw7Wso6UynDcAMy8IYRR6FYQTqTFelwRGNRhMNhBK+vEQwGZYRCIckQWkZ3z8/PJc4ulslStWqroFvqYUU21Go1iRfZXV9fFyWQEK5z5h4OHcuR5zp6/pusahJoEZVA0Gtlbb1ed+0d0OFzUMaNgY7FYhIOunV8fCyMc03Hk57pcwOA3FR9coepRc3RPcZqfHxcrOIaJVNVkuIzXRhcgP3ijivXQirwFxcXOD05weHhoRSIzc1Nkczl5aVUGlpJgvgyV+ppMB2nbqHtrjl6PFnBvY+Pjy4jCKrddwHalo1IPAafFcVu1oudrAeefAiFmo2/lHjXN9axsrIiQv7w4QOWlpaEYUpLv8QFyDSLJeKI3KXhLYdxZSmXqibs+r0SchN+v19cz6oSRh2SJHqVTCZfBmRGMEY1u6bA1bCrsCqWJD8tIRGUDEkhkCYoEAgMsqwXqLtuxhiy0aNy90QRQxenp6dFNiTJ4/GIlSwIWtQv6nCYLmkJmdXSGqbdAUBqikMfMlTn29zckLQ7OjqS3qJTkEDcp7PkRcCXXsDDFDABeZCx7hezqy8/X2ALyGVTSKtyxMoTVSUtmTRxoWI5NjYmsWXl4WASkGHdqwdYZrr5/QEcRqoImSU81FRVscqqOBTkGS1lydcsc02nH+U00FNyKumNeAInGeAs3YZRASKqOzZVOO9ua1J1WDA4k2kWV+0+05HxdAHS9Eg4BKup+stNE7vRBk7NJthJvJ5zzPw2g7W1NczOzmJubq53T1mxKg0AsvImnxLdtBwECg6K6lFLkvlfJvtnXboY057L/fWPWiOomUxIjkaiMQk+C8Dp6alYQkFz1i1Af1C9yDJB6/WGDMZIW8DUY9x4cZ1pR5IYQ967PpaGqZ4HtTX8vmFxoBb5faM1+fzcyDAxa0A2J8aWMy2ki+WnSt6/d6iwe298KrI6BamA+YX5Xlj6020ooN5wqb5TfKr8e4+Osft+WyrNzs6OfAdy5nchCSJR7H4U9/BqoxZ9amMnewPn7Sac/WOa5GqV/S+nyJl+Hy1flIlsCEbRWf1bzRH5PfvmjXzL7O7uqjbwVuogU1HvH9BhD1B1M7RUST/xAgoQqUxP+IzlysqyFFhKhhZSBR8FvPD70DDTaCiX63tHXa2pQYKe1z82fS3qAZd7RYJNSL01qBqWV7UB5ir/R0BXSQrvSQoJYZbwhZrlfwDBKgFk8InpuQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"tools\" title=\"\" src=\"/static/d191b11b104e453dc7b27a092e77959a/b0122/tools.png\" srcset=\"/static/d191b11b104e453dc7b27a092e77959a/04472/tools.png 170w,\n/static/d191b11b104e453dc7b27a092e77959a/9f933/tools.png 340w,\n/static/d191b11b104e453dc7b27a092e77959a/b0122/tools.png 416w\" sizes=\"(max-width: 416px) 100vw, 416px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-wrapping-up\" style=\"position:relative;\"><a href=\"#-wrapping-up\" aria-label=\" wrapping up permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üëè Wrapping Up</h2>\n<p>Netflix's culture of freedom and responsibility lays the groundwork for remarkable innovations in the engineering realm. By paving these roads, Netflix empowers its engineers to think boldly, select the best tools for their tasks, and push boundaries to deliver outstanding streaming experiences to audiences worldwide. It is through this commitment to paving the roads to innovation that Netflix continues to redefine the landscape of the entertainment industry.</p>\n<div style=\"width:100%;height:0;padding-bottom:75%;position:relative;\"><iframe src=\"https://giphy.com/embed/VHrFbmOtBwysbsYnka\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe></div>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":4,"rawMarkdownBody":"\n> **Exploring how Netflix balances developer autonomy with structured support**\n\n## ‚ÑπÔ∏è Overview\n\nStep onto the paved golden road of freedom and responsibility in the world of Netflix engineering, where innovation takes center stage. At Netflix, engineers are embraced by a culture that fosters creativity and provides the autonomy to choose the ideal tools for their tasks where [the golden road](https://www.oreilly.com/videos/oscon-2017/9781491976227/9781491976227-video306724/) of freedom and responsibility paves the way for extraordinary innovation.\n\n[This culture of freedom and responsibility](https://netflixtechblog.com/how-we-build-code-at-netflix-c5d9bd727f15) fuels the development process, where engineers are encouraged to push boundaries and deliver exceptional streaming experiences to millions of viewers worldwide.\n\n## üéØ Goals & Objectives\n\nIn this blog post, we invite you to join us on a captivating exploration of the Netflix engineering landscape. As we discover the secrets behind Netflix's success, we'll dive into the methods, practices, and cutting-edge technologies that shape their groundbreaking solutions.\n\n### Paving the Roads to Innovation: Netflix's Culture of Freedom and Responsibility\n\nNetflix, a trailblazer in the streaming industry, has built its success on a foundation of paved roads that lead to innovation. At the heart of this success lies Netflix's unique culture of freedom and responsibility, which empowers engineers to chart their own paths and drive remarkable advancements in the field of technology.\n\nWithin Netflix's engineering teams, the concept of freedom is not just a buzzword; it is a core value that permeates every aspect of their work. Engineers are encouraged to think outside the box, challenge conventional norms, and explore new horizons. This freedom extends to their choice of tools, allowing them to select the technologies that best align with their goals and preferences. Whether it's experimenting with emerging frameworks or utilizing cutting-edge cloud services, Netflix engineers have the freedom to innovate and bring their ideas to life.\n\nHowever, this freedom is not without responsibility. Netflix understands that true innovation comes with accountability. Engineers are entrusted with the responsibility of delivering exceptional experiences to millions of viewers worldwide. This responsibility drives them to uphold high standards of quality, efficiency, and reliability. They work collaboratively within centralized teams, leveraging shared practices and resources to ensure the smooth functioning of their services.\n\nTo pave these roads to innovation, Netflix has adopted a microservices architecture, replacing their monolithic, datacenter-based application. This transformational shift enables independent operation, allowing teams to make changes at their own pace while maintaining loose coupling. By breaking down their systems into smaller, specialized services, Netflix engineers can iterate rapidly, respond to customer needs more effectively, and scale their infrastructure seamlessly.\n\nNetflix's commitment to paving these roads goes beyond technology. The company invests in fostering a culture that values continuous learning, experimentation, and personal growth. Engineers are encouraged to share knowledge, collaborate across teams, and embrace failures as opportunities for improvement. This collaborative and growth-oriented culture ensures that the roads to innovation remain open, vibrant, and ever-evolving.\n\nBelow are some of the engineering strategies that pave the way for innovation at Netflix:\n\n- üì¶ **Pipelines and Building Blocks**\n- ‚û∞ **Use Templates And Keep It DRY**\n- üõü **Drone Extensions To The Rescue**\n- ‚úÇÔ∏è **Decoupling CI / CD from Deployment**\n- üí∞ **Cost Effectiveness & Specialized Hardware**\n\nhttps://giphy.com/gifs/thedungeonrun-the-dungeon-run-jessica-lynn-parsons-fahima-tadhg-ZFFO5yvRnnJZJPJAki\n\n### Driving Innovation: Netflix's Migration to AWS and Microservices Architecture\n\nOne concrete example of Netflix's paved road in their AWS Java deployment is their migration from a monolithic, datacenter-based application to a microservices architecture. This transformation allowed Netflix to unlock the full potential of cloud-based technologies and paved the way for greater flexibility, scalability, and innovation.\n\nIn the past, Netflix operated a monolithic Java application hosted in traditional data centers. However, recognizing the limitations and the need for agility, they embarked on a journey to [migrate their streaming service to AWS](https://about.netflix.com/en/news/completing-the-netflix-cloud-migration).\n\nBy embracing AWS and adopting a microservices architecture, Netflix engineers gained the freedom to operate independently and make changes at their own pace. Each microservice became a specialized building block responsible for specific functionalities, such as user authentication, recommendation algorithms, or video playback. This decoupling of services enabled teams to iterate rapidly, innovate faster, and respond to customer needs more efficiently.\n\nNetflix's paved road in their AWS Java deployment involved leveraging a range of AWS services to support their microservices architecture. They utilized Amazon EC2 for scalable compute resources, Amazon S3 for reliable and scalable storage, Amazon RDS for managed databases, and Amazon DynamoDB for NoSQL data storage. They also made extensive use of AWS Lambda for serverless computing, which further optimized their resource utilization and enhanced scalability.\n\nWith this paved road in place, Netflix engineers could focus on building and optimizing individual microservices, rather than being burdened by managing and scaling an entire monolithic application. They had the freedom to choose the most suitable tools and technologies for each microservice, ensuring they could deliver exceptional streaming experiences to their millions of viewers worldwide.\n\nOverall, Netflix's journey towards a microservices architecture within AWS showcases their commitment to paving a road of freedom, enabling engineers to embrace cloud technologies and deliver groundbreaking innovations in the streaming industry.\n\n![tools](./tools.png)\n\n## üëè Wrapping Up\n\nNetflix's culture of freedom and responsibility lays the groundwork for remarkable innovations in the engineering realm. By paving these roads, Netflix empowers its engineers to think boldly, select the best tools for their tasks, and push boundaries to deliver outstanding streaming experiences to audiences worldwide. It is through this commitment to paving the roads to innovation that Netflix continues to redefine the landscape of the entertainment industry.\n\nhttps://giphy.com/gifs/over-end-its-VHrFbmOtBwysbsYnka\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":960},"frontmatter":{"id":"72d52cdd64087b00985c2923","path":"/blog/paved-roads-netflix-developers/","humanDate":"Oct 26, 2024","fullDate":"2024-10-26","title":"The Power of Paved Roads: Netflix's Approach to Empowering Developers with Freedom and Responsibility","keywords":["Developer Empowerment","Paved Roads","Freedom","Responsibility"],"excerpt":"Discover Netflix's innovative approach to empowering developers through the concept of paved roads, fostering both freedom and responsibility.","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMBBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAD/9oADAMBAAIQAxAAAAGNOZNJo//EABoQAAIDAQEAAAAAAAAAAAAAAAABAgMREjH/2gAIAQEAAQUCrm4u+fbfujZp/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAGBEAAgMAAAAAAAAAAAAAAAAAAAECERL/2gAIAQIBAT8BUXRln//EABgQAAIDAAAAAAAAAAAAAAAAAAABESAh/9oACAEBAAY/AsFFf//EABkQAAMBAQEAAAAAAAAAAAAAAAABIRExUf/aAAgBAQABPyHVxDveJCvpi8DB1Uf/2gAMAwEAAgADAAAAECgP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFREBAQAAAAAAAAAAAAAAAAAAAQD/2gAIAQIBAT8QGiBv/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAERIUExYf/aAAgBAQABPxBF9x8nwl3Q3jY1Jk6V0gaEaWf/2Q=="},"images":{"fallback":{"src":"/static/b3c28d1b52360aeb9a6bad04bce11507/ed6ab/paved-cover.jpg","srcSet":"/static/b3c28d1b52360aeb9a6bad04bce11507/0489f/paved-cover.jpg 750w,\n/static/b3c28d1b52360aeb9a6bad04bce11507/52025/paved-cover.jpg 1080w,\n/static/b3c28d1b52360aeb9a6bad04bce11507/2e5f4/paved-cover.jpg 1366w,\n/static/b3c28d1b52360aeb9a6bad04bce11507/ed6ab/paved-cover.jpg 1600w","sizes":"100vw"},"sources":[{"srcSet":"/static/b3c28d1b52360aeb9a6bad04bce11507/c9abd/paved-cover.webp 750w,\n/static/b3c28d1b52360aeb9a6bad04bce11507/35e4d/paved-cover.webp 1080w,\n/static/b3c28d1b52360aeb9a6bad04bce11507/c505d/paved-cover.webp 1366w,\n/static/b3c28d1b52360aeb9a6bad04bce11507/21b18/paved-cover.webp 1600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6793750000000001}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/kubernetes-tetragon-log-ebpf-analytics/","title":"Auditing Tetragon Logs for Better eBPF Log Analytics in Kubernetes Clusters üêù","date":"2024-10-26 20:00:00"},"excerpt":"eBPF Log Analytics in Kubernetes Cluster with eBPF-Based Tetragon Using Parseable üï∏Ô∏è üõ∞Ô∏è Overview eBPF is a powerful technology that allows‚Ä¶","html":"<blockquote>\n<p><strong>eBPF Log Analytics in Kubernetes Cluster with eBPF-Based Tetragon Using Parseable üï∏Ô∏è</strong></p>\n</blockquote>\n<h2 id=\"Ô∏è-overview\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-overview\" aria-label=\"Ô∏è overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ∞Ô∏è Overview</h2>\n<p><a href=\"https://ebpf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">eBPF</a> is a powerful technology that allows you to extend the Linux kernel at runtime, without having to modify the kernel source code or reboot. This makes it ideal for a wide range of use cases, including security, observability, and networking.</p>\n<p>One of the most exciting applications of eBPF is log analytics. By using eBPF to hook into kernel calls, you can collect detailed information about everything that is happening in your Kubernetes cluster. This information can then be analyzed with a tool like <a href=\"https://www.parseable.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Parseable</a> to identify trends, patterns, and anomalies.</p>\n<p>In this blog post, we will show you how to use Parseable to audit Tetragon logs in your Kubernetes cluster. We will also examine a specific use case for auditing and alerting on sensitive file access.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 37.05882352941176%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABjUlEQVR42l2RwW7TQBCG/YTcuCIhJC5ceAFuvAAHpHLg0gOICqQKBFLJBVB7KCgRLaKlldK4sROndawkjr2217v7Md6IHPil2dHO7Pzz70xQlgowjGclu72U6EburkXrlrZtMeKdc966u491ZlustducMQalFIFSFR1Ormqe7N5wKr6DvMWJX4v1Byf0+wM2cJTasVrAMlsymU6Ioog8z0WEJmjqmkZURPGUi+sF6TzziU2tYyoEd+/d4f7DB/xDVLWczSzD3yMOjw59szSde5WBtU7IQp7vPOPTx/fs7b0hSZJt8Y/xksdPH/H57Q7D8czHjDRS1vE/ahEXdIduDau8pFSaLJvTNPX20dlowqv9fXoHB4TxplGtZIaLgjpbk6cl2W0lHM7XBcY4rsNTvvVeMvjymg/vXjAcnm8JJ3HEz0Gf4+/HhKMrH0sTxfo8prhMSP7MGV2uZSFORiWERdFQF79Q2VeqVcw0POJ2diHbtFRV5bfabbObT2f+R7qhsQbtJO66vEaLuqIo+Au1JQv6MiwT4AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Parseable\" title=\"\" src=\"/static/88284951b9237c448a28192c26e754cd/c5bb3/parseable.png\" srcset=\"/static/88284951b9237c448a28192c26e754cd/04472/parseable.png 170w,\n/static/88284951b9237c448a28192c26e754cd/9f933/parseable.png 340w,\n/static/88284951b9237c448a28192c26e754cd/c5bb3/parseable.png 680w,\n/static/88284951b9237c448a28192c26e754cd/d6331/parseable.png 702w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"getting-started\" style=\"position:relative;\"><a href=\"#getting-started\" aria-label=\"getting started permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Getting Started</h2>\n<p>eBPF is a technology that enables the Linux kernel to be extended at runtime, i.e., without modifying the kernel source code or rebooting it. It has been noted that eBPF does to Linux exactly what JavaScript does to HTML. The extended Berkeley Packet Filter, or eBPF, allows us to dynamically program the Linux kernel and obtain insights. Generally, eBPF functions in networking, security, and observability.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50.588235294117645%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACWUlEQVR42jWSW1PaUBSF+eNtHzp2nNqOb04ffO1M1d60tJYqXmoVBAI4oiO3AIZICIFcyEkgXL6e0OnDnjlzcvbKt/daCdd18TyP8dgnGN3i984Z9y4JrRzRqIgwrhBmRp4VxKCw+ibkm2B0J3sCWXHveKUhhCDRbDbQdZ2xL4jMnwTqFqK+SdR5x1zbxq9uIGobLPVtQvUdWn6NQWWTqXGE6wW4rkMM5TjOSjgRH2zbJpDqZl+l11HQq9/x9HPmdg6/c0zYTeH1fjMZZVjY18yEysQ38McC4fv/Kp4wJoxRY8EwCCgVDvi8s85xcouBdgxRkevyITeNQ/mTFIZdwPGyLPwLZl6Fge1hyV7LsenbI0aSNhFjxsiuK3dgt/AGFebTNpFoyKY6teCee7fMdFTHdhu05J3vPhB6XTJPbdLaA6ftGuePDYpGl0S/38eyLKaTCUo+yccPrznYfUtPPQSRx81+odTJktWKlAtJmjd7MFWYytFPlV32rj5xWlSod9o0zF5sShNN01Yjm4Y0qFPGG9YkgSopu7idG8zhAwNHxzIbjO0m84khBStkq1lSdxUyrRoFQ+N+YJDw5ULjseOKQp1lpMKswyJUmbtFZsNfiO43IusPS/dSxirNZHAhBUuETlcaEdCVQE8yKX7scry//6YouX2+7qyR3F3HUH/A8D3T2kv0wguc+1fw+AZDeYZTec6iv89j9Yjq7Qm5vEI+n1utLhFnMC4hBS3jllbthF77krFVYunlCM20DHN6RTYbnRGYZ4h+ishvyhz6Mn82pmliGMYK7C/7tdVVsfCLQgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"eBPF\" title=\"\" src=\"/static/7af7101f77fb633ae2be8f209115635b/c5bb3/ebpf.png\" srcset=\"/static/7af7101f77fb633ae2be8f209115635b/04472/ebpf.png 170w,\n/static/7af7101f77fb633ae2be8f209115635b/9f933/ebpf.png 340w,\n/static/7af7101f77fb633ae2be8f209115635b/c5bb3/ebpf.png 680w,\n/static/7af7101f77fb633ae2be8f209115635b/339e3/ebpf.png 977w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><a href=\"https://www.parseable.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Parseable</a> is a log analytics platform, built for the modern, cloud-native era. Parseable uses an index-free mechanism to organize and query data, allowing low latency and high throughput ingestion and query.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 58.235294117647065%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB40lEQVR42o2SS47aQBCGfZUcI0fJMi9NopyCS0SIJQEkYGEWyIgRBoGURbiDI7ANNthW/ARjd7tSVYaIUZJJWvrVUH/V19XVVr5ORp9m09nDcrn8cNNisXiiv8Vnsxnv8/n8Qde/fWy32y+UKisgjjKZJAnEcQxZlsHlcmHlec46nU4cp53jKCEEi/wkScXpDPD4qL9SZAUULMMwlFggz+ezxCIZxTHvRVHIOIpl4AfSD3w6WKZpynHKpf9YWwCuwWDwWpESgIK2bUMQBOD7PhwOB3BdF3a7Pf/2PI9y0PN+ec7egTRL2bMsS+T5Bbrd7juFyHgdaZomw47HIziOUwsLaQwk7Io9ApK32+14DATcbrcCu4Ver/f+Ckyl8d2oT8dkgpMcpwaG4Q+I4oi9/X5PHcFms2EgHWoYhkAGdDqdGkizs20LOwz4xINLYJcPiKIIgSGDffSoS74ywumRPLyVaZmCHqfTuXZYliUNGHDQrPqVCy4QpQCJgybd+/TStxjmCeL0+/0aiIasqgqeW8/ZWMvA4XBYA/F7KlHyyn6yKEbhm3WfcpfPn42qqm//q0OyuPwfHY5GozfKer3+rOt6czwetzRN+02TidZSVa31pau1plPtjzmo5mq1ajYajZc/AcYAYJH9N6M2AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Parseable UI\" title=\"\" src=\"/static/64c9fa08efba5b128c04f1656daf0a35/c5bb3/Parseable-ui.png\" srcset=\"/static/64c9fa08efba5b128c04f1656daf0a35/04472/Parseable-ui.png 170w,\n/static/64c9fa08efba5b128c04f1656daf0a35/9f933/Parseable-ui.png 340w,\n/static/64c9fa08efba5b128c04f1656daf0a35/c5bb3/Parseable-ui.png 680w,\n/static/64c9fa08efba5b128c04f1656daf0a35/b12f7/Parseable-ui.png 1020w,\n/static/64c9fa08efba5b128c04f1656daf0a35/b5a09/Parseable-ui.png 1360w,\n/static/64c9fa08efba5b128c04f1656daf0a35/29007/Parseable-ui.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p><a href=\"https://tetragon.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Tetragon</a> is a powerful Kubernetes-aware security observability and runtime enforcement tool that applies TracingPolicy and filtering directly with eBPF. It ensures the reduction of observation overhead by tracking any process and real-time policy enforcement.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 656px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 168.8235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAiCAYAAABfqvm9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFi0lEQVR42m1WyXLbRhDFv+ZrcswlOfmQa1yxXS5bduzYliNHkiNrl2gtlCgQBMEFJLENdszL6yHEUI7BejWNnp43Pb0MaHVUBw+QnOMiOcXxdAcftn7EP/YmDufHOPAPcTg7xP70AMeLY/xvXQvrTJ3hAUj2NT7B3mgLvz76AS+2f8Pzk9d4uv8crzpv8Hj3KT7cfkQn6+CUtt+ut/p5H/3cQT/rr+Ckd3CUTdmFW3lwywGcfMDRxUBQDFrbtXXCQS5LVSnKpkIt0LWRi7o0cqMbyhXK9l30ZV2g4thobWwr2tSNrCshXFZSJyiqCt1+H7Y7Ql5WyIsc/cEAA8+FN3JhOw5cz0NRFpDHG48xGDic8+AMbExnM6OPypiEOkc1nyLqHKMYnaOKRtCcDOYRRlOFnYuCBBO4o5FZpAMHxfQaF16E3lDh84VCEsbI8wpJrUjYpKjjECW90aqPOpuj4cJwnmK2yHHtNQiiCEEYmo2adIRaDeGFOfywRG9cI1pkSOICqiFhVMVkpoIxiBmbuMroeoKUupQ7VjpFkJEwi02MEsZQ0a7gfF6nHBXfMyKFcFkw/hAMOnCPBlovIU8YB5hFM2qZmCZHqQuOJfJmmawVB2F5BWP0XZSwE4VRWcJvGnj0bNDCzhXsLMWlSlgqGUZr66ytIMB3EQZ4tfcRL7vXeHJ5hWfE72fnHC/xcTbHdhjh/WKBD8SntXXWDoP9EAG2owS7vouDk2f4q3eCjTsHr3s9vLy5wSuOf5Nkl7YfSfCJ4+7aemuS55jS1XXMWJfzusZMQHnBI8t7wGIW2dgwFLfMvk2ILDrhshRfvn2iOEZEw5hjRUJBTcKCi8r2XR6llMH9I1xWvEaotTbjl6NdvH3/Hpubm0iSBBPfx/XtLW5tG3fsqMtuF+Pp9MGaZae0hHXTrCA9KtAtmm+wbrO+TmAIFY8S0wvp3SHbS0bxJGSAGxoNhkODGyZDelj8GbKvHdddweYa6SThsmLGQ84eZewQBjXkGKbsCMYr5VzC9wXhc9OE86IT24A2MsayprUXLkMoRhmR06Ocu2QtRF9Q57PIJdt5qxM7mTf2a5DwWZKSk/MjXHWveGMU6DL4clXJ0f32WnLowZRnPft6hsurr7zGKhOCHkNTthmXxxAaD8vMHDs1crn0svU8l5rkcebUF1XBo+Wcq42dhODeTmAIc+7cZ2Al4DkVUg7+fI4JvYvbGnMZqwlJlnYjelgae58dk5HUlM+9hxmlntOFMxoiY6y8yQQj1p3DYy9Y3DXLY8xFi0bDGdrMqG28Hk7G8Li5JE1sqvsYypELCXAb9LxNkESmbBozN81Lg+LepkVFoqJNpMBkeT0pZRtsOc6qe/hzVIYpr7vzizNcXHVYxNp0jNTp+mM8jEgSF6wnBl5JTUqAudtKlqTQu3kh9VqwVpnA6r/5dZhO4cdS7mfIKJ/EJXgccz/LTIOEBALd2q3b1rpZ6QRWlGoIYmZHMWGKaU/5tZT3UPQyny8hsuiSXBs7A9recwisg9sah70ae9cVHr1ReLKt8Oeeg+1OjKM7jS/dCv1ZY7DXrXFi1/jjsMAvGwrvDhd498WlTQnhEVgHNySksHdV4ecXMR5vKbzeucXWaYCjnjYb9f3GQOTTuwYbexl+eq7wdn+Bje3bJSF5BJbLnQc0Hgcak1DDW2jMWM9jyqIfyXu8hMii81tZ7GcJb5+5hvC4vsRQaVPlC350pvz41LVmBwSI+MVjdWAepitCkc31xWsuzVgVaY55ELJbSmNrYhgky1q6c3roXJ2ZS/XG7mHMjjEXg+evCPuU5fm8v40wiulEYOoxTuLl95tc1iyiR2GDUC0zOIt482b8b9PKC+qzYgmRRScVMI/5F0VJZnm6ZKn3Q41/AV5uGflQSVxsAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Tetragon\" title=\"\" src=\"/static/5e41e4aba4b14209023718e1c66eb875/748f4/tetragon.png\" srcset=\"/static/5e41e4aba4b14209023718e1c66eb875/04472/tetragon.png 170w,\n/static/5e41e4aba4b14209023718e1c66eb875/9f933/tetragon.png 340w,\n/static/5e41e4aba4b14209023718e1c66eb875/748f4/tetragon.png 656w\" sizes=\"(max-width: 656px) 100vw, 656px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>As shown in the above figure, Tetragon is deployed to the Kubernetes cluster. Tetragon uses hook points in eBPF programs to observe kernel calls. If any TracingPolicy is applied, it filters the logs as per the policy configuration. When any event is filtered using TracingPolicy, it stores Tetragon logs locally or uses a webhook backend like Parseable to collect logs.</p>\n<h3 id=\"-pre-requisites\" style=\"position:relative;\"><a href=\"#-pre-requisites\" aria-label=\" pre requisites permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìã Pre-requisites</h3>\n<p>To get started, you'll need the following pre-requisites:</p>\n<ul>\n<li>A Kubernetes cluster with admin access. You can create a local one using <a href=\"https://minikube.sigs.k8s.io/docs/start/\" target=\"_blank\" rel=\"noopener noreferrer\">Minikube</a> or <a href=\"https://kind.sigs.k8s.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Kind</a>.</li>\n<li><code class=\"language-text\">kubectl</code> and <code class=\"language-text\">helm</code> installed.</li>\n</ul>\n<p>We'll implement Tetragon logs using TracingPolicy. The Tetragon server stores them in a local file system and configures <a href=\"https://vector.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">Vector</a>, a lightweight, ultra-fast tool, to send logs to the Parseable server. Finally, we'll verify Tetragon logs in the Parseable UI for sensitive file access via a Kubernetes pod.</p>\n<h2 id=\"hands-on\" style=\"position:relative;\"><a href=\"#hands-on\" aria-label=\"hands on permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Hands-On</h2>\n<p>We'll implement Tetragon logs using TracingPolicy. The Tetragon server stores them in a local file system, and we'll configure <a href=\"https://vector.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">Vector</a>, a lightweight, ultra-fast tool, to send logs to the Parseable server. Finally, we will verify Tetragon logs in the Parseable UI with sensitive file access through the Kubernetes pod.</p>\n<p>Here is the high-level architecture that shows what we would achieve:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 44.11764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABtElEQVR42l1S25LaMAzl5/cDOv2PPvDYaR/aDi/b7jItLQsU2FmaBBNwYifBcWwnp5JZelnPKJFl6Ug60shai7MxEHkO7x2cc+i6i7SmhrUtOrJZ28F2XfQx5C+lhCoV/UsURYG6rtG2LUbDMEDpCrMfC7QUfD4bpNke4iCxXd0iSzZ4mH9B8rTA7nERQTkwWIeb8WvcvHmFPM3gQ6Bk/gLIAPfTbzFL6IGPtyvczX6iqmporVHIE055huzXmt4HkgA+7+Yf8HY6hj6s4527GwVC7vs+ZgUGWA+MJyk+T++jEyd8ea62nrLLk8TxmMd7rJA/LwNZ85HLLooqFCqqlDvwPlxRYd2Ff/bh+P8A29ZGY08tGTJleYHJZIK60UgSan2/RTgfUaoKu90TpLaQeRN1IQR4uBGQ2zUENpsv0TQNCn3G++8HfHoQkBSsTzWqrUC5EUg2Gtle4iBS7KqAZG+wWa9oBtlfwIEAS6VxN/1KXMhY7WyVYvkool5TJSZXMLKmiloK9M98OYTgI/88hz8tMzIPZLlcQCkVH3n32O6e987RVFlC72mSF17dPxxf77yHvwH7bK98p6Pr/wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"architecture\" title=\"\" src=\"/static/4e39a5c3a5021aa7daa5c2a254064615/c5bb3/architecture.png\" srcset=\"/static/4e39a5c3a5021aa7daa5c2a254064615/04472/architecture.png 170w,\n/static/4e39a5c3a5021aa7daa5c2a254064615/9f933/architecture.png 340w,\n/static/4e39a5c3a5021aa7daa5c2a254064615/c5bb3/architecture.png 680w,\n/static/4e39a5c3a5021aa7daa5c2a254064615/f0551/architecture.png 862w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>We will perform the following tasks to understand how Parseable helps us in auditing Tetragon logs:</p>\n<ol>\n<li><strong>Enable Tetragon in the Kubernetes cluster which stores logs locally.</strong></li>\n<li><strong>Send Tetragon logs to Parseable through Vector.</strong></li>\n<li><strong>Access sensitive files from the pod and generate alerts through Parseable.</strong></li>\n</ol>\n<h3 id=\"Ô∏è-setup-environment\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-setup-environment\" aria-label=\"Ô∏è setup environment permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Setup Environment</h3>\n<h4 id=\"install-tetragon-using-helm\" style=\"position:relative;\"><a href=\"#install-tetragon-using-helm\" aria-label=\"install tetragon using helm permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install Tetragon using Helm</h4>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">helm repo <span class=\"token function\">add</span> cilium https://helm.cilium.io\nhelm repo update\nhelm <span class=\"token function\">install</span> tetragon cilium/tetragon <span class=\"token parameter variable\">-n</span> kube-system</code></pre></div>\n<p>Wait for a moment, then:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl get ds tetragon <span class=\"token parameter variable\">-n</span> kube-system\nkubectl logs <span class=\"token parameter variable\">-n</span> kube-system <span class=\"token parameter variable\">-l</span> app.kubernetes.io/name<span class=\"token operator\">=</span>tetragon <span class=\"token parameter variable\">-c</span> export-stdout <span class=\"token parameter variable\">-f</span></code></pre></div>\n<h4 id=\"install-parseable\" style=\"position:relative;\"><a href=\"#install-parseable\" aria-label=\"install parseable permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Install Parseable</h4>\n<p>Follow this <a href=\"https://docs.parseable.io/installation\" target=\"_blank\" rel=\"noopener noreferrer\">installation guide</a> to install Parseable on your Kubernetes cluster. Wait for Parseable to start, and then verify that Parseable pods are running in the <code class=\"language-text\">parseable</code> namespace:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl get pods <span class=\"token parameter variable\">-n</span> parseable</code></pre></div>\n<h4 id=\"configure-vector-to-send-logs-to-parseable\" style=\"position:relative;\"><a href=\"#configure-vector-to-send-logs-to-parseable\" aria-label=\"configure vector to send logs to parseable permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Configure Vector to Send Logs to Parseable</h4>\n<p>Install Vector through Helm. We have a <code class=\"language-text\">vector-tetragon-values.yaml</code> file configured to access the <code class=\"language-text\">tetragon.log</code> file.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">helm repo <span class=\"token function\">add</span> vector https://helm.vector.dev\n<span class=\"token function\">wget</span> https://github.com/seifrajhi/tetragon-vector-parseable-blog/blob/main/vector-tetragon-values.yaml\nhelm <span class=\"token function\">install</span> vector vector/vector <span class=\"token parameter variable\">--namespace</span> vector --create-namespace <span class=\"token parameter variable\">--values</span> vector-tetragon-values.yaml</code></pre></div>\n<p>It will take a few minutes for the Vector pod to get started. Verify the vector pod is running in the <code class=\"language-text\">vector</code> namespace:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl get pods <span class=\"token parameter variable\">-n</span> vector</code></pre></div>\n<p>Now Vector is ready to send the events stored in <code class=\"language-text\">/var/run/cilium/tetragon/tetragon.log</code> file. Once this is done, you can verify the log events in the Parseable UI.</p>\n<h3 id=\"-track-sensitive-file-access-with-parseable\" style=\"position:relative;\"><a href=\"#-track-sensitive-file-access-with-parseable\" aria-label=\" track sensitive file access with parseable permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîç Track Sensitive File Access with Parseable</h3>\n<p>Although integrating Tetragon logs with Parseable has several advantages, we will concentrate on one of the most notable use cases‚Ää‚Äî‚Ääauditing Tetragon events when accessing sensitive files like <code class=\"language-text\">/etc/shadow</code>.</p>\n<h4 id=\"create-a-pod-to-access-files-on-the-host\" style=\"position:relative;\"><a href=\"#create-a-pod-to-access-files-on-the-host\" aria-label=\"create a pod to access files on the host permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Create a Pod to Access Files on the Host</h4>\n<p>Create a pod with privileged access.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token comment\"># dev-pod.yaml</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Pod\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dev<span class=\"token punctuation\">-</span>pod\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">command</span><span class=\"token punctuation\">:</span>\n                <span class=\"token punctuation\">-</span> /nsenter\n                <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>all\n                <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>target=1\n                <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>\n                <span class=\"token punctuation\">-</span> su\n                <span class=\"token punctuation\">-</span> <span class=\"token string\">\"-\"</span>\n            <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> alexeiled/nsenter<span class=\"token punctuation\">:</span><span class=\"token number\">2.34</span>\n            <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> nsenter\n            <span class=\"token key atrule\">securityContext</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">privileged</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n            <span class=\"token key atrule\">stdin</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n            <span class=\"token key atrule\">tty</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">hostNetwork</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">hostPID</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span></code></pre></div>\n<p>Apply the pod configuration:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl apply <span class=\"token parameter variable\">-f</span> dev-pod.yaml</code></pre></div>\n<p>To list the pods:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl get pods</code></pre></div>\n<h4 id=\"apply-tracingpolicy\" style=\"position:relative;\"><a href=\"#apply-tracingpolicy\" aria-label=\"apply tracingpolicy permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Apply TracingPolicy</h4>\n<p>Apply <a href=\"https://tetragon.io/docs/use-cases/filename-access/\" target=\"_blank\" rel=\"noopener noreferrer\">TracingPolicy</a> for read/write access.</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">wget</span> https://github.com/cilium/tetragon/blob/main/examples/tracingpolicy/filename_monitoring_filtered.yaml\nkubectl apply <span class=\"token parameter variable\">-f</span> filename_monitoring_filtered.yaml</code></pre></div>\n<p>This policy monitors a specific file, <code class=\"language-text\">/etc/passwd</code>. If you check the content of the TracingPolicy file, it hooks on kernel functions from which the file can be accessed:</p>\n<ul>\n<li><code class=\"language-text\">security_file_permission</code></li>\n<li><code class=\"language-text\">security_mmap_file</code></li>\n<li><code class=\"language-text\">security_path_truncate</code></li>\n</ul>\n<p>This TracingPolicy will extract read/write event logs.</p>\n<h4 id=\"access-sensitive-files-from-a-pod\" style=\"position:relative;\"><a href=\"#access-sensitive-files-from-a-pod\" aria-label=\"access sensitive files from a pod permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Access Sensitive Files from a Pod</h4>\n<p>Now, exec into the dev-pod and apply the <code class=\"language-text\">cat</code> command to read the <code class=\"language-text\">/etc/passwd</code> file:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl <span class=\"token builtin class-name\">exec</span> <span class=\"token parameter variable\">-it</span> dev-pod <span class=\"token parameter variable\">-n</span> default -- <span class=\"token function\">cat</span> /etc/passwd</code></pre></div>\n<p>You can verify the logs from the Parseable Console. Next, we will generate an alert in Parseable to get a notification when a sensitive file is accessed.</p>\n<h3 id=\"-set-an-alert-in-parseable\" style=\"position:relative;\"><a href=\"#-set-an-alert-in-parseable\" aria-label=\" set an alert in parseable permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üö® Set an Alert in Parseable</h3>\n<p>Parseable allows us to generate an alert when the <code class=\"language-text\">/etc/shadow</code> file is read from the pod. Use the following JSON code to set an alert from the Parseable UI. Click <code class=\"language-text\">console -> config -> alert</code>.</p>\n<p>To generate an alert for a specific pod:</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"version\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"v1\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"alerts\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Unauthorised access\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"message\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"/etc/shadow file is accessed by an unauthorised pod\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"rule\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"composite\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token property\">\"config\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"(process_kprobe_process_arguments =% \\\"shadow\\\")\"</span>\n            <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token property\">\"targets\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token punctuation\">{</span>\n                    <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"webhook\"</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token property\">\"Endpoint\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"&lt;webhook.site_custom_endpoint>\"</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token property\">\"skip_tls_check\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token property\">\"repeat\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"interval\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"10s\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"times\"</span><span class=\"token operator\">:</span> <span class=\"token number\">5</span> <span class=\"token punctuation\">}</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>This alert will trigger when the <code class=\"language-text\">/etc/shadow</code> file is accessed from the pod. Set up the target endpoint by going through <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener noreferrer\">webhook.site</a> and copying your unique URL. Paste it in place of <code class=\"language-text\">webhook.site_custom_endpoint</code>. Click the Submit button.</p>\n<p>Now, let's verify how the above Parseable setup triggers an alert. Exec into the dev-pod and apply the <code class=\"language-text\">cat</code> command to read the <code class=\"language-text\">/etc/passwd</code> file and check the unique URL to see the alerts:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl <span class=\"token builtin class-name\">exec</span> <span class=\"token parameter variable\">-it</span> dev-pod <span class=\"token parameter variable\">-n</span> default -- <span class=\"token function\">cat</span> /etc/passwd</code></pre></div>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üèÅ Conclusion</h2>\n<p>This post explained how Parseable can be used to analyze Tetragon logs in Kubernetes. We set up a logging pipeline from Tetragon to Parseable using Vector, applied a TracingPolicy to filter the logs, and generated alerts in Parseable when sensitive files were accessed.</p>\n<p>If you have any further ideas or feedback, please join our <a href=\"https://slack.parseable.io\" target=\"_blank\" rel=\"noopener noreferrer\">Slack channel</a> to share them. We value your insights and look forward to hearing from you.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/scalable-event-driven-workloads-eks-keda-karpenter/","title":"Deploy Scalable, Cost-Effective Event-Driven Workloads with Amazon EKS, KEDA, and Karpenter","date":"2024-10-26 18:34:00"},"excerpt":"Use the power of Kubernetes for efficient and responsive application scaling. Nowadays, businesses need to handle large amounts of data and‚Ä¶","html":"<blockquote>\n<p><strong>Use the power of Kubernetes for efficient and responsive application scaling.</strong></p>\n</blockquote>\n<p>Nowadays, businesses need to handle large amounts of data and events efficiently. This is where event-driven workflows can help. By using Amazon Elastic Kubernetes Service (EKS), <a href=\"https://keda.sh/\" target=\"_blank\" rel=\"noopener noreferrer\">KEDA</a> (Kubernetes Event-Driven Autoscaling), and <a href=\"https://karpenter.sh/\" target=\"_blank\" rel=\"noopener noreferrer\">Karpenter</a>, you can create a scalable and cost-effective solution for managing your workloads.</p>\n<p>Amazon EKS provides a managed Kubernetes service, making it easier to run Kubernetes without needing to manage the control plane. KEDA helps in scaling your applications based on the number of events, ensuring that your resources are used efficiently. Karpenter, on the other hand, is an open-source Kubernetes cluster autoscaler that helps in optimizing the cost and performance of your workloads.</p>\n<p>In this blog post, we will explore how to set up and run an event-driven workflow using these tools.</p>\n<h2 id=\"understanding-keda\" style=\"position:relative;\"><a href=\"#understanding-keda\" aria-label=\"understanding keda permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Understanding KEDA</h2>\n<p><a href=\"https://keda.sh/\" target=\"_blank\" rel=\"noopener noreferrer\">KEDA</a> is a Kubernetes-based autoscaler that dynamically adjusts the number of pods in your cluster based on the number of events needing to be processed. It is a lightweight, single-purpose component that integrates seamlessly with any Kubernetes cluster.</p>\n<p>KEDA works alongside standard Kubernetes components like the <a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\" target=\"_blank\" rel=\"noopener noreferrer\">Horizontal Pod Autoscaler (HPA)</a> without overwriting or duplicating their functionality.</p>\n<p>KEDA provides multiple scalers that detect whether deployments should be active, scaled in, or scaled out. These scalers support various event sources, including AWS services like <strong>SQS</strong>, <strong>CloudWatch</strong>, and <strong>DynamoDB</strong>, as well as <strong>GCP</strong>, <strong>Azure events</strong>, and more.</p>\n<p>By defining autoscaling policies through Custom Resource Definitions (CRDs), the KEDA operator manages the scaling of Kubernetes objects based on these policies. This ensures that your applications scale precisely according to the event load, optimizing resource usage and reducing costs.</p>\n<h2 id=\"exploring-karpenter\" style=\"position:relative;\"><a href=\"#exploring-karpenter\" aria-label=\"exploring karpenter permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Exploring Karpenter</h2>\n<p><a href=\"https://karpenter.sh/\" target=\"_blank\" rel=\"noopener noreferrer\">Karpenter</a> is a high-performance Kubernetes cluster autoscaler that dynamically provisions worker nodes to meet the resource demands of unscheduled pods.</p>\n<p>Unlike traditional autoscalers, Karpenter uses a groupless architecture, allowing it to select the most appropriate instance types based on the specific needs of your workloads. It continuously evaluates the resource requirements of pending pods and other scheduling constraints, such as node selectors, affinities, and tolerations, to provision the ideal compute capacity.</p>\n<p>Karpenter integrates directly with the Amazon EC2 fleet API, bypassing the need for nodes and EC2 auto scaling groups. This direct provisioning significantly reduces the time required to scale up or down, from minutes to milliseconds. Karpenter also allows you to set quotas on CPU and memory for your EKS cluster, ensuring you only pay for the resources you actually use.</p>\n<p>By intercepting requests to Kubernetes admission controllers, Karpenter can dynamically adjust the number of nodes in your cluster, scaling up when demand increases and scaling down when there are excess resources. This flexibility helps maintain optimal performance and cost-efficiency for your Kubernetes workloads.</p>\n<h2 id=\"hands-on-walkthrough\" style=\"position:relative;\"><a href=\"#hands-on-walkthrough\" aria-label=\"hands on walkthrough permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Hands-On Walkthrough</h2>\n<p>This post is a proof-of-concept implementation that uses Kubernetes to execute code in response to events, such as API requests. The workflow is driven by KEDA, which scales Kubernetes pods based on incoming events like SQS messages. When KEDA scales out pods that remain in a pending state, Karpenter steps in, using provisioners to decide whether to scale out additional nodes.</p>\n<p>By integrating KEDA and Karpenter with Amazon EKS, we can easily build event-driven workflows that orchestrate jobs running on Kubernetes with AWS services, such as Amazon SQS, with minimal code. All AWS resources, Kubernetes manifests, and Kubernetes add-ons are managed and installed using Terraform.</p>\n<p>We will be bootstrapping the components with <a href=\"https://github.com/aws-ia/terraform-aws-eks-blueprints-addons/tree/main\" target=\"_blank\" rel=\"noopener noreferrer\">EKS blueprints addons</a>.</p>\n<h3 id=\"architecture-overview\" style=\"position:relative;\"><a href=\"#architecture-overview\" aria-label=\"architecture overview permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Architecture Overview</h3>\n<p>In this hands-on lab, we will explore an application deployment architecture that uses Kubernetes for container orchestration, AWS SQS for message queuing, KEDA for scaling pods, and Karpenter for scaling nodes.</p>\n<p>Our architecture consists of the following components:</p>\n<ol>\n<li><strong>Application Deployment:</strong> The application is deployed in a Kubernetes cluster, running as a set of pods. These pods handle incoming requests and perform the necessary processing.</li>\n<li><strong>AWS SQS:</strong> Amazon Simple Queue Service (SQS) is used to queue messages that need to be processed by the application. This ensures that messages are handled asynchronously and can be processed as resources become available.</li>\n<li><strong>KEDA:</strong> Kubernetes Event-Driven Autoscaling (KEDA) is responsible for scaling the number of pods based on the number of messages in the SQS queue. When messages are posted to the SQS queue, KEDA scales up the pods to handle the increased load.</li>\n<li><strong>Karpenter:</strong> If the current cluster cannot handle the increased load even after scaling the pods, Karpenter comes into play. Karpenter is an open-source Kubernetes cluster autoscaler that creates additional nodes to accommodate the increased number of pods.</li>\n</ol>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 124.11764705882354%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAYAAAAxFw7TAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC2klEQVR42r2Vy4rUQBSG52F8Ad/Cd3HlTgR3grpypxsdFyKKiKIgoogjOsJ4Q1EZEGn7klvd0t1J3ZLO5ff0dE873Y44OGrgJ6Eq+eo/VeecrOEvX2v/HTiZVPC+QNO2hwO2c8Dn7S/Y3HqD3iBAXdf4HXdtL6CuG0zfn2rXUacX4PHTTajhmMawmN9RQws0zTJwd0FNYX3jHNJaCGMWktZAudkY1/rHHL0na4AVNTxty08ObVmA5zHEiviusgh8HNEYSXNw9RX86VmI91dhfwWcAqROlqTMTELH83mST8HCD4hOH4G4fAyuaQ8OjNMIScrAhwIs5VBjAZVJcBmhs3ED3Vd34apfORyFkNkyNI7JTZBDJhYqMYgDh2BgMRQeQjVIRAnry32AEwI2CrKSC9g0TKVyDDnNxQaZdHj3KcOz10Pk9MwCjSTMV4Dz9DDaILr9BPL5azrFZHEoUTImRw481jvqd0IE3RCp0MhpsVSMYdweYDvf0CyS2D56AvHxixioHrpJB6Hs4N12ihdvNbpdTSGPIVkH+WgAlAESFoDxAL4o9gDnDvNxjo+XbqH3YAPSMIhsdqL9YETVMgaLLYWc4dxNgVNXJfSoj5PrKS7cEagqv98elhDtkJJVLe8hQUbc0aE45KnBo60Id58HQEEVtNXHq88B1XtxsFOeAqXIKFQPxRxSbjBxAzRFDy0BvelB6z5cURwsDxdA9gPodYjGD2CzAOdvKVx5yMmh/3NgScDa9TGxAdYfJri3GWNSHcJhaUJUBJyGXBVdONujPDwEsNAzoM37uPZY4P5LhnL/kD0YdZJpquw2BGnoWVDysoLkqWIsKhtSDvbhCXjmOsPlB/Eibdq9QFdS2uSK2pREqKhC0oREd6YQxUOqmJmEINfUGIbUNISkBalhFOVkyeFSE66qujXGtta6mdxMzs9kdsZ8mxvXVnXTNivf/5O/XraqpmkOrNVvvwNTlXo8ln0pjwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Architecture\" title=\"\" src=\"/static/99b10ffe138fd9f32a12e348f5de6000/c5bb3/Architecture.png\" srcset=\"/static/99b10ffe138fd9f32a12e348f5de6000/04472/Architecture.png 170w,\n/static/99b10ffe138fd9f32a12e348f5de6000/9f933/Architecture.png 340w,\n/static/99b10ffe138fd9f32a12e348f5de6000/c5bb3/Architecture.png 680w,\n/static/99b10ffe138fd9f32a12e348f5de6000/b12f7/Architecture.png 1020w,\n/static/99b10ffe138fd9f32a12e348f5de6000/b5a09/Architecture.png 1360w,\n/static/99b10ffe138fd9f32a12e348f5de6000/0f586/Architecture.png 1498w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h3 id=\"setup-the-infrastructure\" style=\"position:relative;\"><a href=\"#setup-the-infrastructure\" aria-label=\"setup the infrastructure permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Setup the Infrastructure</h3>\n<p>In order to create our infrastructure, we will use the <a href=\"https://github.com/aws-ia/terraform-aws-eks-blueprints-addons\" target=\"_blank\" rel=\"noopener noreferrer\">terraform-aws-eks-blueprints-addons</a> module.</p>\n<p>Follow the steps to set up an Amazon EKS cluster, and Karpenter on the Amazon EKS cluster.</p>\n<p>Clone the repository to your local machine using the following command:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/seifrajhi/eks-keda-karpenter-autoscaling.git</code></pre></div>\n<p>Navigate to the repository's directory:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> eks-keda-karpenter-autoscaling/aws-blueprints-iac</code></pre></div>\n<p>Now, run the following commands to initialize, plan, and apply the Terraform configuration with automatic approval:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">terraform init\nterraform plan\nterraform apply -auto-approve</code></pre></div>\n<p>This will create a VPC, EKS cluster, Karpenter, and Fargate profile, thanks to the <code class=\"language-text\">enable_karpenter</code> set to <code class=\"language-text\">true</code>.</p>\n<p>Then provision the Karpenter <code class=\"language-text\">EC2NodeClass</code> and <code class=\"language-text\">NodePool</code> resources which provide Karpenter the necessary configurations to provision EC2 resources:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl apply <span class=\"token parameter variable\">-f</span> karpenter/karpenter.yaml</code></pre></div>\n<p>Once the Karpenter resources are in place, Karpenter will provision the necessary EC2 resources to satisfy any pending pods in the scheduler's queue.</p>\n<h3 id=\"deploy-keda\" style=\"position:relative;\"><a href=\"#deploy-keda\" aria-label=\"deploy keda permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Deploy KEDA</h3>\n<p>We will use Helm to deploy KEDA. Run the below commands to get the values file:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">helm repo <span class=\"token function\">add</span> kedacore https://kedacore.github.io/charts \nhelm repo update\nhelm show values kedacore/keda <span class=\"token operator\">></span> values.yaml</code></pre></div>\n<p>Before installing the release, we need to update the values. Here is what you need to add:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">serviceAccount</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">annotations</span><span class=\"token punctuation\">:</span> \n        <span class=\"token key atrule\">eks.amazonaws.com/role-arn</span><span class=\"token punctuation\">:</span> &lt;POD_ROLE_ARN<span class=\"token punctuation\">></span></code></pre></div>\n<p>Now to deploy KEDA, you need to run:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">helm <span class=\"token function\">install</span> keda kedacore/keda <span class=\"token parameter variable\">--values</span> values.yaml <span class=\"token parameter variable\">--namespace</span> keda</code></pre></div>\n<h2 id=\"keda-and-karpenter-autoscaling-in-action\" style=\"position:relative;\"><a href=\"#keda-and-karpenter-autoscaling-in-action\" aria-label=\"keda and karpenter autoscaling in action permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>KEDA and Karpenter Autoscaling in Action</h2>\n<p>With KEDA, we are going to scale the deployment replicas to zero by using an empty AWS SQS queue. Then, we will feed that queue to scale up and down the number of replicas.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl create ns keda-karpenter-scaling\nkubectl config set-context <span class=\"token parameter variable\">--current</span> <span class=\"token parameter variable\">--namespace</span><span class=\"token operator\">=</span>keda\nkubectl create deployment nginx-deployment <span class=\"token parameter variable\">--image</span> nginx <span class=\"token parameter variable\">--replicas</span><span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token parameter variable\">--requests</span><span class=\"token operator\">=</span>cpu<span class=\"token operator\">=</span><span class=\"token number\">1</span>,memory<span class=\"token operator\">=</span>3Gi</code></pre></div>\n<p>Running these commands will deploy 2 pods with 1 vCPU and 3 GiB of memory each, requiring one node per pod. Karpenter should create two nodes. If you set 3 replicas, based on the current provisioner configuration, Karpenter will create 2 nodes and leave one pod pending.</p>\n<p>To create an SQS queue, run:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">aws sqs create-queue --queue-name keda-karpenter-scaling</code></pre></div>\n<p>Once the queue is created, deploy the KEDA scaled object and the trigger authentication:</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\">cat &lt;&lt;EOF <span class=\"token punctuation\">|</span> kubectl create <span class=\"token punctuation\">-</span>f <span class=\"token punctuation\">-</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> keda.sh/v1alpha1 \n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> ScaledObject \n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span> \n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> aws<span class=\"token punctuation\">-</span>sqs<span class=\"token punctuation\">-</span>queue<span class=\"token punctuation\">-</span>scaledobject \n    <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> keda\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span> \n    <span class=\"token key atrule\">scaleTargetRef</span><span class=\"token punctuation\">:</span> \n        <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> nginx<span class=\"token punctuation\">-</span>deployment \n        <span class=\"token key atrule\">minReplicaCount</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span>  <span class=\"token comment\"># We don't want pods if the queue is empty </span>\n        <span class=\"token key atrule\">maxReplicaCount</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span>  <span class=\"token comment\"># We don't want more than 2 replicas </span>\n        <span class=\"token key atrule\">pollingInterval</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span> <span class=\"token comment\"># Frequency for metrics (in seconds) </span>\n        <span class=\"token key atrule\">cooldownPeriod</span><span class=\"token punctuation\">:</span> <span class=\"token number\">25</span>  <span class=\"token comment\"># Wait time for downscale (in seconds) </span>\n<span class=\"token key atrule\">triggers</span><span class=\"token punctuation\">:</span> \n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> aws<span class=\"token punctuation\">-</span>sqs<span class=\"token punctuation\">-</span>queue \n        <span class=\"token key atrule\">authenticationRef</span><span class=\"token punctuation\">:</span> \n            <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keda<span class=\"token punctuation\">-</span>aws<span class=\"token punctuation\">-</span>credentials \n        <span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span> \n            <span class=\"token key atrule\">queueURL</span><span class=\"token punctuation\">:</span> https<span class=\"token punctuation\">:</span>//sqs.eu<span class=\"token punctuation\">-</span>west<span class=\"token punctuation\">-</span>1.amazonaws.com/$AWS_ACCOUNT_ID/keda<span class=\"token punctuation\">-</span>karpenter<span class=\"token punctuation\">-</span>scaling\n            <span class=\"token key atrule\">queueLength</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"1\"</span> \n            <span class=\"token key atrule\">awsRegion</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"eu-west-1\"</span> \n            <span class=\"token key atrule\">identityOwner</span><span class=\"token punctuation\">:</span> operator\n<span class=\"token punctuation\">---</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> keda.sh/v1alpha1 \n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> TriggerAuthentication \n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span> \n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keda<span class=\"token punctuation\">-</span>aws<span class=\"token punctuation\">-</span>credentials \n    <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> keda\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span> \n    <span class=\"token key atrule\">podIdentity</span><span class=\"token punctuation\">:</span> \n        <span class=\"token key atrule\">provider</span><span class=\"token punctuation\">:</span> aws<span class=\"token punctuation\">-</span>eks\nEOF</code></pre></div>\n<p>After deploying the KEDA configuration, since the queue is empty, the nginx deployment should scale down to 0 because the minReplicaCount is set to 0.</p>\n<p>With two nodes without any resources running, Karpenter will downscale the number of nodes from 2 to 0.</p>\n<p>The queue length is set to 1, meaning that with (n) messages, we'll have (n) pods, but (n) will be less than maxReplicaCount. For example, with 2 messages in the queue, we'll have 2 pods. With 3 messages in the queue, we'll still have 2 pods due to the Karpenter quota.</p>\n<p>If the queueLength is set to 2, with 1 or 2 messages in the queue, we'll have 1 pod, and with 3‚Äì4 or more messages, we'll have 2 pods because the maxReplicaCount is still set to 2. To test this, you can send messages using:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token keyword\">for</span> <span class=\"token for-or-select variable\">i</span> <span class=\"token keyword\">in</span> <span class=\"token number\">1</span><span class=\"token punctuation\">..</span><span class=\"token number\">2</span>\n<span class=\"token keyword\">do</span>\n    aws sqs send-message <span class=\"token punctuation\">\\</span>\n    --queue-url <span class=\"token variable\"><span class=\"token variable\">$(</span>aws sqs get-queue-url --queue-name keda-karpenter-scaling<span class=\"token variable\">)</span></span> <span class=\"token punctuation\">\\</span>\n    --message-body <span class=\"token string\">\"Keda and Karpenter demo\"</span>\n<span class=\"token keyword\">done</span></code></pre></div>\n<p>This should trigger the KEDA scaled object and create two pods. These two pods will be pending due to the lack of space in the cluster. Karpenter will detect these pending pods, create two nodes, and schedule the pods on the new nodes.</p>\n<h2 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîö Conclusion</h2>\n<p>In this post, we showed how using KEDA and Karpenter on Amazon EKS makes running event-driven workloads easier and more efficient. KEDA scales your applications based on events, while Karpenter quickly adds the necessary nodes. This combination ensures your system is responsive and cost-effective.</p>\n<p>By integrating these tools with Kubernetes, EKS, AWS, and SQS, you can manage your workloads better, optimize resources, and improve performance. This setup helps businesses handle event-driven tasks smoothly and efficiently.</p>\n<p>The end ‚úåüèª</p>\n<h2 id=\"references\" style=\"position:relative;\"><a href=\"#references\" aria-label=\"references permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>References</h2>\n<ul>\n<li><a href=\"https://medium.com/@ledevedeccorentin/run-a-scalable-event-driven-workflow-with-amazon-eks-keda-and-karpenter-558fce1766ec\" target=\"_blank\" rel=\"noopener noreferrer\">Run a scalable event-driven workflow with Amazon EKS, KEDA, and Karpenter</a></li>\n<li><a href=\"https://aws.amazon.com/fr/blogs/containers/scalable-and-cost-effective-event-driven-workloads-with-keda-and-karpenter-on-amazon-eks/\" target=\"_blank\" rel=\"noopener noreferrer\">Scalable and cost-effective event-driven workloads with KEDA and Karpenter on Amazon EKS</a></li>\n<li><a href=\"https://blog.devgenius.io/run-event-driven-workflows-with-amazon-eks-blueprints-keda-and-karpenter-80e325426b4a\" target=\"_blank\" rel=\"noopener noreferrer\">Run event-driven workflows with Amazon EKS Blueprints, KEDA, and Karpenter</a></li>\n<li><a href=\"https://keda.sh/docs/2.14/concepts/scaling-deployments/\" target=\"_blank\" rel=\"noopener noreferrer\">KEDA Documentation</a></li>\n<li><a href=\"https://aws-ia.github.io/terraform-aws-eks-blueprints/\" target=\"_blank\" rel=\"noopener noreferrer\">Terraform AWS EKS Blueprints</a></li>\n<li><a href=\"https://aws-ia.github.io/terraform-aws-eks-blueprints-addons/main/\" target=\"_blank\" rel=\"noopener noreferrer\">Terraform AWS EKS Blueprints Addons</a></li>\n</ul>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}