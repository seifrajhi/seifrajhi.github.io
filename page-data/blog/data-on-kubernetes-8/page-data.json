{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/data-on-kubernetes-8/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>TiDB: A Cloud-Native Database for hybrid workloads</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>The idea of a Kubernetes-native database like TiDB came up to solve the problems of running traditional databases on Kubernetes. Databases like MySQL and Cassandra have been around for a long time and work well, but they can be hard to manage on Kubernetes.¬†</p>\n<p><a href=\"https://docs.pingcap.com/tidb/stable\" target=\"_blank\" rel=\"noopener noreferrer\">TiDB</a>, created by PingCAP, is built from the start to work well with Kubernetes. It can handle both <a href=\"https://www.fivetran.com/blog/databases-demystified-analytical-vs-transactional\" target=\"_blank\" rel=\"noopener noreferrer\">transactional and analytical workloads</a> without needing a separate ETL process. This makes TiDB a very useful  for managing data on Kubernetes.</p>\n<p>Traditional databases often face challenges when adapted to Kubernetes, such as managing multiple nodes and integrating with Kubernetes storage. TiDB addresses these issues by being designed as a cloud-native database from day one.¬†</p>\n<p>It makes use of Kubernetes resources like Pods, StatefulSets, and PersistentVolumes, and is managed by an operator, making deployment and scaling easier. With TiDB, you get the benefits of both transactional and analytical processing in one system, simplifying your data management tasks.</p>\n<h2 id=\"Ô∏è-history-and-development-oftidb\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-history-and-development-oftidb\" aria-label=\"Ô∏è history and development oftidb permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úçÔ∏è History and development of¬†TiDB</h2>\n<p>TiDB, <a href=\"https://docs.pingcap.com/tidb/stable/overview\" target=\"_blank\" rel=\"noopener noreferrer\">short for \"Titanium Database,\"</a> is an open-source, MySQL-compatible database developed by PingCAP. The development of TiDB began in 2015 with the goal of creating a database that could handle both transactional and analytical workloads efficiently. The inspiration for TiDB came from Google's F1 project, which built on top of Spanner, a globally distributed database.</p>\n<p>TiDB was designed to address the limitations of traditional databases, such as scalability and flexibility, by making use of a cloud-native architecture.</p>\n<h3 id=\"overview-of-pingcap-and-their-role-in-the-development-oftidb\" style=\"position:relative;\"><a href=\"#overview-of-pingcap-and-their-role-in-the-development-oftidb\" aria-label=\"overview of pingcap and their role in the development oftidb permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Overview of PingCAP and their role in the development of¬†TiDB</h3>\n<p>PingCAP, the company behind TiDB, was founded by a group of engineers with extensive experience in database systems and distributed computing. Their mission was to build a database that could meet the demands of modern applications, which require both high availability and the ability to process large volumes of data in real-time.</p>\n<p>PingCAP has been the primary contributor to TiDB, continuously improving its features and performance. They have also fostered a strong community around TiDB, encouraging collaboration and contributions from developers worldwide.</p>\n<h3 id=\"key-features-oftidb\" style=\"position:relative;\"><a href=\"#key-features-oftidb\" aria-label=\"key features oftidb permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Key Features of¬†TiDB</h3>\n<p><strong><em>‚úÖ Hybrid Transactional and Analytical Processing (HTAP):</em></strong></p>\n<p>One of the standout features of TiDB is its support for Hybrid Transactional and Analytical Processing (HTAP). This means TiDB can handle both transactional (OLTP) and analytical (OLAP) workloads without the need for a separate ETL process. TiDB achieves this by using two different storage engines: TiKV for transactional workloads and TiFlash for analytical workloads. This dual-engine approach allows TiDB to provide real-time analytics on fresh transactional data, making it highly efficient for applications that require both types of operations.</p>\n<p><strong><em>‚úÖ MySQL compatibility:</em></strong></p>\n<p>TiDB is fully compatible with MySQL, which means it can be used as a drop-in replacement for MySQL databases. This compatibility extends to MySQL protocols and SQL syntax, making it easy for developers to migrate their applications to TiDB without significant changes. This feature also allows TiDB to integrate seamlessly with existing MySQL tools and ecosystems.</p>\n<p><strong><em>‚úÖ Scalability and flexibility:</em></strong></p>\n<p>TiDB is designed to scale horizontally, which means it can handle increasing amounts of data and traffic by adding more nodes to the cluster. This scalability is achieved through a distributed architecture where data is automatically sharded and balanced across multiple nodes. TiDB's flexibility allows it to run on various environments, including on-premises data centers, public clouds, and Kubernetes clusters. This makes TiDB a versatile solution for different deployment scenarios.</p>\n<p><strong><em>‚úÖ High availability and fault tolerance:</em></strong></p>\n<p>TiDB ensures high availability and fault tolerance through its distributed architecture. Data is replicated across multiple nodes, typically with at least three replicas, to provide redundancy. In the event of a node failure, TiDB can automatically failover to another replica, ensuring continuous availability. The Placement Driver (PD) component of TiDB manages metadata and coordinates data placement, further enhancing the system's resilience and ability to recover from failures.</p>\n<h2 id=\"tidb-architecture\" style=\"position:relative;\"><a href=\"#tidb-architecture\" aria-label=\"tidb architecture permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>TiDB Architecture</h2>\n<p>TiDB's architecture is designed for high performance, scalability, and flexibility by separating compute and storage into distinct, independently scalable components.</p>\n<p>Let's look at each component:</p>\n<p><strong><em>‚ùé TiDB:</em></strong></p>\n<p>Each TiDB instance is a stateless service exposing a MySQL endpoint. It parses SQL requests, uses metadata from the Placement Driver to create execution plans, and queries TiKV and TiFlash nodes. Results are assembled and returned to the client. A proxy typically provides load balancing for the TiDB cluster.</p>\n<p><strong><em>‚ùé TiKV:</em></strong></p>\n<p>TiKV is an open-source, distributed key-value database for transactional workloads. It uses RocksDB and provides a custom Distributed SQL API. TiKV ensures high availability and fault tolerance by storing multiple replicas of data across nodes, supporting automatic failover. It is a CNCF Graduated project recognized for its reliability.</p>\n<p><strong><em>‚ùé TiFlash:</em></strong></p>\n<p>TiFlash is a columnar storage engine for analytical workloads, based on ClickHouse. Data is replicated from TiKV to TiFlash in real-time, enabling analytical queries on fresh transactional data without a separate ETL process. Columnar storage offers significant performance advantages for analytical queries.</p>\n<p><strong><em>‚ùé TiSpark:</em></strong></p>\n<p>TiSpark is a library for Apache Spark, supporting complex analytical (OLAP) queries. It integrates with Spark to ingest data from TiFlash using the Distributed SQL API, leveraging Spark's data processing capabilities for large-scale analytics.</p>\n<p><strong><em>‚ùé Placement Driver (PD):</em></strong></p>\n<p>The PD manages metadata for TiDB, deployed in a cluster of at least three nodes. It uses range-based sharding to divide table keys into regions, assigning them to TiKV nodes. PD monitors data amounts, splitting large regions to scale up and merging smaller ones to scale down.</p>\n<p><strong><em>‚ùé TiDB Operator:</em></strong></p>\n<p>The TiDB Operator automates deployment, management, and scaling of TiDB clusters on Kubernetes. It handles tasks like deployment, scaling, upgrades, monitoring, and backup/restore operations, leveraging Kubernetes resources like Pods, StatefulSets, and PersistentVolumes.</p>\n<h3 id=\"how-tidb-uses-kubernetes-resources\" style=\"position:relative;\"><a href=\"#how-tidb-uses-kubernetes-resources\" aria-label=\"how tidb uses kubernetes resources permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>How TiDB uses Kubernetes resources</h3>\n<p>TiDB integrates seamlessly with Kubernetes, using its resources to manage and scale efficiently:</p>\n<ul>\n<li><strong><em>Pods:</em></strong> Each TiDB instance runs as a stateless service in a Pod, easily scalable based on demand.</li>\n<li><strong><em>StatefulSets:</em></strong> TiKV and TiFlash nodes are deployed using StatefulSets, ensuring stable network identities and persistent storage.</li>\n<li><strong><em>PersistentVolumes (PVs) and PersistentVolumeClaims (PVCs):</em></strong> TiDB uses PVs for durable storage and PVCs for specific storage requests.</li>\n</ul>\n<h3 id=\"role-of-the-tidb-operator-in-managing-the-databases\" style=\"position:relative;\"><a href=\"#role-of-the-tidb-operator-in-managing-the-databases\" aria-label=\"role of the tidb operator in managing the databases permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Role of the TiDB operator in managing the databases:</h3>\n<p>The TiDB Operator simplifies running TiDB on Kubernetes by automating:</p>\n<ul>\n<li><strong><em>Deployment:</em></strong> Automates deployment of TiDB components using Kubernetes resources.</li>\n<li><strong><em>Scaling:</em></strong> Automatically scales TiDB clusters based on resource usage and demand.</li>\n<li><strong>Upgrades:</strong> Manages rolling upgrades, minimizing downtime.</li>\n<li><strong><em>Monitoring and alerts:</em></strong> Integrates with Prometheus and Grafana for metrics and alerts.</li>\n<li><strong><em>Backup and restore:</em></strong> Supports backup and restore operations for data durability and recovery.</li>\n</ul>\n<h2 id=\"deploy-tidb-oneks\" style=\"position:relative;\"><a href=\"#deploy-tidb-oneks\" aria-label=\"deploy tidb oneks permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Deploy TiDB on¬†EKS</h2>\n<p>Deploying TiDB on AWS Elastic Kubernetes Service EKS involves several steps to ensure a smooth and efficient setup. Below is a guide to help you through the process.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 54.11764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACCElEQVR42mNggABGKEYBWlpabMZKxvxAJneWV5b89sLtczOdM5VAfJAcAz7w/z/E0LVrCySXLE/3nzYt0cfSUkkMaCwbzMIzM8+whoaGMtvb17P0VGfKNmZHWu6dWa38ZPdk4f///zOCMEP9qlVsbsmhQh7RHjJATTyrluba795Rsuz4ocqu0FAnaS0ZLSF3Y1vJ+vh4DpCh///XM4EcsKotKXr7xOzFu6cVzF/ZkZwHcRTQwOKdmZU5a5LmFe7InF2yJtXlcGZZ5fq0vJW7sotX7C0tCt1RPLN4U96EvduLpm47kTvNovfMMd0FR44smLF33/IZx/fHzJl6yXvW9DPTlsy7Omn+nIvODKX7dpQXbF03seronr7SXZuc/zMwsJ1c2CZ8cnKF8Ka0NK79WVN43tRv4ztcsVTwf/1+lvKZM/m7V23Q6tu4Wrt+2iKxqRvrg7qWVU7tWl45sW9FtQtD+YHDgZVHT0WUHz4WV777gC7c6QQATM3SfS3B09aX9s7aVtW5bE+rKwMZAGQQOBwnTpzIfnzKybxtrbu6DnQdaTsx9UQyQ+iqVcwwzFAPCXBSDG9dtsi1ctrE7NrZ09KaF861YaAU1PbOcSxvnZJZ3TEzvap3mgXFBnZ2zrJtbpiePqF3UeLEnjmGZBkCzQQM8+fHS5w4kTlrx46ERXv3Ji44fjxrEgDPF+NQiWAspgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\" alt text\" title=\"\" src=\"/static/bfa9f3f9d874c5d9e5e293a116ad888c/c5bb3/tidb-eks-steps.png\" srcset=\"/static/bfa9f3f9d874c5d9e5e293a116ad888c/04472/tidb-eks-steps.png 170w,\n/static/bfa9f3f9d874c5d9e5e293a116ad888c/9f933/tidb-eks-steps.png 340w,\n/static/bfa9f3f9d874c5d9e5e293a116ad888c/c5bb3/tidb-eks-steps.png 680w,\n/static/bfa9f3f9d874c5d9e5e293a116ad888c/b12f7/tidb-eks-steps.png 1020w,\n/static/bfa9f3f9d874c5d9e5e293a116ad888c/b5a09/tidb-eks-steps.png 1360w,\n/static/bfa9f3f9d874c5d9e5e293a116ad888c/65781/tidb-eks-steps.png 2778w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Before deploying a TiDB cluster on EKS, make sure the below requirements are satisfied:</p>\n<ul>\n<li><a href=\"https://helm.sh/docs/intro/install/\" target=\"_blank\" rel=\"noopener noreferrer\">Install Helm 3</a>: used for deploying TiDB Operator.</li>\n<li><a href=\"https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html\" target=\"_blank\" rel=\"noopener noreferrer\">Complete all operations in Getting started with eksctl</a>. The guide includes the steps to install and configure <code class=\"language-text\">awscli</code>, <code class=\"language-text\">eksctl</code> used for creating Kubernetes clusters and <code class=\"language-text\">kubectl</code>.</li>\n</ul>\n<h3 id=\"create-eks-cluster-and-nodepool\" style=\"position:relative;\"><a href=\"#create-eks-cluster-and-nodepool\" aria-label=\"create eks cluster and nodepool permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Create EKS Cluster and Node¬†Pool</h3>\n<p>The Recommended instance types and storage are:\nInstance types: to gain better performance, the following is recommended:</p>\n<ul>\n<li><strong><em>PD nodes:</em></strong> <code class=\"language-text\">c7g.xlarge</code></li>\n<li><strong><em>TiDB nodes:</em></strong> <code class=\"language-text\">c7g.4xlarge</code></li>\n<li><strong><em>TiKV or TiFlash nodes:</em></strong> <code class=\"language-text\">m7g.4xlarge</code></li>\n<li><strong><em>Storage:</em></strong> Because AWS supports the EBS <code class=\"language-text\">gp3</code> volume type, it is recommended to use <code class=\"language-text\">EBS gp3</code>. For gp3 provisioning, the following is recommended:</li>\n<li><strong><em>TiKV:</em></strong> 400 MiB/s, 4000 IOPS</li>\n<li><strong><em>TiFlash:</em></strong> 625 MiB/s, 6000 IOPS</li>\n<li><strong><em>AMI type:</em></strong> <code class=\"language-text\">Amazon Linux 2</code></li>\n</ul>\n<p><strong>Create EKS Cluster:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> eksctl.io/v1alpha5\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> ClusterConfig\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">-</span>eks<span class=\"token punctuation\">-</span>demo\n  <span class=\"token key atrule\">region</span><span class=\"token punctuation\">:</span> eu<span class=\"token punctuation\">-</span>west<span class=\"token punctuation\">-</span><span class=\"token number\">1</span>\n<span class=\"token key atrule\">addons</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> aws<span class=\"token punctuation\">-</span>ebs<span class=\"token punctuation\">-</span>csi<span class=\"token punctuation\">-</span>driver\n\n<span class=\"token key atrule\">nodeGroups</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> admin\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> admin\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">-</span>1a\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1a\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> c5.2xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tidb\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">-</span>1b\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1b\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> c5.2xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tidb\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">-</span>1c\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1c\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> c5.2xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tidb\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tidb<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">-</span>1a\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1a\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> c7g.xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> pd\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">-</span>1b\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1b\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> c7g.xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> pd\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">-</span>1c\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1c\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> c7g.xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> pd\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> pd<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tikv<span class=\"token punctuation\">-</span>1a\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1a\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> r5b.2xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tikv\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tikv<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tikv<span class=\"token punctuation\">-</span>1b\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1b\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> r5b.2xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tikv\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tikv<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> tikv<span class=\"token punctuation\">-</span>1c\n    <span class=\"token key atrule\">desiredCapacity</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">privateNetworking</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">availabilityZones</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"eu-west-1c\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">instanceType</span><span class=\"token punctuation\">:</span> r5b.2xlarge\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tikv\n    <span class=\"token key atrule\">taints</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">dedicated</span><span class=\"token punctuation\">:</span> tikv<span class=\"token punctuation\">:</span>NoSchedule\n    <span class=\"token key atrule\">iam</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">withAddonPolicies</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ebs</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span></code></pre></div>\n<p>By default, only two TiDB nodes are required, so you can set the desiredCapacity of the <code class=\"language-text\">tidb-1b</code> node group to 0. You can scale out this node group any time if necessary.</p>\n<p>Execute the following command to create the cluster:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ eksctl create cluster <span class=\"token parameter variable\">-f</span> cluster.yaml</code></pre></div>\n<h3 id=\"configure-storage\" style=\"position:relative;\"><a href=\"#configure-storage\" aria-label=\"configure storage permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Configure Storage</h3>\n<p>**Deploy AWS EBS CSI Driver: **</p>\n<p>If you are using the gp3 storage type, deploy the AWS EBS Container Storage Interface (CSI) driver.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl patch <span class=\"token parameter variable\">-n</span> kube-system ds ebs-csi-node <span class=\"token parameter variable\">-p</span> <span class=\"token string\">'{\"spec\":{\"template\":{\"spec\":{\"tolerations\":[{\"operator\":\"Exists\"}]}}}}'</span></code></pre></div>\n<p>Expected output:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ daemonset.apps/ebs-csi-node patched</code></pre></div>\n<p><strong>Create StorageClass for gp3:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">kind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: gp3\nprovisioner: ebs.csi.aws.com\nallowVolumeExpansion: <span class=\"token boolean\">true</span>\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  type: gp3\n  fsType: ext4\n  iops: <span class=\"token string\">\"4000\"</span>\n  throughput: <span class=\"token string\">\"400\"</span>\nmountOptions:\n  - nodelalloc\n  - noatime</code></pre></div>\n<h3 id=\"deploy-tidb-operator\" style=\"position:relative;\"><a href=\"#deploy-tidb-operator\" aria-label=\"deploy tidb operator permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Deploy TiDB Operator</h3>\n<p>To deploy TiDB Operator in the EKS cluster, follow the below steps.</p>\n<p><strong>Install TiDB Operator CRDs:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl create <span class=\"token parameter variable\">-f</span> https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/manifests/crd.yaml</code></pre></div>\n<p><strong>Install TiDB Operator:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ helm repo <span class=\"token function\">add</span> pingcap https://charts.pingcap.org/ \n$ kubectl create namespace tidb-admin \n$ helm <span class=\"token function\">install</span> <span class=\"token parameter variable\">--namespace</span> tidb-admin tidb-operator pingcap/tidb-operator <span class=\"token parameter variable\">--version</span> v1.6.0</code></pre></div>\n<p><strong>Confirm TiDB Operator Components:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl get pods <span class=\"token parameter variable\">--namespace</span> tidb-admin <span class=\"token parameter variable\">-l</span> app.kubernetes.io/instance<span class=\"token operator\">=</span>tidb-operator</code></pre></div>\n<h3 id=\"deploy-tidb-cluster-and-monitoring-component\" style=\"position:relative;\"><a href=\"#deploy-tidb-cluster-and-monitoring-component\" aria-label=\"deploy tidb cluster and monitoring component permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Deploy TiDB Cluster and Monitoring Component:</h3>\n<p><strong>Create Namespace:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl create namespace tidb-cluster</code></pre></div>\n<p><strong>Deploy TiDB Cluster and Monitor:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ <span class=\"token function\">curl</span> <span class=\"token parameter variable\">-O</span> https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/examples/aws/tidb-cluster.yaml\n$ <span class=\"token function\">curl</span> <span class=\"token parameter variable\">-O</span> https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/examples/aws/tidb-monitor.yaml\n$ <span class=\"token function\">curl</span> <span class=\"token parameter variable\">-O</span> https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/examples/aws/tidb-dashboard.yaml\n$ kubectl apply <span class=\"token parameter variable\">-f</span> tidb-cluster.yaml <span class=\"token parameter variable\">-n</span> tidb-cluster\n$ kubectl apply <span class=\"token parameter variable\">-f</span> tidb-monitor.yaml <span class=\"token parameter variable\">-n</span> tidb-cluster\n$ kubectl apply <span class=\"token parameter variable\">-f</span> tidb-dashboard.yaml <span class=\"token parameter variable\">-n</span> tidb-cluster</code></pre></div>\n<p><strong>View Cluster Status:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">$ kubectl get pods <span class=\"token parameter variable\">-n</span> tidb-cluster</code></pre></div>\n<p>When all the Pods are in the Running or Ready state, the TiDB cluster is successfully started.</p>\n<p><strong>It's your turn to set up TiDB. Good luck and have fun! üòÑ</strong></p>\n<h2 id=\"-closing-thoughts\" style=\"position:relative;\"><a href=\"#-closing-thoughts\" aria-label=\" closing thoughts permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîö Closing thoughts</h2>\n<p>TiDB offers a modern solution to the challenges of running traditional databases on Kubernetes. By being designed as a cloud-native database from the start, TiDB seamlessly integrates with Kubernetes resources, making deployment and scaling straightforward. It efficiently handles both transactional and analytical workloads, eliminating the need for separate ETL processes.</p>\n<br>\n<br>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <em><strong>Until next time üéâ</strong></em></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìªüß° References:</strong></p>\n<ul>\n<li><a href=\"https://docs.pingcap.com/tidb/stable\" target=\"_blank\" rel=\"noopener noreferrer\">https://docs.pingcap.com/tidb/stable</a></li>\n<li><a href=\"https://docs.pingcap.com/tidb-in-kubernetes/stable/deploy-on-aws-eks\" target=\"_blank\" rel=\"noopener noreferrer\">https://docs.pingcap.com/tidb-in-kubernetes/stable/deploy-on-aws-eks</a></li>\n<li><a href=\"https://docs.pingcap.com/tidb/stable/tidb-in-kubernetes\" target=\"_blank\" rel=\"noopener noreferrer\">https://docs.pingcap.com/tidb/stable/tidb-in-kubernetes</a></li>\n<li><a href=\"https://github.com/pingcap/tidb-operator\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/pingcap/tidb-operator</a></li>\n<li>\n<iframe width=\"100%\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/FqMcwv_FL7Q?rel=0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</li>\n<li><a href=\"https://surrealdb.com/docs/surrealdb/deployment/amazon\" target=\"_blank\" rel=\"noopener noreferrer\">https://surrealdb.com/docs/surrealdb/deployment/amazon</a></li>\n</ul>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":9,"rawMarkdownBody":"> **TiDB: A Cloud-Native Database for hybrid workloads**\n\n## üìö Introduction\n\nThe idea of a Kubernetes-native database like TiDB came up to solve the problems of running traditional databases on Kubernetes. Databases like MySQL and Cassandra have been around for a long time and work well, but they can be hard to manage on Kubernetes.¬†\n\n[TiDB](https://docs.pingcap.com/tidb/stable), created by PingCAP, is built from the start to work well with Kubernetes. It can handle both [transactional and analytical workloads](https://www.fivetran.com/blog/databases-demystified-analytical-vs-transactional) without needing a separate ETL process. This makes TiDB a very useful  for managing data on Kubernetes.\n\nTraditional databases often face challenges when adapted to Kubernetes, such as managing multiple nodes and integrating with Kubernetes storage. TiDB addresses these issues by being designed as a cloud-native database from day one.¬†\n\nIt makes use of Kubernetes resources like Pods, StatefulSets, and PersistentVolumes, and is managed by an operator, making deployment and scaling easier. With TiDB, you get the benefits of both transactional and analytical processing in one system, simplifying your data management tasks.\n\n## ‚úçÔ∏è History and development of¬†TiDB\n\n\nTiDB, [short for \"Titanium Database,\"](https://docs.pingcap.com/tidb/stable/overview) is an open-source, MySQL-compatible database developed by PingCAP. The development of TiDB began in 2015 with the goal of creating a database that could handle both transactional and analytical workloads efficiently. The inspiration for TiDB came from Google's F1 project, which built on top of Spanner, a globally distributed database. \n\nTiDB was designed to address the limitations of traditional databases, such as scalability and flexibility, by making use of a cloud-native architecture.\n\n\n### Overview of PingCAP and their role in the development of¬†TiDB\n\nPingCAP, the company behind TiDB, was founded by a group of engineers with extensive experience in database systems and distributed computing. Their mission was to build a database that could meet the demands of modern applications, which require both high availability and the ability to process large volumes of data in real-time. \n\nPingCAP has been the primary contributor to TiDB, continuously improving its features and performance. They have also fostered a strong community around TiDB, encouraging collaboration and contributions from developers worldwide.\n\n### Key Features of¬†TiDB\n\n**_‚úÖ Hybrid Transactional and Analytical Processing (HTAP):_**\n\nOne of the standout features of TiDB is its support for Hybrid Transactional and Analytical Processing (HTAP). This means TiDB can handle both transactional (OLTP) and analytical (OLAP) workloads without the need for a separate ETL process. TiDB achieves this by using two different storage engines: TiKV for transactional workloads and TiFlash for analytical workloads. This dual-engine approach allows TiDB to provide real-time analytics on fresh transactional data, making it highly efficient for applications that require both types of operations.\n\n**_‚úÖ MySQL compatibility:_**\n\nTiDB is fully compatible with MySQL, which means it can be used as a drop-in replacement for MySQL databases. This compatibility extends to MySQL protocols and SQL syntax, making it easy for developers to migrate their applications to TiDB without significant changes. This feature also allows TiDB to integrate seamlessly with existing MySQL tools and ecosystems.\n\n**_‚úÖ Scalability and flexibility:_**\n\nTiDB is designed to scale horizontally, which means it can handle increasing amounts of data and traffic by adding more nodes to the cluster. This scalability is achieved through a distributed architecture where data is automatically sharded and balanced across multiple nodes. TiDB's flexibility allows it to run on various environments, including on-premises data centers, public clouds, and Kubernetes clusters. This makes TiDB a versatile solution for different deployment scenarios.\n\n**_‚úÖ High availability and fault tolerance:_**\n\nTiDB ensures high availability and fault tolerance through its distributed architecture. Data is replicated across multiple nodes, typically with at least three replicas, to provide redundancy. In the event of a node failure, TiDB can automatically failover to another replica, ensuring continuous availability. The Placement Driver (PD) component of TiDB manages metadata and coordinates data placement, further enhancing the system's resilience and ability to recover from failures.\n\n## TiDB Architecture\n\nTiDB's architecture is designed for high performance, scalability, and flexibility by separating compute and storage into distinct, independently scalable components. \n\nLet's look at each component:\n\n**_‚ùé TiDB:_**\n\nEach TiDB instance is a stateless service exposing a MySQL endpoint. It parses SQL requests, uses metadata from the Placement Driver to create execution plans, and queries TiKV and TiFlash nodes. Results are assembled and returned to the client. A proxy typically provides load balancing for the TiDB cluster.\n\n**_‚ùé TiKV:_**\n\nTiKV is an open-source, distributed key-value database for transactional workloads. It uses RocksDB and provides a custom Distributed SQL API. TiKV ensures high availability and fault tolerance by storing multiple replicas of data across nodes, supporting automatic failover. It is a CNCF Graduated project recognized for its reliability.\n\n**_‚ùé TiFlash:_**\n\nTiFlash is a columnar storage engine for analytical workloads, based on ClickHouse. Data is replicated from TiKV to TiFlash in real-time, enabling analytical queries on fresh transactional data without a separate ETL process. Columnar storage offers significant performance advantages for analytical queries.\n\n**_‚ùé TiSpark:_**\n\nTiSpark is a library for Apache Spark, supporting complex analytical (OLAP) queries. It integrates with Spark to ingest data from TiFlash using the Distributed SQL API, leveraging Spark's data processing capabilities for large-scale analytics.\n\n**_‚ùé Placement Driver (PD):_**\n\nThe PD manages metadata for TiDB, deployed in a cluster of at least three nodes. It uses range-based sharding to divide table keys into regions, assigning them to TiKV nodes. PD monitors data amounts, splitting large regions to scale up and merging smaller ones to scale down.\n\n**_‚ùé TiDB Operator:_**\n\nThe TiDB Operator automates deployment, management, and scaling of TiDB clusters on Kubernetes. It handles tasks like deployment, scaling, upgrades, monitoring, and backup/restore operations, leveraging Kubernetes resources like Pods, StatefulSets, and PersistentVolumes.\n\n\n### How TiDB uses Kubernetes resources\n\nTiDB integrates seamlessly with Kubernetes, using its resources to manage and scale efficiently:\n\n- **_Pods:_** Each TiDB instance runs as a stateless service in a Pod, easily scalable based on demand.\n- **_StatefulSets:_** TiKV and TiFlash nodes are deployed using StatefulSets, ensuring stable network identities and persistent storage.\n- **_PersistentVolumes (PVs) and PersistentVolumeClaims (PVCs):_** TiDB uses PVs for durable storage and PVCs for specific storage requests.\n\n### Role of the TiDB operator in managing the databases:\n\nThe TiDB Operator simplifies running TiDB on Kubernetes by automating:\n\n- **_Deployment:_** Automates deployment of TiDB components using Kubernetes resources.\n- **_Scaling:_** Automatically scales TiDB clusters based on resource usage and demand.\n- **Upgrades:** Manages rolling upgrades, minimizing downtime.\n- **_Monitoring and alerts:_** Integrates with Prometheus and Grafana for metrics and alerts.\n- **_Backup and restore:_** Supports backup and restore operations for data durability and recovery.\n\n## Deploy TiDB on¬†EKS\n\nDeploying TiDB on AWS Elastic Kubernetes Service EKS involves several steps to ensure a smooth and efficient setup. Below is a guide to help you through the process.\n\n\n![ alt text](./tidb-eks-steps.png)\n\nBefore deploying a TiDB cluster on EKS, make sure the below requirements are satisfied:\n\n- [Install Helm 3](https://helm.sh/docs/intro/install/): used for deploying TiDB Operator.\n- [Complete all operations in Getting started with eksctl](https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html). The guide includes the steps to install and configure `awscli`, `eksctl` used for creating Kubernetes clusters and `kubectl`.\n\n\n\n### Create EKS Cluster and Node¬†Pool\n\nThe Recommended instance types and storage are:\nInstance types: to gain better performance, the following is recommended:\n\n- **_PD nodes:_** `c7g.xlarge`\n- **_TiDB nodes:_** `c7g.4xlarge`\n- **_TiKV or TiFlash nodes:_** `m7g.4xlarge`\n- **_Storage:_** Because AWS supports the EBS `gp3` volume type, it is recommended to use `EBS gp3`. For gp3 provisioning, the following is recommended:\n- **_TiKV:_** 400 MiB/s, 4000 IOPS\n- **_TiFlash:_** 625 MiB/s, 6000 IOPS\n- **_AMI type:_** `Amazon Linux 2`\n\n\n**Create EKS Cluster:**\n\n\n```Yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n  name: tidb-eks-demo\n  region: eu-west-1\naddons:\n  - name: aws-ebs-csi-driver\n\nnodeGroups:\n  - name: admin\n    desiredCapacity: 1\n    privateNetworking: true\n    labels:\n      dedicated: admin\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: tidb-1a\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1a\"]\n    instanceType: c5.2xlarge\n    labels:\n      dedicated: tidb\n    taints:\n      dedicated: tidb:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: tidb-1b\n    desiredCapacity: 0\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1b\"]\n    instanceType: c5.2xlarge\n    labels:\n      dedicated: tidb\n    taints:\n      dedicated: tidb:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: tidb-1c\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1c\"]\n    instanceType: c5.2xlarge\n    labels:\n      dedicated: tidb\n    taints:\n      dedicated: tidb:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: pd-1a\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1a\"]\n    instanceType: c7g.xlarge\n    labels:\n      dedicated: pd\n    taints:\n      dedicated: pd:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: pd-1b\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1b\"]\n    instanceType: c7g.xlarge\n    labels:\n      dedicated: pd\n    taints:\n      dedicated: pd:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: pd-1c\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1c\"]\n    instanceType: c7g.xlarge\n    labels:\n      dedicated: pd\n    taints:\n      dedicated: pd:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: tikv-1a\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1a\"]\n    instanceType: r5b.2xlarge\n    labels:\n      dedicated: tikv\n    taints:\n      dedicated: tikv:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: tikv-1b\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1b\"]\n    instanceType: r5b.2xlarge\n    labels:\n      dedicated: tikv\n    taints:\n      dedicated: tikv:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n  - name: tikv-1c\n    desiredCapacity: 1\n    privateNetworking: true\n    availabilityZones: [\"eu-west-1c\"]\n    instanceType: r5b.2xlarge\n    labels:\n      dedicated: tikv\n    taints:\n      dedicated: tikv:NoSchedule\n    iam:\n      withAddonPolicies:\n        ebs: true\n```\n\n\nBy default, only two TiDB nodes are required, so you can set the desiredCapacity of the `tidb-1b` node group to 0. You can scale out this node group any time if necessary.\n\nExecute the following command to create the cluster:\n\n```Shell\n$ eksctl create cluster -f cluster.yaml\n```\n\n### Configure Storage\n\n**Deploy AWS EBS CSI Driver: **\n\nIf you are using the gp3 storage type, deploy the AWS EBS Container Storage Interface (CSI) driver.\n\n```Shell\n$ kubectl patch -n kube-system ds ebs-csi-node -p '{\"spec\":{\"template\":{\"spec\":{\"tolerations\":[{\"operator\":\"Exists\"}]}}}}'\n```\n\nExpected output:\n```Shell\n$ daemonset.apps/ebs-csi-node patched\n```\n\n**Create StorageClass for gp3:**\n\n```Shell\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: gp3\nprovisioner: ebs.csi.aws.com\nallowVolumeExpansion: true\nvolumeBindingMode: WaitForFirstConsumer\nparameters:\n  type: gp3\n  fsType: ext4\n  iops: \"4000\"\n  throughput: \"400\"\nmountOptions:\n  - nodelalloc\n  - noatime\n```\n\n### Deploy TiDB Operator\n\nTo deploy TiDB Operator in the EKS cluster, follow the below steps.\n\n**Install TiDB Operator CRDs:**\n\n```Shell\n$ kubectl create -f https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/manifests/crd.yaml\n```\n\n**Install TiDB Operator:**\n\n```Shell\n$ helm repo add pingcap https://charts.pingcap.org/ \n$ kubectl create namespace tidb-admin \n$ helm install --namespace tidb-admin tidb-operator pingcap/tidb-operator --version v1.6.0\n```\n\n**Confirm TiDB Operator Components:**\n```Shell\n$ kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator\n```\n\n### Deploy TiDB Cluster and Monitoring Component:\n\n**Create Namespace:**\n```Shell\n$ kubectl create namespace tidb-cluster\n```\n\n**Deploy TiDB Cluster and Monitor:**\n\n```Shell\n$ curl -O https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/examples/aws/tidb-cluster.yaml\n$ curl -O https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/examples/aws/tidb-monitor.yaml\n$ curl -O https://raw.githubusercontent.com/pingcap/tidb-operator/v1.6.0/examples/aws/tidb-dashboard.yaml\n$ kubectl apply -f tidb-cluster.yaml -n tidb-cluster\n$ kubectl apply -f tidb-monitor.yaml -n tidb-cluster\n$ kubectl apply -f tidb-dashboard.yaml -n tidb-cluster\n```\n\n**View Cluster Status:**\n\n```Shell\n$ kubectl get pods -n tidb-cluster\n```\n\nWhen all the Pods are in the Running or Ready state, the TiDB cluster is successfully started.\n\n**It's your turn to set up TiDB. Good luck and have fun! üòÑ**\n\n## üîö Closing thoughts\n\n\nTiDB offers a modern solution to the challenges of running traditional databases on Kubernetes. By being designed as a cloud-native database from the start, TiDB seamlessly integrates with Kubernetes resources, making deployment and scaling straightforward. It efficiently handles both transactional and analytical workloads, eliminating the need for separate ETL processes.\n\n<br>\n<br>\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  _**Until next time üéâ**_\n\n\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìªüß° References:**\n\n- https://docs.pingcap.com/tidb/stable\n- https://docs.pingcap.com/tidb-in-kubernetes/stable/deploy-on-aws-eks\n- https://docs.pingcap.com/tidb/stable/tidb-in-kubernetes\n- https://github.com/pingcap/tidb-operator\n- https://www.youtube.com/watch?v=FqMcwv_FL7Q\n- https://surrealdb.com/docs/surrealdb/deployment/amazon\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1494},"frontmatter":{"id":"54e37b96a691ae61cbad4dca","path":"/blog/data-on-kubernetes-8/","humanDate":"Sep 27, 2024","fullDate":"2024-09-27","title":"Data on Kubernetes: Part 8‚Ää-‚ÄäExploring TiDB, a cloud-native database","keywords":["Open source","Kubernetes","TiDB","AWS EKS","Cloud Native"],"excerpt":"EKS, Databases, Cloud Native DB","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAACyklEQVR42iWSy29SeRTHb2LVCgIt9CK1QIEWuFyEQguUx/DoBdoCraFPhbRWo1VnatWNr5iYmBg3JrMw7mYxySxNJul2kokxcWFm7cS92/kHZvnx3Ovi5Dx/3/M95/yUfu8GhcV15uc7aNoSsViNZLJFpbJBKtWmWLzM3Nwy6XTb8hcWOui6gdebZdQWZSl/mZO/PvPbx6+cOxtByWRW2dq6Q79/i05nn7W163S719jYOLTsnZ27DAZHVsyU7e07HB4+IRwuY7fHcTo04nqL91/+49nvn1DKpb48+hnDuEqrNRTQa/j9eVZX92m3hwJ2j17vQOyBVVerbdNo7HLz5iOOj19YwGdGQuiZNd78+S+KGchmOzSbV8nn12SkLpFIhVyuJ02usLtrgmxRKKxbrLvdAxm5Sb2+IwQGJBJLOJwJnPYo9/YfophgJhOz+3B4bI2zuXmblZU9axX7UmSCmuvY27tvjfz48WuLucnS1G53ivHxS/in8igXL+aYni4x5S8QCCwSCoktCb/409NFsSUfXJRcnqClC5Y246qaluPM4R5P4nDEsAlLxSzIpOtosQq60E8mDS4lqiS0qly3jZao449WiGs1+QFVubQh0pS1lAVEY2QkyKnTYWlQYXIyh+L2zKFqt3AHethss5x36FzQDvAFNjlnm8Elj3qBInEBCIVLUhPFLnLelUSdaVJtDLix84CmcSRre4XicSeZMX7Fnz5kdmqGUCBD+KeXhNK/4HLpBHxZnme7NMp9ao1tJjwpnM6YjF5mef2Ib3//AycfeP/uhGCkjRJJLON2xVC9aXyqjlctoPrqlnjUItFYA19IZHJRxizJ/gqcHY3QMh7S6rxkuPWU10/e0jBu4w6WUK7/8T/Rpac47LO4xlIWK5cz/kNcGmNjGSYmqnLFedmZfGSnJnW6+Aty1RXGvXWUUyFG7TE8kzm+A3f2c8zonK4nAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/3f9ae8abfe1eb936c594e896bdbf5667/25d3a/eks-tidb.png","srcSet":"/static/3f9ae8abfe1eb936c594e896bdbf5667/9ae6a/eks-tidb.png 750w,\n/static/3f9ae8abfe1eb936c594e896bdbf5667/be7fa/eks-tidb.png 1080w,\n/static/3f9ae8abfe1eb936c594e896bdbf5667/ee3cf/eks-tidb.png 1366w,\n/static/3f9ae8abfe1eb936c594e896bdbf5667/25d3a/eks-tidb.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/3f9ae8abfe1eb936c594e896bdbf5667/8d8ff/eks-tidb.webp 750w,\n/static/3f9ae8abfe1eb936c594e896bdbf5667/eedfa/eks-tidb.webp 1080w,\n/static/3f9ae8abfe1eb936c594e896bdbf5667/e048d/eks-tidb.webp 1366w,\n/static/3f9ae8abfe1eb936c594e896bdbf5667/f594a/eks-tidb.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5593750000000001}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/data-on-kubernetes/","title":"Managing Data on Kubernetes","date":"2024-09-27 20:06:00"},"excerpt":"From databases to Big data: how k8s handles stateful workloads üìó\nThis is a blog series about Data on Kubernetes DoK üî• I have been inspired‚Ä¶","html":"<blockquote>\n<p><strong>From databases to Big data: how k8s handles stateful workloads üìó</strong>\nThis is a blog series about Data on Kubernetes DoK üî•</p>\n</blockquote>\n<p>I have been inspired by the work done by <a href=\"https://dok.community/\" target=\"_blank\" rel=\"noopener noreferrer\">Data On Kubernetes community DOKC</a>.</p>\n<p><strong>üëâ Few weeks ago, I have posted on reddit to ask on some feedback on <a href=\"https://www.reddit.com/r/kubernetes/comments/1dp062w/are_you_running_stateful_data_workloads_or/?sort=old\" target=\"_blank\" rel=\"noopener noreferrer\">running stateful data workloads or running databases on Kubernetes</a> and I got a lot of interesting answers.</strong></p>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>Kubernetes, the popular container management system, was initially designed for stateless applications. But guess what? It's not just for simple apps anymore! k8s has become a great data orchestrator.</p>\n<p>Organizations now recognize data as a valuable asset, and Kubernetes provides an ideal framework for managing data workloads. It handles everything from processing massive datasets to running machine learning pipelines.</p>\n<p>Key features include seamless deployment of stateful applications using StatefulSets and Persistent Volumes, data pipelines as code with tools like Airflow, and service discovery for databases like PostgreSQL, Elasticsearch, and Cassandra.</p>\n<br>\n<br>\n<div style=\"width:100%;height:0;padding-bottom:72%;position:relative;\"><iframe src=\"https://giphy.com/embed/xT9C25UNTwfZuk85WP\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe></div>\n<h2 id=\"stateless-vs-stateful-workloads-in-a-containerized-ecosystem\" style=\"position:relative;\"><a href=\"#stateless-vs-stateful-workloads-in-a-containerized-ecosystem\" aria-label=\"stateless vs stateful workloads in a containerized ecosystem permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Stateless vs. Stateful workloads in a containerized ecosystem</h2>\n<p>When it comes to deploying applications in a containerized environment, understanding the distinction between stateless and stateful workloads is crucial.</p>\n<p>Cloud native apps and specifically containers, often associated with the \"cattle vs. pets\" analogy.</p>\n<h3 id=\"stateless-applications-and-containers\" style=\"position:relative;\"><a href=\"#stateless-applications-and-containers\" aria-label=\"stateless applications and containers permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Stateless Applications and Containers</h3>\n<ul>\n<li><strong>Cattle mindset</strong>: Stateless apps, like cattle, are designed to be disposable and replaceable. They don't carry any emotional attachment; if one fails, you spin up another without hesitation.</li>\n<li><strong>Container alignment</strong>: Containers, with their lightweight and immutable nature, align perfectly with stateless workloads. Each container instance is identical, and orchestration platforms like Kubernetes can easily scale them horizontally.</li>\n<li><strong>Microservices harmony</strong>: Stateless microservices, encapsulated within containers, thrive in this environment. They handle individual requests, perform computations, and communicate with other services via APIs.</li>\n</ul>\n<p>Initially made for stateless applications, Kubernetes excels at managing containerized microservices. Features like auto-scaling, rolling updates, and service discovery simplify the deployment and maintenance of stateless components.</p>\n<h3 id=\"stateful-applications-and-containers\" style=\"position:relative;\"><a href=\"#stateful-applications-and-containers\" aria-label=\"stateful applications and containers permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Stateful Applications and Containers</h3>\n<ul>\n<li><strong>Pets nurturing</strong>: Stateful applications, akin to pets, have unique identities and require special care. Think of your beloved pet dog; it's not interchangeable like cattle.</li>\n<li><strong>Container challenges</strong>: Containers, while great, face challenges when hosting stateful workloads. Data persistence, ordering, and identity become big concerns.</li>\n<li><strong>Managing complexity</strong>: Handling databases, caching systems, and file servers within containers demands thoughtful design. Persistent storage, data consistency, and failover strategies must be carefully orchestrated.</li>\n<li><strong>Kubernetes adaptation</strong>: Kubernetes evolved to accommodate stateful applications. StatefulSets provide stable network identities, and Persistent Volumes (PVs) ensure data survives container restarts.</li>\n<li><strong>Pet-Like attention</strong>: However, treating stateful containers like cattle is a recipe for disaster. Instead, they need the nurturing attention reserved for pets.</li>\n</ul>\n<h2 id=\"considerations-and-challenges-of-managing-stateful-workloads-in-kubernetes\" style=\"position:relative;\"><a href=\"#considerations-and-challenges-of-managing-stateful-workloads-in-kubernetes\" aria-label=\"considerations and challenges of managing stateful workloads in kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Considerations and challenges of managing Stateful workloads in Kubernetes</h2>\n<p>When managing stateful workloads in Kubernetes, a lot of challenges arise, especially when compared to stateless applications. Let's delve into some of these considerations:</p>\n<h3 id=\"persistent-data-management\" style=\"position:relative;\"><a href=\"#persistent-data-management\" aria-label=\"persistent data management permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Persistent Data Management</h3>\n<ul>\n<li>Stateful applications, such as databases or DevOps systems, rely on persistent storage for data persistence.</li>\n<li>Kubernetes provides solutions like Persistent Volumes (PVs) and StatefulSets, but ensuring fault tolerance requires applications to checkpoint their in-memory state.</li>\n<li>Ensuring reliable data persistence is really important for stateful workloads.</li>\n</ul>\n<h3 id=\"scaling-and-updating-challenges\" style=\"position:relative;\"><a href=\"#scaling-and-updating-challenges\" aria-label=\"scaling and updating challenges permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Scaling and Updating Challenges</h3>\n<ul>\n<li>Scaling or updating stateful applications is complex.</li>\n<li>Autoscalers need to participate in state management to handle scaling activities effectively.</li>\n</ul>\n<h3 id=\"reliability-durability-dichotomy\" style=\"position:relative;\"><a href=\"#reliability-durability-dichotomy\" aria-label=\"reliability durability dichotomy permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Reliability-Durability Dichotomy</h3>\n<ul>\n<li>Kubernetes maintains the durability of stateful applications by ensuring access to Persistent Volumes during disruptions.</li>\n<li>However, achieving high-nines availability and consistent performance remains a challenge.</li>\n<li>Traditional failover and recovery strategies may not fully address the sensitivity of stateful applications to disruptions.</li>\n</ul>\n<h2 id=\"databases-on-k8s-success-stories\" style=\"position:relative;\"><a href=\"#databases-on-k8s-success-stories\" aria-label=\"databases on k8s success stories permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Databases on k8s; success stories</h2>\n<p>To see if running DBs on k8s is a good idea or not let us explore some success stories of running stateful workloads and databases in k8s.</p>\n<h3 id=\"Ô∏è-yellowbrick-data\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-yellowbrick-data\" aria-label=\"Ô∏è yellowbrick data permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úîÔ∏è Yellowbrick Data</h3>\n<p>Yellowbrick, an MPP (Massively Parallel Processing) database, stands out as a success story on Kubernetes. Last year, they presented a VLDB (Very Large Databases) paper that shed light on their architecture. What sets Yellowbrick apart is its approach to separating compute and storage components. By doing so, <a href=\"https://yellowbrick.com/blog/cloud/dbas-face-up-to-kubernetes/\" target=\"_blank\" rel=\"noopener noreferrer\">Yellowbrick thrives in a Kubernetes environment</a>, demonstrating that stateful workloads can indeed succeed in this dynamic platform.</p>\n<h3 id=\"Ô∏è-ibm-db2-warehouse-and-ibm-netezza\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-ibm-db2-warehouse-and-ibm-netezza\" aria-label=\"Ô∏è ibm db2 warehouse and ibm netezza permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚úîÔ∏è IBM DB2 Warehouse and IBM Netezza</h3>\n<p>IBM's offerings, including DB2 Warehouse and Netezza, are robust MPP databases. <a href=\"https://www.ibm.com/docs/en/db2-warehouse?topic=warehouse-redeploying-using-kubernetes\" target=\"_blank\" rel=\"noopener noreferrer\">Their adoption of Kubernetes showcases the feasibility</a> of running large-scale workloads. The key to their success lies in Kubernetes operators. But what exactly are these operators?</p>\n<h3 id=\"kubernetes-operators\" style=\"position:relative;\"><a href=\"#kubernetes-operators\" aria-label=\"kubernetes operators permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Kubernetes Operators</h3>\n<p>Operators are programmable extensions. They perform operations that Kubernetes cannot handle natively. Think of them as intelligent, dynamic managers that extend the functionality of the Kubernetes API. Their real impact lies in managing stateful workloads.</p>\n<h2 id=\"benefits-of-running-databases-on-kubernetes\" style=\"position:relative;\"><a href=\"#benefits-of-running-databases-on-kubernetes\" aria-label=\"benefits of running databases on kubernetes permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Benefits of Running Databases on Kubernetes</h2>\n<ul>\n<li><strong>Cost Efficiency</strong>: <a href=\"https://thenewstack.io/stateful-workloads-on-kubernetes-are-a-thing-but-there-is-a-twist/\" target=\"_blank\" rel=\"noopener noreferrer\">Kubernetes leverages cost-effective cloud resources, resulting in significant savings compared to public DBaaS solutions</a>.</li>\n<li><strong>Scalability</strong>: Kubernetes enables easy scaling of database resources based on demand.</li>\n<li><strong>Automation</strong>: Operators handle tasks like backups, scaling, and tuning, streamlining database management.</li>\n</ul>\n<h2 id=\"kubernetes-for-data-science-and-machine-learning\" style=\"position:relative;\"><a href=\"#kubernetes-for-data-science-and-machine-learning\" aria-label=\"kubernetes for data science and machine learning permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Kubernetes for data science and Machine Learning</h2>\n<p><a href=\"https://www.xenonstack.com/blog/generative-ai-platform\" target=\"_blank\" rel=\"noopener noreferrer\">source</a></p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 35.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABWElEQVR42m2R3U7bQBCFefC+Ag9QiasipF5WqDeV4AYVFVVA0iYS+QGcmOD4J5vYa8f2rr37dQlQgshczazOfJpzdk83lqaBpoXWGE46GQc/BOFSAQatayptSfM1rS5xUqw1PFWljduzbNceG8HzkJcN+99WfDrKOO1KOl7B9+uMabIiFDkyS4n9KbGQ6LZxekVR6o/AN6jl16Di6GxNmkq+/hR8Pu7T9X9zl1Qk3pjx6SG9ySPJas39xKc39EkLhTH2PfANbDfWy6rED+cskzn+LGA4E8zDBVfTCVfejCCRdLt/ufgzIhAFSpvdwLquCR78zYWj2wnX/TGdge8yLQiihN7NPf3RlCzPiUTGQ7REG/vR8muQOhoSn3/BuUCsMsKFy22Z07glpTW1yy7wYmQsXc/mMjm6pE6z3cA2j9CLwf83u/2JL71KFVqq56HVrL1HxK3ANop/9Y8VNN/y1esAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Machine Learning on Kubernetes\" title=\"\" src=\"/static/407d34d7bbeaa8c4400a25e3414ea22d/c5bb3/ml-ai-k8s.png\" srcset=\"/static/407d34d7bbeaa8c4400a25e3414ea22d/04472/ml-ai-k8s.png 170w,\n/static/407d34d7bbeaa8c4400a25e3414ea22d/9f933/ml-ai-k8s.png 340w,\n/static/407d34d7bbeaa8c4400a25e3414ea22d/c5bb3/ml-ai-k8s.png 680w,\n/static/407d34d7bbeaa8c4400a25e3414ea22d/159fb/ml-ai-k8s.png 1019w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\"><a href=\"https://www.xenonstack.com/blog/generative-ai-platform\">Machine Learning on Kubernetes</a></div>\n<p>Kubernetes different capabilities address the demands of ML workloads, providing an orchestration framework that transcends mere container management.</p>\n<h3 id=\"Ô∏è-simplified-infrastructure-and-clear-configuration\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-simplified-infrastructure-and-clear-configuration\" aria-label=\"Ô∏è simplified infrastructure and clear configuration permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚≠êÔ∏è Simplified infrastructure and clear configuration</h3>\n<ul>\n<li>Kubernetes simplifies the underlying infrastructure complexities: Data scientists can focus on their models, algorithms, and insights without worrying about hardware details or network intricacies.</li>\n<li>Declarative configurations allow you to express your application's desired state: Kubernetes automatically configures the environment to match that state, consolidating workload management and ensuring consistency across deployments.</li>\n</ul>\n<h3 id=\"Ô∏è-scalability-and-efficient-resource-usage\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-scalability-and-efficient-resource-usage\" aria-label=\"Ô∏è scalability and efficient resource usage permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚≠êÔ∏è Scalability and efficient resource usage</h3>\n<ul>\n<li>Scalability is at the heart of Kubernetes: Whether you're handling a single data science workload or orchestrating a complex ML pipeline, Kubernetes adapts ideally. It scales resources up or down based on demand.</li>\n<li>Managing large datasets, memory-intensive computations, and storage requirements becomes easy: Kubernetes ensures that your applications have the necessary resources, optimizing performance and responsiveness.</li>\n</ul>\n<h3 id=\"Ô∏è-more-than-container-orchestration\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-more-than-container-orchestration\" aria-label=\"Ô∏è more than container orchestration permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚≠êÔ∏è More Than Container Orchestration</h3>\n<ul>\n<li>Kubernetes excels in container orchestration: It manages container lifecycles, dependencies, and services. But it doesn't stop there‚Ää-‚Ääit also handles networking, load balancing, and service discovery.</li>\n<li>With Kubernetes, you can define intricate workflows, ensuring smooth data pipelines: It takes care of service discovery, DNS resolution, and load balancing while maintaining high availability.</li>\n</ul>\n<h2 id=\"Ô∏è-advantages-for-machine-learning\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-advantages-for-machine-learning\" aria-label=\"Ô∏è advantages for machine learning permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚≠êÔ∏è Advantages for Machine Learning</h2>\n<h3 id=\"gpu-support\" style=\"position:relative;\"><a href=\"#gpu-support\" aria-label=\"gpu support permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>GPU Support</h3>\n<p>Machine learning relies on computational power. Kubernetes embraces GPUs, accelerating model training and inference. Whether fine-tuning neural networks or running large-scale simulations, GPUs are a game-changer.</p>\n<h3 id=\"tool-integration\" style=\"position:relative;\"><a href=\"#tool-integration\" aria-label=\"tool integration permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Tool Integration</h3>\n<p>Kubernetes ideally integrates with popular ML tools like Spark, TensorFlow, Jupyter Notebooks, and Kubeflow. You can build, test, and deploy models within the same orchestrated environment.</p>\n<h3 id=\"automated-workflows\" style=\"position:relative;\"><a href=\"#automated-workflows\" aria-label=\"automated workflows permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Automated Workflows</h3>\n<p>Managing ML workflows involves data pre-processing, model training, and deployment. Kubernetes streamlines these tasks. Imagine automating data transformations, hyperparameter tuning, and model versioning‚Ää‚Äî‚Ääall orchestrated through Kubernetes.</p>\n<h2 id=\"Ô∏è-scalable-models-and-improved-accuracy\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-scalable-models-and-improved-accuracy\" aria-label=\"Ô∏è scalable models and improved accuracy permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚≠êÔ∏è Scalable Models and Improved Accuracy</h2>\n<p>Kubernetes scales well for machine learning models. Whether training deep learning models on massive datasets or deploying ensemble models, Kubernetes adapts. It ensures models scale horizontally to meet performance demands.</p>\n<p>By efficiently processing extensive datasets, Kubernetes contributes to model accuracy. Whether predicting customer churn, analyzing medical images, or recommending personalized content, Kubernetes provides the computational power.</p>\n<h2 id=\"-closing-thoughts\" style=\"position:relative;\"><a href=\"#-closing-thoughts\" aria-label=\" closing thoughts permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîö Closing thoughts</h2>\n<p>Kubernetes provides great solutions for managing stateful workloads, including databases and big data applications. Its features, such as scalability, fault tolerance, and efficient resource management, make it an ideal platform for handling data-intensive tasks.</p>\n<p>Stay tuned for next blogs in this series üéâ</p>\n<br>\n<br>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <em><strong>Until next time üéâ</strong></em></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìªüß° References:</strong></p>\n<ul>\n<li><a href=\"https://dok.community/blog/the-future-of-data-on-kubernetes/\" target=\"_blank\" rel=\"noopener noreferrer\">The future of Data on Kubernetes‚Ää-‚ÄäData on Kubernetes Community</a></li>\n<li><a href=\"https://dok.community/blog/the-future-of-data-on-kubernetes/\" target=\"_blank\" rel=\"noopener noreferrer\">Are you running stateful data workloads or running databases on Kubernetes?¬†: r/kubernetes (reddit.com)</a></li>\n<li><a href=\"http://www.youtube.com/watch?v=99uSJXkKpeI\" target=\"_blank\" rel=\"noopener noreferrer\">www.youtube.com/watch?v=99uSJXkKpeI</a></li>\n</ul>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/opentelemtry-sdk/","title":"Get Started with OpenTelemetry SDKs","date":"2024-09-26 13:06:00"},"excerpt":"OpenTelemetry is an observability framework and an active CNCF project that provides a vendor-neutral and tool-agnostic way to collect‚Ä¶","html":"<p>OpenTelemetry is an observability framework and an active <a href=\"https://www.cncf.io/projects/opentelemetry/\" target=\"_blank\" rel=\"noopener noreferrer\">CNCF project</a> that provides a vendor-neutral and tool-agnostic way to collect observability signals across your heterogeneous system.</p>\n<p>In this blog post series, we will dig into two big questions:</p>\n<ul>\n<li>\n<p>how OpenTelemetry instrumentation works on the application side taking <a href=\"https://github.com/open-telemetry/opentelemetry-python/\" target=\"_blank\" rel=\"noopener noreferrer\">Python's SDK</a> as an example. We will touch traces, metrics, logs and context propagation across services.</p>\n</li>\n<li>\n<p>how OpenTelemetry Collector works under the hood and some of the interesting engineering decisions made there.</p>\n</li>\n</ul>\n<p>Gotta be fun üôå</p>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìö Introduction</h2>\n<p>With the rise of the open source community, people and organizations don‚Äôt really want to invest in proprietary protocols and standards anymore. Instead, it's mainstream to pick a widely-recognized open source project as a basis to build on top of it.</p>\n<p>In the observability domain, there are enough open source protocols that cover some of the three key pillars:</p>\n<ul>\n<li><code class=\"language-text\">Logs</code> - stdout and stderr streams your services or application outputs while running in the container.</li>\n<li><code class=\"language-text\">Metrics</code> - aggregations of some measurements over a period of time</li>\n<li><code class=\"language-text\">Traces</code> - a visualization of the steps or the execution path that your workflow passed</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 48.8235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB9klEQVR42n2T60/TYBTG+/9/VIOGywZsEuIWxcRbDH5QAgrtCutAZGxu7NbL2o6NAVvb9edphxFjpOmTnvO8z3nek5xThQce0zSp1+vYtk21WsX3/ZSP4/i/NcrV1RXD0egvjAQJ73memFrYjoMlpn3XTfnhcPRPzXA4ZDweo8h98s7E+w7xHLMoSlohPb+HhI9nf3S/Ec8iBoMByumFjVaz0M57KfSfDpWmQ6PrSG5SqpmoZ13RmGnetlyMZlJjo4peFU6V2GhYDHwPJb/b4Jk+IVOekjEClssBmX2HdwdVHn+7ZPUkEj4kexzyZH/Etl4ju9dhyYhYMaZkKyGLRyH5A5O+1UMpaF3yZ7Ci+ix86bBRhee6zwftXMQBi7sWj7brZLQBq2L66bDGhmqRO415utNl4XOLNeFfVXw8x0LZFMPsD1Lxkj4mdy6x5vJer7MshmvHASuHN6x/jyQP+SgdrovhulycTTo0JqxKQ4Wyi2uZKG9LDV4cOmwZHlsVj+JRn5dai51ynbW9NsWyJ+cuhSOX3H6PrycNXqsNCrpNUTcplkw21R5vSk3cvi1TlklGYSDTC1PM44iZTC0MpoSSpwjm32TCiW5ye8PtzfUc12OmkwmDy8v5Ho7udu8+kr16iDdlLy9aHZoXbdqdLq12J/0BfgFNzNtlsX4T7wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"The Three Pillars of Observability\" title=\"\" src=\"/static/7928c038b5d0d9bbe6a835771d957b9d/c5bb3/observability-pillars.png\" srcset=\"/static/7928c038b5d0d9bbe6a835771d957b9d/04472/observability-pillars.png 170w,\n/static/7928c038b5d0d9bbe6a835771d957b9d/9f933/observability-pillars.png 340w,\n/static/7928c038b5d0d9bbe6a835771d957b9d/c5bb3/observability-pillars.png 680w,\n/static/7928c038b5d0d9bbe6a835771d957b9d/b12f7/observability-pillars.png 1020w,\n/static/7928c038b5d0d9bbe6a835771d957b9d/b5a09/observability-pillars.png 1360w,\n/static/7928c038b5d0d9bbe6a835771d957b9d/10d53/observability-pillars.png 1724w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">The Three Pillars of Observability</div>\n<p>When you think about metrics, <a href=\"https://prometheus.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Prometheus</a> and <a href=\"https://github.com/statsd/statsd\" target=\"_blank\" rel=\"noopener noreferrer\">statsd</a> may come to your mind.\nOn the traces side, there are <a href=\"https://www.jaegertracing.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Jaeger</a> and <a href=\"https://zipkin.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Zipkin</a>.\nThere are also various beats that could scrap your logs like <a href=\"https://www.fluentd.org/\" target=\"_blank\" rel=\"noopener noreferrer\">fluentd</a> or <a href=\"https://grafana.com/oss/loki/\" target=\"_blank\" rel=\"noopener noreferrer\">Grafana Loki</a>.</p>\n<p>Now if you want to cover all three pillars, you need to pick a combination of collectors/protocols to cover each one (well, some are capable of covering a few pillars).</p>\n<p>However, there are still a few problems left:</p>\n<ul>\n<li>even though the protocols are open source, they may still tightly connect your application to the underlying collector or storage, so it won't be that easy to switch gears and use something else</li>\n<li>we have divided observability into three pieces, but in reality, they are three different signals or points of view on the application work, so we may get the whole picture and max value out of them when they are well connected and correlated for us</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 57.64705882352942%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABtElEQVR42pVS20rDQBDN//+B4IsPvvjoBbxgBfFBBCuKii2NuW6STdL0fknT9rhnJEVsfTAwzO7MzpkzJ2Nhx7dYLGDbNlQUwfU8dDo2HNc15sH+dNDtduXder3eqrV2Ac7nc+gklvNqtcRk2EM5n8p9Mpkgy7L/Aa6qEtcPrzh7K3D3rnDxEuHy2cfNe4KTRxeB7/8P0CDi9LaJvUYbx/cfOLh6wtHtKw4bL9g/byIyUvwJyOBP+x5zhdBoFwcuch3D+2xDRwGKNIHyHQyHww3gb9tiSLDRaISqqjYx6sZ4/U2nU7FdLC0mWDCbzcRrrYUBzzTm8zyXJjyPx2PxRVGIsa7GYM7iijDQ7/fNenQ2bJbLpcTLspQVYjHvzHEL2MBxHLRarU0TErGUUpIksyQxGpk7m3Bk3/xN7hw9c57RlR/XhlbHOAHfEMciEHXo9XrCikmyImiapjISHzJGEDJkEzZkjKxYRxxOabELC8mMZ8dxDVglBRwpCENhEQSBsGBzjkgAyjAYDMSTiGhIzRiksUMQKug0Q25YJImGb+4qihGqSHxmChOdomtAyK6uJQ6ZfwFLiZVZzB6zxwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Observability signals are unconnected\" title=\"\" src=\"/static/377a9f18c7ec9379f33c422d2486b7a1/c5bb3/observability-signals-unconnected.png\" srcset=\"/static/377a9f18c7ec9379f33c422d2486b7a1/04472/observability-signals-unconnected.png 170w,\n/static/377a9f18c7ec9379f33c422d2486b7a1/9f933/observability-signals-unconnected.png 340w,\n/static/377a9f18c7ec9379f33c422d2486b7a1/c5bb3/observability-signals-unconnected.png 680w,\n/static/377a9f18c7ec9379f33c422d2486b7a1/b12f7/observability-signals-unconnected.png 1020w,\n/static/377a9f18c7ec9379f33c422d2486b7a1/b5a09/observability-signals-unconnected.png 1360w,\n/static/377a9f18c7ec9379f33c422d2486b7a1/b5c8e/observability-signals-unconnected.png 2194w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">The observability signals are unconnected when you use separate highly specialized protocols</div>\n<p>To sum it up, we want to have:</p>\n<ul>\n<li>one open source vendor-lock-free protocol to rule all observability signals</li>\n<li>a stable abstraction for us for the underlying observability storage(s) without a need to migrate our service every time that storage changes</li>\n<li>a coverage of popular programming languages, not to be limited in what our tech stack looks like</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 84.70588235294117%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAACVUlEQVR42pVT2W4aQRDc33fecjzkB5AQElaQiSxAIQ+RsbFBIWw4A16OZbkW9mI5FypTg0HkQAkjtfaYrprqmm4FZ9ZyuUSz2YRhGOj1ejJ+NBpoPj+jWq1iu93+FaecI/R9H/1+X74v5nO4joXVaiW/Sb7ZbC4nNIweRraPUmsAtamj3Blh4voYj0aXE87nC7SfG7h+0nD1sYKr6ye8uq0hVdAw6HUFYXAZIRUMBgN09B7qTQ1quYpyTXiotdDtdrHb7S4jlEuCtgiCFfS2Bt+1MZ+50o5zSznLI9bQnOL2m4EPouzQZxU3X3V8+t4Xdsz3ef9PuE9tdAy8ffTw5t7Guwcbr+8dvH8wYdv2L3n/JAyCQIbluChoY3xRNSQfK8jW+yi2Rliv10fC05CEf/wU4bPvPA+WZcH3HOnbzHOxWS+x8D24rotWuyuiI3p1AF30pfWiWjmVfloCJ4VATgQVeeKAw+0TPJlMRKOvEYhv+XyZHIV+LBYLafSBhO0yHA4xm80kkWmacmq4x3xODIP/HceRWOYSr7CsUqmEu7s7xGIxxONx5PN5eRr7LZlMIhKJIBqNIpVKyTmmYnqcyWQQCoUQDoeRSCSQTqehcPjr9bqMQqGAdrstNwkYiRHjgVTC3lNVFblc7jiauq5L1dPpVColTuGg8+NQDsvPZrMSxNJZKoEkr1Qq0DRNKmRerVaTe6yE/4vF4r5kKqDJfOetHS6AKibidNuxj17Ru8M+iU+Dl6qQiECa6oi+I8F0amE8NjE292FZtswhIcs7EP7e2CT8CfVIDg1c3R4aAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Observability signals with OTel\" title=\"\" src=\"/static/661cd7278251d290b05c3a8d8f0ce959/c5bb3/otel-observability-signals.png\" srcset=\"/static/661cd7278251d290b05c3a8d8f0ce959/04472/otel-observability-signals.png 170w,\n/static/661cd7278251d290b05c3a8d8f0ce959/9f933/otel-observability-signals.png 340w,\n/static/661cd7278251d290b05c3a8d8f0ce959/c5bb3/otel-observability-signals.png 680w,\n/static/661cd7278251d290b05c3a8d8f0ce959/b12f7/otel-observability-signals.png 1020w,\n/static/661cd7278251d290b05c3a8d8f0ce959/b5a09/otel-observability-signals.png 1360w,\n/static/661cd7278251d290b05c3a8d8f0ce959/a303f/otel-observability-signals.png 1733w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">Observability signals with OTel</div>\n<br>\n<div class=\"info\" style='background-color:#d9edf7; color:#31708f; border-left: solid #bce8f1 12px; border-radius: 33px; padding: 1.7em;'>\n<span>\n<p style='margin-top:1em; text-align:center'>\n<b>The OTEL Origin</b>\n</p>\n<p style='margin-left:1em;'>This ubiquitous open protocol idea is so compelling that at some point there were two projects, <a href=\"https://opentracing.io/\" style=\"color:#31708f\">OpenTracing</a> and <a href=\"https://opencensus.io/\" style=\"color:#31708f\">OpenCensus</a>, that were trying to fill the gap.<br><br>\nThey were trying to compete with each other, but there was not the right context to do that, so it didn't make sense to try to conquer some market shares, but rather to consolidate their effort and come there much quicker shaping the space.\nThat's what happened. Both projects were merged into one known as <a href=\"https://opentelemetry.io/\" style=\"color:#31708f\">OpenTelemetry</a> (aka OTel).\n</p>\n</span>\n</div>\n<br>\n<h2 id=\"the-software-development-kit-sdk\" style=\"position:relative;\"><a href=\"#the-software-development-kit-sdk\" aria-label=\"the software development kit sdk permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>The Software development kit SDK</h2>\n<p>Collecting logs, metrics and traces in a unified way across services implemented in different technical stacks is the central task of OpenTelemetry.</p>\n<p>To get there, OpenTelemetry provides:</p>\n<ul>\n<li>SDKs for <a href=\"https://opentelemetry.io/docs/instrumentation/\" target=\"_blank\" rel=\"noopener noreferrer\">11+ of the most popular languages</a> (like Python, Go, NodeJS, Rust, Java, etc) that inits OTel core components.</li>\n<li>library-specific instrumentations that provide tool/framework-specific signals and context automagically (e.g. <a href=\"https://www.starlette.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Starlette</a>, <a href=\"https://www.python-httpx.org/\" target=\"_blank\" rel=\"noopener noreferrer\">HTTPX</a>, <a href=\"https://aio-pika.readthedocs.io/en/latest/\" target=\"_blank\" rel=\"noopener noreferrer\">aiopika</a> instrumentations, and so on)</li>\n</ul>\n<p>The third thing you could do is to further instrument your codebase with business logic specific traces and metrics.</p>\n<p>This process is generally known as codebase <em>instrumentation</em>.</p>\n<p>There are two ways to setup OTel in your application:</p>\n<ul>\n<li>automatic - when you run some agent before the main application entry point that configures OpenTelemetry (but not all languages support it, for example, Golang doesn't)</li>\n<li>manual - when you configure OpenTelemetry yourself to start collecting your observability signals.</li>\n</ul>\n<p>To understand how OpenTelemetry SDK is designed and implemented, we will delve into the manual setup.</p>\n<p>This is what it takes you to manually setup Python's service:</p>\n<div class=\"gatsby-highlight has-highlighted-lines\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> opentelemetry <span class=\"token keyword\">import</span> metrics<span class=\"token punctuation\">,</span> trace\n<span class=\"token keyword\">from</span> opentelemetry<span class=\"token punctuation\">.</span>sdk<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> MeterProvider\n<span class=\"token keyword\">from</span> opentelemetry<span class=\"token punctuation\">.</span>sdk<span class=\"token punctuation\">.</span>metrics<span class=\"token punctuation\">.</span>export <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>\n    ConsoleMetricExporter<span class=\"token punctuation\">,</span>\n    PeriodicExportingMetricReader<span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> opentelemetry<span class=\"token punctuation\">.</span>sdk<span class=\"token punctuation\">.</span>resources <span class=\"token keyword\">import</span> SERVICE_NAME<span class=\"token punctuation\">,</span> SERVICE_VERSION<span class=\"token punctuation\">,</span> Resource\n<span class=\"token keyword\">from</span> opentelemetry<span class=\"token punctuation\">.</span>sdk<span class=\"token punctuation\">.</span>trace <span class=\"token keyword\">import</span> TracerProvider\n<span class=\"token keyword\">from</span> opentelemetry<span class=\"token punctuation\">.</span>sdk<span class=\"token punctuation\">.</span>trace<span class=\"token punctuation\">.</span>export <span class=\"token keyword\">import</span> BatchSpanProcessor<span class=\"token punctuation\">,</span> ConsoleSpanExporter\n\n<span class=\"gatsby-highlight-code-line\">span_processor <span class=\"token operator\">=</span> BatchSpanProcessor<span class=\"token punctuation\">(</span>ConsoleSpanExporter<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></span><span class=\"gatsby-highlight-code-line\">metric_reader <span class=\"token operator\">=</span> PeriodicExportingMetricReader<span class=\"token punctuation\">(</span>ConsoleMetricExporter<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></span>\nresource <span class=\"token operator\">=</span> Resource<span class=\"token punctuation\">(</span>\n    attributes<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n        SERVICE_NAME<span class=\"token punctuation\">:</span> <span class=\"token string\">\"demo\"</span><span class=\"token punctuation\">,</span>\n        SERVICE_VERSION<span class=\"token punctuation\">:</span> <span class=\"token string\">\"v42\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"gatsby-highlight-code-line\">trace_provider <span class=\"token operator\">=</span> TracerProvider<span class=\"token punctuation\">(</span>resource<span class=\"token operator\">=</span>resource<span class=\"token punctuation\">)</span></span><span class=\"gatsby-highlight-code-line\">metrics_provider <span class=\"token operator\">=</span> MeterProvider<span class=\"token punctuation\">(</span>metric_readers<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>metric_reader<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></span>\n<span class=\"gatsby-highlight-code-line\">trace_provider<span class=\"token punctuation\">.</span>add_span_processor<span class=\"token punctuation\">(</span>span_processor<span class=\"token punctuation\">)</span></span>\n<span class=\"token comment\"># Sets the global default providers</span>\n<span class=\"gatsby-highlight-code-line\">trace<span class=\"token punctuation\">.</span>set_tracer_provider<span class=\"token punctuation\">(</span>trace_provider<span class=\"token punctuation\">)</span></span>metrics<span class=\"token punctuation\">.</span>set_meter_provider<span class=\"token punctuation\">(</span>metrics_provider<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Creates a custom tracer from the global provider</span>\ntracer <span class=\"token operator\">=</span> trace<span class=\"token punctuation\">.</span>get_tracer<span class=\"token punctuation\">(</span><span class=\"token string\">\"users\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Creates a custom meter from the global provider</span>\nmeter <span class=\"token operator\">=</span> metrics<span class=\"token punctuation\">.</span>get_meter<span class=\"token punctuation\">(</span><span class=\"token string\">\"users\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Let's try to unpack what's going on there.</p>\n<h3 id=\"resources\" style=\"position:relative;\"><a href=\"#resources\" aria-label=\"resources permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Resources</h3>\n<p>First of all, let's pay attention to the <code class=\"language-text\">Resource{:.entity.name}</code>. It is an abstraction around entities that could generate signals:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> opentelemetry<span class=\"token punctuation\">.</span>sdk<span class=\"token punctuation\">.</span>resources <span class=\"token keyword\">import</span> SERVICE_NAME<span class=\"token punctuation\">,</span> SERVICE_VERSION<span class=\"token punctuation\">,</span> Resource\n\nresource <span class=\"token operator\">=</span> Resource<span class=\"token punctuation\">(</span>\n    attributes<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n        SERVICE_NAME<span class=\"token punctuation\">:</span> <span class=\"token string\">\"demo\"</span><span class=\"token punctuation\">,</span>\n        SERVICE_VERSION<span class=\"token punctuation\">:</span> <span class=\"token string\">\"v42\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Right off the bat, <code class=\"language-text\">Resource{:.entity.name}</code> illustrates a few important concepts in the observability domain.</p>\n<p>Most context in the observability signals are going to be conveyed via <code class=\"language-text\">attributes{:.variable.parameter}</code> or tags which are essentially key-value pairs. Then, the observability backend could do some processing of these values to correlate various pieces of information.</p>\n<p>OTel strives to standardize the attribute names to keep them consistent across your system. That's why they come as constants.\nIn practice, this is an extremely daunting and challenging task, especially when multiple teams are working on different services in parallel.</p>\n<h3 id=\"providers\" style=\"position:relative;\"><a href=\"#providers\" aria-label=\"providers permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Providers</h3>\n<p>Python's SDK comes with two modules called <code class=\"language-text\">trace{:python}</code> and <code class=\"language-text\">metrics{:python}</code>.\nBoth modules contain a global variable that holds the current provider and a setter method like <code class=\"language-text\">set_tracer_provider(){:.entity.name.function}</code> to configure it.</p>\n<p>If you don't want to configure a real provider, there are also <code class=\"language-text\">NoOpTracerProvider{:.entity.name.class}</code> or <code class=\"language-text\">NoOpMeterProvider{:.entity.name.class}</code> that are helpful to keep all custom instrumentations in place without a need for guarding them via <code class=\"language-text\">if{:python}</code>s, for example.</p>\n<br>\n<div class=\"info\" style='background-color:#d9edf7; color:#31708f; border-left: solid #bce8f1 4px; border-radius: 4px; padding:0.7em;'>\n    <span>\n        <p style='margin-top:1em; text-align:center'>\n            <b>Design Patterns in Wild</b>\n        </p>\n        <p style='margin-left:1em;'>\n            All providers have NoOp implementations which is a great example of <a href=\"https://refactoring.guru/introduce-null-object\" style=\"color:#31708f\">the null object pattern</a>. Since telemetry could spread across codebase, it would be disastrous to have `if` statements everywhere we had it in case we have no proper observability setup under some circumstances like during automated testing.\n        </p>\n    </span>\n</div>\n<br>\n<p>Then, the rest of the codebase refers to the global providers when it needs to create traces or metrics.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 84.11764705882354%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAACRElEQVR42oWUbW+qQBCF+f//qh/bNDc3NjE1Wl8QRQRUFlDq27n7jHdJ2n4oyckuOzNn58wMRPrluVwuiuNYy+VSdV3/5q4IxzzPDdvtVlmWabPZKE3THvP53LBarXobK77EEFsUhZ1H6/Va5/PZbgdN0xicc7aS3Xg81mQy0cfHh50fj0ezhRgAB+TRbrdTVVW9I0ZXO7Vta6iburfXHs5VKsvC9sEn2A+HgyJShchkb3Otliu9Dd6UxInyLFe2ySwIv92u0nyR6PXPX01nC6VZYefUmYz3+70iiAhA2qbaarqLlVRrzfwK4izRZDwxOffGl6cY6eZincuxzvlQWbrU/lDpdDoJtUYIO81pjl7isVHbeeltrcv9qtafjUYjpZtU13OnU3NQ1zp1Rzp+81k9SvaDcLFYPBpR+4Z4B6R2Xef3zgjpcGP1cp7koKIsdbleveTyKyFSkEwX6XgYnZeXFw0GA72/v9vIJEnim1GanZF5enrS8/OzZrOZxdOHnpAMceaAleIOh0Mj5na6xxl2VlQxSmFCsDMdPSHphrkD3Ea24T2AIIKpN0Q2Yv/H5fPz80FI2zlAFhnRbQYYIIdSsOIMKdKpLaPCMAPeuaAn5JbpdGpZ0RxI+YxYIQvkZEb9CLzdbv33y57LekIkQgoZQRCRcfgpkDl2nvv9/oXsB2GQYiPinBWdErBHBrZA9P0J3zz+oZkRG9rOy/cGBDj7hh8XBPBOWVCAGjpvhNQO2eG3RB0BgwxoQth/R/iFATgg/gfhtQYdCd95/QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"The Tracer &amp; Meter Registries\" title=\"\" src=\"/static/a7abcb42e06919377828d647272bad9d/c5bb3/opentelemetry-registries.png\" srcset=\"/static/a7abcb42e06919377828d647272bad9d/04472/opentelemetry-registries.png 170w,\n/static/a7abcb42e06919377828d647272bad9d/9f933/opentelemetry-registries.png 340w,\n/static/a7abcb42e06919377828d647272bad9d/c5bb3/opentelemetry-registries.png 680w,\n/static/a7abcb42e06919377828d647272bad9d/b12f7/opentelemetry-registries.png 1020w,\n/static/a7abcb42e06919377828d647272bad9d/b5a09/opentelemetry-registries.png 1360w,\n/static/a7abcb42e06919377828d647272bad9d/5c263/opentelemetry-registries.png 1636w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">The Tracer & Meter Registries</div>\n<h2 id=\"traces\" style=\"position:relative;\"><a href=\"#traces\" aria-label=\"traces permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Traces</h2>\n<p>The <code class=\"language-text\">TracerProvider{:.entity.name.class}</code> is basically a factory that creates <code class=\"language-text\">Tracer{:.entity.name.class}</code>s and passes most of its params down to a <code class=\"language-text\">Tracer{:.entity.name}</code>.\n<code class=\"language-text\">Tracer{:.entity.name}</code>s represent the specific <code class=\"language-text\">trace</code> that could contain many <code class=\"language-text\">spans</code>.</p>\n<p>Conceptually, <code class=\"language-text\">traces</code> are connected to the specific workflow or operation in the system.\nThat's why their names should be the same for the same processes e.g. <code class=\"language-text\">GET /users/{user_id}/</code> may represent all requests to an API that returns user's data.</p>\n<p>Then, <code class=\"language-text\">spans</code> may represent some steps in your workflow. For instance, to get the user information, you may need to perform a request to your database.\nThat action may be wrapped into a <code class=\"language-text\">span</code>. Additional <code class=\"language-text\">attributes{:.variable.parameter}</code> could be added to the span to record some events, action result statuses, etc.\nIn the end, all <code class=\"language-text\">spans</code> form a hierarchical tree that could be viewed in the observability backend.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 36.47058823529412%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA/ElEQVR42oWQYUvDMBRF+///l6BMQfbBTdHJNqdZutkmbZI2aXoM7TZEi75wuMm74fJ42a5skZUfENqzT8i6Q1SBhXAs9o5H2fAg7MAyvUe/40Of9MS29GSNKTBvM+zuFrO9xoo5tukwrqN2o45EbBtxPtKEadpERvTQFOCOST+JTlHm3cD7qmWzbBAbjzpEjIr8V9nPRt+Ddz15EZg911wtNDdP1XDfHdpfAf3A+VwC+2+M5dL4sg7kJgwqbeCQ9lek4PK1pnhJuqrxyb9ETE04WafPrQrojUWvDSqh15ZKGcqgUb7CBvd3YD85+9kbO8e095m85y6fI6zkC9QfH2lppvQpAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"An example of trace\" title=\"\" src=\"/static/d4fa410953bc03d36a554a71b39b7edb/c5bb3/traces-example.png\" srcset=\"/static/d4fa410953bc03d36a554a71b39b7edb/04472/traces-example.png 170w,\n/static/d4fa410953bc03d36a554a71b39b7edb/9f933/traces-example.png 340w,\n/static/d4fa410953bc03d36a554a71b39b7edb/c5bb3/traces-example.png 680w,\n/static/d4fa410953bc03d36a554a71b39b7edb/b12f7/traces-example.png 1020w,\n/static/d4fa410953bc03d36a554a71b39b7edb/b5a09/traces-example.png 1360w,\n/static/d4fa410953bc03d36a554a71b39b7edb/7e318/traces-example.png 1892w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">An example of trace</div>\n<p>Using <a href=\"#the-sdk\">the tracer inited above</a>, we can create a new trace via:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># the root span</span>\n<span class=\"token keyword\">with</span> tracer<span class=\"token punctuation\">.</span>start_as_current_span<span class=\"token punctuation\">(</span><span class=\"token string\">\"users:get-info\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> span<span class=\"token punctuation\">:</span>\n    span<span class=\"token punctuation\">.</span>set_attribute<span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># nested/child span</span>\n    <span class=\"token keyword\">with</span> tracer<span class=\"token punctuation\">.</span>start_as_current_span<span class=\"token punctuation\">(</span><span class=\"token string\">\"users:get-info:check-permissions\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> span<span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></code></pre></div>\n<h3 id=\"spans\" style=\"position:relative;\"><a href=\"#spans\" aria-label=\"spans permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Spans</h3>\n<p>In OTel protocol, <code class=\"language-text\">traces</code> are rather virtual entities that hold some execution context. The real data points that are being collected, processed and exported are <code class=\"language-text\">spans</code>.</p>\n<p>The <code class=\"language-text\">Span{:.entity.name.class}</code> consists of:</p>\n<ul>\n<li>name - the human-friendly title of the step</li>\n<li>kind like internal, server, client, producer, consumer</li>\n<li>status like <code class=\"language-text\">not set</code>, <code class=\"language-text\">ok</code>, <code class=\"language-text\">error</code></li>\n<li>the span context</li>\n<li>the parent span context</li>\n<li>the resource context</li>\n<li>the trace or instrumentation scope</li>\n<li>span <code class=\"language-text\">attributes{:.variable.parameter}</code></li>\n<li>span events - special entities with the name, timestamp and own set of <code class=\"language-text\">attributes{:.variable.parameter}</code></li>\n<li>span links to other spans that have caused the current span</li>\n<li>start_time &#x26; end_time as <code class=\"language-text\">time.time_ns(){:python}</code></li>\n</ul>\n<p>The <code class=\"language-text\">Span{:.entity.name.class}</code> class is also a <a href=\"https://book.pythontips.com/en/latest/context_managers.html#context-managers\" target=\"_blank\" rel=\"noopener noreferrer\">context manager</a>, so when it starts and exits, the span signals the <code class=\"language-text\">SpanProcessor</code> about that.</p>\n<h3 id=\"span-sampling\" style=\"position:relative;\"><a href=\"#span-sampling\" aria-label=\"span sampling permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Span Sampling</h3>\n<p>There is also an optional opportunity to configure a span sampler.</p>\n<p>Sampling is a way to filter out some spans or other data points if they match some specific criteria or just randomly.\nThe major reasons to sample are:</p>\n<ul>\n<li>to optimize the cost of ingesting and storing observability signals</li>\n<li>filter out boring regular data and mostly keep interesting one e.g. spans with errors, that took more than the threshold</li>\n<li>merely filter based on the presence or absence of <code class=\"language-text\">attributes{:.variable.parameter}</code></li>\n</ul>\n<p>Sampling on the SDK side could allow filtering as soon as possible in the pipeline (or the head sampling).</p>\n<p>OTel comes with a few span samplers out of the box:</p>\n<ul>\n<li><code class=\"language-text\">StaticSampler{:.entity.name.class}</code> that always or never drops spans</li>\n<li><code class=\"language-text\">TraceIdRatio{:.entity.name.class}</code> that probabilistically drops a given portion of spans</li>\n</ul>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 25.294117647058822%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAzElEQVR42oVQ2QrCQAzc//849cV7pVpb6b1bekmvcSdYEBEMhM0mk8wkCh82zzPGcUTf9xIPw4A4jhCGgXtjqTHXtq1gfpmapkmAfLMsgzEWeZ6jqioURYGzvuB01gjCB5qmgbUWaZo6nEHXddLH4XTOUQSRkUO01rgHIbyrD/8eOGUu9q7Y7va4+f6b0IgSDmBPXdeiPkkSqallVRqLVEYCEpWlxf5wwGq9wfF4kjydyojrnk/po8rF1fcNmCTBck+uGEURjFuf/3/2Apg2gcILbKBxAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"OTel SDK Span Pipeline\" title=\"\" src=\"/static/ad6a5407e664f64a485dc7096d755d37/c5bb3/otel-traces-pipeline.png\" srcset=\"/static/ad6a5407e664f64a485dc7096d755d37/04472/otel-traces-pipeline.png 170w,\n/static/ad6a5407e664f64a485dc7096d755d37/9f933/otel-traces-pipeline.png 340w,\n/static/ad6a5407e664f64a485dc7096d755d37/c5bb3/otel-traces-pipeline.png 680w,\n/static/ad6a5407e664f64a485dc7096d755d37/b12f7/otel-traces-pipeline.png 1020w,\n/static/ad6a5407e664f64a485dc7096d755d37/b5a09/otel-traces-pipeline.png 1360w,\n/static/ad6a5407e664f64a485dc7096d755d37/a368f/otel-traces-pipeline.png 4529w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">OTel SDK Span Pipeline</div>\n<p>These two samplers could be also configured to respect parent span decisions, so if the parent span was dropped, all its children spans would be eliminated, too.</p>\n<div class=\"info\" style='background-color:#d9edf7; color:#31708f; border-left: solid #bce8f1 4px; border-radius: 4px; padding:0.7em;'>\n    <span>\n        <p style='margin-top:1em; text-align:center'>\n            <b>Design Patterns in Wild</b>\n        </p>\n        <p style='margin-left:1em;'>\n            Parent span aware sampling is implemented using <a href=\"https://refactoring.guru/design-patterns/composite\" style=\"color:#31708f\">the composite design pattern</a>.<br><br>\n            The parent-based sampler wraps the static or ratio-based sampler mentioned above and adds a logic to propagate the parent span's sampling decision.\n        </p>\n    </span>\n</div>\n<h3 id=\"span-processors\" style=\"position:relative;\"><a href=\"#span-processors\" aria-label=\"span processors permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Span Processors</h3>\n<p>When spans end, they come to span processors. Span processing is the last stage of span's lifecycle before it's exported outside of the service. OpenTelemetry uses it to batch spans and multiplex them to multiple exporters.</p>\n<p>The <code class=\"language-text\">BatchSpanProcessor</code> collects spans and exports them on schedule or when its queue is full. For that, it maintains a separate daemon thread where this logic is executed. The processor waits until a batch is collected or a timeout is reached.\n<a href=\"https://docs.python.org/3/library/threading.html#condition-objects\" target=\"_blank\" rel=\"noopener noreferrer\">Threading.condition</a> is used to implement this elegantly.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 91.1764705882353%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAACJklEQVR42p1TbWvaUBj1v2/fxtiHFhmssMEclQ1WhH4YU4alUh24tipVE19ijO8xRqPRJJqc5dySwV6gZhee3CfPzT333HOeJBCOIAhgriwYSwtyW8FEN6AbJlzXQ9yR4GO3tfE2LyFZMvD803ec5DW8yPZw39LER74fxAP0PBeXxQecX0t4nSkg9a2Kd9k7dAeTR8AgJuDWtvEmW8PplYZn6QJOch28+tJEs/s0w+CPwwSg6zi4uK7i/OoBpx+/4n3uDqncPfqj6T83PcnQ2e2QytdxVujj5ecizvJtJHMSJHUMJ9R3tVphsVjANE2Rz+dz8T6bzUTtb4aug0xJxoeiimTmBumignRJhTLS4R/22G63IjabDXbh4ev1GnYoE2fWfwN0XVcsWksD9mqBy8wFOnIDtmWGGyw4oRyx2qbdbmM0GqHf72MYzj9ub8HaYDCApmnodDrimsdqmeAGDrKkJtTGsiyMx2OQvWEYGA6HxwOWy2Xouo7JZCKYdrtdLJdLUeMBsiyLtaMBK5UK9vu9uHKr1UKv1xNgFJwmRJLEYuj7vrCfzKgX88jB/wKkk2RFIGpHDR/byYUkSaJ2NGCtVhNMyIwMaU7EkAaRYSxARVFwOBwEEIHJljkbmNrSGLpMMM/zRPCbKGfwJgzWE9Vq9VffcWbv0VWaRMdVVRW16XQqmEcdwd+PzJlHwXXBsN5ool5viJl9qYZO022uEYynH/un/AQESlsXZtEOpwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"A Batch Queue with Timeout\" title=\"\" src=\"/static/4fef94e00abdfbb5293a6536a776c7f5/c5bb3/otel-batch-queue-with-timeout.png\" srcset=\"/static/4fef94e00abdfbb5293a6536a776c7f5/04472/otel-batch-queue-with-timeout.png 170w,\n/static/4fef94e00abdfbb5293a6536a776c7f5/9f933/otel-batch-queue-with-timeout.png 340w,\n/static/4fef94e00abdfbb5293a6536a776c7f5/c5bb3/otel-batch-queue-with-timeout.png 680w,\n/static/4fef94e00abdfbb5293a6536a776c7f5/b12f7/otel-batch-queue-with-timeout.png 1020w,\n/static/4fef94e00abdfbb5293a6536a776c7f5/77abb/otel-batch-queue-with-timeout.png 1305w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">A Batch Queue with Timeout</div>\n<p>There are also two <code class=\"language-text\">MultiSpanProcessors</code> that operate on a list of span processors and dispatch them sequentially or concurrently.</p>\n<p>The concurrent span processing happens via <a href=\"https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor\" target=\"_blank\" rel=\"noopener noreferrer\">ThreadPoolExecutor</a>.</p>\n<h2 id=\"ctx-propagation\" style=\"position:relative;\"><a href=\"#ctx-propagation\" aria-label=\"ctx propagation permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Ctx Propagation</h2>\n<p>So far we have been talking about trace spans processing in the scope of one services,\nbut the real value of traces unlocks when multiple microservices take part in a workflow and you could connect what they were doing there into one coherent picture.</p>\n<p>In order to do that, OpenTelemetry needs to propagate some context during cross-service communication,\nso the next microservice in the flow would know that all spans it was going to create should be attached to the parent trace created at the start of the workflow.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 37.05882352941176%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABRElEQVR42l1R127EMAzL/39ii9710oOdeDuJRyYrGc1LBRgeICWS7qyxcNahf/V4Ph5QSsFai2macJ4XjvPEcRx0PnFXjBHOuYbr+xee/TcGPcAYg+7r9YCMI0QYEJcJtdZG0lrDOg/nAwztpRbs+47ruhrxogFLWqCibtx3kHjLN7pe/CDkCOUVYgpNzd1QaQMfIjQ5GJRue6GBht5ParwTtm4rtm1DiAHee3SGiFxuKhA6ws4VUz0g5IAQApZlIfsz5nlGzplIDh+fnzBThQoZOha4uSAShmPqWH7LZU6QvmDwCbms0PTO9mtdaXpsi+9sWUqJulaMcYXwtalmlSkldPpPYSkFNmbKkbPaWk63fa6L13W18ziOjbykjHkhATk1LLvohJAYCCCEwCBFm84/zb94N/hfnBUL0YRjLJ9ZAHN+AbBZGIU8VoPUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"The Context Propagation in a Distributed Workflow\" title=\"\" src=\"/static/5ae49fc56c264f7827b5482ce153c221/c5bb3/otel-context-propagation.png\" srcset=\"/static/5ae49fc56c264f7827b5482ce153c221/04472/otel-context-propagation.png 170w,\n/static/5ae49fc56c264f7827b5482ce153c221/9f933/otel-context-propagation.png 340w,\n/static/5ae49fc56c264f7827b5482ce153c221/c5bb3/otel-context-propagation.png 680w,\n/static/5ae49fc56c264f7827b5482ce153c221/b12f7/otel-context-propagation.png 1020w,\n/static/5ae49fc56c264f7827b5482ce153c221/b5a09/otel-context-propagation.png 1360w,\n/static/5ae49fc56c264f7827b5482ce153c221/31fce/otel-context-propagation.png 2229w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">The Context Propagation in a Distributed Workflow</div>\n<p>OTel holds propagatable information in the <span class=\"green\">runtime context</span>.\nIn Python's SDK, it's implemented using the convenient <a href=\"https://docs.python.org/3/library/contextvars.html\" target=\"_blank\" rel=\"noopener noreferrer\">contextvars</a> standard library which is a perfect mechanism to have scoped \"global\" variables on the level of asyncio.Task-s, for example.</p>\n<p>By default, OTel defines two context vars:</p>\n<ul>\n<li>the <span class=\"green\">current span</span> - holds a reference to the currently active OTel trace span</li>\n<li>the <span class=\"green\">baggage</span> - holds arbitrary key-value information that should be propagated as an additional context for every microservice involved</li>\n</ul>\n<p>Another important thing here is the actual <span class=\"blue\">context propagation</span> which incurs context serialization and deserialization.</p>\n<p>In the realm of HTTP-based communication, OpenTelemetry propagates the context via HTTP headers according to <a href=\"https://www.w3.org/TR/trace-context/\" target=\"_blank\" rel=\"noopener noreferrer\">the W3C Trace Context specification</a>. According to the specification, the current span context is propagated as two headers:</p>\n<ul>\n<li><code class=\"language-text\">traceparent</code> - with trace span ID, parent span ID and parent span flags (e.g. trace was marked as sampled or not)</li>\n<li><code class=\"language-text\">tracestate</code> - arbitrary vendor-specific trace context or identifiers</li>\n</ul>\n<p>The <span class=\"green\">baggage</span> context doesn't seem to be outlined in the specification, but OTel shares it as one more identically named HTTP header.</p>\n<p>The microservice that receives such requests should be aware of context information in the headers, extract it and set it in the local <span class=\"green\">runtime context</span>.</p>\n<p>Since OpenTelemetry is framework- or transport-protocol-agnostic, it just provides all needed functions to extract or inject context.\nTo actually propagate that information, you should instrument your clients and servers and OTel provides plenty of auto-instrumentors in <a href=\"https://opentelemetry.io/ecosystem/registry/\" target=\"_blank\" rel=\"noopener noreferrer\">their registry</a>.</p>\n<h2 id=\"metrics\" style=\"position:relative;\"><a href=\"#metrics\" aria-label=\"metrics permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Metrics</h2>\n<p>Metrics are another observability pillar we are going to review next. The mechanism of collecting metrics is a bit different to traces.</p>\n<p>In case of traces, user code actively creates trace spans and as soon as they are completed, OpenTelemetry can process and export them.\nThe metrics dynamic is much more continuous, so the collection really ends when the service shuts down.\nSince service uptime could be measured in days if not weeks, we need to take a different approach here to export all measurements in between like doing metric data aggregations periodically over a time window.</p>\n<p>Just like in the case of traces, OpenTelemetry provides <span class=\"orange\">MeterProvider</span> that bridges all metrics with metric exporters.\n<span class=\"orange\">MeterProvider</span> creates new instances of <code class=\"language-text\">Meter{:.entity.name.class}</code>.\nMeters are instrumentation-specific measurement components. Each OTel instrumentation library creates its own meter (e.g. HTTP client or server meters).\nWhen you do your custom measurements it's alright to have one global meter per service (but you certainly could have more).</p>\n<p>Using <a href=\"#the-sdk\">the meter inited above</a>, you can measure a custom metric like that:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># globally defined custom metric</span>\nuser_info_cache_miss_counter <span class=\"token operator\">=</span> meter<span class=\"token punctuation\">.</span>create_counter<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"users.cache.miss\"</span><span class=\"token punctuation\">,</span>\n    description<span class=\"token operator\">=</span><span class=\"token string\">\"The number of cache misses when fetching user's info\"</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># later on, you can import the metric and measure what you need</span>\nuser_info_cache_miss_counter<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"user.org_id\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"metric-instruments\" style=\"position:relative;\"><a href=\"#metric-instruments\" aria-label=\"metric instruments permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Metric Instruments</h3>\n<p>Now, having a meter, you could create specific metrics (a.k.a. metric instruments) that you want to measure or observe. Generally, OTel divides metrics into two categories:</p>\n<ul>\n<li><code class=\"language-text\">Synchronous metrics</code> - there are metrics that you measure directly right in your service workflows, so you observe them as soon as the event happens (e.g. a service increases a counter metric in the user login workflow)</li>\n<li><code class=\"language-text\">Asynchronous (or observable) metrics</code> - these metrics are read from \"external\" sources, so you just observe an aggregated or in-time statistics instead of measuring the value directly (e.g. number of items in a queue given that you cannot instrument the queue directly and you could just read its size property)</li>\n</ul>\n<p>OpenTelemetry supports the following metric types:</p>\n<ul>\n<li><span class=\"green\">Counter</span> (and <span class=\"green\">Observable Counter</span>) - an ever-growing (or monotonically increasing) value (for example, the number of requests processed by service)</li>\n<li><span class=\"green\">UpDownCounter</span> (and <span class=\"green\">Observable UpDownCounter</span>) - a value that could grow or fall (for example, the number of in-flight requests)</li>\n<li><span class=\"green\">Histogram</span> (and <span class=\"green\">Observable Histogram</span>) - suitable for measurements on which you want to calculate statistics (for example, request latency)</li>\n<li><span class=\"green\">Gauge</span> - just like the observable <span class=\"green\">UpDownCounter</span>, but each measurement is treated as a separate data point, so they are not summed up (for example, CPU or RAM utilizations)</li>\n</ul>\n<h3 id=\"views--agregations\" style=\"position:relative;\"><a href=\"#views--agregations\" aria-label=\"views  agregations permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Views &#x26; agregations</h3>\n<p>With our metrics defined, we could start measuring, aggregating and collecting actual values.</p>\n<p>Metric instruments don't collect data directly but rather send it to <code class=\"language-text\">MeasurementConsumer{:.entity.name.class}</code> which is a global component initiated on the <span class=\"orange\">MeterProvider's</span> level.\n<code class=\"language-text\">MeasurementConsumer{:.entity.name.class}</code> collects data for each and all <code class=\"language-text\">MetricReader{:.entity.name.class}</code>s configured on the provider.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 38.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABZElEQVR42o2STW8TMRCG96/zBzgjkBBSJSgoAiEOXDj0AAcgJRVIDShNdoFsuh9e/FHvOuvN5mHjRqg0HHglW553Ro/l8URNdo5vDNfaclPbfRiXNfffCx6NK5bC8HoqefChIikMrXNk2lNdeda+J7If72Hzi78J4bil76/jH1XD0VhwPKn4WSjexlc8nzZcKjcU9rgBtIN1Q30kkjO6dY3vOmQth6XoNl0A7tQNfus9eVFSiip4betxrh0u7LmtSEiNNTVfk28cnT7l8WREmqWIUrBMU5IkQWuNUoq6rrHWkccvyWYP0So/aFXUNDVKKubpgifjEc9OX5CLPHiry1UAlmWJlBJjNNpY8u9vKBYjjC4PgW7tQqytZlZcMCvnBG+v3XNb37LZbEJP27YhX05YLU5wtjgE8r/a97Sxv/j87i6fTu4gsumfD/wncJfY3hqdG9mwr50hPn/F/MsxUsQH0/EbOAxi3i+0lk0AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"The Architecture of OTel Metrics\" title=\"\" src=\"/static/5e850c2e48c5ff45838ec4dcc327fa77/c5bb3/otel-metrics-architecture.png\" srcset=\"/static/5e850c2e48c5ff45838ec4dcc327fa77/04472/otel-metrics-architecture.png 170w,\n/static/5e850c2e48c5ff45838ec4dcc327fa77/9f933/otel-metrics-architecture.png 340w,\n/static/5e850c2e48c5ff45838ec4dcc327fa77/c5bb3/otel-metrics-architecture.png 680w,\n/static/5e850c2e48c5ff45838ec4dcc327fa77/b12f7/otel-metrics-architecture.png 1020w,\n/static/5e850c2e48c5ff45838ec4dcc327fa77/b5a09/otel-metrics-architecture.png 1360w,\n/static/5e850c2e48c5ff45838ec4dcc327fa77/89b99/otel-metrics-architecture.png 4741w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">The Architecture of OTel Metrics</div>\n<p>Thinking about our source metrics data, it's just arrays of numbers with attributes (or one number at the time in the case of observable instruments), so there are multiple options possible how they could be aggregated.\nOpenTelemetry provides great flexibility there.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 35.29411764705882%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABP0lEQVR42oWRW0vDQBCF8/9/goIoPlR8EUF8EBVFvFssvalttWnatKZNujG7TePm8rmg4gWLBwYGzmHmnBmL7yhgPHW4cS4o26f4vv1FLEDxi7WenVNG9gGD7hVChETRmJ7foe+3CQIXKRV5npNlOTrNSLP3fhGsqVdHeLd4wwZKzvDFkOqgQs0pI0KXLM2Z+D7b9YDN+oyNumLvXpBqbbiUl1gzCl+RSUaWF1j2/Q6d6ga91i6JUtw5VZbO1li9XOfRfUAnmv7ApVQRrFRmLJcVWzVhlkuU0QuZMJGaQGnCOMUKvCZe/5rJqME8npPEUyMaEkYOczUmMpG1cSPjhNAkCEJJpOLFkUf2CY+1Eu7TMTMj9IIeR+1DU/t0B02Kxef68a7P51itdofzi0sazeYHk5NnqTm8pvhv2h8O3wAl9xPkneXC5AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"OTel Metrics, Views, Aggregations\" title=\"\" src=\"/static/22515c44b0ce08ec183f72acbb5b224a/c5bb3/otel-metrics-logical-structure.png\" srcset=\"/static/22515c44b0ce08ec183f72acbb5b224a/04472/otel-metrics-logical-structure.png 170w,\n/static/22515c44b0ce08ec183f72acbb5b224a/9f933/otel-metrics-logical-structure.png 340w,\n/static/22515c44b0ce08ec183f72acbb5b224a/c5bb3/otel-metrics-logical-structure.png 680w,\n/static/22515c44b0ce08ec183f72acbb5b224a/b12f7/otel-metrics-logical-structure.png 1020w,\n/static/22515c44b0ce08ec183f72acbb5b224a/b5a09/otel-metrics-logical-structure.png 1360w,\n/static/22515c44b0ce08ec183f72acbb5b224a/ebb58/otel-metrics-logical-structure.png 3575w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">OTel Metrics, Views, Aggregations</div>\n<p>First of all, aggregations could be configured on the metric exporter side. Maybe, you are an observability backend vendor like DataDog or Chronosphere and you come up with a better or specific way to deal with metric data points. This would be an opportunity for you to adjust exported data.</p>\n<p>Then, you could leverage a concept of <span class=\"yellow\">views</span> to override the config further. <span class=\"yellow\">Views</span> effectively allow to specify the aggregation strategy per metric instrument and its metadata (e.g. name, attributes).</p>\n<p>By default, OTel implements the following aggregations:</p>\n<ul>\n<li><span class=\"yellow\">Drop Aggregation</span> - a way to drop metric collection completely.</li>\n<li><span class=\"yellow\">Last Value Aggregation</span> - keeps the last aggregated value until it's collected (used by gauges).</li>\n<li><span class=\"yellow\">Sum Aggregation</span> - arithmetic sum of provided data points (used by counters).</li>\n<li><span class=\"yellow\">Explicit Bucket Histogram Aggregation</span> - assigns collected data points to one of 15 predefined buckets. Besides that, it collects sum, count, min and max across given data.</li>\n<li><span class=\"yellow\">Exponential Bucket Histogram Aggregation</span> - similar to the explicit bucket aggregation, but buckets are generated dynamically by the exponentially growing size of the next bucket and much more fine grained (by default, there are 150 buckets).</li>\n</ul>\n<p>The sum and histogram aggregations may collect data between probes as:</p>\n<ul>\n<li><span class=\"yellow\">deltas</span> e.g. differences between the previous aggregated stats (e.g. sums, counts) and the current ones.</li>\n<li><span class=\"yellow\">cumulative data</span> e.g. the previous and the current stats are summed up (so the values keep increasing over time).</li>\n</ul>\n<p>This is called <span class=\"yellow\">aggregation temporality</span>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 51.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABcElEQVR42pVSy0rDQBTtb7t0p27EhYjgzi9xIQVfpUoXKpG0eU5etnk2aZLjnAsptHRRBw537sx9nDl3Rjhi1XWNLMuOCcVo/yDLchRFiVRb4ne5xMJ24Lou6vUaaZpK8dVqJaiqardg0zQg2rZFpRO+DBPfPws8jF/x+DzFxdUtTk7PMf2Y6eQSnudJbBAE6PteGtDn0i5GZVkiz3PpRJiWg7njYfzyjqfJDNd39zi7vMHbZIooCmEYBpaatWmaiOMYlmUhSRJ5Wacr7jy56zoUugGZEmsN6sdzvmKz2YhPRrQ8o+U5Yw5qeGgxkeyHpH8NhbpQjJ6sarJqZQhJEssd2ZERLbHfZMSgAQzwVQgVxnD9QPaOp2BpTS3LFq2VUvoXFFrPSAbCSQuJoSAvGUhw/6mnvHDU1n4Zc7FBGImmvu9LYhiGwpQDGvRstL9lOGhlu74wpCVLW7NTupjn+Yh0Ef5HMuP34XRZmJaF+fw/oLIAixjBSSwAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Aggregation Temporalities\" title=\"\" src=\"/static/f164b8bdcc536352f6468a1b83819da1/c5bb3/opentelemetry-temporalities.png\" srcset=\"/static/f164b8bdcc536352f6468a1b83819da1/04472/opentelemetry-temporalities.png 170w,\n/static/f164b8bdcc536352f6468a1b83819da1/9f933/opentelemetry-temporalities.png 340w,\n/static/f164b8bdcc536352f6468a1b83819da1/c5bb3/opentelemetry-temporalities.png 680w,\n/static/f164b8bdcc536352f6468a1b83819da1/b12f7/opentelemetry-temporalities.png 1020w,\n/static/f164b8bdcc536352f6468a1b83819da1/b5a09/opentelemetry-temporalities.png 1360w,\n/static/f164b8bdcc536352f6468a1b83819da1/3a793/opentelemetry-temporalities.png 2973w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">Aggregation Temporalities</div>\n<h3 id=\"metric-readers\" style=\"position:relative;\"><a href=\"#metric-readers\" aria-label=\"metric readers permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Metric readers</h3>\n<p>As we briefly have mentioned, metrics are collected on schedule by <span class=\"blue\">MetricReader</span> like <span class=\"blue\">PeriodicExportingMetricReader</span> which holds a ticker in a separate thread.\nThe ticker initiates the metrics collection process that creates exportable data according to <span class=\"yellow\">metrics aggregation temporalities</span>.</p>\n<h2 id=\"logs\" style=\"position:relative;\"><a href=\"#logs\" aria-label=\"logs permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Logs</h2>\n<p>Finally, we get to logs. They are the most wide-spread among the signals and have the longest record of being used for diagnosing how code works.</p>\n<p>Logs are simple to operate. You could just write them to a standard output or a file, and then dredge them when you need. No need to have special viewers like you would need in case of traces or metrics.\nThat's why pretty much all languages have their off-the-shelf logging libraries to use.</p>\n<p>Ironically, logs have gotten the last into OpenTelemetry. The integration is either in the experimental stage or doesn't exist for most languages at the moment.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 24.705882352941178%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABHElEQVR42lWQXUvDMBSG+//vvfBX6I2wG2UTHIoO9MKhwobd0q+1aZvPpunH62nBoQdCCDl5c54niEMNtlew2mMcB7i2Qesduq6D9x2cayGEQJ7nSNMUxhj0fU93Hk1DvW1L70b8VvC40FhdTaESUgo83WXYrDgKrlFEa/DdJZSIcTgwbLdb7PZ7SFHj+vkbF8sQ9+9HWKNQKA9OQwUvtxbrG4tTNP3msHlgeF0nkMpB8A9UbIHGlFDagDGGMAzR0/RvhwrLrwqfrMDQd+j6cV6BrB3qsiGEYQ7kZUbTZXQmFEKohEFZ1VBKzehxHP9DnNRMCs7I+FPWWiRxgiw7Eb6kZo8sTchdAs757DGKIvLqZr+Wdq01hmE4B/4AwGh625pHH9sAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"The OTel Log Adapter in Python\" title=\"\" src=\"/static/e10f598585f611a5a600f8ecab0cc8f8/c5bb3/opentelemetry-logs.png\" srcset=\"/static/e10f598585f611a5a600f8ecab0cc8f8/04472/opentelemetry-logs.png 170w,\n/static/e10f598585f611a5a600f8ecab0cc8f8/9f933/opentelemetry-logs.png 340w,\n/static/e10f598585f611a5a600f8ecab0cc8f8/c5bb3/opentelemetry-logs.png 680w,\n/static/e10f598585f611a5a600f8ecab0cc8f8/b12f7/opentelemetry-logs.png 1020w,\n/static/e10f598585f611a5a600f8ecab0cc8f8/b5a09/opentelemetry-logs.png 1360w,\n/static/e10f598585f611a5a600f8ecab0cc8f8/281b3/opentelemetry-logs.png 4441w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\">The Log Bridge in Python</div>\n<p>OpenTelemetry bridges into the existing logging libraries to integrate logs seamlessly for applications. In Python's world, there is the standard <a href=\"https://docs.python.org/3/library/logging.html\" target=\"_blank\" rel=\"noopener noreferrer\">logging</a> package.\nOTel comes with a <code class=\"language-text\">LoggingHandler</code> that plugs the rest of components into the logging system. The LoggingHandler also translates logging.LogRecord into OTel's LogRecord data class.</p>\n<div class=\"info\" style='background-color:#d9edf7; color:#31708f; border-left: solid #bce8f1 4px; border-radius: 4px; padding:0.7em;'>\n    <span>\n        <p style='margin-top:1em; text-align:center'>\n            <b>Design Patterns in Wild</b>\n        </p>\n        <p style='margin-left:1em;'>\n            The OTel's <code>LoggingHandler</code> is a good example of applying <a href=\"https://refactoring.guru/design-patterns/adapter\" style=\"color:#31708f\">the adapter pattern</a> that allowed OpenTelemetry to have its own architecture despite a variety of logging libraries it needed to support.\n        </p>\n    </span>\n</div>\n<p>The remaining architecture resembles what we have reviewed in <a href=\"#span-processors\">the trace part</a>.\nThere is a dedicated LoggerProvider that holds log processors and exporters attached to the processors.\nThe processors send logs to exporters for further saving in observability backends.</p>\n<h2 id=\"semantic-conventions-semconv\" style=\"position:relative;\"><a href=\"#semantic-conventions-semconv\" aria-label=\"semantic conventions semconv permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Semantic Conventions SemConv</h2>\n<p>Before wrapping up, we need to touch on another important topic that is tangentially connected to service instrumentations and metrics.</p>\n<p>Imagine you have three teams in a company that run different subsystems.\nNow let's ask them to define golden signal metrics for their services and see what metric names they come up with.\nChances are we would get three different sets of names for semantically the same metrics. That's even more likely if they work with different tech stacks with different conventions and naming standards.</p>\n<p>Such a lack of consistency would create a lot of mess and hinder reuse of common dashboards, alerts, etc.\nThe same situations can happen in traces when we instrument database queries, object storage access, etc.</p>\n<p>OTel recognized this problem and <a href=\"https://opentelemetry.io/docs/specs/semconv/\" target=\"_blank\" rel=\"noopener noreferrer\">came up with a set of common names for common operations across all three signals</a>.\nSo if you use it, you can come up with a very unified view of the whole system when looking at it through an observability lens.</p>\n<h2 id=\"closing-thoughts\" style=\"position:relative;\"><a href=\"#closing-thoughts\" aria-label=\"closing thoughts permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Closing thoughts</h2>\n<p>In this article, we have reviewed OpenTelemetry integration from the service development perspective by looking into the internals of the SDK.</p>\n<h2 id=\"references\" style=\"position:relative;\"><a href=\"#references\" aria-label=\"references permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>References</h2>\n<ul>\n<li><a href=\"https://opentelemetry.io/docs/concepts/signals/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Signals</a></li>\n<li><a href=\"https://opentelemetry.io/docs/instrumentation/python/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Python SDK</a></li>\n<li><a href=\"https://opentelemetry.io/docs/concepts/signals/baggage/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Baggage</a></li>\n<li><a href=\"https://opentelemetry.io/docs/concepts/sampling/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Sampling</a></li>\n<li><a href=\"https://opentelemetry.io/docs/concepts/signals/logs/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Logs</a></li>\n<li><a href=\"https://opentelemetry.io/docs/languages/python/cookbook/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Python Cookbook</a></li>\n<li><a href=\"https://opentelemetry.io/docs/specs/semconv/\" target=\"_blank\" rel=\"noopener noreferrer\">[OpenTelemetry] Semantic Conventions</a></li>\n</ul>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}