{"componentChunkName":"component---src-templates-blog-template-js","path":"/blog/prometheus-manage-memory-overload/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p><strong>When Prometheus Can't Keep Up with the WAL üìà</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìó Introduction</h2>\n<p>Have you ever had Prometheus crash due to an out-of-memory error while trying to catch up by reading the Write-Ahead Log (WAL)? It's a frustrating problem, but let's check it out.</p>\n<p>Prometheus is great for monitoring, but when it restarts, it needs to process data from the Write-Ahead Log (WAL), which can be memory-intensive. This often leads to OOMKilled crashes, especially if Prometheus is already running close to its memory limits.</p>\n<p>The issue usually stems from either collecting too much data or running too close to memory limits. This has been a long-standing concern, with <a href=\"https://github.com/prometheus/prometheus/issues/6934\" target=\"_blank\" rel=\"noopener noreferrer\">reports dating back to an open issue since 2020 on GitHub</a>, highlighting the significant challenges faced by users in managing Prometheus' memory during WAL replay.</p>\n<h3 id=\"Ô∏è-the-problem\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-the-problem\" aria-label=\"Ô∏è the problem permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚ÅâÔ∏è The Problem</h3>\n<br>\n<div style=\"width:100%;height:0;padding-bottom:100%;position:relative;\"><iframe src=\"https://giphy.com/embed/ka55CqnDNjQ7iIKtRa\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe></div>\n<p>While upgrading <a href=\"https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack\" target=\"_blank\" rel=\"noopener noreferrer\">the Helm chart of kube-prometheus-stack</a>, we noticed several pods were not ready, including <code class=\"language-text\">prometheus-prometheus-operator-prometheus-0</code>, which showed a status of <code class=\"language-text\">3/4 Running</code> with a recent termination due to being OOMKilled.</p>\n<p>The logs revealed the root cause:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token assign-left variable\">ts</span><span class=\"token operator\">=</span><span class=\"token number\">2024</span>‚Äì06‚Äì14T09:49:10.383Z <span class=\"token assign-left variable\">caller</span><span class=\"token operator\">=</span>head.go:840 <span class=\"token assign-left variable\">level</span><span class=\"token operator\">=</span>info <span class=\"token assign-left variable\">component</span><span class=\"token operator\">=</span>tsdb <span class=\"token assign-left variable\">msg</span><span class=\"token operator\">=</span><span class=\"token string\">\"Deletion of corrupted mmap chunk files failed, discarding chunk files completely\"</span> <span class=\"token assign-left variable\">err</span><span class=\"token operator\">=</span><span class=\"token string\">\"cannot handle error: iterate on on-disk chunks: out of sequence m-mapped chunk for series ref 946594555, last chunk: [1718071739971, 1718075459971], new: [1718049629971, 1718053199971]\"</span></code></pre></div>\n<p>It seems like it's stuck in the running state, where the pod is not yet ready. Let's describe the pod to see what is wrong:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">State:       Running\n    Started:   Tue, <span class=\"token number\">14</span> Jun <span class=\"token number\">2024</span> <span class=\"token number\">10</span>:04:03 +0200\nLast State:  Terminated\n    Reason:    OOMKilled</code></pre></div>\n<p>Ah, there it is. Prometheus is indeed running, but it got terminated due to an OOMKill‚Ää‚Äî‚Äärunning out of memory. It seems Prometheus is in the midst of recovering from the Write Ahead Log (WAL), which might be causing the memory spike. This could stem from an error during recovery or a restart, where Prometheus doesn't have enough memory to write everything into the WAL.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 403px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAETUlEQVR42lVTWW8aVxid31apUp+aVKrUxk0fWqlK0lRVWvUhSZc0adLadb3U2Klt8LAMBowNwQYBJoAxywwwMCtzh2UAD8NObIMhTmwH04sfKlW6m66+c893vns+xL+zwEaXM4QaJFGQ1P5vkGj26iCSOpGEq1aIr2WiqICjEoP5HNMIG9VJNFritbWcuSqaq9n/hukAmIvAUs8aK8AgC+sSbfDvPnLHvrI5brcKW3TkOZIOa5moCn85SYXnyzyMM8uCqSIYOdrqTcf96VhecNVKESZhY0IrVu+tsHJPbZuogU1ybxFJ76PxwFzY+0cyNFdkdZAB4pWMIciTLl52ChUyR9fy20XhBeHTW713QXsRtX5dF62p0BJChjTEyymn6X7Q+ThPaSqiWR6D9QEGt+R7dqAAztGRo61aCsQN645nWGh1zfigU7CSEJzc0+TSmnm9ymRfbuUtMGdIroibnVc1tnZMF6TGQazAb6fCagZXU+E1PLCSCK6ClCERUCEcYUgldfdMrgWvp1nYgDmXeX2nSo1Gozf9djW3XQFYKqLJ8JTbZcP0i3tBr8ezHfTvBJzTiFf/NIA9fjI/Oz37O74zPS6yYD17078cjaqSv8yh1ayFwbVbG+qd7a3nS/Mej1On1Ths60HXX8jPE9d/+ezaTzc//O76+8aZHxoFU1PGIe3rflsGJuXq84Skwe/REft29w5KJd1+N5aIbMZ8fyPffPrBszsTz+7c+PXLT14s/wgFdxq5i3fDdj1bYrAyi5U5Y5nDJFqdJZdLrDaXWilQGgVgYfcs4rXP0KElLrrKRlYFYi2X1ucoY5bayKUNILGSTVvEFCaSRinjLYFAZuw2vZDQllhs1z6J8HFjiUNlYKjnLTBDRTTJHHqoxA/rVLuCvz3tvBm0z89OoJDhu7Oz087ZaXvQq799raQjqwgT1af352L+P+noYhVgLG0LUni1WRtHX8KqjeA8P393tY/qjVa704GHi7MuEViEYB0RmAl5pqiwKkdju1R6l0jhjHA5HELAxfk5EAGO48ViMRKJuJxOnucg+LBBJ/zzSGofjfmmHMb7UfeTOGEM0lyOjWeAMByOqQaDgc1mU6lUdrsNPnF0dAwvj9pSBayToedjb4ukelIzZ3f90yz7WTpFhpwNpQyDqlUlmUz6fD7I2e/3xxKGF92jAymz1ShskHtLiJAwRKLot2bvosvRaeYIUZAKAoyjGQbCeJ4/OeldKb8c9FrHbakkbMECN6XNMThonvQbnz6cnsE21497h7Gi1DvpHh225YNit9u9HMJSjd6edg/y3gKjL3D2smCFXmjAxoAt+ejzj3774uPvr73nt5ub/RNZkbvHR/VatdlQBqevAZdu1cu10l6RXauKJmh7aBjYPBCcgpof3r65cP/u01s3WJIINVvFfLjAWmsVut9t9Lqv5DzOESslzqAAS0UYu7UCTAeZdZh2dHf+X8slnBOXkWHmAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cardinality\" title=\"\" src=\"/static/4457980b0539bcef67ad94fef9940f92/045fd/cardinality.png\" srcset=\"/static/4457980b0539bcef67ad94fef9940f92/04472/cardinality.png 170w,\n/static/4457980b0539bcef67ad94fef9940f92/9f933/cardinality.png 340w,\n/static/4457980b0539bcef67ad94fef9940f92/045fd/cardinality.png 403w\" sizes=\"(max-width: 403px) 100vw, 403px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>One potential solution could be allocating more memory to Prometheus and analyzing why the WAL is getting clogged up. Essentially, we need to investigate what changed to suddenly cause this spike in memory usage in our once serene environment.</p>\n<p>The issue persisted due to the WAL replay process requiring 2‚Äì3 times more memory than the running Prometheus instance. Despite running smoothly with around 30Gi of memory usage, the WAL replay process demanded over 50+Gi, ultimately leading to OOMKilled crashes during startup. Simply increasing the RAM limit wasn't a viable solution, as the excessive memory usage occurred specifically during the replay phase.</p>\n<p>This problem aligns with a longstanding issue on GitHub since 2020, where users have consistently reported challenges managing Prometheus' memory during WAL replay. We encountered similar difficulties during our upgrade process, highlighting the critical need for resolution.</p>\n<h3 id=\"-understanding-memory-overheads-in-wal-replay\" style=\"position:relative;\"><a href=\"#-understanding-memory-overheads-in-wal-replay\" aria-label=\" understanding memory overheads in wal replay permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üí° Understanding Memory Overheads in WAL Replay</h3>\n<p>In the past, WAL replay often caused significant overhead, leading to unexpected out-of-memory (OOM) situations. For instance, if your Prometheus was already running at 70% of its memory limit and the overhead during replay surged by 300%, it could easily lead to crashes. Additionally, increased CPU usage during replay, especially in low CPU environments like Kubernetes, could slow down processes like garbage collection, resulting in slower memory release.</p>\n<p>However, recent benchmarks of Prometheus versions at Google show a different picture. While there's been a noticeable 2x increase in CPU usage during replay, the memory overhead, including heap and working sets, is only around 1‚Äì5%. This raises the question: are the reported OOM issues symptoms of a larger problem, with the replay OOM merely surfacing it?</p>\n<p>Currently, two prevalent scenarios appear:</p>\n<ol>\n<li><strong>Excessive Data Collection</strong>: If your Prometheus setup scrapes too many series or samples, it's prone to OOM crashes during replay, regardless of the memory overhead.</li>\n<li><strong>Running Close to Memory Limits</strong>: Even a slight overhead during replay can trigger OOM crashes if Prometheus is already running near its memory limit, such as at 95%.</li>\n</ol>\n<p>These issues often revolve around cardinality‚Ää‚Äî‚Ääthe combination of all label values per metric. High cardinality metrics, like those tracking multiple URLs or response codes, can quickly escalate memory usage. In short, much of Prometheus' memory woes can be attributed to cardinality.</p>\n<h3 id=\"-how-does-remote-write-work\" style=\"position:relative;\"><a href=\"#-how-does-remote-write-work\" aria-label=\" how does remote write work permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîÑ How Does Remote Write Work?</h3>\n<p>The remote write reads data from Prometheus' <a href=\"https://en.wikipedia.org/wiki/Write-ahead_logging\" target=\"_blank\" rel=\"noopener noreferrer\">write ahead log</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 66.47058823529413%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB9ElEQVR42o1T7XLTMBD0Q+ZdYKZ9nfKfJ+B38g+GklJIGju2ZTfEH7Ily7Kk5STXAYYwxTM3kke6vb3dU4QrnzEOVavQtD2OaY40Y4iPGXJWousHcDHiX190FdBapM8SScqQpgnatoVSA4qCoa4r9FK9DuicCxEA9USJHE3D0XKBXqgQQo7oOglBLJ2ZKMm+ztAZAys6sCxFkzxBJd8xHL5B5QmG4x6m47B6hB0krBR/Ay6smqYhrbJQWcseGSvw43SCnXQoEsKaSxe0IdAZ0L3EhaG/xDkHK4oAoKnyicDquoYlPX0YAlzuWtqbaZoB6QzEmHSCo9zIC34+nwOg9dWJoR2HUHEB8+DhnPYTARVUuK6q0IkiCZ7zDKws0Sc7RJ6FT/Ch6TK8huToROuk9UWOvqdkRcYIMf/zFkZJGAKtH+9R7b5CPn5C5A+32y3iOH5haMJFX6jvOnK1Q0UdeCBflDEW9HOLhn4VxL7nMGRm5FtIknnWZpcnGHJQEptxHEOLilZNbJ2dx0SfS+jdl+D2f42NrzRR214fvwYQApTE1psjHz5CfHgfDMQfPrtfLl/GwScTSLzf4VQWeLj/jJu3b/Du7i6MUZbEKFke7uC3nKsMF9BhGLDebHA4xFivN1itVri5vaVnmGK/f6LYB4OuPb2ffzTryGFZsqsAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"wal\" title=\"\" src=\"/static/ae8f0b6c864a690e0f78a8be41523357/c5bb3/wal.png\" srcset=\"/static/ae8f0b6c864a690e0f78a8be41523357/04472/wal.png 170w,\n/static/ae8f0b6c864a690e0f78a8be41523357/9f933/wal.png 340w,\n/static/ae8f0b6c864a690e0f78a8be41523357/c5bb3/wal.png 680w,\n/static/ae8f0b6c864a690e0f78a8be41523357/b12f7/wal.png 1020w,\n/static/ae8f0b6c864a690e0f78a8be41523357/d9b5d/wal.png 1224w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Data generated by scrape is written to the WAL, so this essentially gives us a 2- to 3-hour buffer on disk of data for remote write. The RW system now has a subroutine that reads the WAL and passes the data back to remote write.</p>\n<p>Remote write still has a small in-memory buffer, and the routine reading the WAL pauses where it is if it's not able to append new data to the buffer. This means we no longer drop data if the buffer is full, and the buffer doesn't need to be large enough to handle a longer outage.</p>\n<p>As long as the remote endpoint isn't down for hours, remote write no longer loses data (with some caveats, like Prometheus restarts), since the WAL is truncated every two hours or so.</p>\n<h3 id=\"Ô∏è-issue-resolutions\" style=\"position:relative;\"><a href=\"#%EF%B8%8F-issue-resolutions\" aria-label=\"Ô∏è issue resolutions permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üõ†Ô∏è Issue Resolutions</h3>\n<p>If you've never experienced this issue before (lucky you!), here's a handy solution I found effective. Since Prometheus may not be up and running to utilize PromQL for detecting potential issues, we need an alternative method to identify high cardinality. One approach is to get hands-on with some kubectl exec magic:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">kubectl <span class=\"token builtin class-name\">exec</span> <span class=\"token parameter variable\">-it</span> <span class=\"token parameter variable\">-n</span> monitoring pods/prometheus-prometheus-kube-prometheus-prometheus-0 -- <span class=\"token function\">sh</span></code></pre></div>\n<p>Then, run the Prometheus TSDB analysis:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">/prometheus $ promtool tsdb analyze <span class=\"token builtin class-name\">.</span></code></pre></div>\n<p>This analysis will provide insights into metrics with high cardinality, like <code class=\"language-text\">haproxy_server_http_responses_total</code>, which might be causing memory issues. In such cases, updating or optimizing the problematic metric, such as haproxy, can alleviate memory strain.</p>\n<p>Alternatively, consider increasing Prometheus' memory allocation or deploying it to a specific node group with ample memory resources.</p>\n<p>Here are some additional strategies to mitigate memory overhead and OOM crashes:</p>\n<ul>\n<li><strong>Verify Memory Overhead</strong>: Ensure that the memory overhead during replay is within acceptable limits (e.g., 10‚Äì15%). Running Prometheus close to its memory limit is risky due to dynamic garbage collection and limited room for unexpected cardinality spikes or queries.</li>\n<li><strong>Optimize Storage and Scraping</strong>: Regularly optimize Prometheus' storage, scraping, and remote write configurations to reduce memory usage. Upgrading to newer releases can often provide optimizations in this regard.</li>\n<li><strong>Automate Recovery from OOM</strong>: Implement auto-recovery mechanisms to handle OOM crash loops, such as automatically deleting the Write-Ahead Log (WAL) on OOM events. This ensures smoother recovery from memory-related issues.</li>\n<li><strong>Implement Scraping Limits</strong>: Consider introducing forceful scrape limits to prevent Prometheus from scraping targets when memory usage exceeds a certain threshold. This proactive approach can help avoid memory-intensive situations and potential OOM crashes.</li>\n</ul>\n<p>By implementing these strategies, you can effectively manage Prometheus' memory challenges and ensure smooth operation in your monitoring environment.</p>\n<h3 id=\"-conclusion\" style=\"position:relative;\"><a href=\"#-conclusion\" aria-label=\" conclusion permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üîö Conclusion</h3>\n<p>Dealing with Prometheus OOM errors during WAL replay can be challenging. By understanding the root causes, such as excessive data collection and high cardinality metrics, and implementing solutions like optimizing storage and scraping configurations, increasing memory allocations, and setting up auto-recovery mechanisms, you can mitigate these issues.</p>\n<p><strong>Thank You üñ§</strong></p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>","timeToRead":5,"rawMarkdownBody":"\n> **When Prometheus Can't Keep Up with the WAL üìà**\n\n## üìó Introduction\n\nHave you ever had Prometheus crash due to an out-of-memory error while trying to catch up by reading the Write-Ahead Log (WAL)? It's a frustrating problem, but let's check it out.\n\nPrometheus is great for monitoring, but when it restarts, it needs to process data from the Write-Ahead Log (WAL), which can be memory-intensive. This often leads to OOMKilled crashes, especially if Prometheus is already running close to its memory limits.\n\nThe issue usually stems from either collecting too much data or running too close to memory limits. This has been a long-standing concern, with [reports dating back to an open issue since 2020 on GitHub](https://github.com/prometheus/prometheus/issues/6934), highlighting the significant challenges faced by users in managing Prometheus' memory during WAL replay.\n\n### ‚ÅâÔ∏è The Problem\n\n<br>\n\nhttps://giphy.com/gifs/strangerthings-netflix-stranger-things-ka55CqnDNjQ7iIKtRa\n\nWhile upgrading [the Helm chart of kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack), we noticed several pods were not ready, including `prometheus-prometheus-operator-prometheus-0`, which showed a status of `3/4 Running` with a recent termination due to being OOMKilled.\n\nThe logs revealed the root cause:\n\n```shell\nts=2024‚Äì06‚Äì14T09:49:10.383Z caller=head.go:840 level=info component=tsdb msg=\"Deletion of corrupted mmap chunk files failed, discarding chunk files completely\" err=\"cannot handle error: iterate on on-disk chunks: out of sequence m-mapped chunk for series ref 946594555, last chunk: [1718071739971, 1718075459971], new: [1718049629971, 1718053199971]\"\n```\n\nIt seems like it's stuck in the running state, where the pod is not yet ready. Let's describe the pod to see what is wrong:\n\n```shell\nState:       Running\n    Started:   Tue, 14 Jun 2024 10:04:03 +0200\nLast State:  Terminated\n    Reason:    OOMKilled\n```\n\nAh, there it is. Prometheus is indeed running, but it got terminated due to an OOMKill‚Ää‚Äî‚Äärunning out of memory. It seems Prometheus is in the midst of recovering from the Write Ahead Log (WAL), which might be causing the memory spike. This could stem from an error during recovery or a restart, where Prometheus doesn't have enough memory to write everything into the WAL.\n\n![cardinality](./cardinality.png)\n\nOne potential solution could be allocating more memory to Prometheus and analyzing why the WAL is getting clogged up. Essentially, we need to investigate what changed to suddenly cause this spike in memory usage in our once serene environment.\n\nThe issue persisted due to the WAL replay process requiring 2‚Äì3 times more memory than the running Prometheus instance. Despite running smoothly with around 30Gi of memory usage, the WAL replay process demanded over 50+Gi, ultimately leading to OOMKilled crashes during startup. Simply increasing the RAM limit wasn't a viable solution, as the excessive memory usage occurred specifically during the replay phase.\n\nThis problem aligns with a longstanding issue on GitHub since 2020, where users have consistently reported challenges managing Prometheus' memory during WAL replay. We encountered similar difficulties during our upgrade process, highlighting the critical need for resolution.\n\n### üí° Understanding Memory Overheads in WAL Replay\n\nIn the past, WAL replay often caused significant overhead, leading to unexpected out-of-memory (OOM) situations. For instance, if your Prometheus was already running at 70% of its memory limit and the overhead during replay surged by 300%, it could easily lead to crashes. Additionally, increased CPU usage during replay, especially in low CPU environments like Kubernetes, could slow down processes like garbage collection, resulting in slower memory release.\n\nHowever, recent benchmarks of Prometheus versions at Google show a different picture. While there's been a noticeable 2x increase in CPU usage during replay, the memory overhead, including heap and working sets, is only around 1‚Äì5%. This raises the question: are the reported OOM issues symptoms of a larger problem, with the replay OOM merely surfacing it?\n\nCurrently, two prevalent scenarios appear:\n1. **Excessive Data Collection**: If your Prometheus setup scrapes too many series or samples, it's prone to OOM crashes during replay, regardless of the memory overhead.\n2. **Running Close to Memory Limits**: Even a slight overhead during replay can trigger OOM crashes if Prometheus is already running near its memory limit, such as at 95%.\n\nThese issues often revolve around cardinality‚Ää‚Äî‚Ääthe combination of all label values per metric. High cardinality metrics, like those tracking multiple URLs or response codes, can quickly escalate memory usage. In short, much of Prometheus' memory woes can be attributed to cardinality.\n\n### üîÑ How Does Remote Write Work?\n\nThe remote write reads data from Prometheus' [write ahead log](https://en.wikipedia.org/wiki/Write-ahead_logging).\n\n![wal](./wal.png)\n\nData generated by scrape is written to the WAL, so this essentially gives us a 2- to 3-hour buffer on disk of data for remote write. The RW system now has a subroutine that reads the WAL and passes the data back to remote write.\n\nRemote write still has a small in-memory buffer, and the routine reading the WAL pauses where it is if it's not able to append new data to the buffer. This means we no longer drop data if the buffer is full, and the buffer doesn't need to be large enough to handle a longer outage.\n\nAs long as the remote endpoint isn't down for hours, remote write no longer loses data (with some caveats, like Prometheus restarts), since the WAL is truncated every two hours or so.\n\n### üõ†Ô∏è Issue Resolutions\n\nIf you've never experienced this issue before (lucky you!), here's a handy solution I found effective. Since Prometheus may not be up and running to utilize PromQL for detecting potential issues, we need an alternative method to identify high cardinality. One approach is to get hands-on with some kubectl exec magic:\n\n```sh\nkubectl exec -it -n monitoring pods/prometheus-prometheus-kube-prometheus-prometheus-0 -- sh\n```\n\nThen, run the Prometheus TSDB analysis:\n\n```sh\n/prometheus $ promtool tsdb analyze .\n```\n\nThis analysis will provide insights into metrics with high cardinality, like `haproxy_server_http_responses_total`, which might be causing memory issues. In such cases, updating or optimizing the problematic metric, such as haproxy, can alleviate memory strain.\n\nAlternatively, consider increasing Prometheus' memory allocation or deploying it to a specific node group with ample memory resources.\n\nHere are some additional strategies to mitigate memory overhead and OOM crashes:\n\n- **Verify Memory Overhead**: Ensure that the memory overhead during replay is within acceptable limits (e.g., 10‚Äì15%). Running Prometheus close to its memory limit is risky due to dynamic garbage collection and limited room for unexpected cardinality spikes or queries.\n- **Optimize Storage and Scraping**: Regularly optimize Prometheus' storage, scraping, and remote write configurations to reduce memory usage. Upgrading to newer releases can often provide optimizations in this regard.\n- **Automate Recovery from OOM**: Implement auto-recovery mechanisms to handle OOM crash loops, such as automatically deleting the Write-Ahead Log (WAL) on OOM events. This ensures smoother recovery from memory-related issues.\n- **Implement Scraping Limits**: Consider introducing forceful scrape limits to prevent Prometheus from scraping targets when memory usage exceeds a certain threshold. This proactive approach can help avoid memory-intensive situations and potential OOM crashes.\n\nBy implementing these strategies, you can effectively manage Prometheus' memory challenges and ensure smooth operation in your monitoring environment.\n\n### üîö Conclusion\n\nDealing with Prometheus OOM errors during WAL replay can be challenging. By understanding the root causes, such as excessive data collection and high cardinality metrics, and implementing solutions like optimizing storage and scraping configurations, increasing memory allocations, and setting up auto-recovery mechanisms, you can mitigate these issues.\n\n**Thank You üñ§**\n\n<br>\n\n**_Until next time, „Å§„Å•„Åè üéâ_**\n\n> üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  **_Until next time üéâ_**\n\nüöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:\n\n**‚ôªÔ∏è LinkedIn:** https://www.linkedin.com/in/rajhi-saif/\n\n**‚ôªÔ∏è X/Twitter:** https://x.com/rajhisaifeddine\n\n**The end ‚úåüèª**\n\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n\n**üìÖ Stay updated**\n\nSubscribe to our newsletter for more insights on AWS cloud computing and containers.\n","wordCount":{"words":1173},"frontmatter":{"id":"e3781588b27a4b0373bffe42","path":"/blog/prometheus-manage-memory-overload/","humanDate":"Oct 29, 2024","fullDate":"2024-10-29","title":"Prometheus Restart Troubles: Managing Memory Overload üß†","keywords":["Prometheus","memory overload","WAL","monitoring","kubernetes"],"excerpt":"Explore strategies to manage memory overload in Prometheus, ensuring stability and performance even when dealing with large Write-Ahead Logs (WAL).","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACtklEQVR42j2SS29SURSF718zJh04dugPMDoyPhMHmmjUJupEEx+Jg0Ztq619FyiXZy99UCgVblsoBS6vUqA8boFCsS2fG2oc7Oydc/ZZe+21jrKe3CGRSxCIBAnHwmzt/kaPb0sdIRLX0fe3iexJvafzOxoe5NDOFvu5JEYhTerAIClhFAw2krsoiUODbq2Ic26KoEdlzWHFsziDc3YS98I0q+oimnUO9/wU4bVlQpqLZcssZ80qzXKeuoCetWrQbZKWWokKu65Zpt2ocCK5Hy554BJQzW7BOvWDdRm0ta7R7t/XS7SEQEtySVjmElEK6TiN8gGJg5QAZvfZlKkrLtvgoXdpAU214HPY2FzxoDks6ME1fE4rqrDs39mmfxIStqfCsnN8NBhyXMyKDAmUvXwS2sf8aVS5ODHp1stEVrysCbtV2wIBtx2/U8Bl2Fmzxvm/6Pf25F1X6o5s12ubpERHZTsTx61vMB3w/o+JVQejy3a+eW2M++z81JYYW7Yy6Xczv6kxIz39bNn0UjnKcNGqcN6qDsxRdrJxVqMhnLofe3gdl4D7YkGCySC+6AaqnGnGLlo6hms7gDPiH5y5pX88uMWOUeXwqMFJoz5w+nJlceiifbkCp8ccletMeaqk0nXEQjqeWTpzI/REq95pEzom7ZaJanzFufuWxxvv0YsRDop5lJg41dem725f4LbE89ECw2M5Ho6aGHOT1N49pDLyhsrnZ3TOu3TqRRpmlYmJJ3z8dIMXX54R2wuQE6eVuFgtSEKyKjrUBiK/Gi/xerzAo+8N8qqN1pfnmD8+0Bh7x3mvK6aIu0Lg9s07DA1d5+qVa6w4HZTNEopffndeLM8eZsgUMhyWMwRiaYZ/pVBDBqVanqRmJalOks3tky3myElvWgx4OvySW/fucvvBfVyaGz2f4C/kAfbrUk1tkwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png","srcSet":"/static/dee8a66c7ee1ff012bb686e835e8e69c/6f128/prometheus-cover.png 750w,\n/static/dee8a66c7ee1ff012bb686e835e8e69c/dc9a9/prometheus-cover.png 1080w,\n/static/dee8a66c7ee1ff012bb686e835e8e69c/cb4db/prometheus-cover.png 1366w,\n/static/dee8a66c7ee1ff012bb686e835e8e69c/f9343/prometheus-cover.png 1600w","sizes":"100vw"},"sources":[{"srcSet":"/static/dee8a66c7ee1ff012bb686e835e8e69c/fdac4/prometheus-cover.webp 750w,\n/static/dee8a66c7ee1ff012bb686e835e8e69c/0f929/prometheus-cover.webp 1080w,\n/static/dee8a66c7ee1ff012bb686e835e8e69c/fc20e/prometheus-cover.webp 1366w,\n/static/dee8a66c7ee1ff012bb686e835e8e69c/24ca0/prometheus-cover.webp 1600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.55625}}},"coverCredits":"Photo by Saifeddine Rajhi"}}},"pageContext":{"prevThought":{"frontmatter":{"path":"/blog/container-runtimes-cri-overview/","title":"Container Runtimes and CRI: A Technical Overview üõ†Ô∏è","date":"2024-10-29 19:06:00"},"excerpt":"A Deep Dive into the Evolution Overview üëÄ Containerization technologies have revolutionized the way we build, deploy, and manage‚Ä¶","html":"<blockquote>\n<p><strong>A Deep Dive into the Evolution</strong></p>\n</blockquote>\n<h2 id=\"overview-\" style=\"position:relative;\"><a href=\"#overview-\" aria-label=\"overview  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Overview üëÄ</h2>\n<p>Containerization technologies have revolutionized the way we build, deploy, and manage applications. Docker, Kubernetes, and other popular containerization tools have made it possible to deliver applications more quickly, reliably, and efficiently than ever before.</p>\n<p>At the heart of containerization technology are a number of building blocks, including container runtimes and the Container Runtime Interface (CRI).</p>\n<p>Container runtimes are responsible for creating, running, and managing containers. They provide a layer of abstraction between the host operating system and the container, allowing containers to be isolated from each other and from the host.</p>\n<p>The CRI is a standard interface that allows different container runtimes to be used with Kubernetes. This makes it easier to switch between different container runtimes without having to make major changes to Kubernetes.</p>\n<p>In this blog post, we will explore the evolution of container runtimes and the CRI in more detail.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 25.294117647058822%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABM0lEQVR42lWOW0sCYRRF5/dHRUW9BdJDPkQEEUWQZtJFywLTyhpH/eYaI07f3Md0bDVCLx1YLNh7PxzFdgNWN3Y4O6/SVT/RdLdgjLAnmMMRnm0w0AxMyyXyJR3d42SU8W1q+Kag70x57wuazTuklChhPGV9bYXbmzq6EzDxAsIoI0m/ee72EEMNZyyxbJe+KhCWg2qYOIaBYzt8DMaYwsC2LZIkQTmuPFI6rLJbrrFZqrC9V2GrdEHp6J6r0zM6jSt0V6JqgspFi+7rG63rGrdWxJMjMV/6WCNBT+hkaYpycKCyX+7R7g15aA9pPS89oNUZISceaRTi+z5hUHweRgSFPU+SpglRHPPlecgil2HINMtQGpcx9/UY+GGx4N/N85zZbMZ8Pv9Hnhde5n9d/sdy+wsXImp9Fakn7QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cris\" title=\"\" src=\"/static/046aac5d02b575e8156934d91d50b016/c5bb3/cris.png\" srcset=\"/static/046aac5d02b575e8156934d91d50b016/04472/cris.png 170w,\n/static/046aac5d02b575e8156934d91d50b016/9f933/cris.png 340w,\n/static/046aac5d02b575e8156934d91d50b016/c5bb3/cris.png 680w,\n/static/046aac5d02b575e8156934d91d50b016/b12f7/cris.png 1020w,\n/static/046aac5d02b575e8156934d91d50b016/b5a09/cris.png 1360w,\n/static/046aac5d02b575e8156934d91d50b016/aa440/cris.png 1500w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<div class=\"image-title\"><a href=\"https://landscape.cncf.io/guide#runtime--container-runtime\">Source</a></div>\n<p>Now, welcome to the world of containers!</p>\n<p>Lots of applications can run containers, whereas every application would have a slightly different opinion about what a container runtime should do and support. For example, systemd is able to run containers via <a href=\"https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html\" target=\"_blank\" rel=\"noopener noreferrer\">systemd-nspawn</a>, and <a href=\"https://nixos.org/\" target=\"_blank\" rel=\"noopener noreferrer\">NixOS</a> has integrated <a href=\"https://nixos.org/nixos/manual/#ch-containers\" target=\"_blank\" rel=\"noopener noreferrer\">container management</a> as well. Not to mention all the other existing container runtimes like <a href=\"https://cri-o.io/\" target=\"_blank\" rel=\"noopener noreferrer\">CRI-O</a>, <a href=\"https://katacontainers.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Kata Containers</a>, <a href=\"https://firecracker-microvm.github.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Firecracker</a>, <a href=\"https://github.com/google/gvisor\" target=\"_blank\" rel=\"noopener noreferrer\">gVisor</a>, <a href=\"https://containerd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">containerd</a>, <a href=\"https://linuxcontainers.org/\" target=\"_blank\" rel=\"noopener noreferrer\">LXC</a>, <a href=\"https://github.com/opencontainers/runc\" target=\"_blank\" rel=\"noopener noreferrer\">runc</a>, <a href=\"https://nabla-containers.github.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Nabla Containers</a> and many more.</p>\n<p>A lot of them are now part of the <a href=\"https://www.cncf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Cloud Native Computing Foundation (CNCF)</a> and their <a href=\"https://landscape.cncf.io/\" target=\"_blank\" rel=\"noopener noreferrer\">huge landscape</a>.</p>\n<h2 id=\"a-brief-history-\" style=\"position:relative;\"><a href=\"#a-brief-history-\" aria-label=\"a brief history  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>A Brief History üìú</h2>\n<p>After the invention of cgroups back in 2008, a project called Linux Containers (LXC) started to pop up in the wild, which should revolutionize the container world. LXC combined cgroup and namespace technologies to provide an isolated environment for running applications. You may know that we sometimes live in a parallel world. This means that Google started its own containerization project in 2007 called <a href=\"https://github.com/google/lmctfy\" target=\"_blank\" rel=\"noopener noreferrer\">Let Me Contain That For You (LMCTFY)</a>, which works mainly at the same level as LXC does. With LMCTFY, Google tried to provide a stable and API-driven configuration without users having to understand the details of cgroups and its internals.</p>\n<p>If we now look back into 2013, we see that there was a tool written called Docker, which was built on top of the already existing LXC stack. One invention of Docker was that the user is now able to package containers into images to move them between machines. Docker were the first ones who tried to make containers a standard software unit, as they state in their <a href=\"https://github.com/moby/moby/blob/0db56e6c519b19ec16c6fbd12e3cee7dfa6018c5/README.md\" target=\"_blank\" rel=\"noopener noreferrer\">¬´Standard Container Manifesto¬ª</a>.</p>\n<p>Some years later, they began to work on <a href=\"https://github.com/docker/libcontainer\" target=\"_blank\" rel=\"noopener noreferrer\">libcontainer</a>, a <a href=\"https://golang.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Go</a> native way to spawn and manage containers. LMCTFY was abandoned during that time too, whereas the core concepts and major benefits of LMCTFY were ported into libcontainer and Docker.</p>\n<p>We are now back in 2015, where projects like Kubernetes hit version 1.0. A lot of stuff was ongoing during that time: The CNCF was founded as part of the <a href=\"https://www.linuxfoundation.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Linux Foundation</a> with the target to promote containers. The <a href=\"https://www.opencontainers.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Open Container Initiative (OCI)</a> was founded in 2015 as well, as an open governance structure around the container ecosystem.</p>\n<h2 id=\"open-container-initiative-oci-Ô∏è\" style=\"position:relative;\"><a href=\"#open-container-initiative-oci-%EF%B8%8F\" aria-label=\"open container initiative oci Ô∏è permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Open Container Initiative (OCI) üõ†Ô∏è</h2>\n<p>OCI, short for the Open Container Initiative, is indeed a community project that was established in 2015 to address the need for containerization standards. It is a collaborative effort within the container ecosystem to develop open industry standards for container formats and runtime. The OCI's primary goal is to ensure interoperability between container technologies, making it easier to create and run containerized applications across different platforms and container runtimes.</p>\n<p><strong>Key points about OCI include:</strong></p>\n<ul>\n<li><strong>Standardization:</strong> OCI defines open standards for container images and runtimes. This includes the OCI Image Format specification for container images and the OCI Runtime Specification for container runtimes.</li>\n<li><strong>Interoperability:</strong> By adhering to OCI specifications, container runtimes, and container images from various vendors can work seamlessly together. This promotes compatibility and flexibility in choosing containerization tools.</li>\n<li><strong>Ecosystem Benefits:</strong> OCI standards have been widely adopted in the container ecosystem. This adoption has led to the development of a rich ecosystem of container tools, orchestrators, and platforms that are OCI-compliant.</li>\n</ul>\n<p>On the other side of the container engine is the container runtime controlled through the Open Container Initiative specs. There are two specifications produced by the OCI: OCI-runtime and OCI-image. These specs work together to define how to start containers through the container runtime.</p>\n<p>The OCI runtime spec defines how to interact with a container runtime to control the lifecycle of a container. While it might seem redundant (given that CRI seems to define the same thing), it adds another layer of contract definition to the architecture. As with CRI, this layer of contract gives some guarantees to the system regarding how the developer's code will run.</p>\n<p>The container engine provides the runtime with a filesystem bundle (conforming to the OCI-image spec) to run. Within this filesystem bundle are all the files needed in the runtime and a configuration specifying what to run in the container (also known as its entrypoint).</p>\n<p>For some extremely dense reading, the specs can be found <a href=\"https://github.com/opencontainers/runtime-spec\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> and <a href=\"https://github.com/opencontainers/image-spec\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p>\n<p>If we give an example of OCI Runtime, a simple picture is to imagine a technology such as USB that many vendors produce, whether any version of PC or OS can use USB. That's because they follow USB standards, which OCI Runtime is a similar standard. Same thing, but only used with Container Runtimes.</p>\n<h3 id=\"what-is-container-runtime\" style=\"position:relative;\"><a href=\"#what-is-container-runtime\" aria-label=\"what is container runtime permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>What is Container Runtime?</h3>\n<p>Container runtimes are described as the software responsible for executing containerized applications. They take container images (which specify how an application should look) and launch applications within containers, providing them with the necessary resources.</p>\n<p><strong>Problem Addressed by Container Runtimes:</strong></p>\n<ul>\n<li><strong>Standardization:</strong> Container runtimes ensure that containerized applications are launched in a standardized manner across different environments.</li>\n<li><strong>Security:</strong> They establish security boundaries to prevent unauthorized access to containerized applications.</li>\n<li><strong>Isolation:</strong> They ensure isolation to protect applications from interfering with each other, even if one of them crashes.</li>\n<li><strong>Resource Allocation:</strong> They allocate and manage resources like CPU, storage, and memory for containerized applications.</li>\n</ul>\n<p><strong>How Container Runtimes Help:</strong></p>\n<ul>\n<li><strong>Standardization:</strong> Container runtimes launch applications in a consistent way, regardless of the environment, ensuring predictability.</li>\n<li><strong>Security:</strong> Some container runtimes, like CRI-O and gVisor (via \"runsc\"), emphasize security and harden the security boundaries.</li>\n<li><strong>Isolation:</strong> Container runtimes enforce isolation to prevent interference between applications.</li>\n<li><strong>Resource Allocation:</strong> They set resource limits to prevent one application from consuming all available resources, which could affect other applications.</li>\n</ul>\n<p><strong>Technical Overview:</strong></p>\n<p>Container runtimes vary in their capabilities and focus:</p>\n<ul>\n<li><a href=\"https://containerd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Containerd</a> and <a href=\"https://cri-o.io/\" target=\"_blank\" rel=\"noopener noreferrer\">CRI-O</a>: These are standard container runtime implementations.</li>\n<li><a href=\"https://katacontainers.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Kata</a>: Allows running containers as virtual machines (VMs), expanding the use of containers to other technologies.</li>\n<li><a href=\"https://gvisor.dev/\" target=\"_blank\" rel=\"noopener noreferrer\">gVisor</a> (via runsc): Provides an additional security layer between containers and the host operating system, enhancing security.</li>\n<li><a href=\"https://github.com/opencontainers/runc\" target=\"_blank\" rel=\"noopener noreferrer\">runc</a>: runc is a separate container runtime associated with the Open Container Initiative (OCI) standard. It serves as the reference implementation of the OCI runtime specification and is used to run containers in a standardized way.</li>\n<li><a href=\"https://github.com/containers/crun\" target=\"_blank\" rel=\"noopener noreferrer\">crun</a>: A fast and lightweight fully featured OCI runtime and C library for running containers.</li>\n</ul>\n<p>The CRI interface is built on gRPC and Protobuf over a Unix socket. The spec can be found on <a href=\"https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/cri/runtime/v1alpha2/api.proto\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub</a>.</p>\n<h2 id=\"putting-it-all-together-kubernetes-and-cri-\" style=\"position:relative;\"><a href=\"#putting-it-all-together-kubernetes-and-cri-\" aria-label=\"putting it all together kubernetes and cri  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Putting it all together: Kubernetes and CRI üöÄ</h2>\n<p>The CRI gives Kubernetes the flexibility to run a variety of container managers and container runtimes.</p>\n<p>In Kubernetes, a container runtime is responsible for managing the lifecycle of containers. It is the component that actually runs the container images and provides an interface between Kubernetes and the container.</p>\n<p>Kubernetes could use any container runtime that implements CRI to manage pods, containers, and container images. Docker is the most common container runtime used in production Kubernetes environments, but containerd (initiated by Docker Inc. &#x26; donated to CNCF in March of 2017) may prove to be a better option. For more details, you could refer to the <a href=\"https://kubernetes.io/blog/2017/11/containerd-container-runtime-options-kubernetes/\" target=\"_blank\" rel=\"noopener noreferrer\">official blog</a>.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACH0lEQVR42nVS30/TUBTev2V8EAnDFaJvvBoffPDBHzEx6hIBp6AZGBMIC8p+OHiQhIQH0WyT6ZjtfjjEtVScyjJhZV3b3ULbzXVbb9t5u81FH/xycvOdm/ud75x7r62NYLaddGQw4T+fXhlNLnciOJIMYnEfhgewVBBL9mIktXyW8F0jN3TDQDpbu4O7dOh0/Nm5RGCY8KN1CPcN4V57xDMcW7ITfntnE0u8cBCBM7j3OvnqHzGC1myZptnlOtR1CHtcgyjtcqhphq73JTbdtGqsHOzYo4ujcd9akfoqcY7NRXvYM0mGYnx+MLIw8GbOnYtJzfrYh6Aj7s2IDJIYpmkzOm4xvuBMbUxuh3HhZ/GX9HD33f1sZLWQ/SJx03R0mnr7ms2pUFv4np79RuSrYl9sOWcB6co8niJnKHEXpaDGAqWkQqVlwL3KES0wfL2q6mpOoPfFHDS1XttdMc5lruL3Lm/d/ihkhTrAQhcH1sfupKfySuXC5vNT627X5zBX555kl+bpwElDtp6o3/aP48I47r713rXDUiidp/w34hNRBrcOQUNvIDOjbViP+jd6ziTYu0I4L23dzFRI6+ZNiAKRbZZ8kHoaoFYfJef89MvZlGciMVNQDnszd2u0oFYUjsrHnAAEGUGSRSBWZYWvVT5x1KHE7IMCI5fYGncgM3Wodn7WHzEaAGqwqTZ5ngcA8AJfYktlrqxIitZotf+D32LWIchfG0SqAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"kubelet\" title=\"\" src=\"/static/84d5d4c213fe186b062ae18bded93dae/c5bb3/kubelet.png\" srcset=\"/static/84d5d4c213fe186b062ae18bded93dae/04472/kubelet.png 170w,\n/static/84d5d4c213fe186b062ae18bded93dae/9f933/kubelet.png 340w,\n/static/84d5d4c213fe186b062ae18bded93dae/c5bb3/kubelet.png 680w,\n/static/84d5d4c213fe186b062ae18bded93dae/b12f7/kubelet.png 1020w,\n/static/84d5d4c213fe186b062ae18bded93dae/2bef9/kubelet.png 1024w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"docker-shim-deprecated-from-k8s-124-Ô∏è\" style=\"position:relative;\"><a href=\"#docker-shim-deprecated-from-k8s-124-%EF%B8%8F\" aria-label=\"docker shim deprecated from k8s 124 Ô∏è permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Docker Shim Deprecated from K8s 1.24 ‚ö†Ô∏è</h2>\n<p>In version 1.24, Kubernetes is no longer supported Docker as a container runtime. Docker is being phased out in favor of runtimes that use the Container Runtime Interface (CRI), which was built for Kubernetes. If you're a Kubernetes end-user, you won't notice much of a difference.</p>\n<p>This does not imply that Docker is dead, nor does it imply that you can't or shouldn't use it as a development tool. Docker is still a helpful tool for creating containers, and the images generated by the docker build may be used in your Kubernetes cluster.</p>\n<p>If you wish to create your cluster, you'll have to make certain adjustments to avoid cluster failure. As Docker will be deprecated from K8s 1.24, you'll have to transition to one of the other compatible container runtimes, such as containerd or CRI-O. Simply ensure that the runtime you select supports the current settings of the Docker daemon (such as logging).</p>\n<h3 id=\"demo-cri-o-and-k8s\" style=\"position:relative;\"><a href=\"#demo-cri-o-and-k8s\" aria-label=\"demo cri o and k8s permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Demo: CRI-O and K8s</h3>\n<p>CRI-O may pull from any container registry and supports OCI container images. It's a lightweight alternative as a Kubernetes runtime.</p>\n<p><strong>Features:</strong></p>\n<ul>\n<li>OCI compatible runtime</li>\n<li>containers/storage</li>\n<li>containers/image</li>\n<li>networking (CNI)</li>\n<li>container monitoring</li>\n<li>Several essential Linux functions support security</li>\n</ul>\n<p><strong>How does CRI-O work?</strong></p>\n<p>It is a Kubernetes CRI implementation that allows OCI-compatible runtimes to be used. It's a lighter alternative to using Docker as the runtime for Kubernetes. It enables Kubernetes to use any OCI-compliant container runtime for pod execution. It now supports runc and Kata Containers as container runtimes, and any OCI-compliant runtime can theoretically be plugged in.</p>\n<p><strong>Architecture:</strong></p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.88235294117647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACn0lEQVR42l2Ra08TQRSG+VH6ASWaiJFLLYUALS29t9vdbve+3d4LVEqXlm2LpVYkVUAj9f5FEROIiR/4SxhTnddpExWcZDJnzpnz5H3njIzQddpK26rpOIpphTQrRegiAykeRlZLwJBZKIkIklIMuhCFQc+MGodG40FOTkSJlRfwsa5Oj/xZ70thW8MyUe7sk2K9jdFZNyb9LLxyGgE9h9vOAG7MeXBr0Y9wsgAnr2HSy2CM5q7NeAgbZ3C6rd3/CzzZEmwrOQPOuEIcAQbTyyEwRhbLvAxl3USyUoMnLoM18ljiJNjpG5HWvayAKT9LdFXAsSX9A36jlkUhBlswTty08a7Lh6CSwnJCBZddgYvmJt1BLAsa/FISS/TOJbNw+CIYXwoSVeGvAr+2dJuqJOCIJMh8hMc8k8C40wdHiMUEBd2cWcSYw0W3E7MhblifDXO0HsMdN0NYdmDZuKTwUdqmUeAcIxK/pOPtpxO0nz1HpdVBrbOHh90DmDuPsUXjQS5drqJz+BKfz87Q6J2TWr2DD6uey5b1IdAe5sm404vN9u7QWkhNQcyvgUnmhncP/QKxUIKyUkYslUdUz2B7v0fM8hp6q6GrCiWRRcFqkeZuF92j12g/PYSXAq5PzWLUvjDc95YCcLESAnISbl6BV1CRqlgkygTx5fKUB0BZ5CAUyr9Waw2y33uDvRdHMB5UEKDKBkqCFDJQq69tIFmqgKfDKlQtbHa6RKK9x9Yl4PmTtE1RBNgZiSxwMnYOe0iZdcglE5lqE9nqNrT1GowNC3p5C3xhHWy2hNVGG82DV0QQ/5/yTmrCNLh+MatfWKXMRWcj9z0lcz/yObUv8uF+NOjuc1Fvn4t4h2eC8f/koz4IbACaxBIzFcc7U7QPYL8BNdzEKa+e0tsAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"cri-o\" title=\"\" src=\"/static/39f8ccd779450831bdb5b49cdeab6430/c5bb3/cri-o.png\" srcset=\"/static/39f8ccd779450831bdb5b49cdeab6430/04472/cri-o.png 170w,\n/static/39f8ccd779450831bdb5b49cdeab6430/9f933/cri-o.png 340w,\n/static/39f8ccd779450831bdb5b49cdeab6430/c5bb3/cri-o.png 680w,\n/static/39f8ccd779450831bdb5b49cdeab6430/b12f7/cri-o.png 1020w,\n/static/39f8ccd779450831bdb5b49cdeab6430/b5a09/cri-o.png 1360w,\n/static/39f8ccd779450831bdb5b49cdeab6430/29007/cri-o.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>The following are the architectural elements:</p>\n<ul>\n<li>To deploy a pod, Kubernetes communicates with the kubelet.</li>\n<li>Pods are a Kubernetes notion that consists of one or more containers in the same cgroup that share the same IPC, NET, and PID namespaces.</li>\n<li>To launch a new pod, the kubelet sends a request to the CRI-O daemon using the Kubernetes CRI.</li>\n<li>CRI-O pulls the image from a container registry using the containers/image library.</li>\n<li>Using the containers/storage library, the downloaded image is unpacked into the container's root filesystems and stored in COW file systems.</li>\n<li>After the container's rootfs have been constructed, CRI-O creates an OCI runtime specification JSON file that describes how to use the OCI Generate tools to run the container.</li>\n<li>The specification is then used by CRI-O to launch an OCI Compatible Runtime, which runs the container processes. The OCI Runtime by default is runc.</li>\n<li>A separate conmon process monitors each container. The pty of the container process's PID1 is held by the conmon process. It manages the container's logging and keeps track of the container's exit code.</li>\n<li>CNI is used to set up the pod's networking, therefore any CNI plugin can be used with CRI-O.</li>\n</ul>\n<h2 id=\"conclusion-\" style=\"position:relative;\"><a href=\"#conclusion-\" aria-label=\"conclusion  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Conclusion üéØ</h2>\n<p>Container runtimes and CRIs have evolved rapidly in recent years, driven by the need to support new features and use cases. This overview has provided a high-level overview of the current state of the art, but there is still much more to explore.</p>\n<p>As Kubernetes continues to mature and new container technologies emerge, we can expect to see continued innovation in the container runtime and CRI space.</p>\n<p>I hope this blog post has given you a better understanding of container runtimes and CRIs, and their role in the Kubernetes ecosystem.</p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"},"nextThought":{"frontmatter":{"path":"/blog/docker-image-optimization/","title":"Docker Image Optimization: A Toolbox of efficient Tricks","date":"2024-10-29 18:30:00"},"excerpt":"A Toolbox of Simple Tricks for Docker Image Optimization ‚ò∏ Introduction Docker has revolutionized the way we package and deploy applications‚Ä¶","html":"<blockquote>\n<p><strong>A Toolbox of Simple Tricks for Docker Image Optimization</strong></p>\n</blockquote>\n<h2 id=\"-introduction\" style=\"position:relative;\"><a href=\"#-introduction\" aria-label=\" introduction permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>‚ò∏ Introduction</h2>\n<p>Docker has revolutionized the way we package and deploy applications, but often, images can become bloated and resource-consuming. Fear not! We have curated a collection of handy tricks that will help you optimize your Docker images without compromising functionality.</p>\n<p>Whether you're a seasoned Docker user or just getting started, join us on this journey to discover the secrets of maximizing efficiency and minimizing image size. Get ready to supercharge your Docker workflow with our toolbox of simple but powerful optimization tricks.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.470588235294116%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAACgUlEQVR42l2SS2tTURSF80uc9AcIIjhx6gOKE1FwIFb8B1IcCIoDxYE4F1oE0SqIVYralqbpyzTJTZqkTdOkSe5N0jS5uffcV9KkrQOxn+ckdtLB4uyz9t6Ltfc5Icdx8AKBK+F1BI7/P1bc//gsVM0pVI+C4m0hCDnCYycl2N0S5OVZ2RGUcsO7OgsZQTE7hOJ20gK9KCjnh5zK5xKyVubabSnout6AyK4JkmFZkHbIxV0WPw7v0e+CxPwwjs8KYhLplaFQIWuTjNikIkPObClBzx1Y9rsSB4Kg63DQ8ykmO+SiAZlIwNZawE6iQykj49WA9LJHrxNw8ueAk7+H9I883I6NcAYOXYRwsWyBZdk4jkvbtNB1g2p1D6NapVyuYug1arU6hlEnEDbxrRpP367zcnKOXX2fIAhoy/5Q27KIxuKDRrVU1/Nkk0E4HCabjKH9WkKLLrO2usLCQpgNLcrUksG5e9OMPp7h/O3njFwdJ57apCNdh2r1OjOz8xRLZcq6Ll3VCHwfT+52NrPHp1id6WSDqtxP4Dm0LIdLTwq8npETWD4t/4grd8YZvfuIfu9gOLIlXSpnheIuulGVo9XYb5m8+FFmbCLJ2JsY6VKT3z2PTMXhwrMGZeuYhx8STMV0Jt59ZuTiDdQXHAiqUS3bHhCeFDZNUwq28YRF17XpeRZtmbfl7pqm4PKrLu+jPnljj1SpzvVbD7h28z79wz4hJaAET0WFEnUdIlqG8YkvrGtJ6tkokz/lDrVNhNlgMeeztKHzdeYbMU1jLrLGSjRBt9s9IyihXCpk8gUW1jVKlQrNRp1Ydpvt3crAvWs3Oex1aDRNDPnyx8dH+IE/MPQPnQsAFLtkNggAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/1f9f5105c650a5cabc0f2872736831a0/c5bb3/image.png\" srcset=\"/static/1f9f5105c650a5cabc0f2872736831a0/04472/image.png 170w,\n/static/1f9f5105c650a5cabc0f2872736831a0/9f933/image.png 340w,\n/static/1f9f5105c650a5cabc0f2872736831a0/c5bb3/image.png 680w,\n/static/1f9f5105c650a5cabc0f2872736831a0/b12f7/image.png 1020w,\n/static/1f9f5105c650a5cabc0f2872736831a0/b5a09/image.png 1360w,\n/static/1f9f5105c650a5cabc0f2872736831a0/47f6c/image.png 2206w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          \n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 55.294117647058826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAACcUlEQVR42m2STU8TURSG+S3+AbaGhXHjkmhi+AGsTNiYuCBqosaPhYkJGxMWJhg34kJRRFzwIcV+0ZaWtrT0Y9rptKW0c+9Mp5RSagz6eKdTFiYs3px73nvy5Jxz75gpBNIWWI5S+38N/cvOo1yOctvxciElY1ZbUi1JihlBKSeoFAV6XknFiqa8A4GWVXnBO7s1Rsmr0zKel095tUNg27Eo5yyi64LYhiAZkKRDEt9HQWhVEPymtCKIqruAiuHvXl02LkhHTHbWPC+xPQJKaeF2aXfEUO7ovTMb/cBhz+cQX3fIhDokfR2KSYf9oPK2bI5th7/nXf6c9+j2LDW+eQGUSMvCNAWtlokpJEKpUjYou9INCgUdrWhQ0auUSwZttfdwyuDJQpC5d2tUak1s26al/DG7bZPazxBLJHAfSEgX3MLv9xMLB0hFAsRDPkLBn2xs/mA34mdxq8yV6c/cfrTC+NRzxm/dJ5sv0nYcBVTkQHhnqEq1SuYgN2y922mzma4zv1nijU8nWW5yrPbdaEmuPc3zerVCrmFRkz0mJme4M/uKwaCvRlbjugBLxfrhIblCgWqtxtFhjaVYnXuLKWbeRthOG/w+dUipHzHxokGydsaDD1GWdys8fDbH9clp+v1TD+jusWWaw5HdjqUau1pvoCtwWzbpW3UajQaG8tx13JzvsuATZIoau7kyV29MMfv4JYNfgxHQfRQFu5Ct8mxB4+78e75shajvqb2tB/i0HcU8qrGnSRI5g6WvywQjUeLJDHmt5O3wMqBlW+jVGon9LMWSPuwqp5UpqhdvNltIs0H32EFYNkfq7uSkO2JI/gHu5QRBWe6BYQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alt text\" title=\"\" src=\"/static/c97da10d99b01b00879bae63901163ac/c5bb3/image-1.png\" srcset=\"/static/c97da10d99b01b00879bae63901163ac/04472/image-1.png 170w,\n/static/c97da10d99b01b00879bae63901163ac/9f933/image-1.png 340w,\n/static/c97da10d99b01b00879bae63901163ac/c5bb3/image-1.png 680w,\n/static/c97da10d99b01b00879bae63901163ac/b12f7/image-1.png 1020w,\n/static/c97da10d99b01b00879bae63901163ac/b5a09/image-1.png 1360w,\n/static/c97da10d99b01b00879bae63901163ac/0ddab/image-1.png 2220w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<h2 id=\"-goals--objectives\" style=\"position:relative;\"><a href=\"#-goals--objectives\" aria-label=\" goals  objectives permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üéØ Goals &#x26; Objectives</h2>\n<p>In this article, we will explore a variety of straightforward techniques that will empower you to create smaller and more efficient Docker images.</p>\n<p>Let's dive in! <strong>HAPPY LEARNING üíª</strong></p>\n<h3 id=\"proven-strategies-for-minimizing-docker-image-size\" style=\"position:relative;\"><a href=\"#proven-strategies-for-minimizing-docker-image-size\" aria-label=\"proven strategies for minimizing docker image size permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Proven Strategies for Minimizing Docker Image Size</h3>\n<p>Building smaller Docker containers should be a top priority in your containerization journey. The significance lies in the fact that smaller images, which leverage shared layers, offer enhanced transfer and deployment speeds. However, managing image size becomes challenging as each <code class=\"language-text\">RUN</code> statement generates a new layer, and intermediate artifacts are often necessary before the image is fully prepared.</p>\n<p>If you've come across various Dockerfiles in the community, you might have observed peculiar techniques like the following:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 17.058823529411764%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAc0lEQVR42o2NQQ6DMAwEHYJAMcEEQgMlEv9/IyJazK2oh/Yw8mHXs7SLPQYxxVWmdLUpbG/oQfRcJu+0Q1/ZJ/c/pcqcmR2WGLCGHkk6aPBAR6Ayvb8hlZx5HvGOI7bGIjc11mnAEgRzz0g68hKPwO1f0gt4WUFBqzf0NQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"latest\" title=\"\" src=\"/static/5177b83f2d63ae75efcdbda7782c66f7/c5bb3/latest.png\" srcset=\"/static/5177b83f2d63ae75efcdbda7782c66f7/04472/latest.png 170w,\n/static/5177b83f2d63ae75efcdbda7782c66f7/9f933/latest.png 340w,\n/static/5177b83f2d63ae75efcdbda7782c66f7/c5bb3/latest.png 680w,\n/static/5177b83f2d63ae75efcdbda7782c66f7/b12f7/latest.png 1020w,\n/static/5177b83f2d63ae75efcdbda7782c66f7/b5a09/latest.png 1360w,\n/static/5177b83f2d63ae75efcdbda7782c66f7/29007/latest.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>What is the reason behind using the <code class=\"language-text\">&amp;&amp;</code> symbol in Dockerfiles instead of running two separate <code class=\"language-text\">RUN</code> statements? How does this peculiar approach simplify the build process and unlock the potential for smaller and more efficient Docker images?</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 21.764705882352942%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAdElEQVR42p3Oyw7CIBCF4cPIoiAFelFB0vd/ScxxEtNV1RgX32omfw62aHuKoDOgPxmFgyV4zsHRCd7ed2driCvQmx9YlswyRV5SODwO8vIttsNd0Lc8sq4Tm6oa/rT0p2AVPJquKnPiLUddmbiOnsHKX8EnRRRWZFh9qXcAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"runs\" title=\"\" src=\"/static/379e083859522cea28f4b7c2c0975bf9/c5bb3/runs.png\" srcset=\"/static/379e083859522cea28f4b7c2c0975bf9/04472/runs.png 170w,\n/static/379e083859522cea28f4b7c2c0975bf9/9f933/runs.png 340w,\n/static/379e083859522cea28f4b7c2c0975bf9/c5bb3/runs.png 680w,\n/static/379e083859522cea28f4b7c2c0975bf9/b12f7/runs.png 1020w,\n/static/379e083859522cea28f4b7c2c0975bf9/b5a09/runs.png 1360w,\n/static/379e083859522cea28f4b7c2c0975bf9/29007/runs.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Well, the answer is obvious: when a Docker image is built, each <code class=\"language-text\">RUN</code> statement creates a new layer. These layers consume disk space and can make the resulting image larger. However, by chaining commands with <code class=\"language-text\">&amp;&amp;</code>, you can execute them within a single <code class=\"language-text\">RUN</code> statement, thereby reducing the number of layers generated.</p>\n<p>Using separate <code class=\"language-text\">RUN</code> statements instead of <code class=\"language-text\">&amp;&amp;</code> may seem logical, but it comes with a drawback: each <code class=\"language-text\">RUN</code> statement creates an additional layer, potentially leading to larger image sizes. By utilizing <code class=\"language-text\">&amp;&amp;</code>, you optimize the Docker build process, resulting in smaller and more efficient images. In the previous example, two layers were created instead of consolidating them into a single layer.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 25.882352941176467%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABoElEQVR42gGVAWr+AJWVlSmlpaUosrKyHsPDwxHDw8MRv39/BMTh8COs5ftQq+f4TLjq+0yt5/tLns/eZ7fP1SsAAAAA/+DRQ//o0U//5NNM/+fWTOjMvWXjx7xcAOXl5ez39/fw9/f37PPz8/Dt7+/a56+/IIXUxXM+1rj/QM6y/FnTuv87zK/8PdW3/4nVx28AAAAA3Z7E3eSWyf/fl8P93pjE/t6SxP/emsLrAO3t7fn//////Pz8/fv7+//y8vHtubnWLMLLinKzwUn/r7xM+bnFafuuu0n5ssFJ/8TLjnaiuf8Ly6ie3cmYjP/Lo5f7y6SY/MaWi//Kpp7qAPPz8/v//////////f/////7+vrsu8rDItK6x3PWp7z/zqK2/Naxwf/NoLT81qe8/9a/yHEAAAAAp8tu3ZrKTv+iymT9o8pm/pfGTP+nymzrAPDw8Jz4+Pif9vb2nvX19aPx8fKTVVUqBubj9VPk4P3I5uL/u+jk/b7l4f285eH/x+bm9VMAAAAAYdHLzzfJwflT0MjuUtDI7zXJwfRdz8neNcQglgF4X5MAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"layers\" title=\"\" src=\"/static/c266a7e069ce7db01575db346dc5b05c/c5bb3/layers.png\" srcset=\"/static/c266a7e069ce7db01575db346dc5b05c/04472/layers.png 170w,\n/static/c266a7e069ce7db01575db346dc5b05c/9f933/layers.png 340w,\n/static/c266a7e069ce7db01575db346dc5b05c/c5bb3/layers.png 680w,\n/static/c266a7e069ce7db01575db346dc5b05c/b12f7/layers.png 1020w,\n/static/c266a7e069ce7db01575db346dc5b05c/f680b/layers.png 1108w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Docker layers function akin to Git commits: capturing the modifications between the previous and current image versions. These layers prove beneficial when sharing with other repositories or images, mirroring Git commits' usefulness in sharing code. When fetching an image from a registry, solely the layers absent in your possession are downloaded. This method vastly improves the efficiency of image sharing.</p>\n<p>Nevertheless, layers come at a cost üòø. Layers occupy storage space, and the final image grows heavier with each additional layer. Git repositories exhibit a similar behavior‚Ää‚Äî‚Äärepository size increases in proportion to the number of layers, as Git must retain all changes between commits.</p>\n<p>In the past, it was recommended to consolidate multiple <code class=\"language-text\">RUN</code> statements into a single line, resembling the initial example. However, this practice is no longer advisable. üëå</p>\n<h3 id=\"condense-multiple-layers-into-one-using-multi-stage-docker-builds\" style=\"position:relative;\"><a href=\"#condense-multiple-layers-into-one-using-multi-stage-docker-builds\" aria-label=\"condense multiple layers into one using multi stage docker builds permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Condense Multiple Layers into One Using Multi-Stage Docker Builds</h3>\n<p>Just as you can opt to merge the history of a Git repository into a single commit to simplify it, a similar approach can be applied in Docker through multi-stage builds. In the following scenario, we'll construct a Node.js container. To begin, let's consider an <code class=\"language-text\">index.js</code> file:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 49.411764705882355%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABFElEQVR42pWSWW7DMAxEcwZb4qbNdp2/3v92AjuyG7QpEKP5GIiirBEf6dvnnTq14NMUPUQoBCj6PIdDYx+R/69umahXYd8SeVZxy+KpiK/V/L6aJ9P3DBtz3419r+q1mS9b8pTNRchN2ZnpPUMKsRMCIiQg4viE/KRwKl604ZYK99LUFbjFxCuqrQnYObtC42xryT9Q/b6YV1TPzK8NgdQHHhEdVSokwByohN6KkivWIZMzHt++NFTjPi5lvNysOougf3pc+os8Teca4wWyZe51wUCAs7WGyRZfgViLegF6zXq0IKMdGwY3pn9ZoYh0S0CyU0sZJqeGYfuOM84e8TWyah9TPfUzyUfu936e4+WPPh76Amkj/SpIhte3AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"src\" title=\"\" src=\"/static/64021f4752eb605ffba48dd4de4d96d9/c5bb3/src.png\" srcset=\"/static/64021f4752eb605ffba48dd4de4d96d9/04472/src.png 170w,\n/static/64021f4752eb605ffba48dd4de4d96d9/9f933/src.png 340w,\n/static/64021f4752eb605ffba48dd4de4d96d9/c5bb3/src.png 680w,\n/static/64021f4752eb605ffba48dd4de4d96d9/b12f7/src.png 1020w,\n/static/64021f4752eb605ffba48dd4de4d96d9/b5a09/src.png 1360w,\n/static/64021f4752eb605ffba48dd4de4d96d9/29007/src.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>and <code class=\"language-text\">package.json</code>:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 64.70588235294117%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA90lEQVR42qWT2W6EMAxFnRWckAWmQ6uqb/3//6vERK4DVDOaIhWlD+fJ0sn1Evh80V9xFAsKWLyGxanfzDkucwoLyuP6IxA7dXMSqNIzuMPFB8QO/Ak4I2+YDCWU9DYCveYNr88JDoSiYLaEwdAlCPq4AqW+TXYXRkuBE75PwCkFBSsO2j4rtFtCFw3FrCh7fXpeh0JUwAkN4dQROk3XKGlOdYaNwsHI4q0k1zG8iNgBjQ7aEw5WFY96FQ5GrafTie2E/tcyL2byii4DrEwe+IEGodeyuF4RMhkFzxBWqrRljhCsLr5udf8h/Q+iseUqbF3AM/V3fQPbGhNanNrazQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"json\" title=\"\" src=\"/static/7a6cfbec59bd010a9d6d90ea7dfd716a/c5bb3/json.png\" srcset=\"/static/7a6cfbec59bd010a9d6d90ea7dfd716a/04472/json.png 170w,\n/static/7a6cfbec59bd010a9d6d90ea7dfd716a/9f933/json.png 340w,\n/static/7a6cfbec59bd010a9d6d90ea7dfd716a/c5bb3/json.png 680w,\n/static/7a6cfbec59bd010a9d6d90ea7dfd716a/b12f7/json.png 1020w,\n/static/7a6cfbec59bd010a9d6d90ea7dfd716a/b5a09/json.png 1360w,\n/static/7a6cfbec59bd010a9d6d90ea7dfd716a/29007/json.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>You can package this application with the following Dockerfile:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 49.411764705882355%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAwUlEQVR42q2RyRKCMBAFJwsEErIAgqAe9P+/MfUc3E5aKnro21Sn+oVOo87WEwwRrHrONgWMyaOWr2/u0F5SPniLqUtvjz+BvKLsS4WFvwi3LJy0xGg9nBK/C48sPPE2U4oIpoARhIr5ZK+nwpk3nK3BvGkxhAZ9U2OIDVJdoink98LlU3ZtxH7oMfcJoSqQ+IFgNNwaYeTkWJUsuGJuuauTOyVyVwtOJMSKOFmsSn0IN1rm3smLaJF2TsDpdUKnBc6/bNVK99qKzgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"multi\" title=\"\" src=\"/static/be78467734cef9045d4836b9de29fc74/c5bb3/multi.png\" srcset=\"/static/be78467734cef9045d4836b9de29fc74/04472/multi.png 170w,\n/static/be78467734cef9045d4836b9de29fc74/9f933/multi.png 340w,\n/static/be78467734cef9045d4836b9de29fc74/c5bb3/multi.png 680w,\n/static/be78467734cef9045d4836b9de29fc74/b12f7/multi.png 1020w,\n/static/be78467734cef9045d4836b9de29fc74/b5a09/multi.png 1360w,\n/static/be78467734cef9045d4836b9de29fc74/29007/multi.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>You can build the image with:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> node-multi-layers <span class=\"token builtin class-name\">.</span></code></pre></div>\n<p>And you can test that it works correctly with:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 38.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA0ElEQVR42pVRSQ7CMBDr/9+IoAdI0yyTPe3NZCKKQKgVPVhJPIplewZpL8i1opaKZVneqMzVb27jSym7GJJ5wGgFYwxu1yvGcYQQAs45WGs7L6XsHENrfSxYckJKGTFneB8QY2zv1Id8MpgLIXRss13B7DWqNyg0o7S7frn9dLLF3Go4FIxaQIo7rBJIwTWXDN8jH33c7zAGWHItTkRtpa/remoJvx0Gi9hckaUelRdBRB3zPCM0t2dEh0ISZDSUYqgO7o/Fp2mCb9H/FeSFPQFM4GWjH54+FgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"test\" title=\"\" src=\"/static/a082371fa81660e9a09cae517d1bdd19/c5bb3/test.png\" srcset=\"/static/a082371fa81660e9a09cae517d1bdd19/04472/test.png 170w,\n/static/a082371fa81660e9a09cae517d1bdd19/9f933/test.png 340w,\n/static/a082371fa81660e9a09cae517d1bdd19/c5bb3/test.png 680w,\n/static/a082371fa81660e9a09cae517d1bdd19/b12f7/test.png 1020w,\n/static/a082371fa81660e9a09cae517d1bdd19/b5a09/test.png 1360w,\n/static/a082371fa81660e9a09cae517d1bdd19/29007/test.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Upon visiting <a href=\"http://localhost:3000\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost:3000</a>, you will be warmly greeted with the message \"Hello World!\"</p>\n<p>In the Dockerfile, you will notice the presence of both <code class=\"language-text\">COPY</code> and <code class=\"language-text\">RUN</code> statements. As a result, anticipate the addition of at least two additional layers beyond the base image. However, the resulting image will surprisingly contain more new layers, corresponding to each statement in the Dockerfile.</p>\n<p>Let's explore the multi-stage Docker build approach. For this purpose, we will use the same Dockerfile as mentioned earlier, but we will employ it twice:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 69.41176470588235%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+ElEQVR42qVTSW7DMAz0W2rtlixrdYv+/1cWWFJOEOQY9jAg7MNgNi2/SVw6foFYJQgpQEq84r5KqY+xbLlcuXeotUIpBcJxQKYbAot0UdpcxhggWGvBIKxz85ul0Jc6Qv+GiMocEq3rOi0TeJZTGal1OM8Tcs5wIHF5WCbFjAzrKEjYWkW0SUJK6WqtORnqMbN75EhFPMGybOMx9oRWY5w5cmy+EWrnhse8vPcT9JNbyCQ0mx8arbptg33fZxkETn53KTSbUuGnJsgpAamNaJ9NGFofERsuCZt1NwltkW/Zh2Edvg6Pc/GW/UJes1FyvKai/kVGMf0BTiCZWfe7hlAAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"dockerfile\" title=\"\" src=\"/static/bf220f93f039d6b7663a33aa20754deb/c5bb3/dockerfile.png\" srcset=\"/static/bf220f93f039d6b7663a33aa20754deb/04472/dockerfile.png 170w,\n/static/bf220f93f039d6b7663a33aa20754deb/9f933/dockerfile.png 340w,\n/static/bf220f93f039d6b7663a33aa20754deb/c5bb3/dockerfile.png 680w,\n/static/bf220f93f039d6b7663a33aa20754deb/b12f7/dockerfile.png 1020w,\n/static/bf220f93f039d6b7663a33aa20754deb/b5a09/dockerfile.png 1360w,\n/static/bf220f93f039d6b7663a33aa20754deb/29007/dockerfile.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>The first part of the Dockerfile creates three layers. The layers are then merged and copied across to the second and final stage. Two more layers are added on top of the image for a total of 3 layers.</p>\n<p>Feel free to validate the Docker configuration. Begin by building the container using the following steps:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> node-stages <span class=\"token builtin class-name\">.</span></code></pre></div>\n<p>And now inspect the history:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 59.411764705882355%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABt0lEQVR42pWT23KDMAxEbcAX+YK5hSTNtH3o/38io65MaNI8tQ8aC5CPdmWjvhaz9UUzKcWheYn2/6FC6jZKHVNvWNaQTY2a/wXy0li5yVZg/eAapsUxTZYpoolWTCii5nccILKaPYSE7gk4p7CFybMv+OBaToODQssDgGtueY4tn9Bwj5ZHaupGARff8CTunlSqmKFwElUAoSD3nmO0PAJ4HQwv2PA+2xrn3LGHag+AwzqgfkFDyeMBxOw2mgEsFsB2B6YdeO6hEnGF+hWwt9HwBU1uGImozUbXGoEeKhVlAEfLHrMLhKLifoBvmI+okk2XsudiU2z3nebidB1L7n5ZNluAOqwc0bECI/KATbCb0WRNnk+AROQR14sMFKE+Yx0j3OH9cdoqpR2YqKtzOIA9FI4AltDxrRBfYXGBkxXPA6LWWDkkuDPNQ2HCoYQBQFEFG3mQGaK7nOrs+VwCj5PhGXP7OBn+XHHqWWzLKWu+zXv+M0PY2ALUJByIvKh2kRNmtc+S6l3zUDUBtA6Kx6B4yXBjFa9F8RSfgW2zBf248fT06x0XOd6f5brItaF7LvVOP3Jx+A3kzwYUFY1qCQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"hist\" title=\"\" src=\"/static/b81fe041163c7836bf0cead639255ad0/c5bb3/history.png\" srcset=\"/static/b81fe041163c7836bf0cead639255ad0/04472/history.png 170w,\n/static/b81fe041163c7836bf0cead639255ad0/9f933/history.png 340w,\n/static/b81fe041163c7836bf0cead639255ad0/c5bb3/history.png 680w,\n/static/b81fe041163c7836bf0cead639255ad0/b12f7/history.png 1020w,\n/static/b81fe041163c7836bf0cead639255ad0/b5a09/history.png 1360w,\n/static/b81fe041163c7836bf0cead639255ad0/29007/history.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Congratulations! Now let's check if there has been any change in the file size.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 28.82352941176471%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAsklEQVR42pWRWw6DIBBFXUlFxAfISxGtbVq7/03dAkY/G/pxIDMhh8tQCMtxKyUIGVARmSChppVK1FQnzvoX8VzRaAst79BqgxQLtN6g5Ap6yY+LcoSRonMOvXbgzqfd6ge83+GmF7p2wmifkMOaxHlCOyGmZMKA1gomJJzdG8vygRAeft5TL1vIOoM6wsKcShVSjRB8Bu8dGmZSyrYZs55dkSCkYblIzeNTzkT/zJDVBl+rb6+sbc1WOAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"size\" title=\"\" src=\"/static/2becbf5ed0a41a160dae3922ba91b188/c5bb3/size.png\" srcset=\"/static/2becbf5ed0a41a160dae3922ba91b188/04472/size.png 170w,\n/static/2becbf5ed0a41a160dae3922ba91b188/9f933/size.png 340w,\n/static/2becbf5ed0a41a160dae3922ba91b188/c5bb3/size.png 680w,\n/static/2becbf5ed0a41a160dae3922ba91b188/b12f7/size.png 1020w,\n/static/2becbf5ed0a41a160dae3922ba91b188/b5a09/size.png 1360w,\n/static/2becbf5ed0a41a160dae3922ba91b188/29007/size.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Great job on achieving a slightly smaller file size for the last image! Although you've already optimized the application to a certain extent, it seems that the image size can still be further improved. But fret not, there are additional measures you can take to make it even smaller. Let's explore further techniques to further minimize the image size.</p>\n<hr>\n<h3 id=\"streamline-your-container-by-eliminating-unnecessary-components-with-distroless\" style=\"position:relative;\"><a href=\"#streamline-your-container-by-eliminating-unnecessary-components-with-distroless\" aria-label=\"streamline your container by eliminating unnecessary components with distroless permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Streamline Your Container by Eliminating Unnecessary Components with Distroless</h3>\n<p>The current Docker image includes a plethora of binaries and utilities, including Node.js, yarn, npm, bash, and even an entire Ubuntu operating system. However, when running your container, you only require Node.js as the essential dependency.</p>\n<p>Docker containers should encapsulate a single process, containing only the bare minimum required for its execution. The inclusion of a complete operating system is unnecessary.</p>\n<p>Thankfully, Google has recognized this and introduced <a href=\"https://github.com/GoogleContainerTools/distroless\" target=\"_blank\" rel=\"noopener noreferrer\">GoogleCloudPlatform/distroless</a>, a solution that aligns perfectly with your needs. As described in the repository, \"Distroless\" images exclusively consist of your application and its essential runtime dependencies. They omit package managers, shells, and other programs typically found in a standard Linux distribution.</p>\n<p>This precisely matches your requirements! By adjusting the Dockerfile, you can harness the power of this new base image, resulting in the following configuration:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 69.41176470588235%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAABGUlEQVR42qWUwW6EMAxE+ZEuECAJBCeBLLCwWqn//01Erh3U3kkPIwsOTzNjQ7HCcArTY/k1YlUZrCua5TVFDbdVeLmeAQ70/kBndwS1oIMde/3MghZNbc+2ccjqWo9d41HS5Ocsh5Pc4qJ2HIcVZTdh+RhSZFZu5DibHcP8QUtRR7Oic1fkrnU5wC3O9k0dvnEicWx2yrMR9j6wrSGyExb39hs3d9MFdM8IekWtA5phSZEN9WnhhUpOt6GFFD4OKqSYDGBpNePQL+ndbaBupthSV0pNCcIwlqjHvMi8Za82OuZvBMPbDSlyzkISMKg9BvNCbw+Ke51J+ci7wQTsmzkq6ckVkDuX/YX8AWsBsUo/BKDO4F8wrukH0rOXg2sD6a8AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"distroless\" title=\"\" src=\"/static/c2d84c4285b8f4516b3c951ed8ddfece/c5bb3/distroless.png\" srcset=\"/static/c2d84c4285b8f4516b3c951ed8ddfece/04472/distroless.png 170w,\n/static/c2d84c4285b8f4516b3c951ed8ddfece/9f933/distroless.png 340w,\n/static/c2d84c4285b8f4516b3c951ed8ddfece/c5bb3/distroless.png 680w,\n/static/c2d84c4285b8f4516b3c951ed8ddfece/b12f7/distroless.png 1020w,\n/static/c2d84c4285b8f4516b3c951ed8ddfece/b5a09/distroless.png 1360w,\n/static/c2d84c4285b8f4516b3c951ed8ddfece/29007/distroless.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>And you can compile the image as usual with:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> node-distroless <span class=\"token builtin class-name\">.</span></code></pre></div>\n<p>The application should run as normal. To verify that this is still the case, you could run the container like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> run <span class=\"token parameter variable\">-p</span> <span class=\"token number\">3000</span>:3000 <span class=\"token parameter variable\">-ti</span> <span class=\"token parameter variable\">--rm</span> <span class=\"token parameter variable\">--init</span> node-distroless</code></pre></div>\n<p>And visit the page at <a href=\"http://localhost:3000\" target=\"_blank\" rel=\"noopener noreferrer\">http://localhost:3000</a>.</p>\n<p>Is the image without all the extra binaries smaller?</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 23.52941176470588%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAmUlEQVR42o2OSxKDIBBEOYkiGj4KowLmn9z/Tiw6EFPJMixe9UxVz6thikxqminxtjB++O0dn5LobM7/iM4lJmnBQleQPcFOR5A7Zy6YacfoiFxGLlfB5OKhKUCvEdp4BP/AFp/w6w1ahZx3jGarlrJBzRDSoVcE0bv8UciCCCU9hp7eUnlY64WC56HQ7lkOeWu/gpK1sl4QXs27kZjYgV20AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"smaller\" title=\"\" src=\"/static/0b6cdbff241844b240531065fa1d1911/c5bb3/smaller.png\" srcset=\"/static/0b6cdbff241844b240531065fa1d1911/04472/smaller.png 170w,\n/static/0b6cdbff241844b240531065fa1d1911/9f933/smaller.png 340w,\n/static/0b6cdbff241844b240531065fa1d1911/c5bb3/smaller.png 680w,\n/static/0b6cdbff241844b240531065fa1d1911/b12f7/smaller.png 1020w,\n/static/0b6cdbff241844b240531065fa1d1911/b5a09/smaller.png 1360w,\n/static/0b6cdbff241844b240531065fa1d1911/29007/smaller.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Impressive! The size of the new image is just 76.7MB, a remarkable reduction of 600MB compared to the previous version.</p>\n<p>This is fantastic news! However, there is an important consideration to keep in mind when working with distroless. If you need to inspect a running container, you can attach to it using the following command:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 18.823529411764707%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAbklEQVR42o3P2w5AMAwG4DI7YAcWQ/D+r/mrhbiR2MWX/E2bpqVtraEkoa2YIJj6Vr1Zc+7Ev5Zn6Zgj5uAwuQ6xN1gGjxQs9hSRvM15m8aihRfyWsKphglY5nWTBaOQe7mW5QuvMx/P2V9KXz4BMzlVtb6UvwYAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"exec\" title=\"\" src=\"/static/d1c7fa32ca33d3f1faf7839a0d654797/c5bb3/exec.png\" srcset=\"/static/d1c7fa32ca33d3f1faf7839a0d654797/04472/exec.png 170w,\n/static/d1c7fa32ca33d3f1faf7839a0d654797/9f933/exec.png 340w,\n/static/d1c7fa32ca33d3f1faf7839a0d654797/c5bb3/exec.png 680w,\n/static/d1c7fa32ca33d3f1faf7839a0d654797/b12f7/exec.png 1020w,\n/static/d1c7fa32ca33d3f1faf7839a0d654797/b5a09/exec.png 1360w,\n/static/d1c7fa32ca33d3f1faf7839a0d654797/29007/exec.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>The process of attaching to a running container and running a shell, such as a bash, resembles establishing an SSH session. However, in the case of distroless, being a minimalist version of the original operating system, it lacks additional binaries and utilities, including a shell. As a result, it is not possible to attach to a running container without a shell.</p>\n<p>This limitation has both good and bad implications. On the one hand, it prevents executing any binaries other than Node.js within the container. On the other hand, it reinforces the container's purpose of encapsulating a single process, such as running Node.js applications:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 13.529411764705882%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAYUlEQVR42o2NSQ6AMAhFqUMHtLNpev9zNvmiiQt3XbzAB/Kg0tTQigYvNJxgv6r+Pa9zUK8B1TMyG5TDosUTl+ReEurp3l3PEXI8BWW2iE4jmA1eSCJ+KCJLMo92fx/NCm8xRkCXevU82QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"exec2\" title=\"\" src=\"/static/8b2316630fc11419fa6047c87fbd87b3/c5bb3/exec2.png\" srcset=\"/static/8b2316630fc11419fa6047c87fbd87b3/04472/exec2.png 170w,\n/static/8b2316630fc11419fa6047c87fbd87b3/9f933/exec2.png 340w,\n/static/8b2316630fc11419fa6047c87fbd87b3/c5bb3/exec2.png 680w,\n/static/8b2316630fc11419fa6047c87fbd87b3/b12f7/exec2.png 1020w,\n/static/8b2316630fc11419fa6047c87fbd87b3/b5a09/exec2.png 1360w,\n/static/8b2316630fc11419fa6047c87fbd87b3/29007/exec2.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Indeed, the absence of a shell in a distroless container can be considered good news from a security perspective. In the event of an attacker compromising your application and gaining access to the container, their ability to cause significant damage is limited without a shell. This reduction in available binaries contributes to smaller image sizes and enhances security. However, it can introduce challenges when it comes to debugging.</p>\n<p>It is important to note that attaching to and debugging containers in a production environment is generally not recommended. Instead, relying on comprehensive logging and monitoring practices is advisable.</p>\n<h3 id=\"-optimize-image-size-with-alpine-choosing-a-compact-base-image\" style=\"position:relative;\"><a href=\"#-optimize-image-size-with-alpine-choosing-a-compact-base-image\" aria-label=\" optimize image size with alpine choosing a compact base image permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üêã Optimize Image Size with Alpine: Choosing a Compact Base Image</h3>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 64.70588235294117%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABD0lEQVR42qXT3Y6DIBAF4AGsf6CgqHW1abLv/4KbWHP2aJu9l70gEEK+zBlAvofbj/VqK0S2UstW6c9sZKsThqxaXg9XYY4B995jLDLM3qGzJYiDhy4NsUZeLjdweYaGWJsptJzdTV/GTnA1sj+VYGwsoRwF14ycVN0JfmnZ17rAOkZMocFA+N616Lh3VH4ZXAguhJaxx8I+HnF9eUNDzDL+ZbBh5KN3Zw+JlOodNznyyAqnKkdk1J63fUROgf7AQDAyYldXCIS7uvxfhYGR3fFUiPa2gP+gKf17XwrBOTNY+wGTbxGIxaaGTX2HD632Z6WxhAq+UKyOcY1OjxwzvXe15leTExtbxV9ikrCjTb/xMxW9RbEvwgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"alpine\" title=\"\" src=\"/static/82d3dd3877a217cacabbf7bc7c2ea318/c5bb3/alpine.png\" srcset=\"/static/82d3dd3877a217cacabbf7bc7c2ea318/04472/alpine.png 170w,\n/static/82d3dd3877a217cacabbf7bc7c2ea318/9f933/alpine.png 340w,\n/static/82d3dd3877a217cacabbf7bc7c2ea318/c5bb3/alpine.png 680w,\n/static/82d3dd3877a217cacabbf7bc7c2ea318/b12f7/alpine.png 1020w,\n/static/82d3dd3877a217cacabbf7bc7c2ea318/b5a09/alpine.png 1360w,\n/static/82d3dd3877a217cacabbf7bc7c2ea318/29007/alpine.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Consider replacing the distroless base image with an Alpine-based image for further size reduction. Alpine Linux is a security-focused, lightweight Linux distribution built upon musl libc and busybox. In essence, it offers a smaller footprint while prioritizing security.</p>\n<p>However, it is prudent not to solely rely on claims. Let's verify whether the Alpine-based image is indeed smaller. To achieve this, modify the Dockerfile and employ the <code class=\"language-text\">node:8-alpine</code> base image:</p>\n<p>You can build the image with:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> node-alpine <span class=\"token builtin class-name\">.</span></code></pre></div>\n<p>And you can check the size with:</p>\n<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\"><span class=\"token function\">docker</span> images <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> node-alpine</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"plaintext\"><pre class=\"language-plaintext\"><code class=\"language-plaintext\">node-alpine   aa1f85f8e724   69.7MB</code></pre></div>\n<p>69.7MB! Even smaller than the distroless image!</p>\n<p>Can you attach to a running container, unlike distroless? It's time to find out. Let's start the container first:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 18.823529411764707%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAgElEQVR42n2PbQrEIAxEPceuip9Vo673P92UhFJkof3xGJiQR6LG+uLjDKyx0FrfWGtv9v5/tmOMgRqzIOWElBJ671hrSYYQEGOULKWgtSY9EcE59yhV60egVlFrxRgDc05ZZgkvc8cC773ImSeZCI8jIl8X8kU73OWc5ZWdt5dP+JhvP3FztwUAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"run\" title=\"\" src=\"/static/a6b6d88feee8d68f26ef15391da5fee7/c5bb3/run.png\" srcset=\"/static/a6b6d88feee8d68f26ef15391da5fee7/04472/run.png 170w,\n/static/a6b6d88feee8d68f26ef15391da5fee7/9f933/run.png 340w,\n/static/a6b6d88feee8d68f26ef15391da5fee7/c5bb3/run.png 680w,\n/static/a6b6d88feee8d68f26ef15391da5fee7/b12f7/run.png 1020w,\n/static/a6b6d88feee8d68f26ef15391da5fee7/b5a09/run.png 1360w,\n/static/a6b6d88feee8d68f26ef15391da5fee7/29007/run.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>You can attach to the running container with:</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 13.529411764705882%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAVklEQVR42pWMSQoAIQwEfYcbqDEjJJn/P07oUQ9z91AUNE05ev30Mc6U0ozLIYSfveWcr3CiDOYHrTWMMWBmUFWICIgI63SFI6onVko5Zmb03g97uw1+e4RR/xAz/+0AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"exec3\" title=\"\" src=\"/static/11830baec2d062e3922857eb418163db/c5bb3/exec3.png\" srcset=\"/static/11830baec2d062e3922857eb418163db/04472/exec3.png 170w,\n/static/11830baec2d062e3922857eb418163db/9f933/exec3.png 340w,\n/static/11830baec2d062e3922857eb418163db/c5bb3/exec3.png 680w,\n/static/11830baec2d062e3922857eb418163db/b12f7/exec3.png 1020w,\n/static/11830baec2d062e3922857eb418163db/b5a09/exec3.png 1360w,\n/static/11830baec2d062e3922857eb418163db/29007/exec3.png 1600w\" sizes=\"(max-width: 680px) 100vw, 680px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n          </p>\n<p>Absolutely! You can still connect to a running container, and you'll have a more compact image overall.</p>\n<p>However, there's an important consideration to keep in mind. Alpine-based images utilize muslc, an alternative C standard library. On the other hand, widely used Linux distributions like Ubuntu, Debian, and CentOS rely on glibc, which is more prevalent and faster.</p>\n<p>Both libraries aim to implement the same kernel interface but with different objectives. While glibc prioritizes widespread usage and performance, muslc focuses on minimal space consumption and enhanced security. When an application is compiled, it is typically linked to a specific libc. If you want to use it with another libc, recompilation is necessary.</p>\n<p>Consequently, building your containers with Alpine images might introduce unexpected behavior due to the variance in the standard C library. You might encounter discrepancies, especially when dealing with precompiled binaries such as Node.js C++ extensions. For instance, the prebuilt package for PhantomJS doesn't function correctly on Alpine.</p>\n<h3 id=\"-summary\" style=\"position:relative;\"><a href=\"#-summary\" aria-label=\" summary permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üìù Summary</h3>\n<p>‚û°Ô∏è In summary, the choice of base image for Docker containers depends on your priorities.</p>\n<ul>\n<li><strong>Distroless images</strong> prioritize security by reducing the attack surface area and minimizing the number of binaries.</li>\n<li><strong>Alpine-based images</strong> prioritize size optimization but may have compatibility issues due to the different C library.</li>\n<li><strong>Vanilla base images</strong> are suitable for testing and development, providing a familiar environment with access to a wide range of binaries.</li>\n</ul>\n<p>Consider your requirements for security, size, and development environment when selecting the appropriate base image for your Docker containers.</p>\n<h2 id=\"conclusion-\" style=\"position:relative;\"><a href=\"#conclusion-\" aria-label=\"conclusion  permalink\" class=\"anchor before\"><svg class=\"anchor-icon\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>üåüConclusion üåü</h2>\n<p>Optimizing Docker images is crucial for efficient deployment. Techniques such as layer squashing, using distroless images for enhanced security, and considering Alpine-based images for size reduction provide valuable tools to streamline containerization and improve overall performance.</p>\n<p><strong>Thank You üñ§</strong></p>\n<br>\n<p><strong><em>Until next time, „Å§„Å•„Åè üéâ</em></strong></p>\n<blockquote>\n<p>üí° Thank you for Reading !! üôåüèªüòÅüìÉ, see you in the next blog.ü§ò  <strong><em>Until next time üéâ</em></strong></p>\n</blockquote>\n<p>üöÄ Thank you for sticking up till the end. If you have any questions/feedback regarding this blog feel free to connect with me:</p>\n<p><strong>‚ôªÔ∏è LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/rajhi-saif/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.linkedin.com/in/rajhi-saif/</a></p>\n<p><strong>‚ôªÔ∏è X/Twitter:</strong> <a href=\"https://x.com/rajhisaifeddine\" target=\"_blank\" rel=\"noopener noreferrer\">https://x.com/rajhisaifeddine</a></p>\n<p><strong>The end ‚úåüèª</strong></p>\n<h1 align=\"center\">üî∞ Keep Learning !! Keep Sharing !! üî∞</h1>\n<p><strong>üìÖ Stay updated</strong></p>\n<p>Subscribe to our newsletter for more insights on AWS cloud computing and containers.</p>"}}},"staticQueryHashes":["1271460761","1321585977"],"slicesMap":{}}